{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVM and SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "# from sklearn.cross_validation import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, SVR, LinearSVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 4001, 1000))\n",
    "number_samples = [256, 512, 1024, 2048, 4096, 8192]\n",
    "# number_samples = [4096]\n",
    "C_vec = list(np.arange(0.1, 10, 0.5))\n",
    "max_pus_number, max_sus_number, num_sensors = 15, 1, 225\n",
    "IS_SENSORS = False\n",
    "DUMMY_LOC_VALUE, DUMMY_POWER_VALUE = -1, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "num_columns = (num_sensors if IS_SENSORS else max_pus_number * 3 + 1) + max_sus_number * 3 + 2\n",
    "cols = [i for i in range(num_columns)]\n",
    "dataframe = pd.read_csv('../../../java_workspace/research/spectrum_allocation/resources/data/' +\n",
    "                        'dynamic_pus_using_pus_60000_15PUs_1SUs_square100grid_splat_2020_06_17_21_46.txt', \n",
    "                        delimiter=',', header=None, names=cols)\n",
    "dataframe_max = pd.read_csv('../../../java_workspace/research/spectrum_allocation/resources/data/' +\n",
    "                            'dynamic_pus_max_power_60000_15PUs_1SUs_square100grid_splat_2020_06_17_21_46.txt', delimiter=',', header=None)\n",
    "\n",
    "dataframe.reset_index(drop=True, inplace=True)\n",
    "dataframe_max.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dataframe_tot = pd.concat([dataframe, dataframe_max.iloc[:, dataframe_max.columns.values[-1]]], axis=1,\n",
    "                        ignore_index=True)\n",
    "idx = dataframe_tot[dataframe_tot[dataframe_tot.columns[-1]] == -float('inf')].index\n",
    "dataframe_tot.drop(idx, inplace=True)\n",
    "\n",
    "data_reg = np.concatenate((dataframe_tot.values[:, 0:dataframe_tot.shape[1]-3], \n",
    "                           dataframe_tot.values[:, dataframe_tot.shape[1]-1:dataframe_tot.shape[1]]), axis=1)\n",
    "data_reg[data_reg < -90.0] = -90.0\n",
    "data_class = dataframe_tot.values[:, 0:dataframe_tot.shape[1]-1]\n",
    "y_class_power = dataframe_tot.values[:, -1]\n",
    "del dataframe, dataframe_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.   , 51.   , 15.   , ..., 39.   , 60.   ,  8.127],\n",
       "       [15.   , 91.   , 15.   , ..., 18.   ,  7.   , -3.86 ],\n",
       "       [15.   ,  6.   , 46.   , ...,  6.   , 42.   ,  3.581],\n",
       "       ...,\n",
       "       [15.   , 21.   , 54.   , ..., 80.   , 49.   ,  2.292],\n",
       "       [15.   , 98.   , 23.   , ...,  1.   , 52.   , 21.347],\n",
       "       [15.   , 31.   , 79.   , ..., 87.   , 23.   , 10.367]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "# def split_data(data, train_samples):\n",
    "#     num_inputs = data.shape[1] - 1\n",
    "#     val_samples = round(train_samples/3)\n",
    "#     X_train, y_train = data[0:train_samples, 0: num_inputs], data[0:train_samples, -1]\n",
    "#     X_val, y_val = data[train_samples:train_samples+val_samples, 0: num_inputs],data[train_samples:train_samples+val_samples, -1]\n",
    "#     X_test, y_test = data[train_samples:, 0: num_inputs], data[train_samples:, -1]\n",
    "#     return X_train,X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def split_data(data: np.ndarray, train_samples):\n",
    "    num_inputs = (max_sus_number - 1) * 3 + 2 + (max_pus_number * 3 \n",
    "                                                 if not IS_SENSORS else num_sensors)\n",
    "    val_samples = round(train_samples/3)\n",
    "    test_samples = data.shape[0] - val_samples - train_samples\n",
    "    #init arrays\n",
    "    X_train = np.ones((train_samples, num_inputs), dtype=float) * DUMMY_LOC_VALUE\n",
    "    X_val = np.ones((val_samples, num_inputs), dtype=float) * DUMMY_LOC_VALUE\n",
    "    X_test = np.ones((test_samples, num_inputs), dtype=float) * DUMMY_LOC_VALUE\n",
    "    # read values\n",
    "    if not IS_SENSORS:\n",
    "        # fill train\n",
    "        for train_sample in range(train_samples):\n",
    "            num_pus = int(data[train_sample, 0])\n",
    "            num_sus = int(data[train_sample, 1 + num_pus * 3])\n",
    "            X_train[train_sample, :num_pus * 3] = data[train_sample, 1:1 + num_pus * 3]#pus\n",
    "            #sus except power of last su\n",
    "            X_train[train_sample, max_pus_number * 3: (max_pus_number + num_sus) * 3 \n",
    "                    - 1] = data[train_sample, 2 + num_pus * 3: \n",
    "                                1 + (num_pus + num_sus) * 3]\n",
    "        # fill validation\n",
    "        for val_sample in range(train_samples, train_samples + val_samples):\n",
    "            num_pus = int(data[val_sample, 0])\n",
    "            num_sus = int(data[val_sample, 1 + num_pus * 3])\n",
    "            X_val[val_sample - train_samples, :num_pus * 3] = data[val_sample, 1:1 + num_pus * 3]\n",
    "            X_val[val_sample - train_samples, max_pus_number * 3: \n",
    "                  (max_pus_number + num_sus) * 3 - 1] = data[val_sample, 2 + num_pus * 3:\n",
    "                                                             1 + (num_pus + num_sus) * 3]\n",
    "        # fill test\n",
    "        for test_sample in range(train_samples + val_samples, \n",
    "                                 train_samples + val_samples + test_samples):\n",
    "            num_pus = int(data[test_sample, 0])\n",
    "            num_sus = int(data[test_sample, 1 + num_pus * 3])\n",
    "            X_test[test_sample - (train_samples + val_samples), :num_pus * 3] = data[\n",
    "                test_sample, 1:1 + num_pus * 3]\n",
    "            X_test[test_sample - (train_samples + val_samples), max_pus_number * 3:\n",
    "                   (max_pus_number + num_sus) * 3 - 1] = data[test_sample, 2 + num_pus * 3:\n",
    "                                                              1 + (num_pus + num_sus) * 3]\n",
    "    else:\n",
    "        # read sensors\n",
    "        X_train[:, :num_sensors] = data[:train_samples, :num_sensors]\n",
    "        X_val[:, :num_sensors] = data[train_samples: train_samples + val_samples,\n",
    "                                         :num_sensors]\n",
    "        X_test[:, :num_sensors] = data[train_samples + val_samples : , :num_sensors]\n",
    "        #read sus\n",
    "        for train_sample in range(train_samples):\n",
    "            num_sus = int(data[train_sample, num_sensors])\n",
    "            X_train[train_sample, num_sensors + 1: num_sensors + num_sus * 3] = data[\n",
    "                train_sample, num_sensors + 1:num_sensors + num_sus * 3]\n",
    "            \n",
    "        for val_sample in range(train_samples, train_samples + val_samples):\n",
    "            num_sus = int(data[val_sample, num_sensors])\n",
    "            X_val[val_sample - train_samples, num_sensors + 1: num_sensors + num_sus * 3] = data[\n",
    "                val_sample, num_sensors + 1:num_sensors + num_sus * 3]\n",
    "            \n",
    "        for test_sample in range(train_samples + val_samples, \n",
    "                                 train_samples + val_samples + test_samples):\n",
    "            num_sus = int(data[test_sample, num_sensors])\n",
    "            X_test[test_sample - (train_samples + val_samples), num_sensors + 1:\n",
    "                   num_sensors + num_sus * 3] = data[test_sample, num_sensors + 1:num_sensors + num_sus * 3]\n",
    "\n",
    "    \n",
    "    y_train = data[0 : train_samples, -1]\n",
    "    y_val = data[train_samples : train_samples + val_samples, -1]\n",
    "    y_test = data[train_samples + val_samples:, -1]\n",
    "    return X_train,X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "def false_analysis(y_test, y_pred):\n",
    "    tp = sum(y_pred[y_test==1])\n",
    "    fp = sum(y_pred) - tp\n",
    "    return fp, sum(y_test) - tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 15.     51.     15.     -3.758  71.     90.    -10.665  19.     22.\n",
      " -20.781  32.     77.    -20.519   0.     60.     -6.948  23.      7.\n",
      "  -7.9    43.     33.    -21.315  28.     74.    -16.492  11.     98.\n",
      " -17.556  58.     65.    -13.686  89.     73.     -9.114   4.     30.\n",
      " -15.266  16.     62.    -14.142  52.     24.    -17.158  23.     37.\n",
      " -23.546   1.     39.     60.      8.127]\n",
      "[ 51.     15.     -3.758  71.     90.    -10.665  19.     22.    -20.781\n",
      "  32.     77.    -20.519   0.     60.     -6.948  23.      7.     -7.9\n",
      "  43.     33.    -21.315  28.     74.    -16.492  11.     98.    -17.556\n",
      "  58.     65.    -13.686  89.     73.     -9.114   4.     30.    -15.266\n",
      "  16.     62.    -14.142  52.     24.    -17.158  23.     37.    -23.546\n",
      "  39.     60.   ]\n",
      "8.127\n",
      "***\n",
      "[ 15.     32.     44.     -7.992  16.      2.    -11.236  59.     49.\n",
      " -10.14   85.     72.     -8.34   32.     99.    -15.521  14.     69.\n",
      " -16.729  88.     60.     -1.609  50.      8.    -28.241  21.     75.\n",
      " -20.519  84.     80.    -29.441  29.      1.    -26.88   46.     50.\n",
      " -15.44   50.     59.     -1.302  53.     37.    -17.556  59.     55.\n",
      " -10.907   1.     14.     16.      5.944]\n",
      "[ 32.     44.     -7.992  16.      2.    -11.236  59.     49.    -10.14\n",
      "  85.     72.     -8.34   32.     99.    -15.521  14.     69.    -16.729\n",
      "  88.     60.     -1.609  50.      8.    -28.241  21.     75.    -20.519\n",
      "  84.     80.    -29.441  29.      1.    -26.88   46.     50.    -15.44\n",
      "  50.     59.     -1.302  53.     37.    -17.556  59.     55.    -10.907\n",
      "  14.     16.   ]\n",
      "5.944\n",
      "***\n",
      "[ 15.     20.     10.    -25.102  50.     59.    -20.661  25.     50.\n",
      "  -3.55   76.     22.    -19.152   2.     74.     -2.785  67.      0.\n",
      " -21.119  50.     43.     -2.11   45.     16.    -19.572  15.     41.\n",
      " -22.106  39.     95.    -11.991  10.     44.    -27.123  14.     24.\n",
      " -10.008  33.      8.    -17.616  98.     59.    -22.352  42.     98.\n",
      "  -9.273   1.     46.     52.      0.985]\n",
      "[ 20.     10.    -25.102  50.     59.    -20.661  25.     50.     -3.55\n",
      "  76.     22.    -19.152   2.     74.     -2.785  67.      0.    -21.119\n",
      "  50.     43.     -2.11   45.     16.    -19.572  15.     41.    -22.106\n",
      "  39.     95.    -11.991  10.     44.    -27.123  14.     24.    -10.008\n",
      "  33.      8.    -17.616  98.     59.    -22.352  42.     98.     -9.273\n",
      "  46.     52.   ]\n",
      "0.985\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(data_reg, 256)\n",
    "print(data_reg[0])\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(\"***\")\n",
    "print(data_reg[256])\n",
    "print(X_val[0])\n",
    "print(y_val[0])\n",
    "print(\"***\")\n",
    "print(data_reg[256+85])\n",
    "print(X_test[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-16.501,  87.   ,  52.   , ...,  10.   ,  34.   , -21.746],\n",
       "       [ -4.746,  74.   ,  71.   , ...,     nan,     nan,   5.038],\n",
       "       [-22.775,  97.   ,  57.   , ...,   0.   ,     nan,   2.342],\n",
       "       ...,\n",
       "       [ -2.106,   1.   ,  62.   , ...,     nan,     nan,  16.766],\n",
       "       [-26.324,  77.   ,   2.   , ...,  71.   ,  10.   ,   7.17 ],\n",
       "       [-23.057,   5.   ,  82.   , ...,     nan,     nan,  14.104]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## SVM(SVC)\n",
    "average_class_diff_power = []\n",
    "fp_mean_power = []\n",
    "accuracy, f_score, false_positive, false_negative = [], [], [], []\n",
    "best_c_lst = []\n",
    "fp_penalty_coef, fn_penalty_coef = 1, 1\n",
    "metric = \"fp_min\"  # {\"accuracy\", \"fp_min\"}\n",
    "class_weight = {0:fp_penalty_coef/(fp_penalty_coef + fn_penalty_coef), 1:fn_penalty_coef/(fp_penalty_coef + fn_penalty_coef)}\n",
    "best_c, bestsvcclassifier = None, None\n",
    "for number_sample in number_samples:\n",
    "    best_accuracy = -float('inf')\n",
    "    best_fp = float('inf')\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(data_class, number_sample)\n",
    "    scaler_x = StandardScaler()\n",
    "    scaler_x.fit(X_train)\n",
    "    X_train = scaler_x.transform(X_train)\n",
    "    X_val = scaler_x.transform(X_val)\n",
    "    for c in C_vec:\n",
    "        svclassifier = SVC(kernel='rbf', C=c, class_weight = class_weight)\n",
    "        svclassifier.fit(X_train, y_train)\n",
    "        \n",
    "        #validating\n",
    "        y_pred_val = svclassifier.predict(X_val)\n",
    "        if metric == \"accuracy\":\n",
    "            accuracy_tmp = metrics.accuracy_score(y_val, y_pred_val)\n",
    "            if accuracy_tmp > best_accuracy:\n",
    "                best_accuracy = accuracy_tmp\n",
    "                best_c = c\n",
    "                bestsvcclassifier = svclassifier\n",
    "        elif metric == \"fp_min\":\n",
    "            conf_mat = metrics.confusion_matrix(y_val, y_pred_val)\n",
    "            fp_tmp = conf_mat[0][1] if len(conf_mat) == 2 else 0\n",
    "            if fp_tmp < best_fp:\n",
    "                best_fp = fp_tmp\n",
    "                best_c = c\n",
    "                bestsvcclassifier = svclassifier\n",
    "                    \n",
    "            \n",
    "    best_c_lst.append(best_c)\n",
    "    #predicting\n",
    "    X_test = scaler_x.transform(X_test)\n",
    "    y_pred = bestsvcclassifier.predict(X_test)\n",
    "    \n",
    "    #evaluating\n",
    "    accuracy.append(round(metrics.accuracy_score(y_test, y_pred), 3))\n",
    "    f_score.append(round(metrics.f1_score(y_true=y_test, y_pred=y_pred), 3))\n",
    "    fp, fn = false_analysis(y_test, y_pred)\n",
    "    false_positive.append(int(fp))\n",
    "    false_negative.append(int(fn))\n",
    "    \n",
    "    #Power max calculations\n",
    "    y_class_power_test = y_class_power[len(y_class_power)-X_test.shape[0]:]\n",
    "    y_class_power_pred = np.zeros(y_class_power_test.size)\n",
    "    max_power = max(y_class_power_test) + 10  # 10 is added to increase higher bound\n",
    "    min_power = min(y_class_power_test) - 10  # 10 is subtracted to decrease lower bound\n",
    "    for i in range(len(y_class_power_test)):\n",
    "        h = max_power\n",
    "        l = min_power\n",
    "        while h - l > 0.5:\n",
    "            mid = l + (h - l)/2;\n",
    "            mid_norm = (mid - scaler_x.mean_[-1])/scaler_x.scale_[-1]\n",
    "            X_test[i][-1] = mid_norm\n",
    "            res_tmp = bestsvcclassifier.predict(X_test[i:i+1])\n",
    "            if res_tmp[0]:\n",
    "                l = mid\n",
    "            else:\n",
    "                h = mid\n",
    "        y_class_power_pred[i] = l + (h - l)/2\n",
    "    average_class_diff_power.append(round(np.mean(np.absolute(y_class_power_pred - y_class_power_test)), 3))\n",
    "    fp_samples = np.zeros(len(y_class_power_pred), dtype=float)\n",
    "    fp_samples[y_class_power_pred > y_class_power_test] = (y_class_power_pred - y_class_power_test)[y_class_power_pred > \n",
    "                                                                                                    y_class_power_test]\n",
    "    fp_mean_power.append(round(np.mean(fp_samples), 3))\n",
    "    print('Number_samples:', number_sample, ', accuracy:', accuracy[-1], ', f_score:', f_score[-1], \n",
    "          ', fp:', fp,', fn:', fn, ', error:', average_class_diff_power[-1], 'fp_error:', fp_mean_power[-1])\n",
    "del svclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_class_diff_power)\n",
    "print(fp_mean_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAX_POWER ANAlysis\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, accuracy)\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('%')\n",
    "plt.title('SVM: Classification Accuracy(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_svmAcc.png')\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, f_score)\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('%')\n",
    "plt.title('SVM: Classification F_score(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_svmfscore.png')\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, false_positive)\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('#')\n",
    "plt.title('SVM: Classification FP(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_svmfp.png')\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, false_negative)\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('#')\n",
    "plt.title('SVM: Classification FN(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_svmfn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number_samples:  256  error:  6.83 , fp_error: 3.796\n",
      "Number_samples:  512  error:  6.782 , fp_error: 3.738\n",
      "Number_samples:  1024  error:  6.731 , fp_error: 3.5\n",
      "Number_samples:  2048  error:  6.696 , fp_error: 3.455\n",
      "Number_samples:  4096  error:  6.601 , fp_error: 3.358\n",
      "Number_samples:  8192  error:  6.479 , fp_error: 3.293\n"
     ]
    }
   ],
   "source": [
    "# SVR\n",
    "average_reg_diff_power, best_c_reg_lst, fp_mean_power = [], [], []\n",
    "best_c_reg, bestsvrclassifier =  None, None\n",
    "# TODO: Having different penalties for fp and fn\n",
    "for number_sample in number_samples:\n",
    "    min_err = float('inf')\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(data_reg, number_sample)\n",
    "    scaler_x = StandardScaler()\n",
    "    scaler_x.fit(X_train)\n",
    "    X_train = scaler_x.transform(X_train)\n",
    "    X_val = scaler_x.transform(X_val)\n",
    "    for c in C_vec:\n",
    "        svrlassifier = SVR(kernel='rbf', C=c, degree=X_train.shape[1]+1)\n",
    "        svrlassifier.fit(X_train, y_train)\n",
    "        \n",
    "        #validating\n",
    "        y_pred_val = svrlassifier.predict(X_val)\n",
    "        err_tmp = np.mean(np.absolute(y_pred_val - y_val))\n",
    "        if err_tmp < min_err:\n",
    "            min_err = err_tmp\n",
    "            best_c_reg = c\n",
    "            bestsvrclassifier = svrlassifier\n",
    "            \n",
    "    best_c_reg_lst.append(best_c_reg)\n",
    "    #predicting\n",
    "    X_test = scaler_x.transform(X_test)\n",
    "    y_pred = bestsvrclassifier.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #evaluating\n",
    "    average_reg_diff_power.append(round(np.mean(np.absolute(y_test - y_pred)), 3))\n",
    "    fp_samples = np.zeros(len(y_test), dtype=float)\n",
    "    fp_samples[y_pred > y_test] = (y_pred - y_test)[y_pred > y_test]\n",
    "    fp_mean_power.append(round(np.mean(fp_samples), 3))\n",
    "    print('Number_samples: ', number_sample, ' error: ', average_reg_diff_power[-1], \n",
    "          ', fp_error:', fp_mean_power[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVR\n",
    "average_reg_diff_power, best_c_reg_lst, fp_mean_power = [], [], []\n",
    "best_c_reg, bestsvrclassifier =  None, None\n",
    "for number_sample in number_samples:\n",
    "    min_err = float('inf')\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(data_reg, number_sample)\n",
    "    scaler_x = StandardScaler()\n",
    "    scaler_x.fit(X_train)\n",
    "    X_train = scaler_x.transform(X_train)\n",
    "    X_val = scaler_x.transform(X_val)\n",
    "    for c in C_vec:\n",
    "        svrlassifier = LinearSVR(C=c, loss='epsilon_insensitive')\n",
    "        svrlassifier.fit(X_train, y_train)\n",
    "        \n",
    "        #validating\n",
    "        y_pred_val = svrlassifier.predict(X_val)\n",
    "        err_tmp = np.mean(np.absolute(y_pred_val - y_val))\n",
    "        if err_tmp < min_err:\n",
    "            min_err = err_tmp\n",
    "            best_c_reg = c\n",
    "            bestsvrclassifier = svrlassifier\n",
    "            \n",
    "    best_c_reg_lst.append(best_c_reg)\n",
    "    #predicting\n",
    "    X_test = scaler_x.transform(X_test)\n",
    "    y_pred = bestsvrclassifier.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #evaluating\n",
    "    average_reg_diff_power.append(round(np.mean(np.absolute(y_test - y_pred)), 3))\n",
    "    fp_samples = np.zeros(len(y_test), dtype=float)\n",
    "    fp_samples[y_pred > y_test] = (y_pred - y_test)[y_pred > y_test]\n",
    "    fp_mean_power.append(round(np.mean(fp_samples), 3))\n",
    "    print('Number_samples: ', number_sample, ' error: ', average_reg_diff_power[-1], ', fp_error:', fp_mean_power[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.905, 6.867, 6.803, 6.769, 6.728, 6.607]\n",
      "[3.3, 3.223, 3.399, 3.284, 3.185, 3.195]\n"
     ]
    }
   ],
   "source": [
    "print(average_reg_diff_power)\n",
    "print(fp_mean_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, average_class_diff_power)\n",
    "plt.plot(number_samples, average_reg_diff_power, 'r--')\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('Diff(dB)')\n",
    "plt.title('Average absolute difference power(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "\n",
    "ax.set_yticks(np.arange(0,20, 2))\n",
    "ax.set_ylim([2,20])\n",
    "ax.set_xticks(np.arange(5,4100, 500))\n",
    "# plt.grid(which='minor')\n",
    "# plt.text(40, 50, '# Validation = 34k')\n",
    "# plt.text(400, 45, '# Test = 34k')\n",
    "plt.legend(['SVM', 'SVR'])\n",
    "plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_averag_powerSVMSVR.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_reg_diff_power_tot = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(number_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_reg_diff_power_tot.append(average_reg_diff_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_samples = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150, 200, 250, 300, 400, 500, 700, 1000, 2000, 3000, 4000]\n",
    "average_reg_diff_power_tot = [[4.91, 4.915, 5.02, 7.274, 5.21, 5.476, 5.547, 5.448, 5.358, 5.486, 5.424, 5.585, 5.423, 5.369,\n",
    "                               5.275, 5.22, 5.065, 5.058, 4.915, 4.873, 4.8, 4.787, 4.782], \n",
    "                              [4.739, 4.728, 4.858, 4.9, 4.761, 4.835, 4.898, 4.959, 4.806, 4.913, 4.945, 4.88, 4.8, 4.812,\n",
    "                               4.756, 4.74, 4.764, 4.832, 4.729, 4.745, 4.728, 4.728, 4.731], \n",
    "                              [5.59, 5.33, 4.764, 4.731, 4.728, 4.923, 5.086, 4.798, 4.816, 5.035, 4.827, 4.842, 4.757, 4.796,\n",
    "                               4.734, 4.748, 4.74, 4.734, 4.728, 4.729, 4.726, 4.726, 4.728], \n",
    "                              [4.791, 4.781, 4.732, 5.677, 4.757, 4.837, 4.841, 5.242, 4.81, 4.955, 4.972, 5.106, 4.801, 4.754,\n",
    "                               4.764, 4.748, 4.757, 4.763, 4.737, 4.735, 4.737, 4.74, 4.744]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, average_reg_diff_power_tot[0])\n",
    "plt.plot(number_samples, average_reg_diff_power_tot[1], 'r--')\n",
    "plt.plot(number_samples, average_reg_diff_power_tot[2], 'g.-')\n",
    "plt.plot(number_samples, average_reg_diff_power_tot[3], 'y->')\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('Diff(dB)')\n",
    "plt.title('Average absolute difference power(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "\n",
    "ax.set_yticks(np.arange(0,8, 2))\n",
    "ax.set_ylim([2,8])\n",
    "ax.set_xticks(np.arange(5,4100, 500))\n",
    "# plt.grid(which='minor')\n",
    "# plt.text(40, 50, '# Validation = 34k')\n",
    "# plt.text(400, 45, '# Test = 34k')\n",
    "plt.legend(['linear', 'rbf', 'poly', 'sigmoid'])\n",
    "# plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_averag_powerSVMSVR.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
