{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVM and SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shahrokh/anaconda3/envs/research/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "# from sklearn.cross_validation import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, SVR, LinearSVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "dataframe = pd.read_csv('ML/data/dynamic_pus_sensors_50000_10PUs100_100sensors_200grid_splat_202001_3100_42.txt', delimiter=',', header=None)\n",
    "dataframe_max = pd.read_csv('ML/data/dynamic_pus_max_power50000_10PUs_200grid_splat_202001_3100_42.txt', delimiter=',', header=None)\n",
    "\n",
    "dataframe.reset_index(drop=True, inplace=True)\n",
    "dataframe_max.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dataframe_tot = pd.concat([dataframe, dataframe_max.iloc[:, dataframe_max.columns.values[-1]]], axis=1,\n",
    "                        ignore_index=True)\n",
    "idx = dataframe_tot[dataframe_tot[dataframe_tot.columns[-1]] == -float('inf')].index\n",
    "dataframe_tot.drop(idx, inplace=True)\n",
    "\n",
    "data_reg = np.concatenate((dataframe_tot.values[:, 0:dataframe_tot.shape[1]-3], \n",
    "                           dataframe_tot.values[:, dataframe_tot.shape[1]-1:dataframe_tot.shape[1]]), axis=1)\n",
    "data_class = dataframe_tot.values[:, 0:dataframe_tot.shape[1]-1]\n",
    "y_class_power = dataframe_tot.values[:, -1]\n",
    "del dataframe, dataframe_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 4001, 1000))\n",
    "number_samples = [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 4001, 1000))\n",
    "# number_samples = [6000, 8000, 10000, 12000]\n",
    "C_vec = list(np.arange(0.1, 10, 0.5))\n",
    "noise_floor = -90.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "def split_data(data, train_samples):\n",
    "    num_inputs = data.shape[1] - 1\n",
    "    val_samples = round(train_samples/3)\n",
    "    X_train, y_train = data[0:train_samples, 0: num_inputs], data[0:train_samples, -1]\n",
    "    X_val, y_val = data[train_samples:train_samples+val_samples, 0: num_inputs],data[train_samples:train_samples+val_samples, -1]\n",
    "    X_test, y_test = data[train_samples:, 0: num_inputs], data[train_samples:, -1]\n",
    "    return X_train,X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def false_analysis(y_test, y_pred):\n",
    "    tp = sum(y_pred[y_test==1])\n",
    "    fp = sum(y_pred) - tp\n",
    "    return fp, sum(y_test) - tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36249, 103)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM(SVC)\n",
    "average_class_diff_power = []\n",
    "fp_mean_power = []\n",
    "accuracy, f_score, false_positive, false_negative = [], [], [], []\n",
    "best_c_lst = []\n",
    "fp_penalty_coef, fn_penalty_coef = 1, 1\n",
    "metric = \"accuracy\"  # {\"accuracy\", \"fp_min\"}\n",
    "class_weight = {0:fp_penalty_coef/(fp_penalty_coef + fn_penalty_coef), 1:fn_penalty_coef/(fp_penalty_coef + fn_penalty_coef)}\n",
    "best_c, bestsvcclassifier = None, None\n",
    "for number_sample in number_samples:\n",
    "    best_accuracy = -float('inf')\n",
    "    best_fp = float('inf')\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(data_class, number_sample)\n",
    "    scaler_x = StandardScaler()\n",
    "    scaler_x.fit(X_train)\n",
    "    X_train = scaler_x.transform(X_train)\n",
    "    X_val = scaler_x.transform(X_val)\n",
    "    for c in C_vec:\n",
    "        svclassifier = SVC(kernel='rbf', C=c, class_weight = class_weight)\n",
    "        svclassifier.fit(X_train, y_train)\n",
    "        \n",
    "        #validating\n",
    "        y_pred_val = svclassifier.predict(X_val)\n",
    "        if metric == \"accuracy\":\n",
    "            accuracy_tmp = metrics.accuracy_score(y_val, y_pred_val)\n",
    "            if accuracy_tmp > best_accuracy:\n",
    "                best_accuracy = accuracy_tmp\n",
    "                best_c = c\n",
    "                bestsvcclassifier = svclassifier\n",
    "        elif metric == \"fp_min\":\n",
    "            conf_mat = metrics.confusion_matrix(y_val, y_pred_val)\n",
    "            fp_tmp = conf_mat[0][1] if len(conf_mat) == 2 else 0\n",
    "            if fp_tmp < best_fp:\n",
    "                best_fp = fp_tmp\n",
    "                best_c = c\n",
    "                bestsvcclassifier = svclassifier\n",
    "                    \n",
    "            \n",
    "    best_c_lst.append(best_c)\n",
    "    #predicting\n",
    "    X_test = scaler_x.transform(X_test)\n",
    "    y_pred = bestsvcclassifier.predict(X_test)\n",
    "    \n",
    "    #evaluating\n",
    "    accuracy.append(round(metrics.accuracy_score(y_test, y_pred), 3))\n",
    "    f_score.append(round(metrics.f1_score(y_true=y_test, y_pred=y_pred), 3))\n",
    "    fp, fn = false_analysis(y_test, y_pred)\n",
    "    false_positive.append(int(fp))\n",
    "    false_negative.append(int(fn))\n",
    "    \n",
    "    #Power max calculations\n",
    "    y_class_power_test = y_class_power[len(y_class_power)-X_test.shape[0]:]\n",
    "    y_class_power_pred = np.zeros(y_class_power_test.size)\n",
    "    max_power = max(y_class_power_test) + 10  # 10 is added to increase higher bound\n",
    "    min_power = min(y_class_power_test) - 10  # 10 is subtracted to decrease lower bound\n",
    "    for i in range(len(y_class_power_test)):\n",
    "        h = max_power\n",
    "        l = min_power\n",
    "        while h - l > 0.5:\n",
    "            mid = l + (h - l)/2;\n",
    "            mid_norm = (mid - scaler_x.mean_[-1])/scaler_x.scale_[-1]\n",
    "            X_test[i][-1] = mid_norm\n",
    "            res_tmp = bestsvcclassifier.predict(X_test[i:i+1])\n",
    "            if res_tmp[0]:\n",
    "                l = mid\n",
    "            else:\n",
    "                h = mid\n",
    "        y_class_power_pred[i] = l + (h - l)/2\n",
    "    average_class_diff_power.append(round(np.mean(np.absolute(y_class_power_pred - y_class_power_test)), 3))\n",
    "    fp_samples = np.zeros(len(y_class_power_pred), dtype=float)\n",
    "    fp_samples[y_class_power_pred > y_class_power_test] = (y_class_power_pred - y_class_power_test)[y_class_power_pred > \n",
    "                                                                                                    y_class_power_test]\n",
    "    fp_mean_power.append(round(np.mean(fp_samples), 3))\n",
    "    print('Number_samples:', number_sample, ', accuracy:', accuracy[-1], ', f_score:', f_score[-1], \n",
    "          ', fp:', fp,', fn:', fn, ', error:', average_class_diff_power[-1], 'fp_error:', fp_mean_power[-1])\n",
    "del svclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_class_diff_power)\n",
    "print(fp_mean_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAX_POWER ANAlysis\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, accuracy)\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('%')\n",
    "plt.title('SVM: Classification Accuracy(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_svmAcc.png')\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, f_score)\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('%')\n",
    "plt.title('SVM: Classification F_score(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_svmfscore.png')\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, false_positive)\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('#')\n",
    "plt.title('SVM: Classification FP(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_svmfp.png')\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, false_negative)\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('#')\n",
    "plt.title('SVM: Classification FN(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_svmfn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg[:,-1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number_samples:  120  error:  6.022 , fp_error: 4.028\n",
      "Number_samples:  150  error:  6.047 , fp_error: 3.936\n",
      "Number_samples:  200  error:  6.025 , fp_error: 3.663\n",
      "Number_samples:  250  error:  6.025 , fp_error: 3.867\n",
      "Number_samples:  300  error:  6.048 , fp_error: 4.03\n",
      "Number_samples:  400  error:  6.014 , fp_error: 3.834\n",
      "Number_samples:  500  error:  6.009 , fp_error: 3.809\n",
      "Number_samples:  700  error:  5.987 , fp_error: 3.635\n",
      "Number_samples:  1000  error:  5.991 , fp_error: 3.619\n",
      "Number_samples:  2000  error:  5.98 , fp_error: 3.684\n",
      "Number_samples:  3000  error:  5.977 , fp_error: 3.74\n",
      "Number_samples:  4000  error:  5.967 , fp_error: 3.76\n"
     ]
    }
   ],
   "source": [
    "# SVR\n",
    "average_reg_diff_power, best_c_reg_lst, fp_mean_power = [], [], []\n",
    "best_c_reg, bestsvrclassifier =  None, None\n",
    "# data_reg[data_reg < noise_floor] = noise_floor\n",
    "# TODO: Having different penalties for fp and fn\n",
    "for number_sample in number_samples:\n",
    "    min_err = float('inf')\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(data_reg, number_sample)\n",
    "    X_train[X_train < noise_floor] = noise_floor\n",
    "    X_val[X_val < noise_floor] = noise_floor\n",
    "    X_test[X_test < noise_floor] = noise_floor\n",
    "    scaler_x = StandardScaler()\n",
    "    scaler_x.fit(X_train)\n",
    "    X_train = scaler_x.transform(X_train)\n",
    "    X_val = scaler_x.transform(X_val)\n",
    "    for c in C_vec:\n",
    "        svrlassifier = SVR(kernel='rbf', C=c, degree=X_train.shape[1]+1)\n",
    "        svrlassifier.fit(X_train, y_train)\n",
    "        \n",
    "        #validating\n",
    "        y_pred_val = svrlassifier.predict(X_val)\n",
    "        err_tmp = np.mean(np.absolute(y_pred_val - y_val))\n",
    "        if err_tmp < min_err:\n",
    "            min_err = err_tmp\n",
    "            best_c_reg = c\n",
    "            bestsvrclassifier = svrlassifier\n",
    "            \n",
    "    best_c_reg_lst.append(best_c_reg)\n",
    "    #predicting\n",
    "    X_test = scaler_x.transform(X_test)\n",
    "    y_pred = bestsvrclassifier.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #evaluating\n",
    "    average_reg_diff_power.append(round(np.mean(np.absolute(y_test - y_pred)), 3))\n",
    "    fp_samples = np.zeros(len(y_test), dtype=float)\n",
    "    fp_samples[y_pred > y_test] = (y_pred - y_test)[y_pred > y_test]\n",
    "    fp_mean_power.append(round(np.mean(fp_samples), 3))\n",
    "    print('Number_samples: ', number_sample, ' error: ', average_reg_diff_power[-1], ', fp_error:', fp_mean_power[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVR\n",
    "average_reg_diff_power, best_c_reg_lst, fp_mean_power = [], [], []\n",
    "best_c_reg, bestsvrclassifier =  None, None\n",
    "for number_sample in number_samples:\n",
    "    min_err = float('inf')\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(data_reg, number_sample)\n",
    "    scaler_x = StandardScaler()\n",
    "    scaler_x.fit(X_train)\n",
    "    X_train = scaler_x.transform(X_train)\n",
    "    X_val = scaler_x.transform(X_val)\n",
    "    for c in C_vec:\n",
    "        svrlassifier = LinearSVR(C=c, loss='epsilon_insensitive')\n",
    "        svrlassifier.fit(X_train, y_train)\n",
    "        \n",
    "        #validating\n",
    "        y_pred_val = svrlassifier.predict(X_val)\n",
    "        err_tmp = np.mean(np.absolute(y_pred_val - y_val))\n",
    "        if err_tmp < min_err:\n",
    "            min_err = err_tmp\n",
    "            best_c_reg = c\n",
    "            bestsvrclassifier = svrlassifier\n",
    "            \n",
    "    best_c_reg_lst.append(best_c_reg)\n",
    "    #predicting\n",
    "    X_test = scaler_x.transform(X_test)\n",
    "    y_pred = bestsvrclassifier.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #evaluating\n",
    "    average_reg_diff_power.append(round(np.mean(np.absolute(y_test - y_pred)), 3))\n",
    "    fp_samples = np.zeros(len(y_test), dtype=float)\n",
    "    fp_samples[y_pred > y_test] = (y_pred - y_test)[y_pred > y_test]\n",
    "    fp_mean_power.append(round(np.mean(fp_samples), 3))\n",
    "    print('Number_samples: ', number_sample, ' error: ', average_reg_diff_power[-1], ', fp_error:', fp_mean_power[-1], \n",
    "          'best_c: ', best_c_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.615, 5.589, 5.579, 5.574]\n",
      "[3.64, 3.635, 3.661, 3.629]\n"
     ]
    }
   ],
   "source": [
    "print(average_reg_diff_power)\n",
    "print(fp_mean_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, average_class_diff_power)\n",
    "plt.plot(number_samples, average_reg_diff_power, 'r--')\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('Diff(dB)')\n",
    "plt.title('Average absolute difference power(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "\n",
    "ax.set_yticks(np.arange(0,20, 2))\n",
    "ax.set_ylim([2,20])\n",
    "ax.set_xticks(np.arange(5,4100, 500))\n",
    "# plt.grid(which='minor')\n",
    "# plt.text(40, 50, '# Validation = 34k')\n",
    "# plt.text(400, 45, '# Test = 34k')\n",
    "plt.legend(['SVM', 'SVR'])\n",
    "plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_averag_powerSVMSVR.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_reg_diff_power_tot = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(number_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_reg_diff_power_tot.append(average_reg_diff_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_samples = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150, 200, 250, 300, 400, 500, 700, 1000, 2000, 3000, 4000]\n",
    "average_reg_diff_power_tot = [[4.91, 4.915, 5.02, 7.274, 5.21, 5.476, 5.547, 5.448, 5.358, 5.486, 5.424, 5.585, 5.423, 5.369,\n",
    "                               5.275, 5.22, 5.065, 5.058, 4.915, 4.873, 4.8, 4.787, 4.782], \n",
    "                              [4.739, 4.728, 4.858, 4.9, 4.761, 4.835, 4.898, 4.959, 4.806, 4.913, 4.945, 4.88, 4.8, 4.812,\n",
    "                               4.756, 4.74, 4.764, 4.832, 4.729, 4.745, 4.728, 4.728, 4.731], \n",
    "                              [5.59, 5.33, 4.764, 4.731, 4.728, 4.923, 5.086, 4.798, 4.816, 5.035, 4.827, 4.842, 4.757, 4.796,\n",
    "                               4.734, 4.748, 4.74, 4.734, 4.728, 4.729, 4.726, 4.726, 4.728], \n",
    "                              [4.791, 4.781, 4.732, 5.677, 4.757, 4.837, 4.841, 5.242, 4.81, 4.955, 4.972, 5.106, 4.801, 4.754,\n",
    "                               4.764, 4.748, 4.757, 4.763, 4.737, 4.735, 4.737, 4.74, 4.744]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, average_reg_diff_power_tot[0])\n",
    "plt.plot(number_samples, average_reg_diff_power_tot[1], 'r--')\n",
    "plt.plot(number_samples, average_reg_diff_power_tot[2], 'g.-')\n",
    "plt.plot(number_samples, average_reg_diff_power_tot[3], 'y->')\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('Diff(dB)')\n",
    "plt.title('Average absolute difference power(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "\n",
    "ax.set_yticks(np.arange(0,8, 2))\n",
    "ax.set_ylim([2,8])\n",
    "ax.set_xticks(np.arange(5,4100, 500))\n",
    "# plt.grid(which='minor')\n",
    "# plt.text(40, 50, '# Validation = 34k')\n",
    "# plt.text(400, 45, '# Test = 34k')\n",
    "plt.legend(['linear', 'rbf', 'poly', 'sigmoid'])\n",
    "# plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_averag_powerSVMSVR.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
