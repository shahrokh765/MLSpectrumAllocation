{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers, models, Input\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.utils import Sequence\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datetime, time\n",
    "import os, sys\n",
    "import tqdm\n",
    "import gc\n",
    "from multiprocessing import Process\n",
    "Point = namedtuple('Point', ('x', 'y'))\n",
    "Circle = namedtuple('Circle', ('r'))\n",
    "Square = namedtuple('Square', ('side'))\n",
    "Rectangle = namedtuple('Rectangle', ('length', 'width'))\n",
    "PointWithDistance = namedtuple('PointWithDistance', ('p', 'dist'))\n",
    "float_memory_used = 'float16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "# PART 1\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 10001, 1000))\n",
    "number_samples = [256, 512, 1024, 2048, 4096, 8192] \n",
    "number_samples = [8192]\n",
    "\n",
    "# cnn_type = \"classification\"  # {\"classification\", \"regression\"}\n",
    "validation_size, noise_floor = 0.33, -90.0\n",
    "su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "max_x, max_y, number_image_channels, su_szie = 1000, 1000, 7, 30\n",
    "pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "intensity_degradation, slope = 'log', 3  # 'log', 'linear'\n",
    "max_pus_num, max_sus_num = 20, 1\n",
    "propagation_model = 'log' # 'splat', 'log', 'testbed'\n",
    "noise, std = True, 1\n",
    "if su_shape == 'circle':\n",
    "    su_param = Circle(su_szie)\n",
    "elif su_shape == 'square':\n",
    "    su_param = Square(su_szie)\n",
    "else:\n",
    "    su_param = None\n",
    "    \n",
    "sensors = True\n",
    "if sensors:\n",
    "    sensors_num = 900\n",
    "    sensors_file_path = \"rsc/sensors/\" + str(max(max_x, max_y)) + \"/\" + str(sensors_num) + \"/sensors\"\n",
    "# num_pus = (data_reg.shape[1] - 3)//3\n",
    "\n",
    "# PART 2\n",
    "number_of_proccessors = 6\n",
    "memory_size_allowed = 4 # in Gigabyte\n",
    "float_size = 0\n",
    "if float_memory_used == \"float16\":\n",
    "    float_size = 16\n",
    "elif float_memory_used == \"float\" or \"float32\":\n",
    "    float_size = 32\n",
    "elif float_memory_used == \"float8\":\n",
    "    float_size = 8\n",
    "\n",
    "\n",
    "batch_size = int(memory_size_allowed / (max_x * max_y * number_image_channels * float_size/(8 * 1024 ** 3)))\n",
    "\n",
    "\n",
    "dtime = datetime.datetime.now().strftime('_%Y%m_%d%H_%M')\n",
    "color = \"color\" if number_image_channels > 1 else \"gray\"\n",
    "image_dir = 'ML/data/pictures_' + str(max_x) + '_' + str(max_y) + '/' + propagation_model + (\n",
    "    \"/noisy_std_\" + str(std) if noise else \"\") + '/pu_' + pu_shape + '_su_' + su_shape + '_' + (\n",
    "    \"\" if su_shape == 'point' else str(su_szie)) + \"/\" + style + \"/\" + color +'/' + (\n",
    "    \"\" if pu_shape == 'point' and su_shape == 'point' else (intensity_degradation + '_' + str(slope))) + (\n",
    "    \"/\" + str(sensors_num) + \"sensors\" if sensors else \"/pus\") + \"/images\"\n",
    "\n",
    "if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/images'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "num_columns = (sensors_num if sensors else max_pus_num * 3 + 1) + max_sus_num * 3 + 2\n",
    "cols = [i for i in range(num_columns)]\n",
    "dataset_name = \"dynamic_pus_sensors_50000_min10_max20PUs_1SUs_900sensors_1000grid_1cell_log_noisy_std1_202004_0812_44.txt\"\n",
    "max_dataset_name = \"dynamic_pus_max_power_50000_min10_max20PUs_1SUs_1000grid_1cell_log_noisy_std1_202004_0812_44.txt\"\n",
    "with open('/'.join(image_dir.split('/')[:-1]) + '/datasets' + dtime + '.txt', 'w') as set_file:\n",
    "    set_file.write(dataset_name)\n",
    "    set_file.write(max_dataset_name)\n",
    "\n",
    "dataframe = pd.read_csv('ML/data/' + dataset_name, delimiter=',', header=None, names=cols)\n",
    "dataframe_max = pd.read_csv('ML/data/' + max_dataset_name, delimiter=',', header=None)\n",
    "\n",
    "dataframe.reset_index(drop=True, inplace=True)\n",
    "dataframe_max.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dataframe_tot = pd.concat([dataframe, dataframe_max.iloc[:, dataframe_max.columns.values[-1]]], axis=1,\n",
    "                        ignore_index=True)\n",
    "\n",
    "idx = dataframe_tot[dataframe_tot[dataframe_tot.columns[-1]] == -float('inf')].index\n",
    "dataframe_tot.drop(idx, inplace=True)\n",
    "\n",
    "data_reg = dataframe_tot.values\n",
    "# data_reg = np.concatenate((dataframe_tot.values[:, 0:dataframe_tot.shape[1]-3], \n",
    "#                            dataframe_tot.values[:, dataframe_tot.shape[1]-1:dataframe_tot.shape[1]]), axis=1)\n",
    "# data_class = dataframe_tot.values[:, 0:dataframe_tot.shape[1]-1]\n",
    "# y_class_power = dataframe_tot.values[:, -1]\n",
    "\n",
    "if sensors:\n",
    "    sensors_location = []\n",
    "    with open(sensors_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.split(' ')\n",
    "            sensors_location.append(Point(int(float(line[0])), int(float(line[1]))))\n",
    "del dataframe, dataframe_max, dataframe_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48380, 906)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = data_reg[0:30000][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(p1: Point, p2: Point):\n",
    "    return ((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2) ** 0.5\n",
    "\n",
    "def calculate_mu_sigma(data, num_pus):\n",
    "    sum_non_noise = 0\n",
    "    for pu_n in range(num_pus): # calculate mu\n",
    "        sum_non_noise += data[pu_n*3+2]\n",
    "    mu = ((max_x * max_y - num_pus) * noise_floor + sum_non_noise)/(max_x * max_y)\n",
    "    sum_square = 0\n",
    "    for pu_n in range(num_pus): # calculate sigma\n",
    "        sum_square += (data[pu_n*3+2]-mu)**2\n",
    "    sum_square += (max_x * max_y - num_pus) * (noise_floor - mu)**2\n",
    "    sigma = math.sqrt(sum_square/(max_x * max_y))\n",
    "    return mu, sigma\n",
    "\n",
    "def get_pu_param(pu_shape: str, intensity_degradation: str, pu_p: float, noise_floor: float, slope: float):\n",
    "    pu_param = None\n",
    "    if pu_shape == 'circle':\n",
    "        if intensity_degradation == \"linear\":\n",
    "            pu_param = Circle(int((pu_p - noise_floor) / slope)) # linear\n",
    "        elif intensity_degradation == \"log\":\n",
    "            pu_param = Circle(int(10 ** ((pu_p - noise_floor) / (10 *slope)))) # log_based\n",
    "    elif pu_shape == 'square':\n",
    "        if intensity_degradation == \"linear\":\n",
    "            pu_param = Square(int(2 ** 0.5 * (pu_p - noise_floor) / slope)) # linear\n",
    "        elif intensity_degradation == \"log\":\n",
    "            pu_param = Square(int(2 ** 0.5 * 10 ** ((pu_p - noise_floor) / (10 *slope)))) # log_based\n",
    "    elif pu_shape == 'point':\n",
    "        pu_param = None\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported PU shape(create_image)! \", pu_shape)\n",
    "    return pu_param\n",
    "\n",
    "def create_image(data, slope, sensors_num, style=\"raw_power_z_score\", noise_floor=-90, pu_shape= 'circle', pu_param=None, \n",
    "                 su_shape='circle', su_param=None, intensity_degradation=\"log\", max_pu_power: float=0):  \n",
    "    # style = {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "    # intensity_degradation= {\"log\", \"linear\"}\n",
    "    # if param is None, it's automatically calculated. Highest brightness(or power value) (255 or 1.) would\n",
    "    # assigned to the center(PU location) and radius(side) would be calculated based on its power, slope, and noise floor.\n",
    "    # If it is given, intensity(power) of pixel beside center would be calculated in the same fashin with an exception that \n",
    "    # intensity below zero(noise_floor) would be replaced by zero(noise_floor)\n",
    "    if style == \"raw_power_min_max_norm\":\n",
    "        # In this way, PUs' location are replaced with their power(dBm) and the power would fade with \n",
    "        # slope till gets noise_floor(in circle shape)\n",
    "        \n",
    "        # creating pu matrix\n",
    "        image = np.zeros((1,number_image_channels,max_x, max_y), dtype=float_memory_used)\n",
    "        if not sensors:\n",
    "            pus_num = int(data[0])\n",
    "#             print(pus_num)\n",
    "            for pu_i in range(pus_num):\n",
    "                pu_x = max(0, min(max_x-1, int(data[pu_i * 3 + 1]))) \n",
    "                pu_y = max(0, min(max_x-1, int(data[pu_i * 3 + 2])))\n",
    "                pu_p = data[pu_i * 3 + 3]\n",
    "#                 print(pu_x, pu_y, pu_p)\n",
    "                if pu_param is None:\n",
    "                    pu_param_p = get_pu_param(pu_shape, intensity_degradation, pu_p, noise_floor, slope)\n",
    "                else:\n",
    "                    pu_param_p = pu_param\n",
    "                points = points_inside_shape(center=Point(pu_x, pu_y), shape=pu_shape, param=pu_param_p)\n",
    "                for point in points:\n",
    "                    if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                        if intensity_degradation == \"linear\":\n",
    "                            image[0][int(abs(pu_p))//5][point.p.x][point.p.y] += (pu_p - slope * point.dist - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                        elif intensity_degradation == \"log\":\n",
    "                            if point.dist < 1:\n",
    "                                image[0][int(abs(pu_p))//5][point.p.x][point.p.y] += (pu_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                            else:\n",
    "                                image[0][int(abs(pu_p))//5][point.p.x][point.p.y] += (pu_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                    max_pu_power - noise_floor)\n",
    "        else:\n",
    "            ss_param, ss_shape = pu_param, pu_shape\n",
    "            for ss_i in range(sensors_num):\n",
    "                ss_x, ss_y, ss_p = max(0, min(max_x-1, int(sensors_location[ss_i].x))), max(0, min(max_x-1, int(\n",
    "                    sensors_location[ss_i].y))), max(noise_floor, data[ss_i])\n",
    "                ss_channel = 0 \n",
    "                if -50.0 <= ss_p < -40.0:\n",
    "                    ss_channel = 1\n",
    "                elif -60.0 <= ss_p < -50.0:\n",
    "                    ss_channel = 2\n",
    "                elif -70.0 <= ss_p < -60.0:\n",
    "                    ss_channel = 3\n",
    "                elif -80.0 <= ss_p < -70.0:\n",
    "                    ss_channel = 4\n",
    "#                 elif -70.0 <= ss_p < -65.0:\n",
    "#                     ss_channel = 5\n",
    "                elif ss_p < -80.0:\n",
    "                    ss_channel = 5\n",
    "                if ss_param is None:\n",
    "                    ss_param_p = get_pu_param(ss_shape, intensity_degradation, ss_p, noise_floor, slope)\n",
    "                else:\n",
    "                    ss_param_p = ss_param\n",
    "                points = points_inside_shape(center=Point(ss_x, ss_y), shape=ss_shape, param=ss_param_p)\n",
    "                for point in points:\n",
    "                    if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                        if intensity_degradation == \"linear\":\n",
    "                            image[0][ss_channel][point.p.x][point.p.y] += (ss_p - slope * point.dist - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                        elif intensity_degradation == \"log\":\n",
    "                            if point.dist < 1:\n",
    "                                image[0][ss_channel][point.p.x][point.p.y] += (ss_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                            else:\n",
    "                                image[0][ss_channel][point.p.x][point.p.y] += (ss_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                    max_pu_power - noise_floor)\n",
    "        del points\n",
    "        # creating su matrix\n",
    "        su_num_idx = sensors_num if sensors else (pus_num * 3 + 1)\n",
    "        su_num = int(data[su_num_idx])\n",
    "#         print(su_num)\n",
    "#         su_num = (len(data) - pus_num * (3 if not sensors else 1)) // 2\n",
    "#         if not (len(data) - pus_num * (3 if not sensors else 1)) % 2:\n",
    "#             raise ValueError(\"Data provided is not correct; can't get SUs' information(create_image)\")\n",
    "        if su_param is None:\n",
    "            # if su_param is unavailable, a circle(square) with radius(side) 1 is created\n",
    "            if su_shape == 'circle':\n",
    "                su_param = Circle(1)\n",
    "            elif su_shape == 'square':\n",
    "                su_param = Square(1)\n",
    "            elif su_shape == 'point':\n",
    "                su_param = None\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported SU shape(create_image)! \", su_shape)\n",
    "        \n",
    "        for su_i in range(su_num - 1):\n",
    "            su_x = max(0, min(max_x-1, int(data[su_num_idx + su_i * 3 + 1])))\n",
    "            su_y = max(0, min(max_x-1, int(data[su_num_idx + su_i * 3 + 2])))\n",
    "            su_p = data[su_num_idx + su_i * 3 + 3]\n",
    "#             su_p = su_intensity\n",
    "            points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "            su_channel = 0 if number_image_channels == 1 else -1\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if intensity_degradation == \"linear\":\n",
    "                            su_val = (su_p - slope * point.dist - noise_floor)/(max_pu_power - noise_floor)\n",
    "                    elif intensity_degradation == \"log\":\n",
    "                        if point.dist < 1:\n",
    "                            su_val = (su_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                        else:\n",
    "                            su_val = (su_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                    image[0][su_channel][point.p.x][point.p.y] += su_val\n",
    "            del points\n",
    "        # the last and  target SU\n",
    "        su_intensity = 1.\n",
    "        su_x = max(0, min(max_x-1, int(data[su_num_idx + (su_num - 1) * 3 + 1])))\n",
    "        su_y = max(0, min(max_x-1, int(data[su_num_idx + (su_num - 1) * 3 + 2])))\n",
    "#         print(su_x, su_y)\n",
    "        points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "        su_channel = 0 if number_image_channels == 1 else -1\n",
    "        for point in points:\n",
    "            if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                image[0][su_channel][point.p.x][point.p.y] += su_intensity\n",
    "        del points\n",
    "        return image\n",
    "        \n",
    "#         pu_image = [[(noise_floor - mu)/sigma] * max_y for _ in range(max_x)]\n",
    "    elif style == \"image_intensity\":\n",
    "        # creating PU image\n",
    "        image = np.zeros((1,number_image_channels,max_x, max_y), dtype=float_memory_used)\n",
    "        for pu_i in range(pus_num):\n",
    "            pu_x, pu_y, pu_p = max(0, min(max_x-1, int(data[pu_i*3]))), max(0, min(max_x-1, int(data[pu_i*3+1]))), data[pu_i*3+2]\n",
    "            if pu_param is None:\n",
    "                pu_param_p = get_pu_param(pu_shape, intensity_degradation, pu_p, noise_floor, slope)\n",
    "            else:\n",
    "                pu_param_p = pu_param\n",
    "            points = points_inside_shape(center=Point(pu_x, pu_y), shape=pu_shape, param=pu_param_p)\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if intensity_degradation == \"linear\":\n",
    "                        image[0][0][point.p.x][point.p.y] += max((pu_p - slope * point.dist + abs(noise_floor))\n",
    "                                                              /(pu_p + abs(noise_floor)), 0)\n",
    "                    elif intensity_degradation == \"log\":\n",
    "                        if point.dist < 1:\n",
    "                            image[0][0][point.p.x][point.p.y] = 1\n",
    "                        else:\n",
    "                            image[0][0][point.p.x][point.p.y] += max((pu_p - slope * 10*math.log10(point.dist) + abs(noise_floor))\n",
    "                                                                 /(pu_p + abs(noise_floor)), 0)\n",
    "                    image[0][0][point.p.x][point.p.y] = min(image[0][0][point.p.x][point.p.y], 1.0)\n",
    "                        \n",
    "        # creating SU image\n",
    "        su_num = (len(data) - pus_num * 3) // 2\n",
    "        if not (len(data) - pus_num * 3) % 2:\n",
    "            raise ValueError(\"Data provided is not correct; can't get SUs' information(create_image)\")\n",
    "#         su_image = np.zeros((max_x, max_y), dtype=float_memory_used)\n",
    "        if su_param is None:\n",
    "            # if su_param is unavailable, a circle(square) with radius(side) 1 is created\n",
    "            if su_shape == 'circle':\n",
    "                su_param = Circle(1)\n",
    "            elif su_shape == 'square':\n",
    "                su_param = Square(1)\n",
    "            elif su_shape == 'point':\n",
    "                su_param = None\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported SU shape(create_image)! \", su_shape)\n",
    "        su_intensity = 1.\n",
    "        for su_i in range(su_num):\n",
    "            su_x, su_y, su_p = max(0, min(max_x-1, int(data[pus_num * (3 if not sensors else 1) +su_i*2]))\n",
    "                                  ), max(0, min(max_x-1, int(data[pus_num * (3 if not sensors else 1) + su_i*2+1]))), su_intensity\n",
    "            points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if number_image_channels > 1:\n",
    "                        image[0][1][point.p.x][point.p.y] = su_intensity\n",
    "                    elif number_image_channels == 1:\n",
    "                        image[0][0][point.p.x][point.p.y] = su_intensity\n",
    "#         return np.array([pu_image, su_image, [[0.] * max_y for _ in range(max_x)]], dtype='float32') # return like this to be able to display as an RGB image with pyplot.imshow(imsave)\n",
    "#         return np.append(pu_image, su_image, axis=0)\n",
    "        return image\n",
    "        \n",
    "            \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported style(create_image)! \", style)\n",
    "        \n",
    "def points_inside_shape(center: Point, shape: str, param)-> list:\n",
    "    # This function returns points+distance around center with defined shape\n",
    "    if shape == 'circle':\n",
    "        # First creates points inside a square(around orgigin) with 2*r side and then remove those with distance > r.\n",
    "        # Shift all remaining around center. O(4r^2)\n",
    "        r, origin = param.r, Point(0, 0)\n",
    "        square_points = set((Point(x, y) for x in range(max(-r, -max_x), min(r, max_x) + 1) \n",
    "                             for y in range(max(-r, -max_y), min(r, max_y) + 1)))\n",
    "        points = []\n",
    "        while square_points:\n",
    "            p = square_points.pop()\n",
    "            dist = euclidian_distance(p, origin)\n",
    "            if dist <= r:\n",
    "                points.append(PointWithDistance(Point(p.x + center.x, p.y + center.y), dist))\n",
    "                if p.x != 0:\n",
    "                    points.append(PointWithDistance(Point(-p.x + center.x, p.y + center.y), dist))\n",
    "                    square_points.remove(Point(-p.x, p.y))\n",
    "                if p.y != 0:\n",
    "                    points.append(PointWithDistance(Point(p.x + center.x, -p.y + center.y), dist))\n",
    "                    square_points.remove(Point(p.x, -p.y))\n",
    "                if p.x != 0 and p.y != 0:\n",
    "                    points.append(PointWithDistance(Point(-p.x + center.x, -p.y + center.y), dist))\n",
    "                    square_points.remove(Point(-p.x, -p.y))\n",
    "        del square_points\n",
    "        return points\n",
    "    elif shape == 'square':\n",
    "        half_side = param.side // 2\n",
    "        return [PointWithDistance(Point(x, y), euclidian_distance(Point(x, y), center)) for x in range(-half_side + center.x,\n",
    "                                                                                               half_side + center.x+1) \n",
    "                         for y in range(-half_side + center.y, half_side + center.y + 1)]\n",
    "    elif shape == 'point':\n",
    "        return [PointWithDistance(center, 0)]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported shape(points_inside_shape)! \", shape)\n",
    "        \n",
    "def read_image(image_num):\n",
    "    if style == \"image_intensity\":\n",
    "        image = plt.imread(image_dir + '/image' + str(image_num)+'.png')\n",
    "        image = np.swapaxes(image, 0, 2)\n",
    "        image = np.array(image[:number_image_channels], dtype=float_memory_used).reshape(1, number_image_channels, max_x, max_y)\n",
    "    elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "        suffix = 'npz'  # npy, npz\n",
    "        image = np.load(image_dir + '/image' + str(image_num) + '.' + suffix)  \n",
    "        if type(image) == np.lib.npyio.NpzFile:\n",
    "            image = image['a']\n",
    "    \n",
    "    return image\n",
    "    \n",
    "# TODO: Consider using min_max normalization becasue difference between values using\n",
    "# z-score is huge since most of the pixels have the same value, noise floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 2.000e+00,\n",
       "        4.000e+00, 6.000e+00, 8.000e+00, 1.100e+01, 1.000e+01, 1.700e+01,\n",
       "        2.600e+01, 3.600e+01, 4.300e+01, 5.500e+01, 8.000e+01, 1.240e+02,\n",
       "        1.430e+02, 2.010e+02, 2.380e+02, 2.940e+02, 3.810e+02, 4.160e+02,\n",
       "        5.050e+02, 6.090e+02, 6.910e+02, 8.370e+02, 9.610e+02, 1.086e+03,\n",
       "        1.173e+03, 1.279e+03, 1.373e+03, 1.423e+03, 1.565e+03, 1.557e+03,\n",
       "        1.685e+03, 1.665e+03, 1.518e+03, 1.578e+03, 1.599e+03, 1.480e+03,\n",
       "        1.437e+03, 1.318e+03, 1.267e+03, 1.269e+03, 1.158e+03, 1.059e+03,\n",
       "        1.035e+03, 1.007e+03, 9.420e+02, 9.170e+02, 7.750e+02, 7.610e+02,\n",
       "        7.240e+02, 6.110e+02, 6.150e+02, 5.730e+02, 4.910e+02, 4.740e+02,\n",
       "        4.620e+02, 4.460e+02, 3.750e+02, 3.710e+02, 3.340e+02, 3.080e+02,\n",
       "        3.300e+02, 2.830e+02, 2.520e+02, 2.340e+02, 2.330e+02, 1.960e+02,\n",
       "        1.960e+02, 1.770e+02, 1.780e+02, 1.570e+02, 1.420e+02, 1.360e+02,\n",
       "        1.320e+02, 1.360e+02, 1.010e+02, 1.180e+02, 1.000e+02, 9.000e+01,\n",
       "        1.110e+02, 1.030e+02, 9.200e+01, 8.500e+01, 7.100e+01, 7.700e+01,\n",
       "        5.800e+01, 6.200e+01, 4.700e+01, 5.600e+01, 4.500e+01, 5.600e+01,\n",
       "        5.600e+01, 4.400e+01, 4.100e+01, 3.900e+01, 3.100e+01, 3.600e+01,\n",
       "        3.300e+01, 3.200e+01, 3.000e+01, 3.500e+01, 2.500e+01, 2.300e+01,\n",
       "        2.900e+01, 2.300e+01, 1.900e+01, 2.300e+01, 2.000e+01, 1.600e+01,\n",
       "        1.600e+01, 1.900e+01, 1.800e+01, 1.900e+01, 1.600e+01, 1.300e+01,\n",
       "        2.000e+01, 1.700e+01, 1.300e+01, 1.800e+01, 1.500e+01, 1.200e+01,\n",
       "        1.500e+01, 6.000e+00, 7.000e+00, 9.000e+00, 7.000e+00, 1.000e+01,\n",
       "        7.000e+00, 6.000e+00, 1.200e+01, 1.000e+01, 6.000e+00, 4.000e+00,\n",
       "        4.000e+00, 2.000e+00, 5.000e+00, 6.000e+00, 5.000e+00, 3.000e+00,\n",
       "        4.000e+00, 4.000e+00, 1.000e+00, 3.000e+00, 3.000e+00, 0.000e+00,\n",
       "        4.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 3.000e+00, 1.000e+00,\n",
       "        3.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 3.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        2.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00]),\n",
       " array([-97.906     , -97.42421277, -96.94242553, -96.4606383 ,\n",
       "        -95.97885106, -95.49706383, -95.0152766 , -94.53348936,\n",
       "        -94.05170213, -93.56991489, -93.08812766, -92.60634043,\n",
       "        -92.12455319, -91.64276596, -91.16097872, -90.67919149,\n",
       "        -90.19740426, -89.71561702, -89.23382979, -88.75204255,\n",
       "        -88.27025532, -87.78846809, -87.30668085, -86.82489362,\n",
       "        -86.34310638, -85.86131915, -85.37953191, -84.89774468,\n",
       "        -84.41595745, -83.93417021, -83.45238298, -82.97059574,\n",
       "        -82.48880851, -82.00702128, -81.52523404, -81.04344681,\n",
       "        -80.56165957, -80.07987234, -79.59808511, -79.11629787,\n",
       "        -78.63451064, -78.1527234 , -77.67093617, -77.18914894,\n",
       "        -76.7073617 , -76.22557447, -75.74378723, -75.262     ,\n",
       "        -74.78021277, -74.29842553, -73.8166383 , -73.33485106,\n",
       "        -72.85306383, -72.3712766 , -71.88948936, -71.40770213,\n",
       "        -70.92591489, -70.44412766, -69.96234043, -69.48055319,\n",
       "        -68.99876596, -68.51697872, -68.03519149, -67.55340426,\n",
       "        -67.07161702, -66.58982979, -66.10804255, -65.62625532,\n",
       "        -65.14446809, -64.66268085, -64.18089362, -63.69910638,\n",
       "        -63.21731915, -62.73553191, -62.25374468, -61.77195745,\n",
       "        -61.29017021, -60.80838298, -60.32659574, -59.84480851,\n",
       "        -59.36302128, -58.88123404, -58.39944681, -57.91765957,\n",
       "        -57.43587234, -56.95408511, -56.47229787, -55.99051064,\n",
       "        -55.5087234 , -55.02693617, -54.54514894, -54.0633617 ,\n",
       "        -53.58157447, -53.09978723, -52.618     , -52.13621277,\n",
       "        -51.65442553, -51.1726383 , -50.69085106, -50.20906383,\n",
       "        -49.7272766 , -49.24548936, -48.76370213, -48.28191489,\n",
       "        -47.80012766, -47.31834043, -46.83655319, -46.35476596,\n",
       "        -45.87297872, -45.39119149, -44.90940426, -44.42761702,\n",
       "        -43.94582979, -43.46404255, -42.98225532, -42.50046809,\n",
       "        -42.01868085, -41.53689362, -41.05510638, -40.57331915,\n",
       "        -40.09153191, -39.60974468, -39.12795745, -38.64617021,\n",
       "        -38.16438298, -37.68259574, -37.20080851, -36.71902128,\n",
       "        -36.23723404, -35.75544681, -35.27365957, -34.79187234,\n",
       "        -34.31008511, -33.82829787, -33.34651064, -32.8647234 ,\n",
       "        -32.38293617, -31.90114894, -31.4193617 , -30.93757447,\n",
       "        -30.45578723, -29.974     , -29.49221277, -29.01042553,\n",
       "        -28.5286383 , -28.04685106, -27.56506383, -27.0832766 ,\n",
       "        -26.60148936, -26.11970213, -25.63791489, -25.15612766,\n",
       "        -24.67434043, -24.19255319, -23.71076596, -23.22897872,\n",
       "        -22.74719149, -22.26540426, -21.78361702, -21.30182979,\n",
       "        -20.82004255, -20.33825532, -19.85646809, -19.37468085,\n",
       "        -18.89289362, -18.41110638, -17.92931915, -17.44753191,\n",
       "        -16.96574468, -16.48395745, -16.00217021, -15.52038298,\n",
       "        -15.03859574, -14.55680851, -14.07502128, -13.59323404,\n",
       "        -13.11144681, -12.62965957, -12.14787234, -11.66608511,\n",
       "        -11.18429787, -10.70251064, -10.2207234 ,  -9.73893617,\n",
       "         -9.25714894,  -8.7753617 ,  -8.29357447,  -7.81178723,\n",
       "         -7.33      ]),\n",
       " <a list of 188 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data_reg[:,0:1:400], bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving images once to save time\n",
    "# run this cell just for creating images\n",
    "def creating_image(start, end):\n",
    "    # for image_num in range(115, data_reg.shape[0]):\n",
    "    # for image_num in range(1625, 5000):\n",
    "    for image_num in tqdm.tqdm(range(start, end+1)):  #4463, data_reg.shape[0]\n",
    "        image = create_image(data=data_reg[image_num], slope=slope, style=style, noise_floor=noise_floor,\n",
    "                             pu_shape=pu_shape, su_shape=su_shape, su_param=su_param, \n",
    "                             sensors_num=(sensors_num if sensors else 0), \n",
    "                             intensity_degradation=intensity_degradation, \n",
    "                             max_pu_power=-40.0)\n",
    "        if style == \"image_intensity\":\n",
    "            if number_image_channels != 3:\n",
    "                image = np.append(np.array(image[0]), np.zeros((3-number_image_channels,max_x, max_y), \n",
    "                                                               dtype=float_memory_used), axis=0)\n",
    "            image_save = np.swapaxes(image, 0, 2)\n",
    "            plt.imsave(image_dir + '/image' + str(image_num)+'.png', image_save)\n",
    "        elif style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "    #         np.save(image_dir + '/image' + str(image_num), image)\n",
    "            np.savez_compressed(image_dir + '/image' + str(image_num), a=image)\n",
    "        del image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8065/8065 [7:39:25<00:00,  3.42s/it]   \n",
      "100%|██████████| 8063/8063 [7:41:15<00:00,  3.43s/it]\n",
      "100%|██████████| 8063/8063 [7:45:37<00:00,  3.46s/it]\n",
      "100%|██████████| 8063/8063 [7:45:44<00:00,  3.47s/it]\n",
      "100%|██████████| 8063/8063 [7:45:53<00:00,  3.47s/it]\n",
      "100%|██████████| 8063/8063 [7:47:07<00:00,  3.48s/it]\n"
     ]
    }
   ],
   "source": [
    "jobs = []\n",
    "proc_sizes = [data_reg.shape[0]//number_of_proccessors] * (number_of_proccessors)\n",
    "proc_sizes[-1] += data_reg.shape[0]%number_of_proccessors\n",
    "proc_idx = [(sum(proc_sizes[:i]), sum(proc_sizes[:i+1])-1) for i in range(number_of_proccessors)]\n",
    "\n",
    "for i in range(number_of_proccessors):\n",
    "    p = Process(target=creating_image, args=(proc_idx[i][0], proc_idx[i][1]))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "for i in range(number_of_proccessors):\n",
    "    jobs[i].join()\n",
    "\n",
    "for i in range(number_of_proccessors):\n",
    "    jobs[i].terminate()\n",
    "    jobs[i].close()\n",
    "del jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Point(x=25, y=25)\n",
      "2 Point(x=25, y=75)\n",
      "3 Point(x=25, y=125)\n",
      "4 Point(x=25, y=175)\n",
      "5 Point(x=25, y=225)\n",
      "6 Point(x=25, y=275)\n",
      "7 Point(x=25, y=325)\n",
      "8 Point(x=25, y=375)\n",
      "9 Point(x=25, y=425)\n",
      "10 Point(x=25, y=475)\n",
      "11 Point(x=25, y=525)\n",
      "12 Point(x=25, y=575)\n",
      "13 Point(x=25, y=625)\n",
      "14 Point(x=25, y=675)\n",
      "15 Point(x=25, y=725)\n",
      "16 Point(x=25, y=775)\n",
      "17 Point(x=25, y=825)\n",
      "18 Point(x=25, y=875)\n",
      "19 Point(x=25, y=925)\n",
      "20 Point(x=25, y=975)\n",
      "21 Point(x=75, y=25)\n",
      "22 Point(x=75, y=75)\n",
      "23 Point(x=75, y=125)\n",
      "24 Point(x=75, y=175)\n",
      "25 Point(x=75, y=225)\n",
      "26 Point(x=75, y=275)\n",
      "27 Point(x=75, y=325)\n",
      "28 Point(x=75, y=375)\n",
      "29 Point(x=75, y=425)\n",
      "30 Point(x=75, y=475)\n",
      "31 Point(x=75, y=525)\n",
      "32 Point(x=75, y=575)\n",
      "33 Point(x=75, y=625)\n",
      "34 Point(x=75, y=675)\n",
      "35 Point(x=75, y=725)\n",
      "36 Point(x=75, y=775)\n",
      "37 Point(x=75, y=825)\n",
      "38 Point(x=75, y=875)\n",
      "39 Point(x=75, y=925)\n",
      "40 Point(x=75, y=975)\n",
      "41 Point(x=125, y=25)\n",
      "42 Point(x=125, y=75)\n",
      "43 Point(x=125, y=125)\n",
      "44 Point(x=125, y=175)\n",
      "45 Point(x=125, y=225)\n",
      "46 Point(x=125, y=275)\n",
      "47 Point(x=125, y=325)\n",
      "48 Point(x=125, y=375)\n",
      "49 Point(x=125, y=425)\n",
      "50 Point(x=125, y=475)\n",
      "51 Point(x=125, y=525)\n",
      "52 Point(x=125, y=575)\n",
      "53 Point(x=125, y=625)\n",
      "54 Point(x=125, y=675)\n",
      "55 Point(x=125, y=725)\n",
      "56 Point(x=125, y=775)\n",
      "57 Point(x=125, y=825)\n",
      "58 Point(x=125, y=875)\n",
      "59 Point(x=125, y=925)\n",
      "60 Point(x=125, y=975)\n",
      "61 Point(x=175, y=25)\n",
      "62 Point(x=175, y=75)\n",
      "63 Point(x=175, y=125)\n",
      "64 Point(x=175, y=175)\n",
      "65 Point(x=175, y=225)\n",
      "66 Point(x=175, y=275)\n",
      "67 Point(x=175, y=325)\n",
      "68 Point(x=175, y=375)\n",
      "69 Point(x=175, y=425)\n",
      "70 Point(x=175, y=475)\n",
      "71 Point(x=175, y=525)\n",
      "72 Point(x=175, y=575)\n",
      "73 Point(x=175, y=625)\n",
      "74 Point(x=175, y=675)\n",
      "75 Point(x=175, y=725)\n",
      "76 Point(x=175, y=775)\n",
      "77 Point(x=175, y=825)\n",
      "78 Point(x=175, y=875)\n",
      "79 Point(x=175, y=925)\n",
      "80 Point(x=175, y=975)\n",
      "81 Point(x=225, y=25)\n",
      "82 Point(x=225, y=75)\n",
      "83 Point(x=225, y=125)\n",
      "84 Point(x=225, y=175)\n",
      "85 Point(x=225, y=225)\n",
      "86 Point(x=225, y=275)\n",
      "87 Point(x=225, y=325)\n",
      "88 Point(x=225, y=375)\n",
      "89 Point(x=225, y=425)\n",
      "90 Point(x=225, y=475)\n",
      "91 Point(x=225, y=525)\n",
      "92 Point(x=225, y=575)\n",
      "93 Point(x=225, y=625)\n",
      "94 Point(x=225, y=675)\n",
      "95 Point(x=225, y=725)\n",
      "96 Point(x=225, y=775)\n",
      "97 Point(x=225, y=825)\n",
      "98 Point(x=225, y=875)\n",
      "99 Point(x=225, y=925)\n",
      "100 Point(x=225, y=975)\n",
      "101 Point(x=275, y=25)\n",
      "102 Point(x=275, y=75)\n",
      "103 Point(x=275, y=125)\n",
      "104 Point(x=275, y=175)\n",
      "105 Point(x=275, y=225)\n",
      "106 Point(x=275, y=275)\n",
      "107 Point(x=275, y=325)\n",
      "108 Point(x=275, y=375)\n",
      "109 Point(x=275, y=425)\n",
      "110 Point(x=275, y=475)\n",
      "111 Point(x=275, y=525)\n",
      "112 Point(x=275, y=575)\n",
      "113 Point(x=275, y=625)\n",
      "114 Point(x=275, y=675)\n",
      "115 Point(x=275, y=725)\n",
      "116 Point(x=275, y=775)\n",
      "117 Point(x=275, y=825)\n",
      "118 Point(x=275, y=875)\n",
      "119 Point(x=275, y=925)\n",
      "120 Point(x=275, y=975)\n",
      "121 Point(x=325, y=25)\n",
      "122 Point(x=325, y=75)\n",
      "123 Point(x=325, y=125)\n",
      "124 Point(x=325, y=175)\n",
      "125 Point(x=325, y=225)\n",
      "126 Point(x=325, y=275)\n",
      "127 Point(x=325, y=325)\n",
      "128 Point(x=325, y=375)\n",
      "129 Point(x=325, y=425)\n",
      "130 Point(x=325, y=475)\n",
      "131 Point(x=325, y=525)\n",
      "132 Point(x=325, y=575)\n",
      "133 Point(x=325, y=625)\n",
      "134 Point(x=325, y=675)\n",
      "135 Point(x=325, y=725)\n",
      "136 Point(x=325, y=775)\n",
      "137 Point(x=325, y=825)\n",
      "138 Point(x=325, y=875)\n",
      "139 Point(x=325, y=925)\n",
      "140 Point(x=325, y=975)\n",
      "141 Point(x=375, y=25)\n",
      "142 Point(x=375, y=75)\n",
      "143 Point(x=375, y=125)\n",
      "144 Point(x=375, y=175)\n",
      "145 Point(x=375, y=225)\n",
      "146 Point(x=375, y=275)\n",
      "147 Point(x=375, y=325)\n",
      "148 Point(x=375, y=375)\n",
      "149 Point(x=375, y=425)\n",
      "150 Point(x=375, y=475)\n",
      "151 Point(x=375, y=525)\n",
      "152 Point(x=375, y=575)\n",
      "153 Point(x=375, y=625)\n",
      "154 Point(x=375, y=675)\n",
      "155 Point(x=375, y=725)\n",
      "156 Point(x=375, y=775)\n",
      "157 Point(x=375, y=825)\n",
      "158 Point(x=375, y=875)\n",
      "159 Point(x=375, y=925)\n",
      "160 Point(x=375, y=975)\n",
      "161 Point(x=425, y=25)\n",
      "162 Point(x=425, y=75)\n",
      "163 Point(x=425, y=125)\n",
      "164 Point(x=425, y=175)\n",
      "165 Point(x=425, y=225)\n",
      "166 Point(x=425, y=275)\n",
      "167 Point(x=425, y=325)\n",
      "168 Point(x=425, y=375)\n",
      "169 Point(x=425, y=425)\n",
      "170 Point(x=425, y=475)\n",
      "171 Point(x=425, y=525)\n",
      "172 Point(x=425, y=575)\n",
      "173 Point(x=425, y=625)\n",
      "174 Point(x=425, y=675)\n",
      "175 Point(x=425, y=725)\n",
      "176 Point(x=425, y=775)\n",
      "177 Point(x=425, y=825)\n",
      "178 Point(x=425, y=875)\n",
      "179 Point(x=425, y=925)\n",
      "180 Point(x=425, y=975)\n",
      "181 Point(x=475, y=25)\n",
      "182 Point(x=475, y=75)\n",
      "183 Point(x=475, y=125)\n",
      "184 Point(x=475, y=175)\n",
      "185 Point(x=475, y=225)\n",
      "186 Point(x=475, y=275)\n",
      "187 Point(x=475, y=325)\n",
      "188 Point(x=475, y=375)\n",
      "189 Point(x=475, y=425)\n",
      "190 Point(x=475, y=475)\n",
      "191 Point(x=475, y=525)\n",
      "192 Point(x=475, y=575)\n",
      "193 Point(x=475, y=625)\n",
      "194 Point(x=475, y=675)\n",
      "195 Point(x=475, y=725)\n",
      "196 Point(x=475, y=775)\n",
      "197 Point(x=475, y=825)\n",
      "198 Point(x=475, y=875)\n",
      "199 Point(x=475, y=925)\n",
      "200 Point(x=475, y=975)\n",
      "201 Point(x=525, y=25)\n",
      "202 Point(x=525, y=75)\n",
      "203 Point(x=525, y=125)\n",
      "204 Point(x=525, y=175)\n",
      "205 Point(x=525, y=225)\n",
      "206 Point(x=525, y=275)\n",
      "207 Point(x=525, y=325)\n",
      "208 Point(x=525, y=375)\n",
      "209 Point(x=525, y=425)\n",
      "210 Point(x=525, y=475)\n",
      "211 Point(x=525, y=525)\n",
      "212 Point(x=525, y=575)\n",
      "213 Point(x=525, y=625)\n",
      "214 Point(x=525, y=675)\n",
      "215 Point(x=525, y=725)\n",
      "216 Point(x=525, y=775)\n",
      "217 Point(x=525, y=825)\n",
      "218 Point(x=525, y=875)\n",
      "219 Point(x=525, y=925)\n",
      "220 Point(x=525, y=975)\n",
      "221 Point(x=575, y=25)\n",
      "222 Point(x=575, y=75)\n",
      "223 Point(x=575, y=125)\n",
      "224 Point(x=575, y=175)\n",
      "225 Point(x=575, y=225)\n",
      "226 Point(x=575, y=275)\n",
      "227 Point(x=575, y=325)\n",
      "228 Point(x=575, y=375)\n",
      "229 Point(x=575, y=425)\n",
      "230 Point(x=575, y=475)\n",
      "231 Point(x=575, y=525)\n",
      "232 Point(x=575, y=575)\n",
      "233 Point(x=575, y=625)\n",
      "234 Point(x=575, y=675)\n",
      "235 Point(x=575, y=725)\n",
      "236 Point(x=575, y=775)\n",
      "237 Point(x=575, y=825)\n",
      "238 Point(x=575, y=875)\n",
      "239 Point(x=575, y=925)\n",
      "240 Point(x=575, y=975)\n",
      "241 Point(x=625, y=25)\n",
      "242 Point(x=625, y=75)\n",
      "243 Point(x=625, y=125)\n",
      "244 Point(x=625, y=175)\n",
      "245 Point(x=625, y=225)\n",
      "246 Point(x=625, y=275)\n",
      "247 Point(x=625, y=325)\n",
      "248 Point(x=625, y=375)\n",
      "249 Point(x=625, y=425)\n",
      "250 Point(x=625, y=475)\n",
      "251 Point(x=625, y=525)\n",
      "252 Point(x=625, y=575)\n",
      "253 Point(x=625, y=625)\n",
      "254 Point(x=625, y=675)\n",
      "255 Point(x=625, y=725)\n",
      "256 Point(x=625, y=775)\n",
      "257 Point(x=625, y=825)\n",
      "258 Point(x=625, y=875)\n",
      "259 Point(x=625, y=925)\n",
      "260 Point(x=625, y=975)\n",
      "261 Point(x=675, y=25)\n",
      "262 Point(x=675, y=75)\n",
      "263 Point(x=675, y=125)\n",
      "264 Point(x=675, y=175)\n",
      "265 Point(x=675, y=225)\n",
      "266 Point(x=675, y=275)\n",
      "267 Point(x=675, y=325)\n",
      "268 Point(x=675, y=375)\n",
      "269 Point(x=675, y=425)\n",
      "270 Point(x=675, y=475)\n",
      "271 Point(x=675, y=525)\n",
      "272 Point(x=675, y=575)\n",
      "273 Point(x=675, y=625)\n",
      "274 Point(x=675, y=675)\n",
      "275 Point(x=675, y=725)\n",
      "276 Point(x=675, y=775)\n",
      "277 Point(x=675, y=825)\n",
      "278 Point(x=675, y=875)\n",
      "279 Point(x=675, y=925)\n",
      "280 Point(x=675, y=975)\n",
      "281 Point(x=725, y=25)\n",
      "282 Point(x=725, y=75)\n",
      "283 Point(x=725, y=125)\n",
      "284 Point(x=725, y=175)\n",
      "285 Point(x=725, y=225)\n",
      "286 Point(x=725, y=275)\n",
      "287 Point(x=725, y=325)\n",
      "288 Point(x=725, y=375)\n",
      "289 Point(x=725, y=425)\n",
      "290 Point(x=725, y=475)\n",
      "291 Point(x=725, y=525)\n",
      "292 Point(x=725, y=575)\n",
      "293 Point(x=725, y=625)\n",
      "294 Point(x=725, y=675)\n",
      "295 Point(x=725, y=725)\n",
      "296 Point(x=725, y=775)\n",
      "297 Point(x=725, y=825)\n",
      "298 Point(x=725, y=875)\n",
      "299 Point(x=725, y=925)\n",
      "300 Point(x=725, y=975)\n",
      "301 Point(x=775, y=25)\n",
      "302 Point(x=775, y=75)\n",
      "303 Point(x=775, y=125)\n",
      "304 Point(x=775, y=175)\n",
      "305 Point(x=775, y=225)\n",
      "306 Point(x=775, y=275)\n",
      "307 Point(x=775, y=325)\n",
      "308 Point(x=775, y=375)\n",
      "309 Point(x=775, y=425)\n",
      "310 Point(x=775, y=475)\n",
      "311 Point(x=775, y=525)\n",
      "312 Point(x=775, y=575)\n",
      "313 Point(x=775, y=625)\n",
      "314 Point(x=775, y=675)\n",
      "315 Point(x=775, y=725)\n",
      "316 Point(x=775, y=775)\n",
      "317 Point(x=775, y=825)\n",
      "318 Point(x=775, y=875)\n",
      "319 Point(x=775, y=925)\n",
      "320 Point(x=775, y=975)\n",
      "321 Point(x=825, y=25)\n",
      "322 Point(x=825, y=75)\n",
      "323 Point(x=825, y=125)\n",
      "324 Point(x=825, y=175)\n",
      "325 Point(x=825, y=225)\n",
      "326 Point(x=825, y=275)\n",
      "327 Point(x=825, y=325)\n",
      "328 Point(x=825, y=375)\n",
      "329 Point(x=825, y=425)\n",
      "330 Point(x=825, y=475)\n",
      "331 Point(x=825, y=525)\n",
      "332 Point(x=825, y=575)\n",
      "333 Point(x=825, y=625)\n",
      "334 Point(x=825, y=675)\n",
      "335 Point(x=825, y=725)\n",
      "336 Point(x=825, y=775)\n",
      "337 Point(x=825, y=825)\n",
      "338 Point(x=825, y=875)\n",
      "339 Point(x=825, y=925)\n",
      "340 Point(x=825, y=975)\n",
      "341 Point(x=875, y=25)\n",
      "342 Point(x=875, y=75)\n",
      "343 Point(x=875, y=125)\n",
      "344 Point(x=875, y=175)\n",
      "345 Point(x=875, y=225)\n",
      "346 Point(x=875, y=275)\n",
      "347 Point(x=875, y=325)\n",
      "348 Point(x=875, y=375)\n",
      "349 Point(x=875, y=425)\n",
      "350 Point(x=875, y=475)\n",
      "351 Point(x=875, y=525)\n",
      "352 Point(x=875, y=575)\n",
      "353 Point(x=875, y=625)\n",
      "354 Point(x=875, y=675)\n",
      "355 Point(x=875, y=725)\n",
      "356 Point(x=875, y=775)\n",
      "357 Point(x=875, y=825)\n",
      "358 Point(x=875, y=875)\n",
      "359 Point(x=875, y=925)\n",
      "360 Point(x=875, y=975)\n",
      "361 Point(x=925, y=25)\n",
      "362 Point(x=925, y=75)\n",
      "363 Point(x=925, y=125)\n",
      "364 Point(x=925, y=175)\n",
      "365 Point(x=925, y=225)\n",
      "366 Point(x=925, y=275)\n",
      "367 Point(x=925, y=325)\n",
      "368 Point(x=925, y=375)\n",
      "369 Point(x=925, y=425)\n",
      "370 Point(x=925, y=475)\n",
      "371 Point(x=925, y=525)\n",
      "372 Point(x=925, y=575)\n",
      "373 Point(x=925, y=625)\n",
      "374 Point(x=925, y=675)\n",
      "375 Point(x=925, y=725)\n",
      "376 Point(x=925, y=775)\n",
      "377 Point(x=925, y=825)\n",
      "378 Point(x=925, y=875)\n",
      "379 Point(x=925, y=925)\n",
      "380 Point(x=925, y=975)\n",
      "381 Point(x=975, y=25)\n",
      "382 Point(x=975, y=75)\n",
      "383 Point(x=975, y=125)\n",
      "384 Point(x=975, y=175)\n",
      "385 Point(x=975, y=225)\n",
      "386 Point(x=975, y=275)\n",
      "387 Point(x=975, y=325)\n",
      "388 Point(x=975, y=375)\n",
      "389 Point(x=975, y=425)\n",
      "390 Point(x=975, y=475)\n",
      "391 Point(x=975, y=525)\n",
      "392 Point(x=975, y=575)\n",
      "393 Point(x=975, y=625)\n",
      "394 Point(x=975, y=675)\n",
      "395 Point(x=975, y=725)\n",
      "396 Point(x=975, y=775)\n",
      "397 Point(x=975, y=825)\n",
      "398 Point(x=975, y=875)\n",
      "399 Point(x=975, y=925)\n",
      "400 Point(x=975, y=975)\n"
     ]
    }
   ],
   "source": [
    "for idx, point in enumerate(sensors_location):\n",
    "    print(idx+1, point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823 Point(x=916, y=416) close\n"
     ]
    }
   ],
   "source": [
    "for idx, point in enumerate(sensors_location):\n",
    "    print(idx+1, point,\"close\") if math.sqrt((point.x-917)**2+(point.y-415)**2)<=1.5 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [0, 0, 0, 0]\n",
    "idxx = [[],[],[],[]]\n",
    "for i in range(data_reg.shape[0]):\n",
    "    pus_c = int(data_reg[i][0]) * 3 + 1\n",
    "    idx = int(data_reg[i][pus_c]) - 1\n",
    "    count[idx] += 1\n",
    "    idxx[idx].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24178, 12235, 5997, 3024]\n",
      "[18, 37, 42, 58, 79, 82, 89, 90, 103, 124, 142, 149, 171, 173, 189, 207, 233, 238, 269, 277, 293, 319, 331, 341, 387, 396, 404, 410, 418, 420, 432, 440, 444, 497, 525, 539, 544, 614, 616, 619, 627, 632, 633, 645, 648, 651, 663, 732, 775, 778, 843, 902, 923, 949, 965, 967, 968, 988, 996, 1018, 1020, 1024, 1030, 1036, 1075, 1084, 1105, 1116, 1129, 1133, 1140, 1142, 1152, 1168, 1171, 1188, 1250, 1251, 1264, 1279, 1288, 1306, 1329, 1367, 1369, 1389, 1390, 1421, 1430, 1435, 1440, 1447, 1450, 1456, 1463, 1534, 1539, 1550, 1562, 1594, 1606, 1621, 1632, 1654, 1658, 1664, 1683, 1714, 1754, 1773, 1796, 1820, 1821, 1843, 1848, 1865, 1871, 1897, 1905, 1938, 1943, 1948, 1997, 2017, 2023, 2040, 2053, 2062, 2087, 2103, 2110, 2116, 2119, 2148, 2157, 2169, 2182, 2220, 2227, 2288, 2326, 2364, 2372, 2387, 2402, 2426, 2431, 2434, 2436, 2441, 2447, 2472, 2478, 2491, 2497, 2532, 2543, 2557, 2582, 2588, 2619, 2628, 2706, 2741, 2742, 2743, 2747, 2751, 2762, 2788, 2807, 2870, 2874, 2894, 2915, 2922, 2931, 2957, 2966, 2974, 2989, 3026, 3030, 3046, 3049, 3063, 3082, 3083, 3105, 3119, 3154, 3159, 3178, 3181, 3182, 3196, 3212, 3229, 3232, 3249, 3258, 3260, 3284, 3285, 3290, 3292, 3304, 3307, 3309, 3333, 3340, 3346, 3364, 3365, 3380, 3397, 3437, 3443, 3472, 3499, 3503, 3517, 3518, 3520, 3524, 3572, 3588, 3600, 3608, 3616, 3626, 3641, 3649, 3665, 3666, 3667, 3669, 3676, 3682, 3684, 3729, 3738, 3744, 3749, 3764, 3765, 3784, 3788, 3809, 3812, 3822, 3845, 3852, 3862, 3881, 3891, 3899, 3910, 3942, 3953, 3974, 3978, 4045, 4047, 4052, 4087, 4135, 4140, 4144, 4159, 4160, 4168, 4177, 4183, 4193, 4195, 4207, 4208, 4251, 4264, 4281, 4282, 4287, 4295, 4314, 4320, 4335, 4395, 4406, 4416, 4450, 4467, 4513, 4514, 4521, 4547, 4568, 4578, 4587, 4607, 4622, 4646, 4648, 4672, 4681, 4702, 4708, 4723, 4727, 4728, 4742, 4743, 4748, 4774, 4780, 4799, 4813, 4817, 4822, 4870, 4905, 4913, 4925, 4930, 4952, 4975, 4976, 4982, 4992, 5003, 5028, 5033, 5039, 5051, 5056, 5058, 5063, 5081, 5084, 5095, 5098, 5146, 5174, 5190, 5197, 5240, 5245, 5263, 5278, 5305, 5324, 5339, 5347, 5352, 5365, 5374, 5384, 5385, 5390, 5395, 5427, 5436, 5439, 5447, 5464, 5490, 5502, 5510, 5512, 5514, 5531, 5532, 5533, 5536, 5539, 5557, 5593, 5606, 5626, 5681, 5694, 5713, 5769, 5821, 5842, 5846, 5859, 5863, 5889, 5903, 5942, 5960, 5964, 5989, 5997, 6001, 6016, 6022, 6024, 6037, 6048, 6058, 6077, 6081, 6082, 6099, 6106, 6125, 6146, 6165, 6194, 6208, 6213, 6219, 6225, 6232, 6242, 6245, 6252, 6294, 6308, 6318, 6325, 6327, 6342, 6366, 6370, 6372, 6373, 6386, 6400, 6419, 6423, 6432, 6436, 6443, 6501, 6511, 6520, 6541, 6573, 6601, 6605, 6612, 6616, 6617, 6619, 6631, 6656, 6680, 6718, 6726, 6754, 6762, 6764, 6768, 6783, 6796, 6823, 6828, 6840, 6846, 6847, 6853, 6859, 6881, 6925, 6926, 6929, 6930, 6939, 6955, 6956, 6958, 6967, 7021, 7037, 7050, 7057, 7071, 7078, 7082, 7115, 7118, 7143, 7172, 7198, 7202, 7214, 7227, 7235, 7254, 7268, 7308, 7331, 7382, 7410, 7426, 7427, 7434, 7447, 7458, 7487, 7509, 7512, 7521, 7547, 7557, 7571, 7579, 7583, 7588, 7589, 7591, 7618, 7625, 7632, 7691, 7700, 7705, 7717, 7731, 7733, 7738, 7744, 7757, 7767, 7771, 7777, 7812, 7828, 7889, 7910, 7921, 7922, 7963, 7999, 8016, 8024, 8050, 8051, 8066, 8076, 8108, 8116, 8146, 8173, 8180, 8181, 8183, 8214, 8220, 8228, 8232, 8235, 8263, 8297, 8310, 8311, 8331, 8371, 8372, 8388, 8389, 8393, 8407, 8468, 8472, 8494, 8500, 8509, 8531, 8556, 8571, 8579, 8584, 8622, 8623, 8629, 8655, 8675, 8677, 8687, 8727, 8736, 8738, 8746, 8753, 8786, 8789, 8792, 8816, 8829, 8835, 8839, 8847, 8866, 8899, 8906, 8909, 8930, 8940, 8944, 8952, 8967, 8970, 8987, 8997, 9034, 9061, 9080, 9087, 9095, 9102, 9110, 9127, 9131, 9148, 9158, 9161, 9175, 9178, 9208, 9217, 9242, 9248, 9258, 9266, 9273, 9283, 9288, 9305, 9335, 9342, 9347, 9357, 9371, 9399, 9428, 9441, 9458, 9464, 9473, 9490, 9539, 9541, 9552, 9603, 9608, 9625, 9629, 9635, 9662, 9670, 9671, 9672, 9688, 9699, 9710, 9763, 9774, 9790, 9793, 9865, 9876, 9889, 9896, 9903, 9907, 9952, 10010, 10020, 10021, 10034, 10043, 10046, 10050, 10056, 10074, 10084, 10090, 10105, 10115, 10159, 10170, 10181, 10192, 10213, 10218, 10256, 10259, 10295, 10296, 10303, 10320, 10331, 10336, 10351, 10372, 10421, 10430, 10438, 10458, 10471, 10529, 10531, 10557, 10571, 10591, 10593, 10623, 10629, 10637, 10642, 10662, 10667, 10723, 10769, 10794, 10800, 10812, 10829, 10837, 10838, 10844, 10855, 10865, 10880, 10885, 10887, 10895, 10909, 10914, 10941, 10978, 10980, 10981, 10986, 11010, 11017, 11048, 11056, 11068, 11069, 11116, 11117, 11118, 11135, 11148, 11156, 11166, 11174, 11203, 11204, 11256, 11284, 11287, 11297, 11322, 11341, 11355, 11375, 11403, 11406, 11430, 11442, 11443, 11470, 11484, 11487, 11491, 11508, 11520, 11559, 11578, 11582, 11583, 11590, 11616, 11626, 11627, 11636, 11650, 11672, 11673, 11681, 11693, 11700, 11711, 11733, 11737, 11748, 11751, 11757, 11765, 11781, 11791, 11796, 11802, 11805, 11810, 11832, 11838, 11842, 11852, 11874, 11895, 11935, 11939, 11940, 11943, 11980, 11989, 12002, 12017, 12020, 12021, 12033, 12034, 12037, 12077, 12080, 12089, 12091, 12125, 12136, 12166, 12184, 12193, 12194, 12195, 12212, 12244, 12276, 12312, 12324, 12330, 12361, 12362, 12371, 12374, 12386, 12404, 12417, 12455, 12475, 12515, 12518, 12525, 12529, 12541, 12545, 12546, 12560, 12567, 12569, 12592, 12611, 12651, 12656, 12673, 12676, 12678, 12722, 12725, 12736, 12742, 12757, 12758, 12772, 12782, 12785, 12806, 12833, 12835, 12837, 12849, 12851, 12858, 12888, 12892, 12895, 12922, 12956, 12987, 13013, 13030, 13033, 13063, 13066, 13069, 13078, 13091, 13111, 13112, 13150, 13180, 13196, 13199, 13220, 13235, 13239, 13242, 13244, 13286, 13288, 13296, 13298, 13308, 13313, 13338, 13347, 13360, 13384, 13386, 13412, 13444, 13478, 13489, 13490, 13526, 13529, 13560, 13561, 13570, 13571, 13572, 13576, 13592, 13613, 13635, 13641, 13702, 13746, 13750, 13757, 13773, 13814, 13835, 13869, 13878, 13881, 13904, 13906, 13918, 13923, 13928, 13931, 13937, 13979, 13998, 14039, 14052, 14069, 14075, 14090, 14095, 14098, 14121, 14129, 14145, 14179, 14180, 14194, 14200, 14226, 14247, 14249, 14254, 14261, 14271, 14280, 14309, 14313, 14319, 14326, 14345, 14357, 14409, 14457, 14467, 14485, 14491, 14495, 14499, 14504, 14520, 14526, 14530, 14540, 14541, 14552, 14576, 14581, 14584, 14591, 14594, 14614, 14641, 14665, 14679, 14686, 14757, 14782, 14786, 14793, 14796, 14804, 14813, 14842, 14846, 14874, 14901, 14917, 14930, 15024, 15038, 15040, 15051, 15054, 15072, 15078, 15084, 15091, 15096, 15111, 15122, 15133, 15137, 15149, 15180, 15218, 15259, 15263, 15264, 15273, 15275, 15279, 15299, 15304, 15305, 15318, 15320, 15346, 15361, 15365, 15395, 15442, 15457, 15459, 15480, 15516, 15528, 15539, 15571, 15578, 15585, 15630, 15632, 15635, 15660, 15670, 15679, 15714, 15740, 15764, 15794, 15894, 15926, 15930, 15946, 15956, 15981, 15987, 15989, 15998, 16028, 16034, 16037, 16060, 16067, 16087, 16092, 16096, 16145, 16159, 16173, 16183, 16186, 16189, 16191, 16201, 16206, 16208, 16219, 16231, 16237, 16241, 16272, 16313, 16323, 16349, 16361, 16366, 16367, 16373, 16390, 16410, 16417, 16479, 16489, 16505, 16506, 16507, 16523, 16536, 16581, 16583, 16588, 16607, 16612, 16617, 16637, 16644, 16650, 16651, 16658, 16667, 16673, 16675, 16687, 16724, 16748, 16783, 16795, 16882, 16927, 16941, 16954, 16963, 16989, 17018, 17040, 17075, 17120, 17128, 17134, 17135, 17147, 17149, 17155, 17162, 17246, 17251, 17258, 17261, 17269, 17299, 17305, 17320, 17336, 17347, 17361, 17370, 17371, 17380, 17395, 17396, 17404, 17428, 17467, 17497, 17527, 17539, 17563, 17573, 17576, 17578, 17599, 17621, 17622, 17647, 17661, 17665, 17692, 17726, 17735, 17737, 17738, 17748, 17762, 17791, 17797, 17824, 17841, 17842, 17864, 17881, 17894, 17897, 17898, 17904, 17921, 17938, 17939, 17943, 17956, 17982, 17992, 17998, 18011, 18028, 18071, 18076, 18086, 18095, 18135, 18136, 18143, 18154, 18168, 18205, 18216, 18226, 18229, 18231, 18238, 18241, 18296, 18301, 18337, 18360, 18366, 18369, 18381, 18392, 18430, 18474, 18483, 18486, 18492, 18506, 18508, 18511, 18524, 18535, 18536, 18564, 18576, 18632, 18643, 18653, 18673, 18679, 18686, 18727, 18750, 18754, 18765, 18769, 18774, 18780, 18790, 18842, 18853, 18875, 18906, 18918, 18928, 19041, 19043, 19062, 19068, 19097, 19100, 19110, 19131, 19144, 19162, 19170, 19192, 19207, 19211, 19213, 19221, 19223, 19246, 19266, 19282, 19283, 19311, 19312, 19316, 19319, 19336, 19371, 19379, 19383, 19390, 19428, 19438, 19466, 19482, 19498, 19511, 19520, 19525, 19601, 19610, 19611, 19632, 19640, 19645, 19657, 19660, 19662, 19674, 19675, 19696, 19705, 19768, 19772, 19774, 19785, 19787, 19790, 19805, 19818, 19846, 19860, 19866, 19895, 19898, 19911, 19948, 19951, 19958, 19983, 20043, 20050, 20071, 20094, 20097, 20101, 20114, 20205, 20207, 20209, 20217, 20229, 20236, 20239, 20258, 20262, 20304, 20318, 20358, 20372, 20392, 20407, 20420, 20424, 20429, 20559, 20563, 20580, 20590, 20595, 20624, 20637, 20643, 20647, 20655, 20659, 20663, 20708, 20712, 20728, 20734, 20739, 20752, 20763, 20768, 20779, 20795, 20817, 20823, 20831, 20852, 20858, 20905, 20938, 20946, 20962, 20989, 20991, 20992, 21008, 21014, 21058, 21075, 21084, 21100, 21109, 21150, 21175, 21207, 21208, 21210, 21229, 21237, 21245, 21250, 21264, 21265, 21273, 21284, 21294, 21322, 21341, 21348, 21350, 21379, 21393, 21400, 21478, 21484, 21491, 21494, 21505, 21506, 21514, 21555, 21607, 21613, 21616, 21619, 21654, 21661, 21665, 21708, 21716, 21721, 21734, 21756, 21783, 21784, 21786, 21792, 21800, 21811, 21840, 21884, 21926, 21955, 21983, 22004, 22012, 22016, 22030, 22039, 22042, 22051, 22054, 22057, 22078, 22087, 22090, 22094, 22125, 22131, 22153, 22172, 22193, 22205, 22206, 22208, 22225, 22231, 22236, 22244, 22257, 22258, 22264, 22289, 22296, 22307, 22325, 22333, 22370, 22432, 22433, 22441, 22442, 22453, 22473, 22482, 22484, 22487, 22513, 22516, 22586, 22623, 22626, 22638, 22679, 22683, 22694, 22696, 22697, 22736, 22737, 22759, 22760, 22765, 22778, 22779, 22782, 22809, 22879, 22893, 22914, 22916, 22972, 22978, 22979, 22985, 22989, 22993, 23009, 23013, 23019, 23028, 23045, 23056, 23071, 23092, 23096, 23122, 23127, 23154, 23182, 23199, 23205, 23223, 23232, 23235, 23239, 23256, 23261, 23263, 23274, 23293, 23299, 23330, 23336, 23337, 23354, 23384, 23430, 23462, 23469, 23489, 23492, 23501, 23504, 23543, 23593, 23600, 23631, 23644, 23654, 23663, 23680, 23695, 23699, 23719, 23731, 23733, 23759, 23762, 23778, 23783, 23803, 23805, 23809, 23826, 23865, 23868, 23909, 23926, 23928, 23943, 23945, 23991, 24004, 24008, 24034, 24037, 24051, 24060, 24074, 24085, 24092, 24094, 24140, 24149, 24150, 24166, 24169, 24182, 24184, 24203, 24213, 24219, 24222, 24229, 24247, 24249, 24255, 24267, 24280, 24300, 24306, 24314, 24325, 24352, 24362, 24376, 24397, 24405, 24415, 24417, 24429, 24441, 24446, 24464, 24493, 24509, 24512, 24515, 24533, 24551, 24560, 24562, 24570, 24572, 24580, 24612, 24623, 24647, 24657, 24668, 24669, 24675, 24723, 24732, 24742, 24771, 24784, 24789, 24811, 24818, 24821, 24829, 24832, 24842, 24860, 24919, 24936, 24939, 24978, 24984, 25005, 25046, 25053, 25057, 25060, 25068, 25089, 25106, 25132, 25146, 25182, 25197, 25200, 25213, 25231, 25233, 25251, 25256, 25258, 25268, 25297, 25319, 25356, 25378, 25381, 25385, 25386, 25425, 25436, 25453, 25465, 25484, 25495, 25517, 25520, 25526, 25540, 25560, 25568, 25589, 25623, 25626, 25639, 25686, 25687, 25745, 25753, 25767, 25779, 25786, 25787, 25802, 25831, 25833, 25850, 25861, 25894, 25903, 25905, 25906, 25908, 25926, 25935, 25942, 25951, 25994, 26002, 26011, 26021, 26023, 26037, 26075, 26087, 26089, 26097, 26101, 26107, 26121, 26141, 26147, 26185, 26186, 26204, 26271, 26272, 26277, 26289, 26297, 26310, 26319, 26324, 26332, 26341, 26378, 26396, 26418, 26425, 26426, 26456, 26499, 26514, 26519, 26523, 26527, 26535, 26545, 26555, 26577, 26584, 26600, 26627, 26632, 26651, 26653, 26657, 26662, 26664, 26677, 26678, 26681, 26690, 26697, 26698, 26708, 26714, 26736, 26753, 26765, 26795, 26812, 26828, 26835, 26847, 26862, 26866, 26873, 26899, 26917, 26939, 26974, 26988, 26994, 27008, 27097, 27102, 27105, 27107, 27123, 27139, 27181, 27196, 27197, 27224, 27235, 27238, 27249, 27263, 27297, 27300, 27371, 27378, 27405, 27442, 27477, 27535, 27537, 27548, 27566, 27577, 27595, 27601, 27606, 27618, 27619, 27630, 27636, 27654, 27657, 27702, 27713, 27739, 27752, 27754, 27786, 27804, 27818, 27821, 27825, 27832, 27858, 27863, 27877, 27894, 27907, 27920, 27936, 27940, 27943, 27960, 27966, 27979, 27997, 28010, 28024, 28078, 28103, 28107, 28121, 28129, 28132, 28166, 28171, 28175, 28176, 28183, 28196, 28200, 28213, 28232, 28246, 28247, 28268, 28304, 28360, 28361, 28386, 28401, 28410, 28413, 28435, 28440, 28455, 28478, 28479, 28480, 28481, 28482, 28496, 28528, 28543, 28560, 28573, 28580, 28589, 28597, 28639, 28672, 28675, 28693, 28785, 28789, 28797, 28800, 28807, 28816, 28846, 28858, 28882, 28892, 28897, 28899, 28904, 28916, 28942, 28943, 28948, 28963, 29031, 29120, 29143, 29145, 29147, 29155, 29181, 29226, 29254, 29284, 29325, 29331, 29340, 29342, 29356, 29358, 29380, 29414, 29432, 29445, 29449, 29459, 29466, 29472, 29489, 29572, 29636, 29659, 29666, 29677, 29678, 29680, 29699, 29722, 29726, 29744, 29763, 29782, 29784, 29790, 29809, 29823, 29856, 29885, 29902, 29912, 29954, 29963, 29973, 30011, 30122, 30131, 30154, 30168, 30173, 30192, 30206, 30228, 30239, 30260, 30265, 30266, 30281, 30282, 30300, 30326, 30332, 30335, 30336, 30340, 30346, 30376, 30393, 30397, 30436, 30439, 30478, 30523, 30528, 30540, 30552, 30564, 30567, 30572, 30591, 30592, 30596, 30599, 30617, 30621, 30625, 30645, 30671, 30715, 30731, 30739, 30758, 30764, 30779, 30780, 30783, 30792, 30800, 30819, 30829, 30833, 30840, 30871, 30882, 30887, 30895, 30905, 30915, 30917, 30919, 30925, 30941, 30946, 30947, 30956, 30971, 30973, 30974, 30978, 31025, 31041, 31044, 31072, 31083, 31093, 31118, 31143, 31170, 31187, 31219, 31226, 31248, 31253, 31261, 31316, 31323, 31330, 31344, 31375, 31402, 31403, 31404, 31415, 31426, 31445, 31454, 31455, 31473, 31503, 31509, 31512, 31529, 31549, 31555, 31561, 31569, 31574, 31582, 31587, 31631, 31656, 31700, 31713, 31716, 31740, 31769, 31781, 31787, 31790, 31833, 31865, 31876, 31880, 31894, 31916, 31923, 31947, 31950, 31980, 32008, 32012, 32028, 32030, 32032, 32042, 32051, 32064, 32122, 32131, 32146, 32154, 32180, 32197, 32200, 32201, 32264, 32295, 32301, 32318, 32330, 32372, 32379, 32398, 32433, 32436, 32437, 32439, 32441, 32446, 32448, 32461, 32474, 32479, 32480, 32511, 32515, 32517, 32519, 32548, 32558, 32559, 32579, 32581, 32584, 32612, 32623, 32639, 32644, 32648, 32652, 32653, 32687, 32703, 32708, 32720, 32723, 32765, 32780, 32784, 32787, 32817, 32859, 32867, 32872, 32895, 32908, 32917, 32919, 32936, 32957, 32968, 32971, 33000, 33011, 33020, 33030, 33053, 33059, 33069, 33081, 33102, 33109, 33128, 33146, 33160, 33188, 33298, 33306, 33310, 33319, 33325, 33362, 33371, 33381, 33453, 33470, 33488, 33495, 33507, 33517, 33526, 33529, 33536, 33553, 33599, 33616, 33631, 33652, 33661, 33666, 33674, 33693, 33701, 33702, 33713, 33717, 33719, 33748, 33750, 33755, 33768, 33779, 33785, 33791, 33872, 33889, 33920, 33936, 33937, 33963, 33970, 33972, 33998, 34000, 34002, 34037, 34043, 34065, 34081, 34096, 34118, 34136, 34152, 34202, 34213, 34237, 34239, 34256, 34274, 34279, 34281, 34292, 34315, 34318, 34354, 34362, 34374, 34375, 34387, 34405, 34406, 34428, 34438, 34463, 34477, 34483, 34515, 34548, 34558, 34571, 34602, 34614, 34615, 34627, 34657, 34670, 34701, 34725, 34747, 34751, 34765, 34777, 34790, 34799, 34818, 34859, 34863, 34890, 34926, 34937, 34958, 34976, 34986, 34998, 35002, 35005, 35009, 35031, 35053, 35063, 35066, 35084, 35086, 35106, 35110, 35119, 35128, 35158, 35191, 35218, 35265, 35270, 35295, 35305, 35330, 35344, 35365, 35366, 35369, 35384, 35397, 35424, 35434, 35438, 35477, 35493, 35529, 35540, 35574, 35595, 35609, 35610, 35613, 35614, 35617, 35630, 35633, 35641, 35660, 35661, 35671, 35672, 35675, 35678, 35724, 35727, 35732, 35761, 35770, 35785, 35788, 35789, 35800, 35807, 35810, 35812, 35814, 35855, 35865, 35867, 35868, 35872, 35904, 35923, 35937, 35997, 36014, 36017, 36030, 36041, 36058, 36060, 36082, 36086, 36090, 36106, 36136, 36176, 36197, 36223, 36241, 36259, 36268, 36271, 36283, 36300, 36302, 36318, 36325, 36328, 36339, 36341, 36354, 36369, 36373, 36375, 36400, 36410, 36415, 36418, 36423, 36436, 36498, 36509, 36527, 36553, 36555, 36574, 36579, 36607, 36635, 36662, 36663, 36684, 36697, 36707, 36713, 36719, 36722, 36730, 36733, 36744, 36748, 36765, 36769, 36793, 36794, 36801, 36809, 36811, 36828, 36836, 36850, 36887, 36893, 36901, 36913, 36963, 36964, 36971, 36986, 36993, 36997, 37002, 37003, 37064, 37089, 37090, 37098, 37106, 37109, 37114, 37116, 37131, 37132, 37193, 37199, 37215, 37218, 37235, 37285, 37293, 37304, 37320, 37329, 37348, 37351, 37360, 37378, 37388, 37437, 37440, 37450, 37456, 37495, 37502, 37521, 37532, 37549, 37572, 37593, 37610, 37620, 37653, 37655, 37660, 37692, 37698, 37705, 37728, 37750, 37757, 37765, 37791, 37805, 37807, 37823, 37825, 37867, 37887, 37925, 37933, 37947, 37951, 37991, 38002, 38022, 38088, 38094, 38111, 38136, 38193, 38213, 38240, 38266, 38275, 38283, 38308, 38331, 38346, 38348, 38355, 38380, 38386, 38413, 38449, 38450, 38454, 38462, 38474, 38495, 38500, 38534, 38565, 38568, 38596, 38618, 38620, 38628, 38653, 38659, 38661, 38684, 38688, 38699, 38702, 38711, 38712, 38736, 38740, 38749, 38774, 38782, 38827, 38841, 38848, 38853, 38866, 38882, 38898, 38907, 38914, 38922, 38928, 38931, 38958, 38986, 38989, 38999, 39004, 39008, 39009, 39030, 39067, 39077, 39102, 39119, 39121, 39140, 39161, 39176, 39199, 39212, 39215, 39275, 39291, 39309, 39318, 39349, 39354, 39372, 39374, 39375, 39387, 39412, 39418, 39426, 39430, 39457, 39466, 39474, 39491, 39513, 39516, 39520, 39529, 39537, 39558, 39562, 39585, 39587, 39592, 39602, 39604, 39613, 39620, 39649, 39676, 39677, 39703, 39717, 39720, 39768, 39769, 39775, 39794, 39810, 39820, 39833, 39853, 39855, 39872, 39877, 39881, 39892, 39895, 39907, 39912, 39914, 39924, 39925, 39946, 39960, 39961, 39982, 39993, 40019, 40022, 40039, 40056, 40070, 40118, 40137, 40138, 40145, 40146, 40149, 40151, 40178, 40185, 40190, 40222, 40239, 40245, 40260, 40261, 40268, 40287, 40312, 40321, 40331, 40343, 40344, 40363, 40369, 40373, 40450, 40451, 40462, 40492, 40499, 40501, 40521, 40530, 40574, 40586, 40598, 40601, 40615, 40618, 40627, 40709, 40749, 40752, 40774, 40799, 40825, 40853, 40886, 40887, 40889, 40894, 40906, 40915, 40946, 40952, 40964, 40966, 40998, 41018, 41028, 41031, 41033, 41037, 41055, 41056, 41086, 41088, 41109, 41145, 41162, 41164, 41184, 41199, 41205, 41229, 41279, 41286, 41288, 41300, 41310, 41311, 41313, 41326, 41337, 41355, 41358, 41359, 41364, 41397, 41414, 41418, 41449, 41470, 41477, 41494, 41501, 41517, 41525, 41534, 41542, 41552, 41562, 41573, 41590, 41618, 41628, 41629, 41668, 41678, 41680, 41685, 41694, 41701, 41713, 41732, 41780, 41781, 41799, 41805, 41808, 41819, 41850, 41857, 41885, 41915, 41919, 41945, 41947, 41952, 41979, 41983, 41988, 41999, 42013, 42015, 42032, 42046, 42055, 42082, 42109, 42135, 42141, 42162, 42169, 42187, 42210, 42213, 42239, 42244, 42259, 42279, 42314, 42341, 42345, 42353, 42357, 42382, 42384, 42405, 42433, 42464, 42465, 42468, 42491, 42504, 42509, 42514, 42518, 42547, 42573, 42593, 42621, 42629, 42632, 42634, 42652, 42704, 42715, 42725, 42760, 42767, 42796, 42816, 42823, 42832, 42838, 42853, 42856, 42882, 42888, 42958, 42960, 42974, 42991, 43004, 43011, 43023, 43028, 43034, 43051, 43076, 43078, 43079, 43116, 43121, 43169, 43174, 43200, 43204, 43213, 43220, 43252, 43262, 43293, 43304, 43324, 43337, 43339, 43375, 43399, 43403, 43416, 43417, 43465, 43508, 43509, 43513, 43517, 43562, 43582, 43584, 43595, 43601, 43649, 43655, 43657, 43668, 43676, 43677, 43681, 43702, 43721, 43736, 43763, 43766, 43796, 43800, 43814, 43843, 43848, 43862, 43894, 43896, 43920, 43926, 43947, 43962, 43984, 43996, 44002, 44022, 44056, 44069, 44085, 44103, 44111, 44124, 44139, 44148, 44153, 44249, 44265, 44282, 44292, 44328, 44332, 44340, 44376, 44395, 44401, 44439, 44489, 44500, 44516, 44527, 44541, 44555, 44570, 44587, 44646, 44653, 44658, 44668, 44669, 44674, 44682, 44691, 44785, 44792, 44796, 44828, 44832, 44838, 44843, 44851, 44860, 44873, 44889, 44909, 44917, 44925, 44947, 44949, 44966, 44973, 44982, 44995, 45026, 45043, 45047, 45049, 45055, 45060, 45091, 45111, 45122, 45135, 45152, 45155, 45173, 45179, 45182, 45189, 45230, 45277, 45279, 45293, 45298, 45305, 45311, 45342, 45354, 45377, 45380, 45388, 45396, 45422, 45426]\n"
     ]
    }
   ],
   "source": [
    "print(count)\n",
    "print(idxx[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm = read_image(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-84.109, -83.805, -84.042, -82.897, -84.603, -82.87 , -83.273,\n",
       "       -83.618, -83.755, -83.578, -84.306, -84.746, -84.837, -84.373,\n",
       "       -84.707, -83.461, -83.877, -83.358, -82.371, -79.762, -78.72 ,\n",
       "       -76.838, -73.465, -73.207, -73.174, -76.014, -78.569, -80.534,\n",
       "       -82.715, -83.018, -84.242, -82.866, -83.854, -82.913, -82.812,\n",
       "       -82.339, -82.664, -83.088, -82.979, -84.   , -83.324, -82.779,\n",
       "       -83.599, -83.397, -83.483, -82.898, -82.678, -82.429, -81.751,\n",
       "       -78.915, -76.346, -74.316, -69.5  , -64.095, -66.609, -71.703,\n",
       "       -75.658, -78.365, -80.388, -82.318, -82.108, -81.191, -82.708,\n",
       "       -81.709, -82.198, -80.884, -81.334, -83.268, -81.736, -82.197,\n",
       "       -82.973, -82.939, -83.02 , -83.291, -82.869, -82.017, -82.109,\n",
       "       -81.284, -80.863, -77.688, -76.156, -71.285, -62.591, -48.07 ,\n",
       "       -59.79 , -70.885, -74.361, -76.36 , -80.072, -81.596, -81.84 ,\n",
       "       -80.709, -80.451, -80.148, -80.047, -79.648, -80.114, -80.651,\n",
       "       -81.023, -80.853, -81.462, -81.616, -81.71 , -81.875, -82.3  ,\n",
       "       -82.9  , -81.905, -80.964, -80.101, -78.916, -76.698, -72.896,\n",
       "       -64.535, -55.926, -63.197, -68.975, -72.424, -75.038, -78.96 ,\n",
       "       -80.223, -81.697, -78.558, -78.227, -78.214, -78.112, -76.184,\n",
       "       -78.825, -78.994, -79.589, -80.591, -80.609, -80.4  , -82.477,\n",
       "       -82.398, -82.228, -81.621, -80.385, -81.102, -80.678, -78.631,\n",
       "       -76.493, -73.535, -70.724, -68.157, -68.242, -68.702, -51.603,\n",
       "       -72.703, -79.316, -80.583, -79.829, -77.603, -76.404, -75.933,\n",
       "       -75.915, -76.507, -76.398, -77.177, -78.929, -79.553, -78.546,\n",
       "       -79.827, -80.678, -80.183, -80.584, -80.592, -80.892, -81.182,\n",
       "       -79.926, -78.886, -79.018, -74.583, -74.718, -73.582, -73.595,\n",
       "       -73.162, -68.192, -75.585, -78.406, -80.707, -75.963, -75.176,\n",
       "       -72.669, -73.392, -72.328, -73.999, -74.299, -75.602, -76.053,\n",
       "       -77.661, -78.274, -78.519, -78.446, -79.248, -80.187, -80.829,\n",
       "       -81.198, -80.175, -79.951, -79.405, -78.417, -77.193, -77.144,\n",
       "       -75.34 , -75.787, -76.398, -75.909, -76.967, -78.675, -81.623,\n",
       "       -76.945, -72.461, -71.525, -68.547, -68.668, -69.13 , -71.609,\n",
       "       -72.995, -75.052, -75.97 , -76.047, -77.541, -76.786, -79.003,\n",
       "       -80.105, -79.761, -80.658, -80.442, -79.833, -79.248, -78.889,\n",
       "       -77.258, -77.399, -76.723, -77.676, -78.549, -78.093, -79.105,\n",
       "       -80.186, -80.498, -73.286, -70.635, -68.491, -64.038, -62.169,\n",
       "       -64.815, -69.435, -72.907, -74.59 , -74.581, -74.736, -75.919,\n",
       "       -75.492, -76.919, -77.546, -78.994, -79.271, -79.188, -79.465,\n",
       "       -78.244, -77.557, -77.121, -75.701, -74.72 , -75.743, -77.235,\n",
       "       -77.026, -78.844, -79.753, -79.57 , -73.282, -68.912, -65.19 ,\n",
       "       -58.256, -48.703, -61.128, -67.886, -70.094, -72.867, -71.432,\n",
       "       -71.242, -71.632, -71.662, -74.872, -77.776, -78.429, -78.139,\n",
       "       -78.125, -78.396, -77.469, -76.552, -76.127, -75.126, -75.091,\n",
       "       -74.104, -75.078, -76.746, -78.343, -78.561, -80.157, -73.883,\n",
       "       -70.108, -63.125, -55.391, -45.752, -59.447, -66.04 , -72.676,\n",
       "       -71.787, -70.081, -67.593, -64.815, -66.948, -72.415, -75.683,\n",
       "       -77.52 , -77.916, -78.288, -78.772, -77.099, -73.417, -73.346,\n",
       "       -71.35 , -70.833, -70.77 , -73.407, -75.352, -76.726, -77.658,\n",
       "       -80.123, -72.439, -70.899, -67.679, -61.984, -59.497, -64.994,\n",
       "       -68.687, -71.823, -70.26 , -69.254, -60.062, -51.658, -63.136,\n",
       "       -68.905, -74.444, -75.911, -77.975, -76.94 , -77.323, -74.702,\n",
       "       -73.663, -71.796, -66.57 , -66.294, -68.321, -68.89 , -72.427,\n",
       "       -74.055, -77.218, -79.202, -74.414, -73.128, -68.994, -68.264,\n",
       "       -67.334, -66.024, -70.197, -71.388, -72.012, -67.512, -60.216,\n",
       "       -52.048, -61.466, -69.85 , -73.96 , -75.445, -77.23 , -77.694,\n",
       "       -76.333, -75.123, -71.074, -66.665, -63.324, -57.089, -62.752,\n",
       "       -68.035, -71.351, -74.108, -76.235, -77.611, -76.65 , -76.326,\n",
       "       -73.233, -70.057, -70.992, -72.803, -72.877, -74.586, -73.617,\n",
       "       -71.022, -67.169, -65.733, -68.147, -71.56 , -74.351, -77.617,\n",
       "       -77.637, -77.252, -77.247, -75.25 , -69.941, -64.694, -56.919,\n",
       "       -29.537, -56.831, -64.157, -71.974, -74.491, -76.423, -77.648,\n",
       "       -76.788, -76.109, -75.684, -75.156, -74.864, -74.054, -75.596,\n",
       "       -75.2  , -73.709, -74.964, -71.512, -70.942, -72.91 , -75.398,\n",
       "       -77.644, -77.367, -78.466, -78.355, -75.853, -74.953, -69.382,\n",
       "       -67.068, -61.878, -56.302, -59.54 , -64.624, -68.994, -73.659,\n",
       "       -75.98 , -76.797, -78.096, -77.151, -78.28 , -76.091, -76.614,\n",
       "       -76.756, -76.469, -76.614, -75.66 , -75.557, -74.966, -75.55 ,\n",
       "       -75.84 , -76.445, -78.3  , -78.262, -78.034, -78.058, -76.634,\n",
       "       -74.644, -73.842, -70.537, -66.441, -64.699, -67.378, -70.019,\n",
       "       -72.183, -75.206, -75.427, -76.358, -79.214, -79.546, -79.099,\n",
       "       -77.325, -76.977, -75.991, -76.187, -76.501, -76.605, -76.481,\n",
       "       -77.07 , -76.415, -76.869, -77.511, -79.174, -78.579, -78.199,\n",
       "       -78.49 , -78.056, -75.688, -76.046, -71.599, -73.019, -71.402,\n",
       "       -70.624, -72.112, -73.955, -74.769, -74.986, -74.202, -78.675,\n",
       "       -77.713, -78.451, -78.806, -78.03 , -77.824, -78.361, -77.2  ,\n",
       "       -77.985, -77.454, -78.443, -77.998, -78.278, -77.455, -78.802,\n",
       "       -78.103, -78.476, -77.956, -77.145, -76.782, -74.6  , -74.246,\n",
       "       -73.853, -72.679, -73.022, -72.548, -73.523, -73.069, -73.634,\n",
       "       -75.31 , -80.051, -79.868, -78.856, -78.548, -78.382, -78.182,\n",
       "       -78.481, -78.633, -77.908, -78.924, -77.922, -78.346, -77.811,\n",
       "       -78.882, -78.37 , -78.641, -78.511, -77.922, -77.437, -77.302,\n",
       "       -75.674, -75.703, -74.486, -74.082, -75.415, -73.67 , -74.146,\n",
       "       -72.483, -72.857, -73.43 , -79.711, -79.973, -78.179, -78.304,\n",
       "       -78.708, -77.695, -78.281, -77.354, -77.884, -77.991, -77.294,\n",
       "       -77.609, -77.623, -77.203, -78.011, -78.17 , -78.219, -78.097,\n",
       "       -77.586, -76.597, -76.659, -76.068, -75.177, -75.024, -75.609,\n",
       "       -72.639, -72.626, -71.896, -70.159, -70.734, -79.119, -78.491,\n",
       "       -78.546, -77.717, -77.764, -77.149, -77.202, -77.406, -76.984,\n",
       "       -75.785, -76.429, -77.015, -76.712, -77.577, -76.969, -77.726,\n",
       "       -77.714, -76.817, -77.316, -76.389, -75.191, -76.14 , -75.392,\n",
       "       -74.169, -72.546, -72.686, -71.661, -70.782, -69.535, -67.087,\n",
       "       -76.962, -76.831, -77.13 , -76.916, -76.098, -75.951, -75.632,\n",
       "       -75.145, -76.282, -75.446, -74.995, -74.81 , -75.628, -75.831,\n",
       "       -76.586, -75.706, -76.179, -75.719, -77.137, -76.189, -75.817,\n",
       "       -74.475, -74.35 , -74.134, -73.47 , -71.307, -67.972, -67.297,\n",
       "       -64.515, -65.241, -76.445, -75.797, -76.148, -75.337, -75.473,\n",
       "       -73.422, -73.698, -74.399, -72.354, -72.803, -71.523, -72.491,\n",
       "       -74.852, -74.354, -74.551, -74.95 , -75.108, -76.168, -75.307,\n",
       "       -74.741, -74.706, -74.306, -73.068, -72.129, -70.955, -70.896,\n",
       "       -65.874, -60.822, -57.818, -58.548, -73.351, -73.993, -75.089,\n",
       "       -73.911, -72.06 , -70.435, -71.065, -71.385, -70.397, -68.973,\n",
       "       -67.24 , -70.122, -71.226, -73.162, -71.989, -72.378, -72.372,\n",
       "       -73.399, -73.611, -72.935, -71.174, -71.211, -73.294, -73.282,\n",
       "       -70.314, -67.789, -66.302, -59.844, -53.617, -49.237, -68.741,\n",
       "       -70.308, -72.603, -72.604, -68.927, -48.859, -68.593, -66.352,\n",
       "       -66.685, -64.629, -54.361, -63.398, -70.013, -70.548, -70.241,\n",
       "       -67.132, -67.853, -70.551, -71.268, -68.189, -65.773, -70.486,\n",
       "       -71.759, -73.436, -70.892, -66.575, -65.677, -58.013, -47.463,\n",
       "       -22.097, -58.824, -68.037, -71.124, -72.09 , -70.526, -66.324,\n",
       "       -65.415, -58.598, -58.237, -62.302, -55.849, -63.956, -68.371,\n",
       "       -67.252, -64.036, -58.521, -64.688, -68.84 , -69.703, -59.697,\n",
       "       -52.878, -65.171, -71.78 , -73.925, -71.64 , -67.845, -63.81 ,\n",
       "       -58.832, -54.919, -50.5  , -54.614, -66.515, -68.517, -71.053,\n",
       "       -71.247, -69.019, -66.607, -55.092, -44.098, -60.208, -66.529,\n",
       "       -67.958, -70.648, -68.588, -60.557, -30.13 , -60.112, -68.373,\n",
       "       -69.844, -63.423, -61.216, -66.594, -71.866, -71.768, -70.785,\n",
       "       -70.864, -67.091, -64.446, -60.538, -58.848, -63.848, -64.424,\n",
       "       -67.312, -71.774, -71.422, -69.758, -67.16 , -62.938, -61.933,\n",
       "       -64.926, -70.231, -71.221, -71.752, -70.043, -66.456, -60.377,\n",
       "       -65.322, -70.655, -71.373, -71.001, -69.882, -70.905, -72.944,\n",
       "       -74.057, -73.212, -71.976, -69.331, -66.818, -64.295, -64.377,\n",
       "       -56.416, -59.617, -64.072, -67.821, -70.632, -71.631, -70.254,\n",
       "       -69.306, -68.809, -69.557, -72.595, -72.434, -72.133, -72.616,\n",
       "       -71.462, -69.584, -71.635, -72.289, -74.139, -73.546, -74.412,\n",
       "       -74.96 , -74.466, -75.051, -72.704, -72.111, -71.737, -70.32 ,\n",
       "       -69.082, -69.542, -43.776, -56.129, -62.552, -66.306, -70.51 ,\n",
       "       -71.405, -71.361, -70.652, -73.111, -73.134, -74.072, -74.584,\n",
       "       -74.821, -73.558, -73.227, -73.574, -75.214, -74.071, -75.184,\n",
       "       -74.338, -75.006, -76.402, -76.026, -74.483, -76.054, -75.331,\n",
       "       -73.297, -71.065, -71.32 , -71.2  ,   1.   , 604.   , 130.   ,\n",
       "        -3.849,   1.   ,  32.451])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f21b97f3310>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 4320x4320 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(60,60))         # Sample figsize in inches\n",
    "sns.heatmap(imm[0][6], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(num_filters, kernel_lam, bias_lam):\n",
    "#     num_filters, lam = 5, 5\n",
    "    data_format = 'channels_first'\n",
    "    convolution_init, dense_init = \"lecun_normal\", \"RandomNormal\"\n",
    "    convolution_filter, dense_filter = 'selu', 'linear' #softsign, sigmoid; relu, linear\n",
    "    filter_shape, pool_size = (3, 3), (2,2)\n",
    "    cnn = models.Sequential()\n",
    "    cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size=pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(2*num_filters, filter_shape,padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size=pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(2*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "#                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                          kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "#                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                          kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam), \n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(2*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "#                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                          kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam), \n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "#                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                          kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Flatten())\n",
    "    cnn.add(layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=convolution_init))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization())\n",
    "    cnn.add(layers.Dense(1, activation=dense_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=dense_init))\n",
    "    return cnn\n",
    "\n",
    "\n",
    "class DataBatchGenerator(Sequence):\n",
    "    def __init__(self, dataset:np.ndarray, batch_size:int, start_idx:int, number_image_channels:int,\n",
    "                 max_x, max_y, float_memory_used):\n",
    "#         print(dataset.shape[0])\n",
    "        self.dataset, self.batch_size, self.start_idx = dataset, batch_size, start_idx\n",
    "        self.number_image_channels, self.max_x, self.max_y = number_image_channels, max_x, max_y\n",
    "        self.float_memory_used = float_memory_used\n",
    "    \n",
    "    def __len__(self):\n",
    "        return np.ceil(self.dataset.shape[0] / self.batch_size).astype(np.int)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        size = min(self.dataset.shape[0] - idx * self.batch_size, self.batch_size)\n",
    "        batch_x = np.empty((size, self.number_image_channels, self.max_x, self.max_y), dtype=self.float_memory_used)\n",
    "        batch_y = np.empty((size), dtype=self.float_memory_used)\n",
    "        for i in range(size):\n",
    "            batch_x[i] = read_image(self.start_idx + idx * self.batch_size + i)\n",
    "            batch_y[i] = self.dataset[idx * self.batch_size + i][-1]\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "def custom_loss(fp_penalty_coef, fn_penalty_coef):\n",
    "    # custom loss function that penalize false positive and negative differently\n",
    "    def loss(y_true, y_pred):\n",
    "        res = y_pred - y_true\n",
    "        res = tf.where(res > 0, res * fp_penalty_coef, res * fn_penalty_coef)\n",
    "        return K.mean(K.square(res))\n",
    "    return loss\n",
    "\n",
    "def fp_mae(y_true, y_pred):\n",
    "    # custom metric that replace false negative with zero and return the mean of new vector\n",
    "    res = y_pred - y_true\n",
    "    res = tf.nn.relu(res)\n",
    "#     res = tf.where(res <= 0, 0, res)\n",
    "    return K.mean(res)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(10, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 10, 1000, 1000)    640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 500, 500)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10, 500, 500)      40        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 500, 500)      1820      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 20, 250, 250)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 20, 250, 250)      80        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 250, 250)      5430      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 125, 125)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 125, 125)      120       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 40, 125, 125)      10840     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 40, 62, 62)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 40, 62, 62)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 40, 62, 62)        14440     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 40, 31, 31)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 40, 31, 31)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 40, 31, 31)        14440     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 40, 15, 15)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 40, 15, 15)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 40, 15, 15)        14440     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 40, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 40, 7, 7)          160       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1960)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                39220     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 102,671\n",
      "Trainable params: 102,191\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_samples: 8192 , New samples: 8192\n",
      "Validation size: 2704 , starts: 8192 , ends: 10895\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 7.37824, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00002: val_mae improved from 7.37824 to 7.32890, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 7.32890\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 7.32890\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 7.32890\n",
      "\n",
      "Epoch 00006: val_mae improved from 7.32890 to 7.19969, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 7.19969\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 7.19969\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 7.19969\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 7.19969\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 7.19969\n",
      "\n",
      "Epoch 00012: val_mae improved from 7.19969 to 7.10344, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 7.10344\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 7.10344\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 7.10344\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 7.10344\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 7.10344\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 7.10344\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 7.10344\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 7.10344\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 7.10344\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 7.10344\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 7.10344\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 7.10344\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 7.10344\n",
      "\n",
      "Lambda: 0 , Time: 3:51:05\n",
      "Train Error(all epochs): 3.6595736 \n",
      " [15.327, 7.64, 7.44, 7.308, 7.217, 7.159, 7.063, 7.026, 6.982, 6.866, 6.741, 6.667, 6.493, 6.328, 6.196, 5.949, 5.738, 5.468, 5.212, 4.888, 4.644, 4.384, 4.121, 3.918, 3.66]\n",
      "Train FP Error(all epochs): 1.6976804 \n",
      " [1.698, 3.601, 3.569, 3.594, 3.553, 3.551, 3.516, 3.484, 3.466, 3.417, 3.352, 3.337, 3.25, 3.163, 3.106, 2.959, 2.862, 2.747, 2.584, 2.466, 2.312, 2.198, 2.054, 1.972, 1.838]\n",
      "Val Error(all epochs): 7.103435516357422 \n",
      " [7.378, 7.329, 7.467, 7.496, 8.352, 7.2, 7.293, 7.373, 7.28, 8.25, 7.756, 7.103, 7.421, 7.776, 9.726, 7.235, 7.313, 10.501, 7.721, 7.361, 7.728, 8.278, 8.376, 7.818, 8.113]\n",
      "Val FP Error(all epochs): 1.5571386814117432 \n",
      " [4.47, 3.853, 5.369, 4.926, 4.841, 4.248, 3.551, 3.622, 4.455, 2.416, 2.971, 4.263, 4.968, 5.768, 1.65, 4.467, 3.934, 1.557, 3.958, 4.167, 4.58, 3.612, 3.461, 3.848, 3.638]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 7.89683, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00002: val_mae improved from 7.89683 to 7.33455, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 7.33455\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 7.33455\n",
      "\n",
      "Lambda: 0.001 , Time: 3:50:01\n",
      "Train Error(all epochs): 2.9707553 \n",
      " [15.601, 7.735, 7.417, 7.309, 7.275, 7.251, 7.176, 7.049, 6.974, 6.823, 6.621, 6.407, 6.205, 5.881, 5.531, 5.181, 4.862, 4.509, 4.192, 3.966, 3.775, 3.502, 3.349, 3.161, 2.971]\n",
      "Train FP Error(all epochs): 1.4846799 \n",
      " [1.661, 3.567, 3.592, 3.583, 3.603, 3.565, 3.547, 3.525, 3.447, 3.406, 3.324, 3.197, 3.095, 2.938, 2.76, 2.597, 2.437, 2.264, 2.111, 1.965, 1.902, 1.76, 1.694, 1.574, 1.485]\n",
      "Val Error(all epochs): 7.334549903869629 \n",
      " [7.897, 7.335, 7.349, 7.429, 7.452, 12.567, 7.524, 10.24, 7.469, 7.414, 7.47, 7.576, 7.504, 7.483, 9.66, 7.697, 7.849, 7.85, 7.682, 7.931, 8.64, 8.251, 7.823, 7.913, 8.109]\n",
      "Val FP Error(all epochs): 2.103821277618408 \n",
      " [4.778, 3.899, 3.539, 3.561, 3.673, 2.104, 3.442, 2.526, 3.96, 4.816, 3.901, 3.421, 5.087, 4.861, 2.108, 4.599, 3.548, 4.517, 4.354, 3.992, 2.894, 3.276, 3.728, 4.253, 3.838]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 7.90960, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00002: val_mae improved from 7.90960 to 7.49946, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00003: val_mae improved from 7.49946 to 7.47107, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 7.47107\n",
      "\n",
      "Epoch 00005: val_mae improved from 7.47107 to 7.41729, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 7.41729\n",
      "\n",
      "Epoch 00007: val_mae improved from 7.41729 to 7.19764, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 7.19764\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 7.19764\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 7.19764\n",
      "\n",
      "Epoch 00011: val_mae improved from 7.19764 to 7.02890, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 7.02890\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 7.02890\n",
      "\n",
      "Epoch 00014: val_mae improved from 7.02890 to 6.98448, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 6.98448\n",
      "\n",
      "Epoch 00016: val_mae improved from 6.98448 to 6.77462, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 6.77462\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 6.77462\n",
      "\n",
      "Epoch 00019: val_mae improved from 6.77462 to 6.67902, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 6.67902 to 6.62352, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 6.62352\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 6.62352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00023: val_mae did not improve from 6.62352\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 6.62352\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 6.62352\n",
      "\n",
      "Lambda: 0.01 , Time: 3:48:19\n",
      "Train Error(all epochs): 3.8349254 \n",
      " [15.702, 7.808, 7.439, 7.35, 7.38, 7.303, 7.245, 7.162, 7.108, 7.066, 6.933, 6.809, 6.684, 6.557, 6.347, 6.174, 5.851, 5.596, 5.3, 5.007, 4.791, 4.519, 4.292, 4.071, 3.835]\n",
      "Train FP Error(all epochs): 1.7382325 \n",
      " [1.738, 3.5, 3.619, 3.609, 3.595, 3.632, 3.558, 3.572, 3.516, 3.52, 3.431, 3.398, 3.298, 3.28, 3.164, 3.072, 2.952, 2.795, 2.652, 2.497, 2.411, 2.262, 2.164, 2.031, 1.925]\n",
      "Val Error(all epochs): 6.623520851135254 \n",
      " [7.91, 7.499, 7.471, 7.593, 7.417, 7.672, 7.198, 7.319, 7.293, 7.643, 7.029, 7.123, 7.066, 6.984, 7.007, 6.775, 7.005, 6.96, 6.679, 6.624, 6.917, 6.72, 6.632, 6.986, 6.826]\n",
      "Val FP Error(all epochs): 2.7281148433685303 \n",
      " [5.097, 4.682, 3.34, 3.595, 3.608, 2.942, 4.172, 4.078, 3.928, 2.728, 4.022, 3.722, 4.299, 4.208, 3.353, 3.69, 4.611, 2.819, 4.59, 3.795, 3.584, 3.543, 3.73, 4.327, 3.091]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 8.29889, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00002: val_mae improved from 8.29889 to 7.40681, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00003: val_mae improved from 7.40681 to 7.35571, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 7.35571\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 7.35571\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 7.35571\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 7.35571\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 7.35571\n",
      "\n",
      "Epoch 00009: val_mae improved from 7.35571 to 7.23058, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 7.23058\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 7.23058\n",
      "\n",
      "Epoch 00012: val_mae improved from 7.23058 to 7.12910, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 7.12910\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 7.12910\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 7.12910\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 7.12910\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 7.12910\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 7.12910\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 7.12910\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 7.12910\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 7.12910\n",
      "\n",
      "Epoch 00022: val_mae improved from 7.12910 to 7.07002, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 7.07002 to 7.06871, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 7.06871\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 7.06871\n",
      "\n",
      "Lambda: 0.1 , Time: 3:46:43\n",
      "Train Error(all epochs): 4.8035865 \n",
      " [15.546, 7.597, 7.395, 7.383, 7.322, 7.293, 7.239, 7.221, 7.145, 7.08, 7.034, 6.955, 6.79, 6.682, 6.568, 6.482, 6.285, 6.133, 5.948, 5.841, 5.59, 5.418, 5.134, 5.073, 4.804]\n",
      "Train FP Error(all epochs): 1.6203955 \n",
      " [1.62, 3.505, 3.561, 3.597, 3.554, 3.579, 3.581, 3.56, 3.514, 3.473, 3.459, 3.452, 3.328, 3.311, 3.228, 3.221, 3.123, 3.051, 2.955, 2.905, 2.786, 2.69, 2.584, 2.54, 2.417]\n",
      "Val Error(all epochs): 7.068714141845703 \n",
      " [8.299, 7.407, 7.356, 7.396, 7.372, 7.398, 7.59, 15.322, 7.231, 7.337, 7.255, 7.129, 42.085, 11.832, 7.295, 7.159, 7.458, 7.979, 7.425, 7.815, 16.925, 7.07, 7.069, 13.356, 7.722]\n",
      "Val FP Error(all epochs): 0.03720635548233986 \n",
      " [5.989, 3.997, 3.561, 3.456, 4.166, 3.699, 3.971, 1.858, 4.079, 3.556, 4.07, 4.642, 0.037, 1.191, 2.882, 3.136, 5.69, 2.077, 5.762, 2.436, 0.552, 5.238, 5.082, 1.096, 4.903]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 7.33929, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_4.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 7.33929\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 7.33929\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 7.33929\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 7.33929\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 7.33929\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 7.33929\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 7.33929\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 7.33929\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 7.33929\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 7.33929\n",
      "\n",
      "Epoch 00012: val_mae improved from 7.33929 to 7.29737, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_4.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 7.29737 to 7.25953, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_4.h5\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 7.25953\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 7.25953\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 7.25953\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 7.25953\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 7.25953\n",
      "\n",
      "Epoch 00019: val_mae improved from 7.25953 to 7.24321, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_4.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 7.24321 to 7.20790, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_4.h5\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 7.20790\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 7.20790\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 7.20790\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 7.20790\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 7.20790\n",
      "\n",
      "Lambda: 1 , Time: 3:46:48\n",
      "Train Error(all epochs): 7.231047 \n",
      " [15.661, 7.795, 7.642, 7.522, 7.48, 7.45, 7.398, 7.411, 7.371, 7.341, 7.344, 7.315, 7.316, 7.319, 7.328, 7.289, 7.275, 7.255, 7.253, 7.239, 7.236, 7.239, 7.255, 7.231, 7.24]\n",
      "Train FP Error(all epochs): 1.589548 \n",
      " [1.59, 3.442, 3.454, 3.488, 3.476, 3.533, 3.516, 3.511, 3.522, 3.546, 3.527, 3.536, 3.517, 3.541, 3.547, 3.539, 3.543, 3.534, 3.527, 3.532, 3.555, 3.536, 3.52, 3.555, 3.556]\n",
      "Val Error(all epochs): 7.207896709442139 \n",
      " [7.339, 8.964, 7.48, 7.769, 7.755, 7.519, 7.499, 7.415, 7.342, 7.42, 7.39, 7.297, 7.26, 7.342, 7.341, 7.341, 7.296, 7.307, 7.243, 7.208, 7.545, 7.525, 7.264, 8.152, 7.319]\n",
      "Val FP Error(all epochs): 2.3604536056518555 \n",
      " [4.542, 2.62, 3.49, 2.892, 2.875, 3.248, 3.064, 3.587, 4.549, 3.235, 3.282, 3.604, 3.711, 3.503, 3.554, 3.415, 3.562, 3.597, 3.814, 4.239, 3.159, 3.119, 4.283, 2.36, 3.489]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 9.52174, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_5.h5\n",
      "\n",
      "Epoch 00002: val_mae improved from 9.52174 to 7.33837, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_5.h5\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 7.33837\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 7.33837\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 7.33837\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 7.33837\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 7.33837\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 7.33837\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 7.33837\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 7.33837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_mae did not improve from 7.33837\n",
      "\n",
      "Epoch 00012: val_mae improved from 7.33837 to 7.26167, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_5.h5\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 7.26167\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 7.26167\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 7.26167\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 7.26167\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 7.26167\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 7.26167\n",
      "\n",
      "Epoch 00019: val_mae improved from 7.26167 to 7.23688, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_5.h5\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 7.23688\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 7.23688\n",
      "\n",
      "Epoch 00022: val_mae improved from 7.23688 to 7.22349, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_5.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 7.22349 to 7.22043, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/models/8192/best_model_lambda_5.h5\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 7.22043\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 7.22043\n",
      "\n",
      "Lambda: 10 , Time: 3:47:26\n",
      "Train Error(all epochs): 7.234008 \n",
      " [18.919, 8.233, 7.903, 7.755, 7.647, 7.583, 7.529, 7.485, 7.448, 7.399, 7.396, 7.352, 7.345, 7.345, 7.312, 7.31, 7.283, 7.285, 7.295, 7.255, 7.257, 7.253, 7.236, 7.234, 7.251]\n",
      "Train FP Error(all epochs): 0.74087334 \n",
      " [0.741, 2.635, 2.9, 3.029, 3.083, 3.163, 3.175, 3.222, 3.23, 3.259, 3.298, 3.293, 3.312, 3.336, 3.345, 3.356, 3.367, 3.365, 3.36, 3.406, 3.38, 3.394, 3.397, 3.419, 3.409]\n",
      "Val Error(all epochs): 7.220425605773926 \n",
      " [9.522, 7.338, 7.485, 7.364, 7.785, 7.809, 7.744, 7.612, 7.479, 7.418, 7.41, 7.262, 7.274, 7.368, 7.307, 7.357, 7.472, 7.677, 7.237, 7.293, 7.322, 7.223, 7.22, 7.478, 7.251]\n",
      "Val FP Error(all epochs): 1.6088446378707886 \n",
      " [1.609, 4.582, 3.111, 3.404, 5.525, 2.622, 2.917, 3.232, 3.112, 3.263, 3.242, 3.704, 3.648, 3.365, 3.547, 3.379, 3.152, 2.794, 3.859, 3.644, 3.536, 3.995, 4.035, 3.106, 3.858]\n",
      "\n",
      "Trainig set size: 8192 , Time: 22:50:26 , best_lambda: 0.01 , min_  error: 6.624\n",
      "Test starts:  10896 , ends:  48379\n",
      "2343/2343 [==============================] - 1631s 696ms/step\n",
      "average_error:  6.538 , fp_average_error:  3.696\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CNN: support batching\n",
    "TEST = True\n",
    "mini_batch, epochs = 16, 25\n",
    "MAX_QUEUE_SIZE, WORKERS = 6, 1\n",
    "fp_penalty_coef, fn_penalty_coef = 1, 1\n",
    "hyper_metric, mode = 'val_mae', 'min'  # the metric that hyper parameters are tuned with\n",
    "prev_sample = 0\n",
    "lambda_vec = [0, 0.001, 0.01, 0.1, 1, 10]  #0.003, 0.01, 0.03, 0.1, 0.3, 1, 3\n",
    "# MODEL_PATH = 'models/'\n",
    "average_diff_power, fp_mean_power = [],[] #[7.177, 8.088, 8.183], [3.438, 3.506, 2.662]\n",
    "best_lambda = []\n",
    "# average_diff_power, fp_mean_power = [7.568, 7.916],[3.357, 2.705] \n",
    "# checkpointers = [ModelCheckpoint(filepath=MODEL_PATH + str(lamb_idx)+ '.h5',\n",
    "#                                  verbose=1, save_best_only=True, monitor=hyper_metric, mode=mode, period=1)\n",
    "#                  for lamb_idx in range(len(lambda_vec))]\n",
    "\n",
    "for num_sample_idx, number_sample in enumerate(number_samples):\n",
    "#     if num_sample_idx < 3:\n",
    "#         continue\n",
    "#     if num_sample_idx == 0:\n",
    "    MODEL_PATH = '/'.join(image_dir.split('/')[:-1]) + '/models/' + str(number_sample)\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.makedirs(MODEL_PATH)\n",
    "    MODEL_PATH += \"/best_model_lambda_\"\n",
    "    if True:\n",
    "        cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "        for cnn in cnns:\n",
    "#             cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae', fp_mean])\n",
    "            cnn.compile(loss=custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                        optimizer='adam', \n",
    "                        metrics=['mse', 'mae', fp_mae])\n",
    "        checkpointers = [ModelCheckpoint(filepath=MODEL_PATH + str(lamb_idx)+ '.h5',\n",
    "                                         verbose=1, save_best_only=True, monitor=hyper_metric, mode=mode, period=1)\n",
    "                         for lamb_idx in range(len(lambda_vec))]\n",
    "    else:\n",
    "        cnns = []\n",
    "        cnns = [models.load_model(MODEL_PATH + str(lamb_idx) + '.h5', \n",
    "                                  custom_objects={ 'loss': custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                                                  'fp_mae': fp_mae }) \n",
    "                for lamb_idx in range(len(lambda_vec))]\n",
    "    number_start = time.time()\n",
    "    train_generator = DataBatchGenerator(dataset=data_reg[prev_sample:number_sample], batch_size=mini_batch,\n",
    "                                         start_idx=prev_sample, number_image_channels=number_image_channels,\n",
    "                                         max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "    \n",
    "\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "    val_generator = DataBatchGenerator(dataset=data_reg[number_sample:number_sample+val_size], \n",
    "                                       batch_size=mini_batch,\n",
    "                                       start_idx=number_sample, number_image_channels=number_image_channels,\n",
    "                                       max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "  \n",
    "    print('number_samples:', number_sample, \", New samples:\", number_sample - prev_sample)\n",
    "    print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", number_sample + val_size - 1)\n",
    "\n",
    "    for lamb_idx, lamb in enumerate(lambda_vec[:len(lambda_vec) - num_sample_idx//2]):\n",
    "#         if num_sample_idx == 3 and lamb_idx < 4:\n",
    "#             continue\n",
    "        lambda_start = time.time()\n",
    "        cnns[lamb_idx].fit(train_generator, epochs=epochs, verbose=0, validation_data=val_generator, \n",
    "                           shuffle=True, callbacks=[checkpointers[lamb_idx]], \n",
    "                           workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, use_multiprocessing=False)\n",
    "        \n",
    "        print(\"\\nLambda:\", lamb, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - lambda_start))))\n",
    "        print(\"Train Error(all epochs):\", min(cnns[lamb_idx].history.history['mae']), '\\n', \n",
    "              [round(val, 3) for val in cnns[lamb_idx].history.history['mae']])\n",
    "        print(\"Train FP Error(all epochs):\", min(cnns[lamb_idx].history.history['fp_mae']), '\\n',\n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['fp_mae']])\n",
    "        print(\"Val Error(all epochs):\", min(cnns[lamb_idx].history.history['val_mae']), '\\n', \n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['val_mae']])\n",
    "        print(\"Val FP Error(all epochs):\", min(cnns[lamb_idx].history.history['val_fp_mae']), '\\n',\n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['val_fp_mae']])\n",
    "#     if num_sample_idx == 3:    \n",
    "#         models_min_mae = [8.27781, 8.23545, 8.20838, 7.74743]\n",
    "#         models_min_mae += [min(cnns[lamb_idx].history.history[hyper_metric]) for lamb_idx in range(4,lamb_idx+1)]\n",
    "#     else:\n",
    "    models_min_mae = [min(cnns[lamb_idx].history.history[hyper_metric]) for lamb_idx in range(lamb_idx+1)]\n",
    "    best_lamb_idx = models_min_mae.index(min(models_min_mae))\n",
    "    best_lambda.append(lambda_vec[best_lamb_idx])\n",
    "    print(\"\\nTrainig set size:\", number_sample, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - \n",
    "                                                                                              number_start)))\n",
    "          ,\", best_lambda:\", lambda_vec[best_lamb_idx], \", min_\" , (\"fp_\" if hyper_metric == \"val_fp_mae\" else \"\"),\n",
    "          \"error:\", round(min(models_min_mae), 3))\n",
    "    del cnns, train_generator, val_generator, checkpointers\n",
    "    \n",
    "    if TEST:\n",
    "        # evaluating test images\n",
    "        best_model = None\n",
    "        best_model = models.load_model(MODEL_PATH + str(best_lamb_idx) + '.h5', \n",
    "                                       custom_objects={ 'loss': custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                                                       'fp_mae': fp_mae })\n",
    "        test_generator = DataBatchGenerator(dataset=data_reg[number_sample + val_size:], \n",
    "                                            batch_size=mini_batch,\n",
    "                                            start_idx=number_sample + val_size, \n",
    "                                            number_image_channels=number_image_channels,\n",
    "                                            max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "\n",
    "        print(\"Test starts: \", number_sample + val_size, \", ends: \", data_reg.shape[0] - 1)\n",
    "        time.sleep(1)\n",
    "        test_res = best_model.evaluate(test_generator, verbose=1, \n",
    "                                       workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, use_multiprocessing=False)\n",
    "        \n",
    "        test_mae_idx, test_fp_mae_idx = [best_model.metrics_names.index(mtrc) for mtrc in ['mae','fp_mae']]\n",
    "        test_mae, test_fp_mae = test_res[test_mae_idx], test_res[test_fp_mae_idx]\n",
    "        average_diff_power.append(round(test_mae, 3))\n",
    "        fp_mean_power.append(round(test_fp_mae, 3))\n",
    "\n",
    "        print('average_error: ', average_diff_power[-1], ', fp_average_error: ', \n",
    "              fp_mean_power[-1])\n",
    "        print(\"\\n\\n\")\n",
    "        var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                     dtime + \".dat\", \"wb\") # file for saving results\n",
    "        pickle.dump([average_diff_power, fp_mean_power, number_samples, best_lambda, \n",
    "                     dataset_name, max_dataset_name], file=var_f)\n",
    "        var_f.close()\n",
    "        del best_model, test_generator\n",
    "#     prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_min_mae = [8.27781, 8.23545, 8.20838]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power = [8.166, 7.844, 7.592]\n",
    "fp_mean_power = [4.56, 4.42, 4.37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.538]\n",
      "[3.696]\n",
      "[8192]\n",
      "[0.01]\n"
     ]
    }
   ],
   "source": [
    "print(average_diff_power)\n",
    "print(fp_mean_power)\n",
    "print(number_samples)\n",
    "print(best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<built-in function GetOperationInputs> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1443\u001b[0m     \u001b[0m__swig_setmethods__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m     \u001b[0m__setattr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_swig_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTF_Output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m     \u001b[0m__swig_getmethods__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m_swig_setattr\u001b[0;34m(self, class_type, name, value)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_swig_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_swig_setattr_nondynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m_swig_setattr_nondynamic\u001b[0;34m(self, class_type, name, value, static)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SwigPyObject'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2bfc622779b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlambda_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#, 0.3, 1, 3, 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0maverage_diff_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_mean_power\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlamb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlambda_vec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcnns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-2bfc622779b0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlambda_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#, 0.3, 1, 3, 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0maverage_diff_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_mean_power\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlamb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlambda_vec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcnns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-21260a02aa4c>\u001b[0m in \u001b[0;36mcnn_model\u001b[0;34m(num_filters, kernel_lam, bias_lam)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m#                          kernel_initializer='lecun_normal'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;31m#     cnn.add(layers.Dropout(0.25))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'cntk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             sample_size = K.prod([K.shape(inputs)[axis]\n\u001b[0;32m--> 189\u001b[0;31m                                   for axis in reduction_axes])\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0msample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/keras/layers/normalization.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'cntk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             sample_size = K.prod([K.shape(inputs)[axis]\n\u001b[0;32m--> 189\u001b[0;31m                                   for axis in reduction_axes])\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0msample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m    977\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10392\u001b[0m                         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10393\u001b[0m                         \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10394\u001b[0;31m                         shrink_axis_mask=shrink_axis_mask, name=name)\n\u001b[0m\u001b[1;32m  10395\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10396\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    791\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    792\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    794\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    546\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    547\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3427\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3428\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3429\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3430\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3431\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_control_flow_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_control_flow_post_processing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m     \u001b[0mavailable\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m     \"\"\"\n\u001b[0;32m-> 1800\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m       \u001b[0mcontrol_flow_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckInputFromValidContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2161\u001b[0m     \u001b[0;34m\"\"\"The list of `Tensor` objects representing the data inputs of this op.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs_val\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2163\u001b[0;31m       \u001b[0mtf_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetOperationInputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2164\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2165\u001b[0m       retval = [\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function GetOperationInputs> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "# CNN: support batching\n",
    "TEST = True\n",
    "mini_batch, epochs = 16, 30\n",
    "batch_size = (batch_size // mini_batch) * mini_batch\n",
    "prev_sample = 0\n",
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]  #, 0.3, 1, 3, 10\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "for cnn in cnns:\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "for number_sample in number_samples:\n",
    "    number_start = time.time()\n",
    "    current_sample = number_sample - prev_sample\n",
    "    train_samples = [batch_size] * (current_sample//batch_size) + ([current_sample%batch_size] if \n",
    "                                                                    current_sample%batch_size else [])\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "#     val_samples = [batch_size] * (val_size//batch_size) + ([val_size%batch_size] if \n",
    "#                                                                val_size%batch_size else [])\n",
    "    \n",
    "    print('number_samples:', number_sample)\n",
    "    print(\"Train batches:\", train_samples)\n",
    "    for i, train_sample in enumerate(train_samples):\n",
    "        print(\"Train batch#:\", i, \", batch size:\", train_sample, \", starts:\", prev_sample + i * batch_size,\n",
    "                      \", ends:\", prev_sample + i * batch_size + train_sample - 1)\n",
    "    print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", number_sample + val_size - 1)\n",
    "#     print(\"Validation Batches:\", val_samples)\n",
    "#     for i, val_sample in enumerate(val_samples):\n",
    "#         print(\"Validation batch#:\", i, \", batch size:\", val_sample, \", starts:\", number_sample + i * batch_size,\n",
    "#                       \", ends:\", number_sample + i * batch_size + val_sample - 1)\n",
    "        \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb_idx, lamb in enumerate(lambda_vec):\n",
    "        lambda_start = time.time()\n",
    "        \n",
    "#         cnn = cnn_model(10, lamb, 0)\n",
    "#         cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "        # training on all batches\n",
    "        for i, train_sample in enumerate(train_samples):\n",
    "#             if lamb_idx == 0:\n",
    "#                 print(\"Train batch#:\", i, \", batch size:\", train_sample, \", starts:\", prev_sample + i * batch_size,\n",
    "#                       \", ends:\", prev_sample + i * batch_size + train_sample - 1)\n",
    "            x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "            y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "            for image_num in range(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample):\n",
    "                x_train[(image_num - prev_sample) % batch_size] = read_image(image_num)\n",
    "                y_train[(image_num - prev_sample) % batch_size] = np.asarray(data_reg[image_num][-1], \n",
    "                                                                             dtype=float_memory_used)\n",
    "            cnns[lamb_idx].fit(x_train, y_train, epochs=epochs, verbose=2, batch_size=mini_batch,\n",
    "                               validation_split=0.2, \n",
    "                               shuffle=True)\n",
    "            del x_train, y_train\n",
    "#         if lamb_idx == 0:\n",
    "#             print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", \n",
    "#                   number_sample + val_size - 1)\n",
    "        print(\"\\nLambda:\", lamb)\n",
    "        print(\"Train Error(all epochs): \", cnns[lamb_idx].history.history['mae'])\n",
    "        \n",
    "        # validating\n",
    "        val_mae, val_fp_mae = 0.0, 0.0\n",
    "#         for i, val_sample in enumerate(val_samples):\n",
    "#             x_val = np.empty((val_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "#             for image_num in range(val_sample):\n",
    "#                 x_val[image_num] = read_image(image_num + number_sample + i * batch_size)\n",
    "#             yp_val = cnns[lamb_idx].predict(x_val)\n",
    "        for image_num in range(val_size):\n",
    "            val_y = data_reg[image_num + number_sample][-1]\n",
    "            image = read_image(image_num + number_sample)\n",
    "            val_yp = cnns[lamb_idx].predict(image)[0][0]\n",
    "#             for image_num in range(val_sample):\n",
    "#                 val_yp = yp_val[image_num][0]\n",
    "#                 val_y = data_reg[image_num + number_sample + i * batch_size][-1]\n",
    "            val_mae += abs(val_y - val_yp)\n",
    "            if val_yp > val_y:\n",
    "                val_fp_mae += abs(val_yp - val_y)\n",
    "        val_mae /= val_size\n",
    "        val_fp_mae /= val_size\n",
    "        print(\"Val Error:\", round(val_mae, 3), \", Time:\", str(datetime.timedelta(seconds=int(time.time() - lambda_start))))\n",
    "        if val_mae < min_error:\n",
    "            min_error = val_mae\n",
    "            best_model = cnns[lamb_idx]\n",
    "            best_lam = lamb\n",
    "            best_lam_idx = lamb_idx\n",
    "    print(\"\\nTrainig set size:\", number_sample, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - number_start)))\n",
    "          ,\", best_lambda:\", best_lam, \", min_error:\", round(min_error, 3))\n",
    "    \n",
    "    \n",
    "    if TEST:\n",
    "        # evaluating test images\n",
    "        sum_mae, sum_fp_mae = 0, 0\n",
    "        test_size = 0\n",
    "\n",
    "        y_test_p = np.empty((data_reg.shape[0] - (number_sample + val_size)), dtype=float_memory_used)\n",
    "    #     test_size = data_reg.shape[0] - (number_sample + val_size)\n",
    "    #     test_samples = [batch_size] * (test_size//batch_size) + ([test_size%batch_size] if \n",
    "    #                                                              test_size%batch_size else [])\n",
    "        print(\"Test starts: \", number_sample + val_size, \", ends: \", data_reg.shape[0] - 1)\n",
    "        time.sleep(1)\n",
    "    #     for i, test_sample in tqdm.tqdm(enumerate(test_samples)):\n",
    "    #         x_test = np.empty((test_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "    #         for image_num in range(test_sample):\n",
    "    #             x_test[image_num] = read_image(number_sample + val_size + i * batch_size)\n",
    "    #         yp_test = cnns[best_lam_idx].predict(x_test)\n",
    "    #         for image_num in range(test_sample):\n",
    "    #             test_y = data_reg[number_sample + val_size + i * batch_size][-1]\n",
    "    #             test_yp = yp_test[image_num][0]\n",
    "    #             sum_mae += abs(test_yp - test_y)\n",
    "    #             if test_yp > test_y:\n",
    "    #                 sum_fp_mae += abs(test_yp - test_y)\n",
    "\n",
    "        for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "            test_size += 1\n",
    "            test_image = read_image(test_num)\n",
    "            test_y = data_reg[test_num][-1]\n",
    "            test_yp = best_model.predict(test_image)[0][0]\n",
    "            y_test_p[test_num - (number_sample + val_size)] = test_yp\n",
    "            sum_mae += abs(test_yp - test_y)\n",
    "            if test_yp > test_y:\n",
    "                sum_fp_mae += abs(test_yp - test_y)\n",
    "        fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "        average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "        print('average_error: ', average_diff_power[-1], ', fp_average_error: ', \n",
    "              fp_mean_power[-1])\n",
    "        print(\"\\n\\n\")\n",
    "        var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                     dtime + \".dat\", \"wb\") # file for saving results\n",
    "        pickle.dump([average_diff_power, fp_mean_power, number_samples], file=var_f)\n",
    "        var_f.close()\n",
    "    prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d_216_1/kernel:0' shape=(3, 3, 7, 10) dtype=float32, numpy=\n",
       " array([[[[ 0.13334414, -0.0261361 , -0.07441936,  0.16142276,\n",
       "            0.10993325,  0.04581179,  0.24121895,  0.23147854,\n",
       "            0.17021964, -0.0591266 ],\n",
       "          [ 0.09241038,  0.10264444,  0.00484879, -0.02517582,\n",
       "            0.06216534, -0.06764037,  0.02806018,  0.08384448,\n",
       "            0.13874047,  0.15180951],\n",
       "          [ 0.1893204 , -0.05741746,  0.00313846,  0.03854534,\n",
       "           -0.20698836,  0.00660574, -0.1372445 , -0.11774021,\n",
       "            0.10552079, -0.1360089 ],\n",
       "          [-0.1331031 ,  0.02123114,  0.00091115, -0.03792882,\n",
       "            0.22543769, -0.07044397, -0.09563252, -0.04734167,\n",
       "           -0.09483308,  0.04207201],\n",
       "          [ 0.06165536,  0.04747773,  0.00436929,  0.0485286 ,\n",
       "           -0.16992377,  0.06714778,  0.20848735,  0.16978653,\n",
       "           -0.07686065, -0.09264071],\n",
       "          [ 0.08572359, -0.19217153, -0.08705788,  0.12219634,\n",
       "           -0.27800012,  0.1237585 , -0.21454357,  0.04010623,\n",
       "           -0.13206151, -0.07199094],\n",
       "          [-0.13942277,  0.12991397,  0.05158436,  0.20681241,\n",
       "            0.0927059 , -0.06157902,  0.09529742, -0.06181924,\n",
       "           -0.20937485,  0.08383203]],\n",
       " \n",
       "         [[ 0.14524975, -0.05317885,  0.07710187, -0.06027135,\n",
       "           -0.03889057, -0.13648398, -0.11979997,  0.1689479 ,\n",
       "           -0.1522798 , -0.05902102],\n",
       "          [ 0.06488625,  0.12912498,  0.09674022,  0.20966475,\n",
       "           -0.04465631,  0.12140161,  0.14916958, -0.02789529,\n",
       "            0.03566265, -0.07232169],\n",
       "          [-0.07508589,  0.11446775, -0.13920276,  0.22177145,\n",
       "            0.08524486,  0.0902052 , -0.10775251,  0.08795813,\n",
       "           -0.0761055 , -0.09227429],\n",
       "          [ 0.02373275, -0.11338315,  0.1032308 , -0.07559496,\n",
       "            0.04385605, -0.1355971 ,  0.10978308,  0.10370436,\n",
       "            0.03486014,  0.04627065],\n",
       "          [-0.21984474,  0.05307737,  0.04838712,  0.16839921,\n",
       "            0.11966983,  0.14054751, -0.10383917, -0.17774169,\n",
       "           -0.08481254,  0.01736768],\n",
       "          [ 0.04152398, -0.06096472, -0.00492838,  0.1368062 ,\n",
       "            0.1721607 ,  0.07199505, -0.14697716, -0.23859444,\n",
       "           -0.1461731 , -0.03527378],\n",
       "          [-0.27617452,  0.15010485,  0.11511505, -0.12417073,\n",
       "           -0.08122088,  0.14036025,  0.1422506 ,  0.17473486,\n",
       "            0.08986371,  0.01991365]],\n",
       " \n",
       "         [[ 0.04023483,  0.01661961, -0.08479083, -0.28282636,\n",
       "            0.12767118,  0.0509973 , -0.05391447,  0.19763674,\n",
       "            0.16401489,  0.02086166],\n",
       "          [ 0.02320998,  0.21452   ,  0.02131915, -0.22229502,\n",
       "            0.07397044,  0.08494943,  0.04313029, -0.19079794,\n",
       "           -0.15622707, -0.12654568],\n",
       "          [-0.16471341,  0.07649319,  0.01780317,  0.17973316,\n",
       "            0.00282395,  0.01653246,  0.14217037, -0.07009459,\n",
       "            0.2320501 , -0.25558722],\n",
       "          [-0.13088815, -0.03935688, -0.01927   ,  0.06664042,\n",
       "            0.05449986, -0.27412698,  0.04830834,  0.05888246,\n",
       "           -0.11925068, -0.29004106],\n",
       "          [ 0.09491049, -0.02301907,  0.0727259 , -0.1380526 ,\n",
       "            0.06161747,  0.08663608,  0.00969613, -0.02390122,\n",
       "           -0.07748399, -0.11728296],\n",
       "          [-0.28847724, -0.17691025,  0.10943054,  0.17433746,\n",
       "           -0.01487851, -0.18751724, -0.12222388,  0.05808705,\n",
       "           -0.11082985, -0.17230581],\n",
       "          [-0.04870008, -0.2375922 ,  0.0976412 ,  0.22535303,\n",
       "            0.01409588, -0.02963496,  0.2672263 ,  0.00094256,\n",
       "            0.05225825,  0.03488791]]],\n",
       " \n",
       " \n",
       "        [[[-0.19926119, -0.03603117, -0.05551852, -0.10433564,\n",
       "           -0.14335166,  0.06645513, -0.2795412 , -0.17509606,\n",
       "            0.15266582, -0.05958281],\n",
       "          [ 0.00352683, -0.05189499,  0.14581002, -0.09802195,\n",
       "           -0.0185049 , -0.19627838, -0.17125873, -0.11177973,\n",
       "           -0.15869416,  0.23808493],\n",
       "          [ 0.07290543, -0.04298121,  0.01518185,  0.24427563,\n",
       "           -0.04966308,  0.13753985,  0.09585362,  0.13073985,\n",
       "            0.14580618, -0.05254631],\n",
       "          [ 0.04517658, -0.0560442 , -0.04483185, -0.19104496,\n",
       "           -0.02319299, -0.01029402, -0.15246606,  0.26141602,\n",
       "           -0.09231006,  0.27955005],\n",
       "          [-0.1809828 ,  0.06103823,  0.14722025,  0.08918977,\n",
       "            0.05734708, -0.11969002,  0.06482836, -0.1559477 ,\n",
       "            0.0741372 ,  0.04197035],\n",
       "          [-0.06164405,  0.10421135,  0.11966567, -0.11889777,\n",
       "            0.02610188, -0.02379085,  0.25728026,  0.22226161,\n",
       "            0.05567339, -0.09093149],\n",
       "          [-0.0941878 , -0.13269533,  0.14010622, -0.15810324,\n",
       "            0.09464984,  0.04383229,  0.11680618, -0.05575173,\n",
       "            0.05689744,  0.12688859]],\n",
       " \n",
       "         [[ 0.09463172,  0.07173032, -0.17775638,  0.12823975,\n",
       "            0.22743171, -0.03096067, -0.07845164,  0.10056094,\n",
       "            0.1375068 , -0.00266118],\n",
       "          [-0.13137127, -0.05241982,  0.1078676 , -0.1591938 ,\n",
       "            0.14385167,  0.17707717,  0.15017428, -0.05183896,\n",
       "            0.08562967,  0.07045954],\n",
       "          [ 0.00724656,  0.04945549, -0.00321115, -0.10365249,\n",
       "           -0.11740654, -0.03923345,  0.05962155,  0.10888351,\n",
       "           -0.09101029,  0.13877763],\n",
       "          [ 0.07962049,  0.05093174, -0.0761327 ,  0.12048989,\n",
       "            0.03043546, -0.10803499,  0.03744312,  0.02285842,\n",
       "            0.03543871, -0.05152218],\n",
       "          [-0.07119177, -0.07241955,  0.02490062,  0.00423546,\n",
       "           -0.04316133,  0.19139971, -0.01283269, -0.07494903,\n",
       "           -0.02201682, -0.06245283],\n",
       "          [ 0.00799846,  0.18765801, -0.09534817, -0.077469  ,\n",
       "           -0.11586822, -0.0051675 , -0.0102727 , -0.11339141,\n",
       "            0.03436622,  0.09942368],\n",
       "          [ 0.07523795,  0.03675905,  0.02437227, -0.01435202,\n",
       "           -0.02034545, -0.09359565, -0.02359232,  0.04803864,\n",
       "            0.20680504, -0.00644547]],\n",
       " \n",
       "         [[-0.1005403 ,  0.11378611,  0.21102735,  0.06846891,\n",
       "            0.09442588,  0.09777017, -0.11909521,  0.12265773,\n",
       "           -0.06148191, -0.07069711],\n",
       "          [ 0.01405865, -0.10141152, -0.11822031, -0.13485955,\n",
       "           -0.16953868, -0.21654141, -0.05722266, -0.01606212,\n",
       "           -0.07794228, -0.1521405 ],\n",
       "          [-0.08736753,  0.02725688, -0.01609255, -0.1761448 ,\n",
       "           -0.02491948, -0.07835825, -0.02474505, -0.2482235 ,\n",
       "            0.19618578, -0.08405739],\n",
       "          [-0.13201593,  0.07316361,  0.14873287,  0.03337387,\n",
       "            0.04706023, -0.03948716, -0.15505248,  0.06093074,\n",
       "            0.05425106,  0.18854883],\n",
       "          [ 0.12107033, -0.19670665,  0.03158212,  0.08311516,\n",
       "            0.01700125, -0.04055984, -0.08617479,  0.03713043,\n",
       "           -0.04209922, -0.01615153],\n",
       "          [ 0.0248774 , -0.02845379, -0.07260788, -0.1052746 ,\n",
       "            0.15719673, -0.07497114,  0.0163184 ,  0.15407056,\n",
       "           -0.19900005, -0.0528684 ],\n",
       "          [-0.09391885, -0.03256474,  0.02134794, -0.06547134,\n",
       "            0.02687071,  0.0165927 , -0.21028309,  0.18223254,\n",
       "            0.1601678 ,  0.06802534]]],\n",
       " \n",
       " \n",
       "        [[[-0.11673861, -0.02761208, -0.05152625,  0.26689234,\n",
       "            0.05464312, -0.0165887 , -0.15953052, -0.20351106,\n",
       "           -0.00750204, -0.04550588],\n",
       "          [-0.18615605,  0.19847395, -0.22109997, -0.04208753,\n",
       "            0.0015387 , -0.08712109, -0.12053566,  0.04012857,\n",
       "            0.12612605,  0.0755921 ],\n",
       "          [-0.19893515,  0.09130076, -0.02334492,  0.10549977,\n",
       "            0.10952222, -0.20525998,  0.13201837,  0.09622242,\n",
       "           -0.27899146, -0.1937835 ],\n",
       "          [ 0.02993972,  0.06206925, -0.02340401,  0.1940042 ,\n",
       "           -0.27053413, -0.02356468,  0.0402792 ,  0.00274105,\n",
       "            0.10014538,  0.1180291 ],\n",
       "          [ 0.09827848, -0.05272344, -0.24212418,  0.18239398,\n",
       "            0.28893584,  0.03425925,  0.18894415, -0.16935891,\n",
       "           -0.19899593, -0.17445645],\n",
       "          [-0.16428833,  0.15912978, -0.03123697,  0.19525754,\n",
       "            0.1313913 , -0.1464028 ,  0.19579571, -0.03027558,\n",
       "            0.02622594,  0.05283794],\n",
       "          [ 0.00537856, -0.02129651,  0.01653795, -0.03506261,\n",
       "            0.06030509,  0.0077933 , -0.26723355,  0.08907922,\n",
       "           -0.23224692,  0.15809113]],\n",
       " \n",
       "         [[-0.04699924,  0.21412279, -0.13859469,  0.15074492,\n",
       "           -0.05260769,  0.02953377,  0.21503067,  0.09594385,\n",
       "            0.18201022,  0.18532227],\n",
       "          [ 0.0813347 ,  0.1836983 , -0.05178611,  0.14537628,\n",
       "            0.13789822,  0.1196593 , -0.13453369, -0.05221471,\n",
       "           -0.26833838,  0.20581754],\n",
       "          [ 0.26625836, -0.22261377,  0.03792743,  0.14181626,\n",
       "           -0.13818225, -0.03733314, -0.2065161 , -0.11526174,\n",
       "            0.0504146 , -0.08647973],\n",
       "          [ 0.09377266,  0.2062351 ,  0.05943884,  0.03329353,\n",
       "           -0.10891343, -0.11080927,  0.23227565,  0.23207027,\n",
       "            0.15182719, -0.16632546],\n",
       "          [-0.01662905,  0.14488567,  0.1271512 ,  0.02320437,\n",
       "            0.01788143,  0.05921528, -0.0353229 , -0.188283  ,\n",
       "            0.1494947 , -0.18092439],\n",
       "          [-0.13061637,  0.1592543 ,  0.00978735, -0.05683037,\n",
       "            0.17805217,  0.02800326,  0.26188764, -0.11778035,\n",
       "            0.06277441, -0.12744053],\n",
       "          [ 0.00465929, -0.04557341, -0.15533756, -0.05069922,\n",
       "           -0.14725295, -0.0853371 , -0.20699254,  0.07564644,\n",
       "            0.02780418,  0.2634452 ]],\n",
       " \n",
       "         [[ 0.01776883, -0.03514121, -0.12700932,  0.12356611,\n",
       "           -0.10552283,  0.20057616,  0.04670141,  0.12937702,\n",
       "           -0.05964081,  0.2509442 ],\n",
       "          [-0.03483937,  0.04906264, -0.0862985 , -0.22901045,\n",
       "            0.00186068, -0.07967521, -0.02993756, -0.03580993,\n",
       "            0.23193611, -0.02563061],\n",
       "          [ 0.01709478,  0.07445383, -0.19091251, -0.0331335 ,\n",
       "            0.0253082 ,  0.02352164,  0.2859322 ,  0.10892042,\n",
       "            0.18633689, -0.0595445 ],\n",
       "          [-0.20758714,  0.07152744, -0.01677686, -0.01780074,\n",
       "           -0.12487143,  0.00212223, -0.01722952,  0.2022124 ,\n",
       "           -0.2645012 , -0.04340143],\n",
       "          [ 0.13472383,  0.00098047, -0.10209464,  0.14819503,\n",
       "           -0.08379597, -0.18391946, -0.01674595,  0.14736894,\n",
       "            0.11205667, -0.14535202],\n",
       "          [-0.07028721, -0.13803037, -0.09943354, -0.27029005,\n",
       "            0.04495002, -0.04398946,  0.05618115,  0.1637726 ,\n",
       "           -0.21474266, -0.09334109],\n",
       "          [-0.15808658, -0.23804595,  0.18949424,  0.04920245,\n",
       "           -0.20425159, -0.18336712, -0.08576456, -0.13084741,\n",
       "            0.00551501,  0.05699825]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_216_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.00394855,  0.01156156,  0.00672093, -0.00029083,  0.0033301 ,\n",
       "        -0.00794703, -0.01068521, -0.00623209, -0.00136579,  0.0004727 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_246_1/gamma:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.99889743, 1.0080869 , 0.9918417 , 0.99180245, 0.99210924,\n",
       "        1.0056474 , 1.0041177 , 1.0091603 , 0.999746  , 0.99256486],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_246_1/beta:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 1.2581445e-02,  7.9289870e-03, -7.9357335e-03, -1.1723038e-02,\n",
       "        -7.7971257e-03,  2.2734562e-03,  5.4945835e-05, -6.2508588e-03,\n",
       "         4.6733394e-04,  5.2858326e-03], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_217_1/kernel:0' shape=(3, 3, 10, 20) dtype=float32, numpy=\n",
       " array([[[[-0.00613516, -0.07706599,  0.006248  , ...,  0.01483129,\n",
       "           -0.13148054,  0.01379959],\n",
       "          [-0.06125846, -0.04463966,  0.15691034, ...,  0.06724139,\n",
       "           -0.08870574,  0.04128341],\n",
       "          [ 0.18929154, -0.07877082,  0.09513605, ..., -0.06041372,\n",
       "           -0.03992198, -0.18455972],\n",
       "          ...,\n",
       "          [ 0.02003453, -0.11194929, -0.11064813, ..., -0.08062167,\n",
       "            0.13399614, -0.022826  ],\n",
       "          [ 0.10247879, -0.09553227,  0.04918528, ...,  0.23149642,\n",
       "           -0.09936932, -0.01014787],\n",
       "          [-0.06446787,  0.0508823 ,  0.03458132, ...,  0.09098805,\n",
       "            0.05103992, -0.22692856]],\n",
       " \n",
       "         [[ 0.00899815, -0.01982983,  0.2108407 , ..., -0.11129528,\n",
       "            0.04713659,  0.02240109],\n",
       "          [ 0.0239722 ,  0.03624769, -0.13892104, ..., -0.1916124 ,\n",
       "            0.11251629,  0.05872869],\n",
       "          [-0.14052154, -0.02749509,  0.067243  , ..., -0.07384579,\n",
       "            0.1350736 ,  0.04331046],\n",
       "          ...,\n",
       "          [-0.1179302 , -0.04421049,  0.02058602, ..., -0.18133816,\n",
       "            0.14051902, -0.00200996],\n",
       "          [-0.13089395, -0.02914838,  0.02653082, ...,  0.09342858,\n",
       "           -0.08133891,  0.13094549],\n",
       "          [ 0.06657103, -0.18192683,  0.2327268 , ...,  0.06579488,\n",
       "            0.16109888, -0.0417343 ]],\n",
       " \n",
       "         [[ 0.14598422,  0.02474008, -0.2001503 , ..., -0.05117525,\n",
       "           -0.08759225,  0.09137008],\n",
       "          [ 0.11352185,  0.10408597,  0.05276801, ...,  0.02367296,\n",
       "            0.0709122 , -0.05202084],\n",
       "          [ 0.04591953,  0.00177405, -0.05923538, ..., -0.04373968,\n",
       "            0.09335176, -0.23466058],\n",
       "          ...,\n",
       "          [ 0.04117727,  0.09622082, -0.00483591, ..., -0.00573619,\n",
       "           -0.00544672, -0.07039722],\n",
       "          [-0.15966627,  0.13912055,  0.04043337, ...,  0.18531808,\n",
       "            0.12856238,  0.12779331],\n",
       "          [-0.11824572, -0.00606683, -0.02776809, ...,  0.03119941,\n",
       "           -0.06217549, -0.1021296 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.11843395, -0.11313166,  0.10206358, ...,  0.1424125 ,\n",
       "            0.02883888,  0.10749669],\n",
       "          [-0.0932157 ,  0.08986368,  0.08855385, ..., -0.04054831,\n",
       "            0.20761569,  0.17895086],\n",
       "          [ 0.21287711, -0.13902958, -0.05071876, ..., -0.10464473,\n",
       "            0.13464488,  0.00796567],\n",
       "          ...,\n",
       "          [-0.01583735, -0.10220268,  0.16242856, ..., -0.22936785,\n",
       "           -0.02587985,  0.05995097],\n",
       "          [-0.05231554, -0.07904537,  0.09455277, ...,  0.03787832,\n",
       "            0.05256969, -0.03759636],\n",
       "          [-0.09452608, -0.05021729, -0.00096467, ..., -0.1103365 ,\n",
       "            0.10697437, -0.14381793]],\n",
       " \n",
       "         [[-0.04669933,  0.01557779, -0.0037258 , ...,  0.12755205,\n",
       "            0.11051998,  0.04037065],\n",
       "          [ 0.07087644,  0.08811377,  0.0231888 , ..., -0.06829704,\n",
       "            0.07152358, -0.01255593],\n",
       "          [ 0.06456453,  0.1441479 ,  0.21550633, ...,  0.11959073,\n",
       "           -0.21130289, -0.01518227],\n",
       "          ...,\n",
       "          [ 0.06106412,  0.13728103, -0.02890644, ...,  0.07025255,\n",
       "           -0.0409243 , -0.0301967 ],\n",
       "          [-0.10983857,  0.08415116, -0.16161825, ..., -0.03688908,\n",
       "           -0.1048198 ,  0.06283347],\n",
       "          [-0.02078158,  0.07726054,  0.22857217, ..., -0.02705708,\n",
       "           -0.21459246,  0.20110175]],\n",
       " \n",
       "         [[ 0.10718577, -0.03096308, -0.03471959, ..., -0.15640563,\n",
       "           -0.17416269,  0.1678829 ],\n",
       "          [ 0.23790742, -0.12122889,  0.05106934, ..., -0.14332658,\n",
       "            0.13123561, -0.17268288],\n",
       "          [-0.07216983,  0.02125906,  0.04503383, ...,  0.02436657,\n",
       "            0.05501794,  0.01041913],\n",
       "          ...,\n",
       "          [-0.23144129, -0.04420161, -0.1883411 , ...,  0.06308959,\n",
       "            0.07754758, -0.0654578 ],\n",
       "          [ 0.0442895 ,  0.0457861 ,  0.08194239, ..., -0.15825216,\n",
       "            0.04440489, -0.0206511 ],\n",
       "          [-0.028714  ,  0.13239929, -0.03383066, ...,  0.09529423,\n",
       "           -0.22242351, -0.07872296]]],\n",
       " \n",
       " \n",
       "        [[[-0.09778915,  0.05839903,  0.02432927, ..., -0.04064826,\n",
       "           -0.10225639,  0.10601223],\n",
       "          [ 0.10263681, -0.01321077, -0.14533637, ..., -0.07213327,\n",
       "           -0.20481627, -0.02181217],\n",
       "          [-0.05705408, -0.16224189,  0.06692079, ..., -0.13675866,\n",
       "            0.03165859,  0.08559091],\n",
       "          ...,\n",
       "          [ 0.1333062 , -0.01051405,  0.10658982, ..., -0.13980907,\n",
       "           -0.13984981, -0.13669503],\n",
       "          [ 0.14150469,  0.06306539, -0.049619  , ..., -0.08240972,\n",
       "           -0.17580837, -0.15314321],\n",
       "          [ 0.12678467,  0.00361737,  0.12182796, ...,  0.05166734,\n",
       "            0.01910091,  0.19070801]],\n",
       " \n",
       "         [[-0.07456422,  0.04228234, -0.04476889, ...,  0.01102671,\n",
       "            0.03837417,  0.00232783],\n",
       "          [-0.1743557 ,  0.03958088,  0.21821131, ..., -0.06465518,\n",
       "           -0.05084631,  0.07745536],\n",
       "          [ 0.07760292,  0.0065304 , -0.1256236 , ...,  0.01159124,\n",
       "            0.18457702, -0.15225986],\n",
       "          ...,\n",
       "          [ 0.0826866 , -0.04612084, -0.08189004, ..., -0.1406778 ,\n",
       "           -0.15322529,  0.01678441],\n",
       "          [-0.07755306, -0.01942021, -0.04269481, ...,  0.20054315,\n",
       "            0.04770061, -0.06134127],\n",
       "          [-0.06864616, -0.02571295, -0.01662292, ..., -0.1724913 ,\n",
       "            0.01081838,  0.00735117]],\n",
       " \n",
       "         [[ 0.04716585, -0.04663199, -0.22949034, ...,  0.06523322,\n",
       "           -0.03782558,  0.11918577],\n",
       "          [-0.04422992,  0.02638413, -0.03934672, ..., -0.00764357,\n",
       "           -0.06596323,  0.00637577],\n",
       "          [-0.13985588,  0.04368904, -0.13685353, ..., -0.07130355,\n",
       "            0.13632149,  0.02693932],\n",
       "          ...,\n",
       "          [ 0.16433991, -0.18598363,  0.0482639 , ...,  0.07945465,\n",
       "           -0.00088441, -0.07022502],\n",
       "          [-0.0102343 ,  0.03097694,  0.01139166, ...,  0.00272   ,\n",
       "            0.09357451, -0.04334646],\n",
       "          [-0.10491278, -0.01409396, -0.11717147, ...,  0.08654676,\n",
       "           -0.1032054 ,  0.03606071]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_217_1/bias:0' shape=(20,) dtype=float32, numpy=\n",
       " array([-0.0060811 , -0.0068215 ,  0.00610762,  0.00381076, -0.00332611,\n",
       "         0.01825029, -0.00569285,  0.0057989 , -0.00631325, -0.00456895,\n",
       "        -0.00355404, -0.00981498, -0.00726559,  0.01567949,  0.00570573,\n",
       "         0.00865319,  0.00934281, -0.00607597,  0.0064635 ,  0.0063222 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_247_1/gamma:0' shape=(20,) dtype=float32, numpy=\n",
       " array([1.0085537 , 0.9999157 , 1.0029037 , 1.0036793 , 0.9965737 ,\n",
       "        0.9955619 , 0.99597555, 0.9951744 , 0.99155873, 0.99123126,\n",
       "        1.0021704 , 1.0111369 , 1.0073707 , 0.9978239 , 0.9897377 ,\n",
       "        0.9979535 , 1.0064371 , 1.0076557 , 0.99272054, 0.9983158 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_247_1/beta:0' shape=(20,) dtype=float32, numpy=\n",
       " array([-0.00536959, -0.00913435,  0.00736503, -0.00202524, -0.00472902,\n",
       "         0.00195614, -0.00162657, -0.00393156, -0.00975933, -0.00361821,\n",
       "         0.0016747 , -0.01143507,  0.00245739,  0.00032578, -0.00409207,\n",
       "        -0.00324961,  0.00862126, -0.01241841,  0.00541203,  0.00482147],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_218_1/kernel:0' shape=(3, 3, 20, 10) dtype=float32, numpy=\n",
       " array([[[[ 0.02090567, -0.01063356,  0.01568592, ..., -0.00421554,\n",
       "           -0.04153974, -0.04014684],\n",
       "          [ 0.04146984, -0.06783944, -0.0200508 , ...,  0.09385803,\n",
       "            0.04323528,  0.01106868],\n",
       "          [ 0.03960693,  0.05715526,  0.05039765, ...,  0.13124132,\n",
       "           -0.01877139,  0.12398075],\n",
       "          ...,\n",
       "          [ 0.01227695, -0.00760612,  0.05333555, ..., -0.06424541,\n",
       "           -0.01374738,  0.04552693],\n",
       "          [ 0.0417938 , -0.02966972,  0.0077204 , ...,  0.10324682,\n",
       "           -0.0336564 ,  0.08304278],\n",
       "          [ 0.06021956, -0.07890533, -0.05801883, ...,  0.08471491,\n",
       "            0.14794236, -0.03558924]],\n",
       " \n",
       "         [[-0.06004382,  0.14762361, -0.14524157, ..., -0.05869973,\n",
       "            0.03716639,  0.10489431],\n",
       "          [-0.12088605,  0.00969887, -0.15406442, ..., -0.0068292 ,\n",
       "           -0.09708827, -0.15776071],\n",
       "          [ 0.00866788,  0.02003344, -0.00541908, ...,  0.0622683 ,\n",
       "            0.06663585,  0.05296098],\n",
       "          ...,\n",
       "          [-0.02643398,  0.07877985,  0.02854742, ..., -0.05691448,\n",
       "           -0.10097322, -0.0748076 ],\n",
       "          [ 0.0615546 ,  0.03269725,  0.14803933, ...,  0.14153697,\n",
       "            0.11893072,  0.05922618],\n",
       "          [ 0.12306278,  0.01435436,  0.0020571 , ..., -0.12050573,\n",
       "           -0.0762575 ,  0.16076486]],\n",
       " \n",
       "         [[-0.1540486 ,  0.11167903,  0.03835633, ...,  0.11817916,\n",
       "           -0.15860094, -0.05598804],\n",
       "          [-0.15525052, -0.14420928,  0.03094636, ..., -0.04865462,\n",
       "            0.0121097 ,  0.02022653],\n",
       "          [-0.06025796,  0.01669158, -0.02238417, ..., -0.04274051,\n",
       "            0.10321181, -0.09857506],\n",
       "          ...,\n",
       "          [-0.00701016,  0.1400375 , -0.13470443, ...,  0.10114507,\n",
       "           -0.12888566, -0.04554447],\n",
       "          [ 0.07841129,  0.00090785, -0.01532124, ..., -0.12396181,\n",
       "           -0.0439156 , -0.02015512],\n",
       "          [ 0.00565134, -0.02282265,  0.04575562, ...,  0.12269929,\n",
       "            0.11260708,  0.0627861 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.03517975, -0.09904189,  0.08187799, ...,  0.09351594,\n",
       "            0.05125515, -0.00984296],\n",
       "          [ 0.00697843,  0.08033408, -0.10224243, ..., -0.04909829,\n",
       "           -0.04039364,  0.16326733],\n",
       "          [-0.07986713, -0.11045446, -0.0182618 , ...,  0.03425604,\n",
       "            0.04857165, -0.01289561],\n",
       "          ...,\n",
       "          [-0.01944935,  0.16133569, -0.13886565, ..., -0.04946548,\n",
       "           -0.09193281,  0.07258816],\n",
       "          [ 0.03535461, -0.01553783, -0.12240314, ..., -0.03787487,\n",
       "           -0.03542279, -0.10071688],\n",
       "          [-0.02973528, -0.0235173 , -0.14208344, ...,  0.01603398,\n",
       "           -0.10384908, -0.03715665]],\n",
       " \n",
       "         [[-0.00868847,  0.09747783,  0.05609084, ..., -0.06709271,\n",
       "           -0.0365287 ,  0.02167607],\n",
       "          [ 0.00520192,  0.04545872, -0.00385959, ..., -0.10382078,\n",
       "            0.09922986,  0.04590368],\n",
       "          [-0.12633488, -0.09125228,  0.01445932, ..., -0.03902439,\n",
       "            0.0587509 ,  0.13841613],\n",
       "          ...,\n",
       "          [-0.16209798,  0.13320892, -0.07741296, ...,  0.07428703,\n",
       "           -0.10164525,  0.02643708],\n",
       "          [ 0.02213026,  0.01649134,  0.0436659 , ...,  0.0232906 ,\n",
       "            0.04629252, -0.00076802],\n",
       "          [ 0.03799146,  0.0559881 , -0.02978235, ...,  0.00977015,\n",
       "            0.11580397, -0.03857177]],\n",
       " \n",
       "         [[ 0.06608044, -0.0416215 ,  0.06630466, ...,  0.055699  ,\n",
       "            0.00784587,  0.09676087],\n",
       "          [-0.00490601,  0.12060454, -0.05847608, ...,  0.03492145,\n",
       "            0.00243892, -0.02397208],\n",
       "          [ 0.02921079, -0.00870965, -0.02787584, ...,  0.00931264,\n",
       "           -0.10823767,  0.05034735],\n",
       "          ...,\n",
       "          [ 0.03446243, -0.1045508 ,  0.06442372, ...,  0.07789522,\n",
       "            0.01189602,  0.08175033],\n",
       "          [ 0.00793133, -0.10998193, -0.02340578, ...,  0.06498767,\n",
       "           -0.15805757, -0.12531461],\n",
       "          [ 0.06383936,  0.04361217,  0.01095787, ...,  0.00465115,\n",
       "           -0.04824472,  0.00653344]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00245395,  0.03652324,  0.16486716, ...,  0.05380679,\n",
       "           -0.05727434, -0.11223233],\n",
       "          [ 0.05858332,  0.06456722,  0.00737718, ..., -0.05184856,\n",
       "            0.06343709, -0.00745704],\n",
       "          [-0.02949599, -0.04968589, -0.10517275, ..., -0.05019437,\n",
       "            0.05241147,  0.0156231 ],\n",
       "          ...,\n",
       "          [ 0.01725427,  0.15474428, -0.06188389, ...,  0.00435201,\n",
       "           -0.00123665,  0.10892878],\n",
       "          [ 0.01494043, -0.03885448,  0.01336966, ..., -0.0267803 ,\n",
       "            0.06688994, -0.14476316],\n",
       "          [ 0.14485203, -0.10829151, -0.07587951, ...,  0.06992213,\n",
       "           -0.10144979,  0.02104662]],\n",
       " \n",
       "         [[ 0.02576772,  0.01628014,  0.08864211, ..., -0.0828298 ,\n",
       "            0.03301449,  0.0850352 ],\n",
       "          [ 0.07903824,  0.04840345,  0.05991028, ...,  0.08987902,\n",
       "           -0.10944261,  0.03650283],\n",
       "          [ 0.03825856, -0.00832999, -0.04583719, ...,  0.06594151,\n",
       "           -0.07302982,  0.07432107],\n",
       "          ...,\n",
       "          [-0.04050666, -0.12797402,  0.07386046, ..., -0.10249872,\n",
       "            0.04911845,  0.06743121],\n",
       "          [ 0.07613551,  0.00332004, -0.07916892, ..., -0.00123999,\n",
       "            0.05332122, -0.13459298],\n",
       "          [-0.02192901,  0.04683131,  0.00082733, ..., -0.00446338,\n",
       "           -0.12011667,  0.03525013]],\n",
       " \n",
       "         [[-0.04359539, -0.06374618,  0.1202983 , ...,  0.00113101,\n",
       "            0.02773231,  0.0731922 ],\n",
       "          [ 0.02177648,  0.07440197, -0.06188597, ..., -0.09979589,\n",
       "           -0.00345127,  0.15094717],\n",
       "          [-0.00584744, -0.031125  ,  0.06415071, ...,  0.03767491,\n",
       "            0.05926217, -0.12075986],\n",
       "          ...,\n",
       "          [ 0.04383463, -0.05182926,  0.03458637, ..., -0.11864363,\n",
       "            0.01741709, -0.15909383],\n",
       "          [-0.12114664, -0.08047332,  0.09436321, ...,  0.02143348,\n",
       "            0.14162898, -0.03481112],\n",
       "          [ 0.01134355,  0.00687216,  0.02118197, ...,  0.0458432 ,\n",
       "            0.02889669, -0.01219227]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_218_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 4.9985615e-03, -6.2674466e-03,  2.9960005e-03, -5.8403853e-03,\n",
       "        -7.8184283e-05, -2.7212226e-03,  1.2709799e-03,  8.3391936e-03,\n",
       "         1.3473940e-02,  1.5454404e-03], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_248_1/gamma:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.99919415, 1.0033033 , 0.99802935, 1.000345  , 0.99773407,\n",
       "        1.0104444 , 1.0010378 , 0.9978654 , 1.0017155 , 0.9996311 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_248_1/beta:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.01331361, -0.00868953,  0.00726795,  0.00127022,  0.00731085,\n",
       "        -0.0044188 , -0.0090006 ,  0.0002409 , -0.00658916,  0.0044319 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_219_1/kernel:0' shape=(3, 3, 10, 10) dtype=float32, numpy=\n",
       " array([[[[ 2.83129606e-02, -1.62238032e-02,  1.03980504e-01,\n",
       "            1.16387211e-01, -1.06103413e-01,  5.61737977e-02,\n",
       "           -1.46659836e-01, -1.29340915e-02,  1.27901323e-02,\n",
       "            5.08181863e-02],\n",
       "          [ 9.80623253e-03, -9.37586352e-02, -1.98928304e-02,\n",
       "           -1.94695219e-01,  2.00361088e-01,  1.11831360e-01,\n",
       "            2.42758051e-01, -5.33776470e-02,  1.82724893e-01,\n",
       "           -2.01382041e-01],\n",
       "          [-8.73721913e-02,  4.33610752e-03,  4.48629409e-02,\n",
       "            5.48482053e-02,  8.65596533e-02,  2.04726696e-01,\n",
       "            2.42778962e-03,  7.55755603e-02,  1.12725645e-01,\n",
       "           -8.08122940e-03],\n",
       "          [ 1.87131241e-02,  2.89434455e-02, -9.44256485e-02,\n",
       "           -7.55071547e-03, -3.37521769e-02, -9.08817127e-02,\n",
       "           -1.92754716e-01, -3.49253858e-03, -7.13579729e-02,\n",
       "           -1.08991116e-01],\n",
       "          [ 1.05075799e-01, -2.05045298e-01, -1.68525428e-02,\n",
       "            2.29099188e-02, -1.71253443e-01, -1.90423220e-01,\n",
       "           -8.28932002e-02, -8.61670077e-02, -7.59391934e-02,\n",
       "            1.02766417e-01],\n",
       "          [ 1.50967371e-02, -1.48425549e-01, -1.78931765e-02,\n",
       "            1.73622563e-01,  7.03308210e-02, -1.47450194e-01,\n",
       "            3.78412120e-02, -1.73187628e-01,  1.86909065e-02,\n",
       "            1.24283642e-01],\n",
       "          [-8.66790563e-02,  2.08363533e-01, -2.15889933e-03,\n",
       "            1.31178916e-01,  5.47453202e-02, -1.24806426e-01,\n",
       "           -1.41787799e-02, -2.28378568e-02, -2.13128418e-01,\n",
       "            9.85392258e-02],\n",
       "          [ 2.00720485e-02, -5.98793551e-02, -1.57219812e-01,\n",
       "            1.22725964e-02, -1.11461073e-01, -1.41769096e-01,\n",
       "           -6.00360036e-02, -1.04730532e-01, -2.06204563e-01,\n",
       "           -9.85325128e-02],\n",
       "          [ 1.13914095e-01, -4.76640165e-02, -9.19190645e-02,\n",
       "            1.26577899e-01,  1.16801009e-01, -1.39470711e-01,\n",
       "            1.13734327e-01, -3.09173437e-03,  4.84448113e-02,\n",
       "           -2.80253701e-02],\n",
       "          [-7.73362964e-02,  4.04877998e-02,  8.21664631e-02,\n",
       "            1.34849161e-01, -5.47892861e-02, -1.04941633e-02,\n",
       "            1.29061297e-01,  1.57013908e-01,  1.52578220e-01,\n",
       "            7.48907030e-03]],\n",
       " \n",
       "         [[ 6.11932902e-03, -2.01341957e-01, -6.55429363e-02,\n",
       "            2.36354306e-01, -1.28261894e-01,  1.24785705e-02,\n",
       "           -6.12892136e-02,  1.89868510e-02, -1.59349188e-01,\n",
       "           -1.18715525e-01],\n",
       "          [ 4.51506525e-02, -4.20441888e-02, -7.08670635e-03,\n",
       "           -4.88252798e-03, -7.80906156e-02, -2.43846208e-01,\n",
       "           -2.31665194e-01, -1.65995300e-01,  2.43167460e-01,\n",
       "            2.33564109e-01],\n",
       "          [-1.00800224e-01,  8.09214711e-02,  9.82760489e-02,\n",
       "           -4.53637056e-02, -7.35944510e-02,  4.42068614e-02,\n",
       "            3.55523340e-02, -9.24341157e-02,  1.25541553e-01,\n",
       "            8.92291367e-02],\n",
       "          [ 1.51286796e-01, -3.83212566e-02,  4.72230464e-02,\n",
       "            3.73164192e-02,  1.42405853e-01,  6.37520179e-02,\n",
       "            8.13184679e-02, -3.31907496e-02, -2.84174234e-02,\n",
       "            6.62456304e-02],\n",
       "          [ 1.42802238e-01, -6.38124533e-03,  3.67526300e-02,\n",
       "            2.14254007e-01, -4.47148345e-02, -1.12954974e-01,\n",
       "           -2.18075924e-02, -7.93670267e-02, -3.08635482e-03,\n",
       "            8.13045874e-02],\n",
       "          [-1.21790268e-01,  2.42588706e-02,  1.54956177e-01,\n",
       "            2.93280147e-02, -9.38752573e-03,  8.03945288e-02,\n",
       "           -6.01228513e-02,  1.97463080e-01, -9.00273323e-02,\n",
       "           -2.03024633e-02],\n",
       "          [-5.71390167e-02,  1.48167282e-01, -2.24257652e-02,\n",
       "            1.80787429e-01, -1.91152856e-01,  7.82837421e-02,\n",
       "           -9.25571695e-02, -1.24554791e-01,  1.04387037e-01,\n",
       "            4.86497506e-02],\n",
       "          [ 1.21415062e-02, -1.17459297e-01,  1.29809305e-01,\n",
       "            4.45848657e-03,  2.13454694e-01, -2.84447726e-02,\n",
       "           -6.14425167e-02,  1.73679944e-02,  7.73714185e-02,\n",
       "           -1.43704489e-01],\n",
       "          [ 3.15138586e-02, -9.94348302e-02,  9.24090073e-02,\n",
       "            9.74579379e-02,  8.72250944e-02,  3.41705121e-02,\n",
       "            1.99354161e-02, -2.02842817e-01,  1.89016894e-01,\n",
       "           -1.42573178e-01],\n",
       "          [-1.25684381e-01, -1.00860551e-01,  1.66402146e-01,\n",
       "            1.84860025e-02,  5.38686551e-02, -7.63851032e-02,\n",
       "            2.20281482e-01, -7.81994238e-02, -2.29272675e-02,\n",
       "           -5.43190204e-02]],\n",
       " \n",
       "         [[-4.01767008e-02, -3.81764583e-02, -9.16618761e-03,\n",
       "            2.57409681e-02, -1.05128229e-01,  6.99722916e-02,\n",
       "           -2.14407697e-01,  1.73669323e-04,  1.60017461e-01,\n",
       "           -6.00143410e-02],\n",
       "          [ 1.34740472e-01, -9.66027975e-02, -2.19858973e-03,\n",
       "            1.11641444e-01,  1.19974781e-02,  1.43931573e-02,\n",
       "            8.19125250e-02,  2.36033320e-01,  7.85621479e-02,\n",
       "            3.52069363e-02],\n",
       "          [-1.61485925e-01,  2.34725237e-01,  2.11585134e-01,\n",
       "           -1.98489696e-01,  4.65236567e-02, -4.63504046e-02,\n",
       "           -7.07902387e-02, -6.04882911e-02,  8.41681063e-02,\n",
       "           -4.46977094e-02],\n",
       "          [ 1.33270755e-01, -1.77671947e-02,  3.69175598e-02,\n",
       "           -2.01188549e-01,  2.16184463e-02, -1.80943087e-01,\n",
       "           -4.58246395e-02,  8.48286897e-02, -1.54296026e-01,\n",
       "           -2.31164377e-02],\n",
       "          [ 1.79150149e-01, -6.76531792e-02, -1.56912953e-01,\n",
       "            4.04863358e-02,  4.27235328e-02, -6.50712028e-02,\n",
       "           -1.93436593e-01, -6.32430017e-02,  1.10042244e-01,\n",
       "           -1.39101848e-01],\n",
       "          [-3.99310365e-02,  2.42456421e-02,  4.05376889e-02,\n",
       "           -7.04867914e-02,  2.25961015e-01,  1.17363364e-01,\n",
       "           -5.90360612e-02, -6.30392730e-02, -6.30781129e-02,\n",
       "           -1.29879162e-01],\n",
       "          [ 8.54523629e-02, -2.15316445e-01,  6.61987662e-02,\n",
       "            1.52793795e-01, -1.21433884e-01,  7.31147528e-02,\n",
       "            3.67294401e-02,  2.71249209e-02, -8.48096684e-02,\n",
       "            9.98852998e-02],\n",
       "          [ 3.34720127e-02, -1.25386119e-02, -1.13391310e-01,\n",
       "           -4.81449850e-02, -1.01651937e-01, -5.83157837e-02,\n",
       "            6.98072910e-02, -2.51918249e-02,  1.01924531e-01,\n",
       "            1.03339896e-01],\n",
       "          [-1.21283501e-01, -1.44275418e-02, -1.04601830e-01,\n",
       "            1.18158452e-01, -1.30609661e-01, -8.51946846e-02,\n",
       "            1.06896400e-01,  7.87511989e-02, -1.38920724e-01,\n",
       "            5.03838398e-02],\n",
       "          [ 9.79290053e-06,  2.07273707e-01, -1.56843942e-02,\n",
       "            1.53424710e-01,  1.43007105e-02,  2.11922497e-01,\n",
       "           -8.35004970e-02, -3.15120220e-02, -8.58905464e-02,\n",
       "            9.53425840e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 2.00899113e-02,  1.06507167e-01,  1.12569794e-01,\n",
       "            5.49545279e-03,  7.51778856e-02, -4.37212503e-03,\n",
       "            1.04209311e-01, -7.66417310e-02,  6.01512287e-03,\n",
       "           -1.04138918e-01],\n",
       "          [ 3.18270549e-03,  8.21854025e-02,  5.57398312e-02,\n",
       "            1.91434324e-01,  3.84605117e-02,  4.93508503e-02,\n",
       "            1.62451621e-02,  1.71981305e-01, -1.04712464e-01,\n",
       "            6.04983866e-02],\n",
       "          [-1.49672627e-01,  1.13039106e-01, -1.94703713e-01,\n",
       "           -2.60298867e-02,  1.79217413e-01,  5.45258038e-02,\n",
       "           -2.98164245e-02,  2.23772824e-02,  7.14413151e-02,\n",
       "           -2.02146575e-01],\n",
       "          [-5.72881997e-02,  8.11996907e-02, -3.08678262e-02,\n",
       "            2.38460228e-01,  3.87122408e-02, -9.00933594e-02,\n",
       "           -2.40432024e-02, -6.07253201e-02,  4.65678126e-02,\n",
       "            2.07203515e-02],\n",
       "          [ 1.56572223e-01, -2.69654170e-02, -8.72026458e-02,\n",
       "           -2.38066599e-01, -2.35741660e-01, -1.40856817e-01,\n",
       "            5.61638176e-02,  6.03501461e-02, -3.35139968e-02,\n",
       "           -6.20052814e-02],\n",
       "          [ 3.56668308e-02, -2.23486260e-01,  9.45441350e-02,\n",
       "            1.73284292e-01,  1.98778555e-01, -6.15402311e-02,\n",
       "           -5.03478609e-02,  2.19090562e-02, -9.25640985e-02,\n",
       "           -3.44366953e-02],\n",
       "          [ 9.05511230e-02, -7.97437280e-02, -1.51533827e-01,\n",
       "           -2.45877672e-02,  7.41868913e-02,  5.57781160e-02,\n",
       "           -1.38228804e-01,  1.38877630e-01,  6.86035911e-03,\n",
       "           -1.35780334e-01],\n",
       "          [ 3.76973152e-02,  4.19895798e-02,  4.39788215e-02,\n",
       "           -2.73699574e-02, -1.23707771e-01, -5.33239543e-02,\n",
       "            9.20776799e-02, -1.05991952e-01,  2.45116472e-01,\n",
       "            1.70258984e-01],\n",
       "          [-3.85737978e-02,  3.77977937e-02, -1.34565502e-01,\n",
       "            1.67865772e-02,  1.79697387e-02,  6.42088726e-02,\n",
       "            3.02807149e-02, -1.91765353e-01,  2.07179412e-01,\n",
       "            7.59577900e-02],\n",
       "          [-2.60505918e-02, -5.73843345e-03, -1.47325858e-01,\n",
       "           -3.20808589e-02,  1.05278902e-01,  3.87905575e-02,\n",
       "           -1.10959955e-01, -9.13213938e-02,  2.18660124e-02,\n",
       "           -3.05902194e-02]],\n",
       " \n",
       "         [[-1.23221174e-01, -6.07353577e-04, -1.35187283e-01,\n",
       "           -6.13944381e-02, -1.17465109e-01,  1.52044594e-01,\n",
       "            1.19614944e-01,  9.87146720e-02, -2.00308576e-01,\n",
       "           -2.29040042e-01],\n",
       "          [ 7.88311511e-02, -1.09998554e-01,  2.38945156e-01,\n",
       "           -1.34254187e-01, -7.02443253e-03, -2.36085467e-02,\n",
       "           -1.93788297e-02,  6.25462681e-02, -1.07806124e-01,\n",
       "            2.26303991e-02],\n",
       "          [ 6.59231991e-02,  6.75223544e-02,  5.03149517e-02,\n",
       "            4.55942526e-02, -3.14266160e-02, -5.69219217e-02,\n",
       "           -5.68435080e-02,  9.75023434e-02, -2.26747200e-01,\n",
       "           -2.86582746e-02],\n",
       "          [ 1.80034190e-02, -1.98804736e-01, -8.07423797e-03,\n",
       "            2.42109708e-02,  7.15936301e-03,  8.01295117e-02,\n",
       "           -1.32244006e-01,  1.37002021e-01, -5.79625405e-02,\n",
       "           -1.88237011e-01],\n",
       "          [-5.71402311e-02, -4.22745757e-02,  7.14820847e-02,\n",
       "            1.14351451e-01, -5.98136932e-02,  5.01520969e-02,\n",
       "            3.45501900e-02, -6.32073283e-02, -1.18889302e-01,\n",
       "           -2.23582551e-01],\n",
       "          [-4.12171558e-02, -1.63696483e-01,  5.49158789e-02,\n",
       "            9.33221802e-02,  7.14174509e-02, -6.26139119e-02,\n",
       "            4.56676520e-02,  1.05864212e-01,  1.53272048e-01,\n",
       "            8.63303095e-02],\n",
       "          [ 7.59049505e-02,  3.00823450e-02, -3.52703817e-02,\n",
       "            1.51237443e-01,  9.42618772e-02, -5.78911714e-02,\n",
       "           -1.88533396e-01,  1.85683534e-01, -6.58352524e-02,\n",
       "            1.11291893e-02],\n",
       "          [-1.81884207e-02,  1.38931096e-01, -6.68178685e-03,\n",
       "           -9.54097435e-02, -1.86438905e-03, -1.56380624e-01,\n",
       "            6.25710264e-02,  8.60823989e-02,  1.05746709e-01,\n",
       "           -1.59648314e-01],\n",
       "          [ 4.11932468e-02, -3.02847736e-02,  4.39207405e-02,\n",
       "            2.05051631e-01,  1.54822562e-02, -1.42320961e-01,\n",
       "           -4.87674773e-02, -1.02113135e-01,  2.12309901e-02,\n",
       "           -1.37282208e-01],\n",
       "          [-4.61015292e-02,  4.73923571e-02, -1.28647164e-01,\n",
       "            3.61755155e-02,  1.92175701e-01, -1.08970247e-01,\n",
       "           -1.67172533e-02, -1.03741273e-01, -9.14234817e-02,\n",
       "           -4.69418876e-02]],\n",
       " \n",
       "         [[ 1.97339877e-01, -7.92988986e-02,  3.61178927e-02,\n",
       "            8.75269324e-02, -1.27176102e-02,  1.71080425e-01,\n",
       "            2.23619431e-01, -1.64433405e-01, -9.96130854e-02,\n",
       "            3.44512835e-02],\n",
       "          [ 6.31227195e-02,  1.86223760e-01,  6.69227913e-02,\n",
       "            8.71588066e-02,  1.62240833e-01,  9.18638241e-03,\n",
       "            3.68096232e-02,  1.32041704e-02,  6.75824413e-05,\n",
       "           -4.22172621e-02],\n",
       "          [-1.10416561e-01,  3.98903862e-02, -7.48601779e-02,\n",
       "           -1.74434975e-01, -1.80871427e-01, -1.01983920e-01,\n",
       "           -9.76700410e-02,  1.06864423e-01,  3.02613038e-03,\n",
       "           -2.24782843e-02],\n",
       "          [ 6.83157220e-02, -1.52197881e-02,  9.79706496e-02,\n",
       "            7.68000484e-02, -2.31230766e-01, -9.90973087e-04,\n",
       "           -2.65486985e-02,  1.15314730e-01,  3.98474634e-02,\n",
       "            8.69876966e-02],\n",
       "          [ 1.40313685e-01,  1.46533594e-01, -6.51161075e-02,\n",
       "           -1.79117575e-01, -2.81689912e-02,  2.70518716e-02,\n",
       "           -1.32394224e-01,  2.51960419e-02, -7.56366625e-02,\n",
       "           -1.09888412e-01],\n",
       "          [-4.34448533e-02, -1.00457175e-02,  3.21859419e-02,\n",
       "           -6.23803623e-02, -1.33000359e-01, -1.15383923e-01,\n",
       "           -2.52384469e-02, -1.09912001e-01, -8.42400715e-02,\n",
       "           -1.65273443e-01],\n",
       "          [-6.06370643e-02, -3.23680602e-02,  4.55051772e-02,\n",
       "           -3.92534509e-02,  1.06640838e-01, -1.74291939e-01,\n",
       "           -6.02066368e-02, -2.57290117e-02, -4.42988090e-02,\n",
       "            6.82166964e-02],\n",
       "          [-7.94913396e-02,  2.23139040e-02, -9.35547501e-02,\n",
       "            5.75350299e-02,  5.55182993e-02,  2.99230199e-02,\n",
       "            2.28930354e-01, -4.30358425e-02, -1.76778406e-01,\n",
       "           -3.75630744e-02],\n",
       "          [-1.52267501e-01, -6.42918870e-02,  2.45847646e-02,\n",
       "            1.20171353e-01, -1.07269645e-01,  1.77991539e-01,\n",
       "           -1.71826363e-01,  1.47688374e-01,  5.74155292e-03,\n",
       "            6.37402758e-02],\n",
       "          [-1.28713310e-01,  4.82489914e-02, -4.67829108e-02,\n",
       "            1.05251744e-01, -2.60181464e-02,  1.74795583e-01,\n",
       "           -2.31962115e-01, -4.60058488e-02, -5.17882071e-02,\n",
       "           -7.63179883e-02]]],\n",
       " \n",
       " \n",
       "        [[[-1.44817248e-01,  2.26501569e-01, -6.66333511e-02,\n",
       "            2.10161716e-01, -3.24297585e-02,  1.21231750e-01,\n",
       "            1.04640760e-02,  1.14110850e-01, -2.48254873e-02,\n",
       "           -8.51678401e-02],\n",
       "          [ 6.60309047e-02, -5.13744131e-02, -4.83217426e-02,\n",
       "            2.13335156e-01, -5.97906373e-02, -1.41597008e-02,\n",
       "            2.04290561e-02,  1.16385892e-01, -1.05206758e-01,\n",
       "            7.37921372e-02],\n",
       "          [-1.19293474e-01, -3.85328941e-03, -9.86413732e-02,\n",
       "           -1.63997129e-01, -3.44718359e-02,  9.56578255e-02,\n",
       "           -1.20063625e-01,  8.15209597e-02, -2.21521333e-01,\n",
       "            1.03575267e-01],\n",
       "          [ 1.95028171e-01, -1.26510382e-01, -7.74103701e-02,\n",
       "           -1.69102192e-01,  7.19323978e-02, -4.03051041e-02,\n",
       "            1.62848845e-01,  3.21326181e-02,  8.33434463e-02,\n",
       "           -1.62626430e-01],\n",
       "          [-8.75652730e-02, -1.49491966e-01,  4.28811368e-03,\n",
       "            3.23839635e-02,  1.37482926e-01,  1.60996914e-01,\n",
       "           -8.75477493e-02,  7.81943724e-02,  6.33267462e-02,\n",
       "           -1.30919129e-01],\n",
       "          [-1.89303473e-01, -1.87263578e-01, -2.62267813e-02,\n",
       "            1.76763430e-01, -1.15484316e-02,  8.36394876e-02,\n",
       "            5.89777790e-02, -1.11105904e-01,  5.87093942e-02,\n",
       "            5.47035299e-02],\n",
       "          [-2.08298549e-01,  2.30278913e-03,  1.16173305e-01,\n",
       "           -5.41599058e-02, -8.23790729e-02, -1.35533875e-02,\n",
       "            1.33200869e-01, -6.03954755e-02,  1.96013507e-02,\n",
       "            3.12862471e-02],\n",
       "          [-1.85225368e-01, -8.42582434e-02, -1.15580134e-01,\n",
       "           -9.96347889e-02, -3.65294293e-02,  1.04543768e-01,\n",
       "           -8.10248107e-02,  9.70584601e-02,  6.56780452e-02,\n",
       "            1.60754502e-01],\n",
       "          [ 3.11631411e-02,  2.21990682e-02,  7.80974329e-02,\n",
       "           -1.48668915e-01,  1.43399224e-01, -4.82461564e-02,\n",
       "            3.16404887e-02,  9.08872262e-02, -4.38953340e-02,\n",
       "            4.53006756e-03],\n",
       "          [-1.97347045e-01,  5.47768846e-02, -7.89908171e-02,\n",
       "           -1.58007741e-01,  1.25662357e-01,  1.09114312e-01,\n",
       "           -1.11749873e-01,  1.00479506e-01,  8.23318139e-02,\n",
       "           -1.01387180e-01]],\n",
       " \n",
       "         [[ 2.33938098e-02, -9.43448618e-02, -6.36696368e-02,\n",
       "            1.74629074e-02, -3.73220965e-02, -9.87456739e-02,\n",
       "            6.62156707e-03,  8.11567530e-02,  1.52127802e-01,\n",
       "            1.19627461e-01],\n",
       "          [-1.69830605e-01, -9.37439203e-02,  1.05857998e-01,\n",
       "           -4.16716896e-02,  6.91281334e-02, -1.68573167e-02,\n",
       "            1.69957429e-01,  7.32689165e-03,  5.44025302e-02,\n",
       "            5.06813191e-02],\n",
       "          [-2.28049960e-02, -7.82734454e-02,  3.35688926e-02,\n",
       "            3.65514010e-02, -3.18110362e-02,  1.49431005e-01,\n",
       "            8.57109651e-02,  2.67472747e-03,  1.60440847e-01,\n",
       "            7.99737051e-02],\n",
       "          [ 4.91654128e-02,  3.52480523e-02, -3.43381353e-02,\n",
       "            2.15078983e-03, -1.40986711e-01, -1.70772851e-01,\n",
       "           -2.80163810e-02,  7.13505433e-05,  5.86924492e-04,\n",
       "           -1.14723993e-02],\n",
       "          [ 8.04784521e-02,  3.89645323e-02, -3.97195108e-03,\n",
       "           -4.08654623e-02, -3.92556228e-02,  1.07515231e-01,\n",
       "           -4.24126647e-02, -1.86153591e-01, -7.11496472e-02,\n",
       "            2.82673053e-02],\n",
       "          [-4.15638052e-02,  1.19508067e-02,  1.61667794e-01,\n",
       "           -5.98270074e-02,  1.59446061e-01, -1.54596463e-01,\n",
       "           -7.53921568e-02,  9.29858722e-03, -1.06049754e-01,\n",
       "            8.28401148e-02],\n",
       "          [ 1.21008217e-01, -4.27485742e-02,  1.39313042e-01,\n",
       "           -1.36166960e-01, -3.57744209e-02, -2.24507570e-01,\n",
       "           -1.47161499e-01, -7.15941638e-02, -1.14483694e-02,\n",
       "           -7.64013873e-03],\n",
       "          [ 4.46193703e-02,  6.67277798e-02, -3.73464776e-03,\n",
       "           -8.73474255e-02,  1.32458001e-01,  1.00006141e-01,\n",
       "           -1.37554884e-01, -7.53911659e-02, -5.00236899e-02,\n",
       "            2.74028201e-02],\n",
       "          [-4.06835079e-02,  7.67779797e-02, -3.67930345e-03,\n",
       "            1.60293102e-01, -9.20196995e-02, -1.03736660e-02,\n",
       "            7.64677152e-02, -3.93676311e-02, -1.77490652e-01,\n",
       "           -4.54227999e-02],\n",
       "          [ 1.16835363e-01, -2.86053400e-02, -1.81422345e-02,\n",
       "            3.87039520e-02, -2.17868648e-02,  1.51334047e-01,\n",
       "           -1.48274109e-01,  1.91059664e-01, -2.39984598e-02,\n",
       "            5.10003045e-02]],\n",
       " \n",
       "         [[ 2.61268318e-02, -2.80166529e-02,  1.15276687e-01,\n",
       "           -2.17348672e-02, -1.20558091e-01, -9.46394801e-02,\n",
       "            1.15609176e-01, -2.09887475e-01,  1.63544729e-01,\n",
       "           -1.23697519e-01],\n",
       "          [ 6.32945597e-02,  9.43811436e-04, -9.15335044e-02,\n",
       "            1.71730921e-01, -3.68504822e-02, -1.29017040e-01,\n",
       "            1.35943172e-02, -5.16752079e-02,  1.34774551e-01,\n",
       "            2.17116047e-02],\n",
       "          [ 4.05768231e-02, -7.65066892e-02, -9.12971124e-02,\n",
       "           -8.82846713e-02, -2.78011169e-02,  4.94951792e-02,\n",
       "           -1.06464466e-02, -5.60789481e-02,  3.15501541e-02,\n",
       "           -1.46239996e-01],\n",
       "          [-7.02964887e-02, -2.11720690e-01,  5.88321835e-02,\n",
       "            6.51261583e-02, -1.23016223e-01,  6.94340691e-02,\n",
       "           -4.82710600e-02,  8.33265558e-02, -1.01150116e-02,\n",
       "           -1.12979785e-01],\n",
       "          [ 9.89388525e-02, -1.67651594e-01, -1.74290240e-01,\n",
       "           -3.42526436e-02,  7.54584670e-02, -9.62401628e-02,\n",
       "           -2.77377870e-02, -2.37906516e-01, -9.84840393e-02,\n",
       "            1.66777018e-02],\n",
       "          [-7.32936561e-02, -2.10263096e-02, -1.26178876e-01,\n",
       "            1.32635962e-02,  2.07519475e-02,  1.24720454e-01,\n",
       "            1.93842184e-02,  2.52824835e-02, -1.62117369e-02,\n",
       "            6.89930022e-02],\n",
       "          [-9.29243788e-02,  1.63770676e-01,  1.31339535e-01,\n",
       "           -6.65975874e-03,  1.06957085e-01, -6.68346807e-02,\n",
       "            7.12891072e-02, -1.65606692e-01,  1.10420033e-01,\n",
       "           -2.30020117e-02],\n",
       "          [-2.39494704e-02, -2.72205845e-02, -9.64355692e-02,\n",
       "           -7.17165768e-02, -1.00173734e-01, -5.15200421e-02,\n",
       "           -3.80541496e-02, -6.95788935e-02,  4.53404896e-02,\n",
       "            8.21581408e-02],\n",
       "          [-1.19920053e-01, -7.69955590e-02, -1.02899656e-01,\n",
       "            9.14903358e-02, -5.14953025e-02,  8.42553675e-02,\n",
       "           -3.65705676e-02, -2.82598846e-03,  1.30101413e-01,\n",
       "            4.11561430e-02],\n",
       "          [ 4.03209701e-02, -1.04061730e-01, -2.15942726e-01,\n",
       "            9.21981782e-03,  2.14306235e-01,  7.95683637e-02,\n",
       "            8.54182988e-03, -1.10809542e-02, -1.15611874e-01,\n",
       "            9.50715840e-02]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_219_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([-0.00359031,  0.00930855,  0.0001581 , -0.01199857,  0.01158896,\n",
       "         0.00556783, -0.00089094,  0.00080338, -0.00311097, -0.01332143],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_249_1/gamma:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.9998816 , 1.0022944 , 0.99472344, 1.0043478 , 0.9926456 ,\n",
       "        1.0033965 , 1.0001464 , 1.0021745 , 0.9974514 , 1.0024154 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_249_1/beta:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.00724354, -0.00172935, -0.00293744,  0.00704751, -0.00181972,\n",
       "         0.00639493, -0.01191419,  0.01088994,  0.00031498,  0.00212661],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_220_1/kernel:0' shape=(3, 3, 10, 10) dtype=float32, numpy=\n",
       " array([[[[-0.04071948, -0.10485952,  0.01714608, -0.00553399,\n",
       "           -0.04601976, -0.15614097,  0.01015718, -0.01447301,\n",
       "           -0.08060953, -0.01971467],\n",
       "          [ 0.10052959,  0.12239464, -0.04159877, -0.01063146,\n",
       "            0.01214133, -0.09487503,  0.1215203 ,  0.15190482,\n",
       "            0.02280762,  0.15189311],\n",
       "          [ 0.06481729,  0.02730891, -0.10479853, -0.22123197,\n",
       "            0.01312567,  0.02179761,  0.02754615,  0.07520343,\n",
       "           -0.15668066,  0.05704654],\n",
       "          [ 0.06913419,  0.16359174, -0.12802126,  0.06997892,\n",
       "           -0.15446733, -0.14898828,  0.02798152, -0.07788127,\n",
       "           -0.0007164 , -0.2034076 ],\n",
       "          [ 0.0710422 ,  0.01030962, -0.22790797,  0.06738345,\n",
       "            0.00239257, -0.17682263,  0.06270509, -0.11894358,\n",
       "           -0.11957943,  0.11605055],\n",
       "          [ 0.19660985,  0.03488865, -0.02263503, -0.18835084,\n",
       "            0.0132584 ,  0.11811081, -0.06893843, -0.10773569,\n",
       "            0.10691939, -0.00357162],\n",
       "          [-0.16067961,  0.09657294, -0.04251616,  0.09307007,\n",
       "            0.1380811 , -0.07799418,  0.13037837, -0.07571174,\n",
       "           -0.11876293,  0.15251985],\n",
       "          [-0.1596559 , -0.10186213, -0.05905106, -0.00574584,\n",
       "            0.04571532,  0.11937636, -0.16703257,  0.15985481,\n",
       "            0.09312058,  0.01634785],\n",
       "          [-0.1570705 , -0.05822331,  0.01686043, -0.15325579,\n",
       "            0.10246415, -0.15451688,  0.17035854, -0.12048357,\n",
       "            0.03490257,  0.0536119 ],\n",
       "          [-0.11687016, -0.07540125,  0.02444064, -0.17479359,\n",
       "           -0.14535907, -0.02633318,  0.22531435,  0.2060504 ,\n",
       "           -0.01372607, -0.19613992]],\n",
       " \n",
       "         [[ 0.03584301, -0.17299747, -0.04163562,  0.09959974,\n",
       "            0.00024959, -0.19808501, -0.01001026, -0.03504771,\n",
       "            0.09851305,  0.08893088],\n",
       "          [-0.04703859, -0.01428755, -0.12625444,  0.03017144,\n",
       "            0.03471938, -0.01430298,  0.13372639, -0.06289706,\n",
       "           -0.11124481,  0.14173086],\n",
       "          [-0.05502491, -0.00274278, -0.05702636,  0.21902218,\n",
       "           -0.19908437,  0.07024401, -0.07636495, -0.05490524,\n",
       "            0.12540717,  0.06467061],\n",
       "          [-0.15175089,  0.02079302,  0.09135033, -0.20282026,\n",
       "           -0.00815917,  0.02331526, -0.03340711, -0.2332676 ,\n",
       "           -0.17544949,  0.05481697],\n",
       "          [ 0.06899571,  0.02624624,  0.05847004, -0.0886029 ,\n",
       "            0.03417983, -0.20107238, -0.10540645, -0.08783702,\n",
       "            0.0434263 ,  0.13393244],\n",
       "          [ 0.1185165 , -0.05626282, -0.15149537,  0.09938962,\n",
       "           -0.0516636 , -0.02684043, -0.16565251, -0.03567411,\n",
       "            0.06572168, -0.01274624],\n",
       "          [ 0.06294444,  0.11881127,  0.08658954, -0.22784126,\n",
       "            0.05728424,  0.07628844,  0.06929845,  0.13603081,\n",
       "           -0.06107324, -0.04483739],\n",
       "          [ 0.08387396,  0.03528679, -0.03536478,  0.1490879 ,\n",
       "            0.05306144, -0.00647309, -0.16366966, -0.12046362,\n",
       "           -0.21901882, -0.09095283],\n",
       "          [-0.15251149, -0.15765509, -0.14195757,  0.06762421,\n",
       "           -0.15752289, -0.01296381, -0.02569367, -0.07656731,\n",
       "            0.16692142, -0.07053657],\n",
       "          [-0.03376301,  0.01094438,  0.19577473,  0.01565439,\n",
       "            0.10653786, -0.09451327, -0.03955395,  0.0212913 ,\n",
       "           -0.07982403,  0.1518836 ]],\n",
       " \n",
       "         [[ 0.06127471,  0.12454933, -0.09871164, -0.02527269,\n",
       "           -0.24028088, -0.05731723, -0.09198619,  0.19669445,\n",
       "            0.09193442,  0.04997336],\n",
       "          [-0.15162796,  0.07103198, -0.2218252 , -0.06372958,\n",
       "            0.06751615, -0.11743066, -0.02287547, -0.02629605,\n",
       "            0.09435048, -0.06150759],\n",
       "          [ 0.03620581,  0.00529569, -0.1737143 ,  0.18374074,\n",
       "            0.14244598,  0.04220079, -0.02583253,  0.12407978,\n",
       "           -0.06102292, -0.24223   ],\n",
       "          [ 0.1340856 ,  0.10628098,  0.10994002,  0.08776351,\n",
       "           -0.08998794,  0.03906384,  0.1969851 ,  0.07152422,\n",
       "            0.10800077,  0.01129551],\n",
       "          [-0.10427738, -0.14131749, -0.09314509,  0.15294255,\n",
       "            0.00875395, -0.19724834,  0.07097492, -0.19248793,\n",
       "            0.11776944, -0.18697022],\n",
       "          [-0.21740752,  0.17058925,  0.02181068, -0.00537843,\n",
       "           -0.11766393,  0.02217668, -0.00633296,  0.18343277,\n",
       "           -0.02777596, -0.14459547],\n",
       "          [ 0.03907492, -0.03859345, -0.02074963,  0.16998057,\n",
       "           -0.05929814, -0.12201289,  0.10748371, -0.04498356,\n",
       "            0.02333236,  0.21452245],\n",
       "          [-0.13871734,  0.0768059 , -0.08137463,  0.03905621,\n",
       "           -0.02389872, -0.08273219,  0.178774  ,  0.01808699,\n",
       "            0.09966321, -0.02609221],\n",
       "          [ 0.12111259,  0.17795041, -0.17967065, -0.08150757,\n",
       "            0.09129849,  0.02136693,  0.08330797, -0.12106644,\n",
       "           -0.01447172,  0.04401728],\n",
       "          [-0.05973915, -0.13731964,  0.00412354, -0.20115303,\n",
       "            0.11221953,  0.12197675,  0.11637232, -0.01218905,\n",
       "            0.10711353,  0.04065799]]],\n",
       " \n",
       " \n",
       "        [[[ 0.11289847, -0.15464102, -0.00503754, -0.20162842,\n",
       "            0.05786053,  0.00533249, -0.18682201,  0.07544801,\n",
       "            0.02992214,  0.1668975 ],\n",
       "          [-0.10690458, -0.10048852, -0.02218767,  0.11023614,\n",
       "            0.09695517, -0.14174752,  0.06219684, -0.1919142 ,\n",
       "           -0.11960484,  0.01888142],\n",
       "          [-0.09511629, -0.18400536, -0.01591347, -0.06207559,\n",
       "           -0.10421262, -0.00059714,  0.16427276, -0.04733974,\n",
       "            0.06939485,  0.06274066],\n",
       "          [ 0.17805433,  0.06046224, -0.19576204, -0.22586821,\n",
       "            0.02761406,  0.01868501,  0.01100948,  0.11048465,\n",
       "            0.03097244, -0.1579483 ],\n",
       "          [-0.01618839, -0.15260719, -0.0739207 ,  0.15400434,\n",
       "           -0.03664052, -0.04921087,  0.09785999, -0.06049857,\n",
       "            0.10606468, -0.02535314],\n",
       "          [ 0.00225398, -0.01712299, -0.09167674,  0.06150055,\n",
       "            0.04941973, -0.15490845,  0.0133996 , -0.20383632,\n",
       "           -0.06137588, -0.01955652],\n",
       "          [-0.10831454,  0.14457142,  0.08378258, -0.07117862,\n",
       "            0.08462255, -0.06013887,  0.01102784, -0.09678876,\n",
       "           -0.04734738, -0.11299018],\n",
       "          [ 0.12706931, -0.16220117,  0.01146989,  0.16133499,\n",
       "           -0.11934187, -0.09769115, -0.01804904, -0.0156853 ,\n",
       "           -0.02324687, -0.07757235],\n",
       "          [ 0.02574534, -0.14199553, -0.03150017, -0.03116885,\n",
       "            0.07719991,  0.07375062,  0.10555299, -0.05428745,\n",
       "            0.10313854,  0.07112016],\n",
       "          [-0.11598127, -0.0091943 , -0.08493185, -0.09912208,\n",
       "            0.13042375, -0.04010193, -0.00853848,  0.07666725,\n",
       "           -0.06170472, -0.04473584]],\n",
       " \n",
       "         [[ 0.18541652, -0.08166829,  0.05931174,  0.0687143 ,\n",
       "            0.0206749 , -0.00349296,  0.02489174, -0.2250181 ,\n",
       "            0.02561674,  0.01654119],\n",
       "          [ 0.02235785,  0.15290965,  0.16797732, -0.10170828,\n",
       "            0.06666873,  0.06588035, -0.02047775, -0.04356691,\n",
       "            0.09203377, -0.15294786],\n",
       "          [ 0.12796025,  0.00598191,  0.09989008, -0.0790161 ,\n",
       "            0.12956847, -0.04990802, -0.15634565, -0.13368894,\n",
       "            0.1074358 ,  0.00722903],\n",
       "          [-0.07765963,  0.09684461,  0.10540554, -0.17978643,\n",
       "            0.01679352,  0.02194397, -0.19048038,  0.05023158,\n",
       "           -0.10282219, -0.0738554 ],\n",
       "          [ 0.04523521,  0.12468612, -0.00278854, -0.06440792,\n",
       "            0.01214961,  0.03171487, -0.15661153,  0.10195048,\n",
       "           -0.05681071,  0.09453958],\n",
       "          [-0.24545331,  0.03853856, -0.15444192,  0.0375212 ,\n",
       "           -0.17065908,  0.02467153,  0.11351469,  0.05238007,\n",
       "            0.08989196,  0.05569572],\n",
       "          [ 0.02132878,  0.09569966, -0.01469224,  0.05609416,\n",
       "            0.09769177,  0.09231827,  0.07557043,  0.01838791,\n",
       "           -0.12677646,  0.01195089],\n",
       "          [ 0.06954648, -0.22083355, -0.01797156, -0.14597464,\n",
       "            0.06826974, -0.081863  ,  0.11297221, -0.0428413 ,\n",
       "            0.10324905,  0.1393388 ],\n",
       "          [ 0.06487879, -0.03823928,  0.11502053, -0.01297036,\n",
       "           -0.11708786,  0.05787999, -0.1587728 , -0.16029215,\n",
       "            0.17177664, -0.06030221],\n",
       "          [-0.08974628, -0.07788979, -0.04751116, -0.11183922,\n",
       "           -0.04852448,  0.2261977 ,  0.03013522,  0.16078137,\n",
       "           -0.03389005,  0.02587434]],\n",
       " \n",
       "         [[-0.22064258, -0.1908499 ,  0.1619993 ,  0.00171418,\n",
       "            0.00499647,  0.0356807 , -0.03211457,  0.0227444 ,\n",
       "            0.01557114,  0.07679296],\n",
       "          [ 0.16405907, -0.10235137,  0.19470684,  0.06001658,\n",
       "           -0.01353316, -0.05786043, -0.00766128,  0.0117112 ,\n",
       "            0.09051093, -0.01511177],\n",
       "          [ 0.08177408, -0.10976675, -0.00812047, -0.00562421,\n",
       "           -0.00303697, -0.15946068,  0.08626227, -0.00499012,\n",
       "           -0.1173096 , -0.03632371],\n",
       "          [-0.14015436, -0.06482852, -0.15247655, -0.07005783,\n",
       "            0.10436854, -0.14747691,  0.1761564 , -0.17428459,\n",
       "            0.05565731,  0.0011449 ],\n",
       "          [-0.0943415 ,  0.0610148 , -0.02266471, -0.06868771,\n",
       "           -0.00603163,  0.09057862, -0.18225738,  0.0421923 ,\n",
       "           -0.15266865,  0.01043644],\n",
       "          [ 0.14794429,  0.07333588,  0.03740503, -0.02257978,\n",
       "            0.06609224,  0.19682123, -0.1163616 , -0.08159977,\n",
       "            0.0072358 ,  0.06852735],\n",
       "          [-0.0651397 ,  0.01005876, -0.04705166, -0.12529229,\n",
       "           -0.09129009, -0.23530817,  0.04610407, -0.02511613,\n",
       "            0.23942219, -0.14881833],\n",
       "          [ 0.07650554, -0.03960873,  0.05548701, -0.06427865,\n",
       "           -0.01404515, -0.00616937, -0.13400944,  0.05420984,\n",
       "           -0.15849394,  0.01798212],\n",
       "          [-0.09546657, -0.00642325,  0.01698399,  0.01165512,\n",
       "           -0.1624189 , -0.06639475,  0.17512451, -0.13609318,\n",
       "           -0.10183471, -0.13549955],\n",
       "          [ 0.07150143, -0.04271057, -0.05001621, -0.15579191,\n",
       "           -0.02295755, -0.08440073,  0.16827273, -0.05433117,\n",
       "           -0.01002587, -0.19261776]]],\n",
       " \n",
       " \n",
       "        [[[-0.20251998,  0.06005263, -0.04277775, -0.17661318,\n",
       "            0.06117032,  0.04669086,  0.03107794,  0.1361526 ,\n",
       "            0.01230303, -0.01073117],\n",
       "          [-0.07932968,  0.03389952,  0.03450581,  0.11374214,\n",
       "           -0.05691527,  0.13838384,  0.04805163,  0.11313576,\n",
       "            0.00486441, -0.21703206],\n",
       "          [ 0.07742762,  0.10740251, -0.06258997,  0.01293524,\n",
       "           -0.10563585, -0.12704892,  0.12839483, -0.04431823,\n",
       "            0.08342117, -0.02499664],\n",
       "          [-0.09744524, -0.11671849, -0.081049  ,  0.0633539 ,\n",
       "           -0.11850443, -0.04462986,  0.07294473,  0.12783615,\n",
       "           -0.10020887,  0.08576722],\n",
       "          [-0.16309842, -0.04522684, -0.06323169, -0.02649159,\n",
       "            0.05199269, -0.01176355, -0.18834168, -0.04120415,\n",
       "           -0.0309468 , -0.02431837],\n",
       "          [-0.17008474,  0.03527879,  0.2277572 ,  0.0088373 ,\n",
       "            0.0708084 ,  0.05941654, -0.10174911, -0.06945047,\n",
       "           -0.068343  ,  0.06255998],\n",
       "          [ 0.0323961 ,  0.10770498,  0.05446687,  0.01792963,\n",
       "            0.10994683,  0.08290577, -0.03532308, -0.06596331,\n",
       "            0.17329252,  0.03543949],\n",
       "          [-0.17184028,  0.15156507, -0.21384974,  0.15247706,\n",
       "            0.0694531 ,  0.04920005, -0.17181833,  0.18541402,\n",
       "            0.05097588, -0.17945701],\n",
       "          [ 0.20021752, -0.1243031 ,  0.02150231,  0.05106107,\n",
       "            0.08970558,  0.06849953, -0.18999201,  0.12235851,\n",
       "            0.12034073, -0.19433671],\n",
       "          [-0.04437713,  0.03170646,  0.07078171, -0.03053322,\n",
       "            0.10315339, -0.22447115, -0.13915972,  0.15811579,\n",
       "           -0.00648672, -0.01367181]],\n",
       " \n",
       "         [[ 0.16140978,  0.11316536, -0.20823586,  0.01832259,\n",
       "           -0.05768735,  0.09112018, -0.03280644,  0.05539392,\n",
       "           -0.17670569, -0.13981041],\n",
       "          [ 0.03498236,  0.11269991,  0.06907249,  0.00681815,\n",
       "           -0.03897691, -0.14707784,  0.01052724, -0.1433602 ,\n",
       "           -0.10020322, -0.0380563 ],\n",
       "          [ 0.02061832, -0.07458472,  0.03065838,  0.03084412,\n",
       "           -0.06744804,  0.1126416 , -0.08785947,  0.08583914,\n",
       "            0.04491587,  0.02384045],\n",
       "          [-0.07670262, -0.10945703, -0.03515705, -0.0132307 ,\n",
       "           -0.10082775,  0.19376473, -0.08196668,  0.11700287,\n",
       "           -0.15478927,  0.06883012],\n",
       "          [ 0.19329807, -0.07721043, -0.05044011, -0.07425848,\n",
       "            0.01303517,  0.00928462,  0.16434738,  0.02432305,\n",
       "            0.19915117, -0.1370751 ],\n",
       "          [ 0.11291897,  0.03270883, -0.0741464 , -0.22647488,\n",
       "            0.10608979,  0.18271068,  0.07438621, -0.01800349,\n",
       "           -0.16483486,  0.06453727],\n",
       "          [-0.06176921, -0.08688622,  0.20038864,  0.12067015,\n",
       "            0.10269438, -0.2071071 ,  0.0278663 ,  0.20764521,\n",
       "            0.07976376,  0.06854606],\n",
       "          [ 0.0587667 ,  0.05752633, -0.06581632, -0.23164083,\n",
       "           -0.07636323, -0.06333343, -0.10733242, -0.11426241,\n",
       "           -0.16433886, -0.04515222],\n",
       "          [ 0.01505341,  0.06945779,  0.06915069, -0.00130332,\n",
       "            0.17749286,  0.02595201, -0.16322969,  0.07412928,\n",
       "           -0.0337011 ,  0.19729573],\n",
       "          [-0.05369836, -0.10434227, -0.00446344, -0.05092714,\n",
       "           -0.11501723, -0.09971204, -0.1293128 ,  0.0031383 ,\n",
       "           -0.11612388,  0.13635582]],\n",
       " \n",
       "         [[ 0.02212952,  0.14714009, -0.23290543,  0.14697589,\n",
       "           -0.15616232, -0.13103327, -0.03035648,  0.05661544,\n",
       "           -0.16774169, -0.05829484],\n",
       "          [-0.08871987,  0.05801985, -0.19764267, -0.18147   ,\n",
       "           -0.0206146 ,  0.01274008, -0.09907413,  0.01654987,\n",
       "           -0.11404741, -0.10752384],\n",
       "          [-0.06638953,  0.04510949, -0.00762828,  0.06289761,\n",
       "            0.07442535, -0.161487  ,  0.13958897,  0.06849246,\n",
       "            0.08515238,  0.000786  ],\n",
       "          [-0.12195646, -0.01146095,  0.03910394,  0.0471328 ,\n",
       "            0.02098483,  0.03838791,  0.00285232, -0.13144788,\n",
       "           -0.05738182,  0.03315028],\n",
       "          [-0.07006919, -0.10729159, -0.0334678 ,  0.10826814,\n",
       "            0.13783583,  0.19463652,  0.09013799, -0.05372679,\n",
       "            0.05105552,  0.06432493],\n",
       "          [-0.00549034, -0.13485856,  0.03763136,  0.01879119,\n",
       "           -0.03949698,  0.0134861 , -0.04179855, -0.21516779,\n",
       "            0.07669239,  0.03330083],\n",
       "          [ 0.05061371,  0.14030577,  0.03123054, -0.15735008,\n",
       "           -0.16376708,  0.0801961 , -0.05549176, -0.031226  ,\n",
       "            0.04177024, -0.13219434],\n",
       "          [-0.0754587 , -0.03180633,  0.02867719, -0.13401198,\n",
       "            0.11331809, -0.07974488,  0.13790596,  0.1288196 ,\n",
       "           -0.04573924,  0.00581217],\n",
       "          [-0.11379898, -0.10041856, -0.12411294, -0.20843421,\n",
       "            0.02338842,  0.08861326,  0.04386873, -0.09510503,\n",
       "            0.05781312, -0.00976666],\n",
       "          [-0.12648784,  0.16420619,  0.04192559, -0.10347714,\n",
       "           -0.1059532 ,  0.01498076,  0.08983373,  0.00621853,\n",
       "            0.09020483, -0.05104116]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_220_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.00197952,  0.000255  , -0.00790314,  0.00083751,  0.00138084,\n",
       "         0.00356111, -0.01154541,  0.00106886, -0.00576153, -0.00365566],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_250_1/gamma:0' shape=(10,) dtype=float32, numpy=\n",
       " array([1.0093904, 0.9823292, 1.0047513, 0.9891817, 0.9999991, 1.0094211,\n",
       "        1.013434 , 0.9825863, 1.0096635, 1.0008535], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_250_1/beta:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 3.70635977e-03,  3.70083237e-03, -7.12216645e-03,  1.43356575e-02,\n",
       "        -5.76976733e-03, -5.98404149e-04, -1.57424845e-02,  3.97230469e-05,\n",
       "         2.08421401e-03,  1.47233149e-02], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_221_1/kernel:0' shape=(3, 3, 10, 10) dtype=float32, numpy=\n",
       " array([[[[-1.49680197e-01, -2.81311218e-02, -1.06407747e-01,\n",
       "            1.96579665e-01,  5.35590202e-02,  1.30665660e-01,\n",
       "            1.75376132e-01,  3.73159833e-02,  1.11317396e-01,\n",
       "           -9.37561225e-03],\n",
       "          [-1.34816870e-01,  6.31669834e-02, -7.94403628e-02,\n",
       "            1.39063090e-01,  9.76344347e-02, -9.13428068e-02,\n",
       "            8.73562545e-02,  8.75391345e-03,  6.88722283e-02,\n",
       "           -7.06084296e-02],\n",
       "          [-1.18113984e-03, -1.40973374e-01,  2.03572884e-01,\n",
       "           -1.18924133e-01, -1.08975284e-01,  1.03204131e-01,\n",
       "           -6.72276970e-03, -1.48482472e-01,  8.27709287e-02,\n",
       "           -2.12832680e-03],\n",
       "          [ 1.38651505e-01,  1.08192943e-01, -1.23593986e-01,\n",
       "           -7.05923587e-02, -8.71801153e-02,  1.84071288e-01,\n",
       "            1.10211700e-01, -8.07639658e-02, -1.95592642e-01,\n",
       "           -8.26702192e-02],\n",
       "          [-9.94699299e-02, -1.07054763e-01, -5.23898639e-02,\n",
       "           -5.42491712e-02,  2.01344024e-02,  2.42214873e-02,\n",
       "            1.64175797e-02,  1.20985433e-01,  4.86409925e-02,\n",
       "            7.69801512e-02],\n",
       "          [-8.52369219e-02, -1.21187329e-01,  7.64299259e-02,\n",
       "           -1.98289320e-01,  1.54101193e-01,  1.18926547e-01,\n",
       "            1.53621465e-01, -5.86784258e-02,  2.36623764e-01,\n",
       "            1.29226185e-02],\n",
       "          [ 2.71709375e-02, -6.13340661e-02, -1.78482607e-02,\n",
       "            1.49160907e-01, -1.73055218e-04,  1.16560422e-01,\n",
       "            3.77960168e-02,  1.83996543e-01,  1.24050363e-03,\n",
       "           -1.00240223e-01],\n",
       "          [-4.57102209e-02, -3.39884944e-02, -1.86633304e-01,\n",
       "           -2.46123910e-01,  1.38793886e-01, -9.83169824e-02,\n",
       "            2.17247140e-02,  3.69331837e-02,  4.76752557e-02,\n",
       "           -5.47556542e-02],\n",
       "          [-2.06578359e-01, -1.85784340e-01, -3.48497927e-02,\n",
       "           -4.31498466e-03,  7.64293410e-03, -3.27919461e-02,\n",
       "           -1.00645043e-01,  4.84678745e-02, -2.19642967e-01,\n",
       "            2.07518041e-02],\n",
       "          [-1.15115782e-02, -1.77961327e-02,  2.01726794e-01,\n",
       "           -8.66440833e-02, -6.40381053e-02, -9.26993322e-03,\n",
       "           -1.11482456e-01, -1.94860343e-02,  6.11087568e-02,\n",
       "           -7.73886815e-02]],\n",
       " \n",
       "         [[-7.47056082e-02, -8.84091016e-03, -2.33575076e-01,\n",
       "            1.36886895e-01,  2.15550974e-01,  4.39960547e-02,\n",
       "            9.35931876e-02,  3.34682949e-02, -2.39152405e-02,\n",
       "            7.93463886e-02],\n",
       "          [-1.45578876e-01, -1.53541192e-01, -2.15596519e-03,\n",
       "            5.89195490e-02, -1.66202962e-01,  1.15048490e-01,\n",
       "            1.14936426e-01, -1.75685678e-02, -2.00182021e-01,\n",
       "            9.13383812e-03],\n",
       "          [-4.28714789e-02, -1.20123802e-02,  2.33108759e-01,\n",
       "           -8.22080225e-02,  6.41822144e-02, -4.79891375e-02,\n",
       "            5.40179424e-02, -4.09348309e-03,  1.22995190e-01,\n",
       "            5.70756458e-02],\n",
       "          [ 7.96533078e-02, -1.00307629e-01, -1.36671901e-01,\n",
       "            5.06461971e-02,  1.36794478e-01,  1.20585058e-02,\n",
       "            5.70732206e-02, -1.91772640e-01, -1.69597894e-01,\n",
       "           -2.57042013e-02],\n",
       "          [-1.87047701e-02,  7.57228732e-02, -9.47461128e-02,\n",
       "            1.00886479e-01, -1.62676588e-01,  2.46307980e-02,\n",
       "            1.11355193e-01,  2.35538393e-01, -1.18823163e-01,\n",
       "            6.09402219e-03],\n",
       "          [ 5.68431914e-02,  4.14320081e-03,  2.79352218e-02,\n",
       "           -5.27897850e-02, -8.07667524e-02,  1.41782582e-01,\n",
       "           -7.45272487e-02, -3.07364929e-02,  6.95183799e-02,\n",
       "            1.81575507e-01],\n",
       "          [-1.02249615e-01, -1.02215834e-01, -1.24335382e-02,\n",
       "           -1.18095484e-02, -1.14101274e-02, -3.90266106e-02,\n",
       "           -6.24566488e-02,  2.20102087e-01,  2.75235679e-02,\n",
       "            6.45985734e-03],\n",
       "          [ 1.38521582e-01, -7.55202174e-02, -1.61772326e-01,\n",
       "            4.52878959e-02, -2.49117147e-02, -7.83284893e-04,\n",
       "           -1.19661674e-01, -8.43393952e-02,  7.61132687e-02,\n",
       "           -1.61605820e-01],\n",
       "          [-3.29880267e-02,  1.00795135e-01, -7.58266747e-02,\n",
       "            7.65054002e-02, -1.62856057e-01, -9.46197659e-02,\n",
       "            9.10825431e-02, -1.36923650e-02, -1.24775171e-01,\n",
       "            2.34196529e-01],\n",
       "          [-2.21790057e-02, -2.88499668e-02,  1.06571302e-01,\n",
       "           -2.22299710e-01, -3.22095379e-02, -5.36386147e-02,\n",
       "           -1.00468509e-01,  2.91865859e-02, -3.53289843e-02,\n",
       "            1.30740225e-01]],\n",
       " \n",
       "         [[-4.94829454e-02,  9.59822685e-02,  1.34878367e-01,\n",
       "           -1.05875529e-01,  1.25939637e-01, -7.20457658e-02,\n",
       "           -6.71485439e-02, -1.47675037e-01,  3.79866958e-02,\n",
       "           -2.54017543e-02],\n",
       "          [ 1.22674249e-01, -5.52300476e-02,  2.04978153e-01,\n",
       "            1.23918727e-02, -9.47810560e-02, -1.37793375e-02,\n",
       "            7.80836791e-02, -1.02386028e-01,  1.29711311e-02,\n",
       "           -7.56295845e-02],\n",
       "          [ 6.70239031e-02, -8.30368418e-03, -1.09383456e-01,\n",
       "           -1.12906948e-01,  1.16848655e-01,  1.00945115e-01,\n",
       "           -1.09600723e-01,  2.17050701e-01, -5.94233200e-02,\n",
       "            2.28721678e-01],\n",
       "          [ 2.59420672e-03,  1.68077871e-01, -7.18516037e-02,\n",
       "           -4.95075509e-02, -7.00223222e-02, -1.16094835e-01,\n",
       "           -1.88895375e-01, -1.74512297e-01,  1.03838429e-01,\n",
       "           -1.63749263e-01],\n",
       "          [ 4.80861440e-02, -1.77174062e-02,  4.24010567e-02,\n",
       "           -3.42526771e-02, -1.68942541e-01,  8.75190794e-02,\n",
       "           -2.44816989e-01,  6.94306120e-02,  6.21153079e-02,\n",
       "            1.37290135e-01],\n",
       "          [-2.08797172e-01, -4.05532308e-02, -4.29239459e-02,\n",
       "            8.96525458e-02, -1.89520866e-02,  1.84562236e-01,\n",
       "            1.36201784e-01, -3.01860981e-02,  1.25725225e-01,\n",
       "            2.49877460e-02],\n",
       "          [ 1.39584485e-02, -9.47535262e-02, -2.21405141e-02,\n",
       "            9.24755782e-02,  8.36518928e-02, -6.96720649e-03,\n",
       "           -7.20776990e-02, -3.25784758e-02, -3.67111228e-02,\n",
       "            2.31812999e-01],\n",
       "          [-6.13574795e-02, -6.37081414e-02,  2.74964310e-02,\n",
       "            2.70515457e-02, -1.56575561e-01,  2.83582998e-03,\n",
       "            8.35375488e-03,  6.32457212e-02, -1.57961667e-01,\n",
       "            2.86451802e-02],\n",
       "          [ 3.34097818e-02,  1.91885214e-02,  9.11539048e-02,\n",
       "            1.37058824e-01,  8.44052881e-02, -3.01868096e-02,\n",
       "            1.27720889e-02, -2.01866459e-02,  9.49821472e-02,\n",
       "            1.30769491e-01],\n",
       "          [ 6.05794303e-02,  2.67430171e-02,  1.07398639e-02,\n",
       "           -1.08180352e-01, -8.17065686e-02, -4.98952456e-02,\n",
       "           -1.40352711e-01, -1.61531389e-01, -1.97286233e-02,\n",
       "           -2.57325303e-02]]],\n",
       " \n",
       " \n",
       "        [[[-5.39280064e-02,  1.67594641e-01, -9.17426944e-02,\n",
       "           -1.02081418e-01,  3.45276445e-02, -7.74610788e-02,\n",
       "           -1.24233454e-01,  1.17162026e-01,  3.20462473e-02,\n",
       "            1.68169081e-01],\n",
       "          [ 5.10880463e-02, -8.38677064e-02,  1.40391767e-01,\n",
       "           -7.46513531e-02,  1.10769182e-01,  9.88962576e-02,\n",
       "            1.25173047e-01, -7.63666332e-02, -9.18156505e-02,\n",
       "            9.08718109e-02],\n",
       "          [-6.14559278e-03,  6.58683851e-02, -3.04469932e-02,\n",
       "           -1.17772453e-01,  1.07677348e-01,  1.31930094e-02,\n",
       "            1.33603722e-01,  8.21027085e-02,  4.84314524e-02,\n",
       "            3.54344882e-02],\n",
       "          [ 3.58222798e-02,  1.16257384e-01,  6.22684211e-02,\n",
       "           -1.76238403e-01, -1.74277253e-03,  8.58085230e-02,\n",
       "            7.66934007e-02, -2.01055333e-01,  1.20316833e-01,\n",
       "            1.64935235e-02],\n",
       "          [ 1.76936816e-02, -1.55859562e-02, -6.96527287e-02,\n",
       "            6.57303333e-02,  5.83223104e-02, -2.25793980e-02,\n",
       "           -1.19101703e-02, -1.28977269e-01, -1.33931696e-01,\n",
       "           -1.92136049e-01],\n",
       "          [ 7.72732822e-03, -6.29518330e-02,  1.42663531e-03,\n",
       "           -2.27829423e-02,  1.13558425e-02, -1.86278984e-01,\n",
       "            3.35377385e-03,  7.06866756e-02,  7.20796222e-03,\n",
       "            1.63015053e-01],\n",
       "          [-7.32125267e-02,  6.63840249e-02, -1.14432603e-01,\n",
       "           -5.58559708e-02, -1.91648737e-01, -3.74244675e-02,\n",
       "            5.54271750e-02, -1.57391354e-01,  1.93031117e-01,\n",
       "           -4.39109094e-02],\n",
       "          [-6.34488687e-02,  4.90583405e-02, -7.45063052e-02,\n",
       "           -8.99688378e-02,  1.07905623e-02,  7.75345191e-02,\n",
       "            1.54253751e-01, -6.86039636e-03,  3.26282568e-02,\n",
       "           -3.87118477e-03],\n",
       "          [ 5.53019978e-02,  7.22846463e-02,  1.06936917e-01,\n",
       "            1.16029933e-01,  2.21494352e-03,  9.31462646e-03,\n",
       "            3.24176922e-02,  1.25462832e-02,  1.36775136e-01,\n",
       "           -6.49383618e-03],\n",
       "          [ 7.27056293e-03, -1.55529752e-01, -6.07924387e-02,\n",
       "           -1.01503558e-01, -1.65364444e-01, -1.15813792e-01,\n",
       "           -8.70182067e-02, -1.33265793e-01, -5.25717773e-02,\n",
       "           -5.58144674e-02]],\n",
       " \n",
       "         [[-2.60091363e-03, -3.93324606e-02,  9.52863842e-02,\n",
       "            1.97784916e-01,  1.95907857e-02,  1.26940668e-01,\n",
       "           -1.04159534e-01,  5.43266274e-02, -4.64087948e-02,\n",
       "            9.67282522e-03],\n",
       "          [ 1.54243529e-01,  1.98608935e-01,  1.91035364e-02,\n",
       "            1.10068418e-01, -3.28944027e-02,  6.63913414e-02,\n",
       "           -6.70764968e-03,  1.86666511e-02,  6.22768104e-02,\n",
       "           -1.19018868e-01],\n",
       "          [-1.39641896e-01,  1.05240000e-02,  9.22252014e-02,\n",
       "           -9.33112204e-02, -1.84091642e-01,  2.02633157e-01,\n",
       "           -1.04232915e-01, -7.39971409e-03, -1.02201596e-01,\n",
       "           -2.01537296e-01],\n",
       "          [ 5.91648370e-02, -6.77326927e-03, -6.46430627e-02,\n",
       "           -1.37257531e-01, -4.14509289e-02, -4.60041054e-02,\n",
       "           -2.31061522e-02,  4.07638066e-02, -1.75786361e-01,\n",
       "           -5.33430502e-02],\n",
       "          [ 3.54920588e-02,  1.42556027e-01,  8.63464251e-02,\n",
       "            1.40445353e-02,  1.47527328e-03,  1.50682479e-01,\n",
       "            2.22244784e-01, -2.16357484e-01, -1.07420444e-01,\n",
       "            4.31216024e-02],\n",
       "          [-6.11734651e-02,  9.21869949e-02, -5.65241426e-02,\n",
       "           -2.96385884e-02, -1.75565314e-02,  3.25573012e-02,\n",
       "            1.06514804e-01, -1.41993925e-01, -3.88675258e-02,\n",
       "            7.25356117e-02],\n",
       "          [-1.96413562e-01, -7.09757134e-02,  2.45310161e-02,\n",
       "           -2.36587916e-02,  5.90995178e-02,  9.04940590e-02,\n",
       "            1.41443327e-01,  2.56511550e-02,  5.03312424e-02,\n",
       "            7.23049268e-02],\n",
       "          [ 6.33128062e-02,  2.36100666e-02,  4.06751037e-02,\n",
       "           -8.12039077e-02,  8.23835954e-02,  6.55425861e-02,\n",
       "           -5.58932759e-02, -1.19248129e-01, -8.08746088e-03,\n",
       "            1.83601037e-01],\n",
       "          [ 2.02790454e-01,  1.83140442e-01, -1.68053228e-02,\n",
       "            3.10031809e-02, -7.07050636e-02, -3.20337601e-02,\n",
       "            1.71345830e-01, -4.90078591e-02,  1.77566901e-01,\n",
       "            6.13179021e-02],\n",
       "          [ 6.95571080e-02,  1.19671166e-01,  1.34246409e-01,\n",
       "            7.16535076e-02, -5.09294458e-02, -1.27774417e-01,\n",
       "           -1.99407250e-01,  2.29503989e-01, -1.83411129e-02,\n",
       "            4.22849059e-02]],\n",
       " \n",
       "         [[ 4.04368304e-02, -2.88768020e-02, -1.06188422e-02,\n",
       "           -3.12712900e-02,  1.61021411e-01, -2.22817250e-02,\n",
       "            8.57803151e-02, -5.86468168e-02, -1.67912379e-01,\n",
       "           -1.13414377e-01],\n",
       "          [ 2.36013848e-02,  7.50278309e-02, -2.62412038e-02,\n",
       "           -9.15828273e-02,  9.23719853e-02,  1.04178198e-01,\n",
       "            2.83821113e-02, -7.69179314e-02, -8.28887895e-02,\n",
       "            7.48398975e-02],\n",
       "          [-1.65404305e-02, -9.48879421e-02, -8.04012828e-03,\n",
       "           -8.05114396e-03,  4.29966785e-02,  4.92052920e-02,\n",
       "            1.01576276e-01, -5.66836223e-02,  1.73120216e-01,\n",
       "            1.40896976e-01],\n",
       "          [-1.98316067e-01, -9.32448059e-02, -5.05019724e-02,\n",
       "           -7.47036934e-02, -1.68954998e-01, -1.94620445e-01,\n",
       "            7.69003853e-02,  1.94854308e-02,  1.85638860e-01,\n",
       "           -1.22129671e-01],\n",
       "          [-1.10229202e-01, -4.19616513e-02, -2.87538581e-02,\n",
       "           -1.43047631e-01,  6.77324980e-02, -1.20855018e-03,\n",
       "           -4.61208075e-02,  9.39248279e-02,  7.57611096e-02,\n",
       "            7.49965012e-02],\n",
       "          [ 6.50469363e-02, -1.11282118e-01,  6.93727657e-02,\n",
       "           -5.99698052e-02, -1.60088297e-02, -2.38666162e-02,\n",
       "           -5.72486334e-02, -9.65825990e-02, -6.67491183e-03,\n",
       "            1.29542992e-01],\n",
       "          [ 1.04570135e-01, -7.75957629e-02, -2.40392778e-02,\n",
       "            1.97381988e-01,  3.20416540e-02,  1.84741259e-01,\n",
       "           -2.32209209e-02, -3.04796081e-03,  1.72492445e-01,\n",
       "           -1.25666201e-01],\n",
       "          [ 9.71554406e-03,  5.97857758e-02, -7.69614801e-02,\n",
       "            1.35467604e-01, -1.24438420e-01,  5.70588410e-02,\n",
       "            1.20569788e-01, -4.38539460e-02,  6.12866227e-03,\n",
       "            2.16522694e-01],\n",
       "          [-2.20400438e-01,  5.77064604e-02, -1.29826680e-01,\n",
       "            5.30939922e-02, -2.98254844e-03,  1.35260567e-01,\n",
       "           -4.64693122e-02, -1.35895371e-01, -8.52931663e-02,\n",
       "           -2.03872427e-01],\n",
       "          [ 5.97086586e-02,  9.83923599e-02,  7.80172125e-02,\n",
       "            1.26716301e-01,  1.15544632e-01,  1.03848159e-01,\n",
       "            4.37828666e-03,  1.00937456e-01, -2.42823195e-02,\n",
       "           -7.42272884e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 1.92128289e-02,  1.77934226e-02, -5.53577673e-03,\n",
       "           -6.63697571e-02, -1.40888870e-01, -7.45937154e-02,\n",
       "           -4.82417233e-02, -7.10275546e-02, -3.94047052e-02,\n",
       "            8.05705488e-02],\n",
       "          [ 8.62730071e-02,  9.94455535e-03,  3.47991996e-02,\n",
       "            7.12873489e-02, -9.57207233e-02, -6.55744150e-02,\n",
       "           -3.02342251e-02, -3.15203555e-02,  1.64673761e-01,\n",
       "            7.17963874e-02],\n",
       "          [ 2.60472409e-02, -7.02779740e-03, -2.30330274e-01,\n",
       "            7.49110505e-02,  1.10953651e-01, -1.33140087e-01,\n",
       "            1.55009940e-01, -3.11664622e-02, -4.24729697e-02,\n",
       "            1.03534475e-01],\n",
       "          [ 6.04713373e-02,  2.05682561e-01, -9.54778269e-02,\n",
       "           -1.62574306e-01,  7.96765089e-02,  2.90449639e-03,\n",
       "            1.55522078e-01, -6.13388717e-02, -1.09134197e-01,\n",
       "           -3.42827961e-02],\n",
       "          [-1.71907708e-01,  9.78100225e-02, -4.37815711e-02,\n",
       "           -1.76050887e-01,  9.80441868e-02, -8.18742588e-02,\n",
       "            1.43085644e-01,  2.07248360e-01,  5.44944704e-02,\n",
       "           -3.73346321e-02],\n",
       "          [-2.67435536e-02,  6.55322075e-02, -7.86309466e-02,\n",
       "            6.49956614e-02, -1.78760543e-01, -2.54943371e-02,\n",
       "           -1.55982301e-01,  1.38953626e-01,  9.11766738e-02,\n",
       "           -1.86520010e-01],\n",
       "          [-1.03331774e-01,  4.88946997e-02,  9.34663862e-02,\n",
       "           -6.95407018e-02,  1.66091416e-02, -9.96493772e-02,\n",
       "           -2.13903427e-01, -2.01650411e-01, -2.34020799e-01,\n",
       "           -5.94956391e-02],\n",
       "          [-6.07179254e-02,  1.23180442e-01, -1.21208891e-01,\n",
       "            1.52541086e-01,  1.18657365e-01, -1.48040010e-02,\n",
       "           -1.90515950e-01, -2.63537420e-03, -1.22922231e-02,\n",
       "           -7.93105811e-02],\n",
       "          [ 1.46470889e-01,  1.21206902e-01, -1.37490988e-01,\n",
       "            6.40377849e-02, -9.16145220e-02, -1.50441200e-01,\n",
       "           -7.55041763e-02,  5.98738752e-02, -2.31982842e-02,\n",
       "            2.20536336e-01],\n",
       "          [ 1.05487369e-01,  1.28338754e-01, -1.52771801e-01,\n",
       "           -1.88242853e-01, -1.10845469e-01, -1.40596122e-01,\n",
       "           -1.20144151e-01,  2.45242100e-02,  1.51708767e-01,\n",
       "           -1.01708561e-01]],\n",
       " \n",
       "         [[ 1.72845334e-01, -1.25604019e-01,  1.33641317e-01,\n",
       "            4.04579490e-02,  8.35966021e-02,  1.39085367e-01,\n",
       "           -2.91587343e-03,  5.89791313e-02, -1.10722467e-01,\n",
       "           -8.25300533e-03],\n",
       "          [-3.85943651e-02, -5.52834244e-03, -6.60579130e-02,\n",
       "           -4.00725901e-02, -7.33786449e-02, -5.57579473e-02,\n",
       "            5.49288765e-02, -7.71716461e-02,  9.67678949e-02,\n",
       "           -5.36358766e-02],\n",
       "          [ 6.31357506e-02, -7.95869902e-02,  2.30668597e-02,\n",
       "           -1.25354260e-01,  4.57943007e-02, -1.31031916e-01,\n",
       "           -2.23545469e-02, -1.45911336e-01, -2.58782338e-02,\n",
       "            1.26057863e-01],\n",
       "          [ 1.42065957e-01, -6.37072995e-02,  1.58923030e-01,\n",
       "            1.36071444e-01,  2.32386366e-01,  2.99505480e-02,\n",
       "            1.59596339e-01,  1.16529599e-01,  8.29188302e-02,\n",
       "            4.13727425e-02],\n",
       "          [-8.39753449e-02, -1.22638559e-03, -1.22768596e-01,\n",
       "            1.76768869e-01, -4.71950434e-02, -4.97799888e-02,\n",
       "           -9.00771767e-02,  4.85064164e-02,  6.78406358e-02,\n",
       "           -8.99808332e-02],\n",
       "          [-2.27302998e-01,  1.02155045e-01, -2.28036195e-01,\n",
       "            9.61558223e-02,  1.34382434e-02, -1.59893651e-02,\n",
       "           -4.69922610e-02,  3.54808718e-02,  1.02006935e-01,\n",
       "            7.01127350e-02],\n",
       "          [ 5.33290021e-02,  3.64869498e-02,  6.65657222e-02,\n",
       "            1.25354365e-01,  1.80090964e-02, -4.92076427e-02,\n",
       "           -9.24024284e-02, -3.73851992e-02, -1.61868349e-01,\n",
       "           -6.48851842e-02],\n",
       "          [-7.01166913e-02,  1.58480749e-01,  2.07382396e-01,\n",
       "           -6.58719540e-02,  4.88419533e-02, -2.45018918e-02,\n",
       "           -1.10430539e-01,  7.38897473e-02,  6.01079352e-02,\n",
       "            1.10069431e-01],\n",
       "          [ 9.77990776e-02,  2.81934198e-02, -1.06900953e-01,\n",
       "            6.20236620e-02, -1.51472734e-02, -5.14046215e-02,\n",
       "            2.27638502e-02,  2.13117838e-01, -1.41426787e-01,\n",
       "            1.06300861e-01],\n",
       "          [-1.81076095e-01, -5.51315770e-02, -3.71913537e-02,\n",
       "            8.13364461e-02,  9.51878130e-02,  2.31749862e-02,\n",
       "            5.63872904e-02, -1.39083579e-01, -1.43878609e-02,\n",
       "            9.25984606e-02]],\n",
       " \n",
       "         [[ 1.36738136e-01, -6.34746477e-02,  1.66212648e-01,\n",
       "            9.85228047e-02,  1.38977438e-01, -1.03970706e-01,\n",
       "            1.40005937e-02,  1.53721021e-02, -4.81428504e-02,\n",
       "            5.00008352e-02],\n",
       "          [ 1.15253128e-01,  8.35740566e-03, -1.12546887e-02,\n",
       "            4.10504714e-02,  2.47760210e-02,  1.58003084e-02,\n",
       "            2.12162256e-01,  4.83559333e-02,  3.87155600e-02,\n",
       "            1.36043280e-01],\n",
       "          [-1.48874342e-01, -4.93719354e-02, -8.75356123e-02,\n",
       "            9.88865942e-02, -6.89833462e-02,  1.58193648e-01,\n",
       "            5.75094819e-02, -1.07686117e-03, -5.68900518e-02,\n",
       "           -2.07435936e-02],\n",
       "          [ 5.35938516e-02,  1.06049046e-01, -5.05688675e-02,\n",
       "           -1.31206550e-02,  7.94260055e-02, -2.19230905e-01,\n",
       "           -2.94644907e-02, -1.60624027e-01, -1.47828788e-01,\n",
       "            1.84335597e-02],\n",
       "          [ 3.48137431e-02, -5.34157865e-02, -2.16885135e-02,\n",
       "           -6.33188710e-02, -9.05745625e-02, -7.91164264e-02,\n",
       "           -2.10458964e-01, -6.76964000e-02, -1.80010900e-01,\n",
       "           -9.71905049e-03],\n",
       "          [ 6.61928579e-02,  1.20223477e-01, -1.90484464e-01,\n",
       "           -7.68819973e-02, -1.28065795e-01,  5.69903776e-02,\n",
       "           -7.33211190e-02, -1.85040031e-02,  1.05476305e-01,\n",
       "           -7.10267350e-02],\n",
       "          [ 1.24808298e-02, -4.60802019e-02, -1.11355275e-01,\n",
       "            6.49864301e-02,  4.54837084e-02,  1.05324537e-01,\n",
       "            2.29376461e-02, -1.19073108e-01, -1.38661247e-02,\n",
       "           -1.79929640e-02],\n",
       "          [ 9.60325450e-02,  1.83594823e-01, -1.58979416e-01,\n",
       "            1.00522146e-01,  1.11762155e-02,  2.41647605e-02,\n",
       "           -2.18177699e-02,  1.85354859e-01, -1.09150745e-02,\n",
       "            1.15122646e-01],\n",
       "          [ 4.16480787e-02,  4.95696254e-02, -8.30421448e-02,\n",
       "            7.16779083e-02, -1.18645743e-01,  1.66722015e-01,\n",
       "            1.91439301e-01, -1.49367750e-02, -5.70707396e-03,\n",
       "           -1.21999301e-01],\n",
       "          [-1.46046758e-01,  1.34193942e-01, -1.04773799e-02,\n",
       "            1.38629824e-01, -6.06858805e-02, -2.07495406e-01,\n",
       "           -1.32488281e-01, -2.08368316e-01,  6.05427995e-02,\n",
       "            1.39334664e-01]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_221_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([-0.0062598 ,  0.01044028,  0.00826102,  0.00102786,  0.0070779 ,\n",
       "        -0.01753479,  0.00921691,  0.00088934, -0.0003165 ,  0.00144496],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_251_1/gamma:0' shape=(10,) dtype=float32, numpy=\n",
       " array([1.0206   , 1.012373 , 0.9850669, 1.0041416, 1.0102712, 0.9787165,\n",
       "        0.9942517, 1.0116374, 1.0117885, 0.9851484], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_251_1/beta:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.00484862,  0.01330577,  0.02101878,  0.00546109, -0.00357618,\n",
       "        -0.00865569,  0.01535316,  0.01735472, -0.00729665, -0.00832963],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_222_1/kernel:0' shape=(3, 3, 10, 10) dtype=float32, numpy=\n",
       " array([[[[ 6.09884225e-02, -1.55911520e-01,  9.18808728e-02,\n",
       "            1.53676269e-03,  5.16833141e-02, -1.08217997e-02,\n",
       "           -4.36521694e-02,  1.48633197e-01, -9.18598175e-02,\n",
       "            2.58852411e-02],\n",
       "          [ 5.19879609e-02, -4.10362408e-02,  6.83984607e-02,\n",
       "            2.52555124e-03, -2.04759493e-01,  1.38535276e-01,\n",
       "           -5.86690428e-03, -4.08499874e-02,  5.56018203e-02,\n",
       "            1.61608949e-01],\n",
       "          [ 2.09904820e-01, -5.13222218e-02,  8.10022503e-02,\n",
       "            7.11881071e-02,  1.56515595e-02, -1.68078229e-01,\n",
       "            3.81507240e-02, -6.74333831e-04, -1.31781250e-01,\n",
       "            6.29176944e-02],\n",
       "          [ 1.30435228e-02, -7.94094875e-02, -6.18874375e-03,\n",
       "           -4.98803221e-02, -1.24663994e-01, -1.15591541e-01,\n",
       "           -8.88058171e-02, -6.01012036e-02, -1.94526270e-01,\n",
       "            4.12803255e-02],\n",
       "          [ 1.29509240e-01,  6.09131344e-02,  2.03955546e-02,\n",
       "           -4.90079857e-02,  3.84364091e-02,  6.47365525e-02,\n",
       "           -1.61823064e-01,  2.28582054e-01, -3.57664153e-02,\n",
       "            1.01007037e-01],\n",
       "          [-1.62467107e-01,  1.56917498e-01, -8.92669521e-03,\n",
       "            6.24041520e-02,  1.74723551e-01,  9.41444114e-02,\n",
       "            6.63095266e-02,  9.04447660e-02,  8.76063183e-02,\n",
       "            4.88353074e-02],\n",
       "          [ 1.15862727e-01,  1.59298424e-02, -1.27125708e-02,\n",
       "           -1.20021395e-01, -1.42834798e-01, -3.79167460e-02,\n",
       "            3.38648930e-02, -1.79873988e-01,  5.13253771e-02,\n",
       "            1.32107303e-01],\n",
       "          [ 1.40298158e-01, -1.27087101e-01,  6.43701181e-02,\n",
       "           -1.84707731e-01,  1.49094462e-01, -4.23004180e-02,\n",
       "            1.75103962e-01, -1.12789813e-02, -1.08008876e-01,\n",
       "            2.07520336e-01],\n",
       "          [-1.02187358e-01, -6.60104975e-02,  2.85069495e-02,\n",
       "           -2.51403470e-02,  1.21435270e-01, -7.89074227e-02,\n",
       "           -3.65192927e-02, -1.22461677e-01, -6.09741546e-02,\n",
       "           -7.44605884e-02],\n",
       "          [-6.00945465e-02,  9.92450938e-02, -3.98885868e-02,\n",
       "            7.21316114e-02, -1.90605402e-01, -1.14099510e-01,\n",
       "            1.39880344e-01, -1.06888019e-01,  2.62934994e-02,\n",
       "           -1.49898633e-01]],\n",
       " \n",
       "         [[-2.13918164e-01, -6.71755224e-02,  1.44938603e-01,\n",
       "           -6.01470843e-02,  2.52604723e-01,  5.40407710e-02,\n",
       "            4.49910946e-02,  1.23251565e-01,  1.24979794e-01,\n",
       "           -1.10018790e-01],\n",
       "          [ 2.21881270e-01,  9.24755633e-02,  1.22763634e-01,\n",
       "           -1.91852927e-01, -3.44604664e-02,  3.72907557e-02,\n",
       "           -6.26171678e-02,  3.17012891e-03,  1.04743809e-01,\n",
       "           -1.60263237e-02],\n",
       "          [ 4.77342531e-02,  9.81134623e-02,  7.02554658e-02,\n",
       "            5.67419939e-02,  8.02766755e-02, -2.28695720e-02,\n",
       "           -5.28047187e-03, -1.27478866e-02,  6.05510399e-02,\n",
       "           -4.73402105e-02],\n",
       "          [-1.26675561e-01,  1.52781978e-01, -3.76594514e-02,\n",
       "           -3.94495241e-02, -1.91794947e-01, -1.12947136e-01,\n",
       "            5.87089024e-02, -1.02343678e-01,  1.70376480e-01,\n",
       "            8.24336428e-03],\n",
       "          [ 7.01066405e-02, -2.42821947e-02, -1.25176013e-01,\n",
       "           -1.58636257e-01, -1.77911818e-01, -7.83485472e-02,\n",
       "           -8.41975063e-02, -7.50746112e-03, -1.40094519e-01,\n",
       "            4.63505127e-02],\n",
       "          [-3.87127027e-02, -6.61593825e-02, -8.03589448e-02,\n",
       "            2.19131052e-03, -1.34593681e-01, -2.33924761e-01,\n",
       "           -2.90767523e-03,  5.28427996e-02, -3.24732363e-02,\n",
       "            8.84874240e-02],\n",
       "          [ 1.03716865e-01,  5.59312031e-02, -7.19450861e-02,\n",
       "           -2.10272506e-01,  1.02196261e-01, -7.70337582e-02,\n",
       "            9.20567289e-02,  8.42153504e-02,  1.13757484e-01,\n",
       "           -1.93421707e-01],\n",
       "          [-2.03814059e-02,  1.43949986e-01,  9.89322588e-02,\n",
       "            2.11724713e-01, -4.90998887e-02, -1.50525704e-01,\n",
       "            1.85306519e-01,  1.55779928e-01,  7.76550323e-02,\n",
       "            1.06205093e-02],\n",
       "          [ 3.06025520e-02,  4.15136032e-02, -1.44123763e-01,\n",
       "            2.44146436e-02,  6.59703612e-02,  9.15602073e-02,\n",
       "            1.16755143e-02,  1.49887167e-02, -1.94965333e-01,\n",
       "           -1.89973131e-01],\n",
       "          [-1.01540357e-01,  1.64853185e-01,  6.01237193e-02,\n",
       "           -1.04176784e-02,  1.61645994e-01, -1.07164793e-01,\n",
       "           -6.43010512e-02,  1.56997576e-01, -1.63661003e-01,\n",
       "            1.41821012e-01]],\n",
       " \n",
       "         [[-6.58762604e-02, -6.92506805e-02, -1.54798096e-02,\n",
       "            1.99335925e-02,  1.70848772e-01,  9.04776379e-02,\n",
       "            2.74351034e-02,  1.74217336e-02, -9.63249207e-02,\n",
       "           -5.43724895e-02],\n",
       "          [-3.66811752e-02, -1.39256582e-01,  8.70228000e-03,\n",
       "           -7.19759241e-02, -5.08343130e-02,  1.82408273e-01,\n",
       "           -5.78069799e-02,  5.10350056e-02,  6.81904852e-02,\n",
       "           -1.56853408e-01],\n",
       "          [ 4.68716724e-03, -4.16644625e-02,  1.09844301e-02,\n",
       "            1.24518527e-02,  8.31575245e-02,  1.90592647e-01,\n",
       "           -5.79037368e-02,  1.44653860e-02, -7.86593556e-02,\n",
       "           -1.17759164e-02],\n",
       "          [ 8.98692980e-02,  1.36323154e-01, -2.01560222e-02,\n",
       "            1.16608866e-01, -2.89750900e-02, -4.50599566e-02,\n",
       "           -3.94578837e-02,  2.47135460e-01,  2.57095005e-02,\n",
       "            5.06814942e-02],\n",
       "          [ 2.80491170e-02,  2.14132220e-02,  1.64653063e-01,\n",
       "            3.87462378e-02,  3.29150259e-02, -2.28710040e-01,\n",
       "            6.44334629e-02, -1.75837234e-01, -6.53662160e-02,\n",
       "           -2.34033223e-02],\n",
       "          [ 2.94972993e-02,  8.22214708e-02,  3.71754505e-02,\n",
       "           -1.21380508e-01,  1.43267006e-01,  4.30392437e-02,\n",
       "            2.07553372e-01, -1.13371797e-01, -7.29790255e-02,\n",
       "            8.57114196e-02],\n",
       "          [ 1.61846094e-02,  6.82179332e-02, -8.19583982e-03,\n",
       "           -5.14749996e-02, -3.29122171e-02, -1.31908860e-02,\n",
       "           -5.33885173e-02, -3.28062065e-02,  2.66196597e-02,\n",
       "            1.33457080e-01],\n",
       "          [ 8.15095231e-02, -1.73285097e-01,  1.04799554e-01,\n",
       "           -1.29630845e-02,  1.81698352e-02,  2.06590831e-01,\n",
       "           -9.35521051e-02, -1.79075032e-01, -3.47759924e-03,\n",
       "           -1.09985515e-01],\n",
       "          [-3.85013558e-02, -4.63656336e-02,  2.35404130e-02,\n",
       "            6.86504319e-02,  1.68991566e-01,  3.28610800e-02,\n",
       "            1.38017133e-01, -4.32992838e-02, -1.98117360e-01,\n",
       "           -1.67059571e-01],\n",
       "          [-1.26659870e-01, -6.14094362e-02, -3.14549319e-02,\n",
       "            4.73948866e-02, -5.30263782e-02,  2.63188640e-03,\n",
       "           -3.49291936e-02, -6.14689887e-02,  7.07498044e-02,\n",
       "           -1.28549233e-01]]],\n",
       " \n",
       " \n",
       "        [[[-1.82318920e-03,  1.58854146e-02, -1.94047481e-01,\n",
       "           -3.24399509e-02, -6.61604013e-03,  5.57613969e-02,\n",
       "           -1.81691106e-02,  4.67351116e-02,  1.15099840e-01,\n",
       "            5.16282879e-02],\n",
       "          [-1.85927272e-01,  1.75824184e-02, -1.73490137e-01,\n",
       "           -1.28140420e-01,  2.13512644e-01,  8.41040537e-02,\n",
       "            7.88671747e-02,  5.54748476e-02,  5.77501208e-02,\n",
       "           -2.88808113e-03],\n",
       "          [-4.81532030e-02,  5.08492403e-02, -1.45248502e-01,\n",
       "           -3.25083844e-02, -4.92570139e-02, -1.58101916e-02,\n",
       "            1.00662462e-01, -7.95356855e-02,  5.03704175e-02,\n",
       "            2.03764960e-02],\n",
       "          [-4.22944762e-02, -4.58547100e-02,  6.97943866e-02,\n",
       "           -7.30946362e-02, -1.45391181e-01,  7.38340802e-03,\n",
       "           -2.03544274e-03,  1.98411345e-01,  4.26901914e-02,\n",
       "           -1.31678283e-01],\n",
       "          [-7.15149343e-02, -1.12513982e-01,  1.02087006e-01,\n",
       "           -1.06376559e-01,  1.53624833e-01,  1.52645767e-01,\n",
       "           -3.31143057e-03,  1.18051559e-01, -8.44356567e-02,\n",
       "            2.98468154e-02],\n",
       "          [ 9.04143453e-02, -1.28598571e-01,  3.59382480e-02,\n",
       "           -1.61953479e-01, -9.37252268e-02, -1.16764553e-01,\n",
       "           -1.53854921e-01,  2.68188938e-02, -7.91809037e-02,\n",
       "            1.53061986e-01],\n",
       "          [ 4.44421284e-02,  6.51991963e-02, -1.85128093e-01,\n",
       "            1.44432679e-01, -1.36698723e-01, -9.50672552e-02,\n",
       "            1.74300186e-02,  1.00136586e-01,  3.29212137e-02,\n",
       "           -1.45648435e-01],\n",
       "          [-1.36186898e-01, -1.50406301e-01,  1.90345217e-02,\n",
       "            5.48743531e-02,  2.73896828e-02, -4.92608882e-02,\n",
       "            9.10690147e-03, -1.38297863e-02,  8.93360525e-02,\n",
       "            9.89797935e-02],\n",
       "          [-1.90612599e-02, -3.74721438e-02,  2.32740149e-01,\n",
       "           -1.59774810e-01,  1.01502709e-01,  2.25890294e-01,\n",
       "           -1.21507108e-01,  5.68931960e-02,  6.63412139e-02,\n",
       "            2.05370076e-02],\n",
       "          [ 8.72998834e-02,  3.61935496e-02,  1.79456430e-04,\n",
       "           -1.81920633e-01, -2.79958416e-02, -1.39296325e-02,\n",
       "           -1.79953769e-01,  7.07977265e-02,  2.19890438e-02,\n",
       "           -2.84942761e-02]],\n",
       " \n",
       "         [[ 1.01596676e-01,  3.93851986e-03, -1.43210009e-01,\n",
       "            6.30257353e-02, -2.44287178e-02, -1.38574108e-01,\n",
       "            6.91541210e-02,  4.49186899e-02, -1.91653818e-01,\n",
       "            8.36449191e-02],\n",
       "          [ 1.24641120e-01,  1.01457663e-01, -1.05865046e-01,\n",
       "            2.62778662e-02, -9.23217908e-02,  2.72993334e-02,\n",
       "           -6.63280440e-03,  1.09415159e-01,  6.44654930e-02,\n",
       "           -5.95266782e-02],\n",
       "          [-1.57383785e-01, -7.53770862e-03,  1.20534502e-01,\n",
       "            3.56074460e-02, -1.19481571e-01,  8.19243565e-02,\n",
       "            1.72155857e-01,  1.70612521e-02,  6.02865927e-02,\n",
       "           -2.84028184e-02],\n",
       "          [ 1.81452166e-02, -7.89756700e-02, -6.85189515e-02,\n",
       "            2.98589021e-02,  1.27622470e-01, -2.96098031e-02,\n",
       "            1.49903595e-01, -1.49620384e-01,  5.24331145e-02,\n",
       "            1.77456066e-01],\n",
       "          [-1.00342497e-01,  1.54135093e-01,  2.18511477e-01,\n",
       "            5.91389015e-02,  1.73015326e-01, -1.15863383e-01,\n",
       "           -2.15712711e-01, -8.87726620e-02, -2.15742573e-01,\n",
       "           -6.22709394e-02],\n",
       "          [-8.80780965e-02, -1.48520932e-01, -3.39175873e-02,\n",
       "           -1.47602439e-01, -5.26952147e-02, -1.72419082e-02,\n",
       "           -1.77932322e-01, -1.45525590e-01,  1.47714972e-01,\n",
       "            6.36498109e-02],\n",
       "          [-2.40673404e-02,  1.79054625e-02, -1.14512183e-01,\n",
       "            9.48490016e-03,  6.46733586e-03, -3.94448042e-02,\n",
       "            5.88647686e-02,  2.04063609e-01, -3.25348675e-02,\n",
       "            1.22611679e-01],\n",
       "          [ 7.30698556e-02,  6.16005957e-02,  1.43148992e-02,\n",
       "           -1.83108856e-03, -1.04686283e-01, -9.93366241e-02,\n",
       "           -1.70938119e-01, -1.18930995e-01,  8.71630386e-02,\n",
       "            1.45819291e-01],\n",
       "          [ 4.42778692e-02,  9.28258970e-02,  1.42958211e-02,\n",
       "           -4.03711852e-03,  1.97738279e-02,  2.22641453e-01,\n",
       "           -7.89072886e-02,  1.60942331e-01, -5.63588925e-03,\n",
       "            5.40717579e-02],\n",
       "          [-8.09699073e-02,  2.33436357e-02, -6.38746619e-02,\n",
       "           -1.26720175e-01, -1.62958235e-01,  1.23562165e-01,\n",
       "            9.83533114e-02, -5.56362309e-02, -3.47247906e-02,\n",
       "           -5.98955452e-02]],\n",
       " \n",
       "         [[-8.37513953e-02, -9.82432589e-02,  6.98158219e-02,\n",
       "           -2.25838348e-01,  1.59346953e-01,  3.08765983e-03,\n",
       "            3.75548303e-02, -3.88259068e-02, -1.00911453e-01,\n",
       "           -1.03307657e-01],\n",
       "          [ 1.97575584e-01,  1.60355896e-01,  6.95593730e-02,\n",
       "           -4.14747894e-02, -3.35847326e-02,  3.82494517e-02,\n",
       "            2.49884147e-02, -2.25087963e-02, -2.31039189e-02,\n",
       "           -6.34907633e-02],\n",
       "          [-6.77883029e-02,  1.40978489e-02,  8.33611339e-02,\n",
       "           -8.49131793e-02,  5.40235154e-02,  2.21297175e-01,\n",
       "           -2.03892179e-02,  3.55404876e-02,  6.72701597e-02,\n",
       "            3.10638621e-02],\n",
       "          [ 1.23960897e-01,  8.72278214e-03, -5.74046839e-03,\n",
       "           -7.40369558e-02, -8.00102670e-03, -6.55037165e-02,\n",
       "           -1.79585844e-01,  1.39023392e-02,  2.24092484e-01,\n",
       "           -2.15746667e-02],\n",
       "          [-5.40797412e-02,  5.57266101e-02, -1.52766556e-01,\n",
       "           -1.43109813e-01, -1.50904417e-01,  1.52364790e-01,\n",
       "           -3.03326491e-02,  1.63265839e-02, -9.15180147e-02,\n",
       "            4.28685732e-02],\n",
       "          [-3.24619114e-02, -5.75355161e-03,  5.33844680e-02,\n",
       "           -2.72240937e-02,  1.15254737e-01, -1.07539475e-01,\n",
       "            1.05242670e-01,  2.19424456e-01, -2.09927540e-02,\n",
       "           -1.11736253e-01],\n",
       "          [ 7.27966204e-02, -7.76667073e-02, -8.13511088e-02,\n",
       "            1.46623403e-01, -1.23419903e-01, -1.91197414e-02,\n",
       "            3.72774303e-02, -1.70879792e-02, -1.75712302e-01,\n",
       "           -1.28107116e-01],\n",
       "          [-5.81778549e-02,  7.52703426e-03, -5.36224395e-02,\n",
       "           -1.53226420e-01, -1.76591828e-01,  7.51886219e-02,\n",
       "            1.83194727e-02, -1.66053548e-02,  1.25225857e-01,\n",
       "            7.61967450e-02],\n",
       "          [-6.47076368e-02,  7.81276226e-02,  5.90285659e-02,\n",
       "           -1.03489295e-01,  1.26920745e-01,  3.21165174e-02,\n",
       "            6.91256151e-02,  1.33773923e-01,  1.62373170e-01,\n",
       "           -1.52625337e-01],\n",
       "          [-3.38198338e-03,  9.60136950e-02, -1.03340603e-01,\n",
       "            2.15928163e-02, -1.72715947e-01, -6.54332489e-02,\n",
       "            1.34748304e-02,  1.84389338e-01,  2.14733124e-01,\n",
       "           -1.27636895e-01]]],\n",
       " \n",
       " \n",
       "        [[[-5.72487153e-02, -8.48052278e-02,  3.22265662e-02,\n",
       "           -5.78179918e-02,  1.28101677e-01,  1.58473939e-01,\n",
       "           -7.54220560e-02,  1.32093668e-01,  2.33383805e-01,\n",
       "           -1.15722366e-01],\n",
       "          [-1.02224788e-02, -1.60959110e-01, -2.02564567e-01,\n",
       "            1.11231148e-01,  8.12135357e-03,  4.37409021e-02,\n",
       "           -1.63944885e-02,  3.87283005e-02, -1.03581138e-01,\n",
       "            9.66289192e-02],\n",
       "          [ 1.70913041e-01, -9.86335799e-02, -2.22286731e-01,\n",
       "           -1.93155110e-01,  7.00056106e-02,  9.87530276e-02,\n",
       "           -3.02797779e-02, -3.65099832e-02, -3.35889868e-02,\n",
       "           -1.37804057e-02],\n",
       "          [-1.14387140e-01, -6.47734329e-02, -4.94480133e-03,\n",
       "           -1.34902552e-01,  1.18751340e-01,  9.33219790e-02,\n",
       "           -1.67215541e-01,  2.52969265e-02, -1.24690764e-01,\n",
       "            1.08907409e-01],\n",
       "          [-6.02494143e-02,  4.37940424e-03, -1.16560765e-01,\n",
       "            7.19733490e-03,  2.02703089e-01, -7.45186508e-02,\n",
       "           -1.44066596e-02, -3.16836722e-02,  1.24907687e-01,\n",
       "           -7.63059333e-02],\n",
       "          [-3.83481383e-02, -2.13824064e-02, -2.75953449e-02,\n",
       "            6.84097409e-02, -1.69583216e-01,  5.95436199e-03,\n",
       "           -1.00538835e-01, -1.17597524e-02, -8.25946555e-02,\n",
       "           -1.04783960e-01],\n",
       "          [ 1.03725612e-01,  1.56569656e-03, -8.72428864e-02,\n",
       "           -1.35807589e-01,  3.58727798e-02,  5.36341369e-02,\n",
       "           -5.95963299e-02, -1.02669545e-01, -1.92129537e-02,\n",
       "           -5.29571250e-03],\n",
       "          [ 1.66431412e-01, -8.50443915e-02, -3.68361216e-04,\n",
       "           -1.22271016e-01, -6.22071549e-02,  1.84024990e-01,\n",
       "           -2.06981655e-02,  5.10773808e-02, -1.64195761e-01,\n",
       "           -7.47016212e-03],\n",
       "          [-1.33918226e-01,  8.10595378e-02,  1.91381991e-01,\n",
       "            5.97120337e-02, -1.25407830e-01, -3.39757986e-02,\n",
       "            1.42521173e-01, -2.16524497e-01, -1.72460034e-01,\n",
       "            3.27481590e-02],\n",
       "          [-9.17129964e-02, -1.33029699e-01,  1.40553817e-01,\n",
       "            2.17585359e-02, -2.09670052e-01, -1.32320493e-01,\n",
       "            5.36734015e-02, -6.50676936e-02, -1.29806519e-01,\n",
       "            1.33882836e-01]],\n",
       " \n",
       "         [[ 1.77583709e-01,  7.08102807e-02, -3.56910601e-02,\n",
       "            2.93368306e-02,  1.22254997e-01,  1.12285845e-01,\n",
       "            1.02203555e-01, -9.37266573e-02,  4.18816768e-02,\n",
       "            8.75405744e-02],\n",
       "          [-5.05812056e-02, -4.99347895e-02, -1.37910038e-01,\n",
       "           -1.20067693e-01, -2.29363680e-01,  2.72239074e-02,\n",
       "            1.82496414e-01, -1.11918829e-01,  1.24363698e-01,\n",
       "           -2.42734049e-02],\n",
       "          [-1.51678041e-01, -3.48596200e-02, -8.25854391e-02,\n",
       "            5.61607741e-02,  3.47820632e-02,  1.52223960e-01,\n",
       "            1.13834448e-01,  7.94520974e-03,  1.10888965e-02,\n",
       "           -1.45252571e-01],\n",
       "          [ 1.35262772e-01, -1.50139228e-01,  2.75228396e-02,\n",
       "           -9.38156992e-03, -1.38097093e-01, -3.54256555e-02,\n",
       "            2.03926843e-02,  1.46144882e-01,  3.45589779e-02,\n",
       "            1.09135181e-01],\n",
       "          [-1.84741840e-02,  8.79635215e-02,  2.00954959e-01,\n",
       "           -6.98660091e-02, -1.77546404e-02,  7.23016262e-02,\n",
       "            4.78423573e-02,  4.67819646e-02, -1.49977699e-01,\n",
       "           -1.52793974e-02],\n",
       "          [-1.18439220e-01, -3.81074138e-02, -1.26110688e-01,\n",
       "           -8.90176464e-03, -1.29179403e-01, -2.09559157e-01,\n",
       "           -6.02095723e-02, -6.51390254e-02,  1.00703910e-01,\n",
       "            5.50648421e-02],\n",
       "          [-4.35692780e-02,  1.21340938e-01, -1.78980842e-01,\n",
       "            5.71243614e-02,  1.54734597e-01, -5.60330376e-02,\n",
       "           -2.92591006e-02,  6.46137297e-02,  4.10101824e-02,\n",
       "            1.21786036e-01],\n",
       "          [ 3.55715714e-02, -4.23233472e-02,  7.59725496e-02,\n",
       "            5.39392084e-02, -1.43719777e-01,  1.69608351e-02,\n",
       "           -2.08356440e-01,  1.04784913e-01,  1.04015715e-01,\n",
       "            6.46675229e-02],\n",
       "          [-2.75656898e-02,  1.00417562e-01, -9.97113660e-02,\n",
       "           -9.30047408e-02, -8.76960009e-02,  9.78812352e-02,\n",
       "           -1.82487652e-01,  9.78306960e-03,  6.39280584e-03,\n",
       "           -1.72535109e-03],\n",
       "          [-1.92937572e-02,  7.16361851e-02, -5.94575889e-02,\n",
       "            3.82559486e-02, -1.42993182e-01, -1.46934018e-01,\n",
       "            1.94515109e-01, -1.71059519e-01,  2.74748113e-02,\n",
       "            1.81733117e-01]],\n",
       " \n",
       "         [[ 8.81209504e-04,  4.02738042e-02, -8.63057077e-02,\n",
       "            1.08388431e-01,  1.55251175e-01, -1.16841279e-01,\n",
       "           -1.67092800e-01, -2.98405020e-03, -7.43149966e-02,\n",
       "           -2.19333440e-01],\n",
       "          [-1.61251381e-01,  5.02078272e-02, -8.63676593e-02,\n",
       "           -9.01486054e-02, -6.28710538e-02, -1.87068488e-02,\n",
       "           -4.93947789e-02, -2.34395582e-02, -9.83483046e-02,\n",
       "            1.65921822e-02],\n",
       "          [-7.74485320e-02, -4.57736403e-02, -1.02327608e-01,\n",
       "           -2.31521819e-02, -1.10409766e-01, -1.46637470e-01,\n",
       "           -1.04474314e-02,  2.04918012e-02, -5.89139052e-02,\n",
       "           -3.72169986e-02],\n",
       "          [ 6.97484463e-02,  9.64208320e-02, -1.37324080e-01,\n",
       "           -6.01743609e-02, -1.52207851e-01,  6.03301264e-02,\n",
       "            1.16438670e-02,  1.07263736e-01,  1.98158398e-01,\n",
       "           -3.21472064e-02],\n",
       "          [ 8.53320137e-02, -4.13481966e-02,  2.71352306e-02,\n",
       "           -1.31538287e-01, -7.74883777e-02,  2.63664778e-03,\n",
       "            2.34595202e-02, -1.05661817e-01,  1.67327136e-01,\n",
       "           -1.93270594e-01],\n",
       "          [-4.43720780e-02, -7.14359456e-04, -1.13732196e-01,\n",
       "            8.67425874e-02,  3.29676233e-02,  1.02667540e-01,\n",
       "           -1.29162585e-02, -4.07149680e-02, -1.27355844e-01,\n",
       "           -1.44696552e-02],\n",
       "          [-2.18618557e-01,  1.37471005e-01,  1.70343012e-01,\n",
       "           -1.51689779e-02,  1.86409056e-01,  1.71448976e-01,\n",
       "           -1.54014798e-02, -7.06073865e-02,  1.34535804e-01,\n",
       "            1.65892318e-01],\n",
       "          [ 2.73819696e-02,  1.61369368e-01,  9.99595001e-02,\n",
       "            2.73034461e-02,  7.36600719e-03, -5.33396639e-02,\n",
       "           -3.27817611e-02,  1.06058352e-01, -3.62744331e-02,\n",
       "            6.09628074e-02],\n",
       "          [-8.53351429e-02,  3.21087800e-02,  1.34820491e-01,\n",
       "            4.01169509e-02,  1.72940999e-01, -1.55232772e-01,\n",
       "            2.08530471e-01, -4.83142287e-02,  1.01973787e-01,\n",
       "           -6.35484159e-02],\n",
       "          [ 5.69912456e-02,  2.40827650e-01,  2.71893349e-02,\n",
       "            6.79329410e-02,  6.79738820e-02,  1.00607254e-01,\n",
       "            1.88058652e-02, -1.38892308e-01, -1.58151060e-01,\n",
       "            8.87979269e-02]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_222_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.01038157,  0.01591234, -0.01501723, -0.00158185, -0.00270523,\n",
       "         0.00681001,  0.00779648,  0.01508327, -0.00130156,  0.01191309],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_252_1/gamma:0' shape=(10,) dtype=float32, numpy=\n",
       " array([1.0190768 , 1.0104896 , 0.9892408 , 0.9941015 , 0.9771624 ,\n",
       "        0.99164206, 1.0099045 , 0.9773337 , 1.0104694 , 1.0175258 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_252_1/beta:0' shape=(10,) dtype=float32, numpy=\n",
       " array([-0.01144655, -0.00905783,  0.02508394, -0.02210938, -0.01558204,\n",
       "        -0.0015242 ,  0.00679631,  0.00771992, -0.02037501,  0.01387537],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_91_1/kernel:0' shape=(490, 20) dtype=float32, numpy=\n",
       " array([[-0.01174289, -0.06218738, -0.00271733, ...,  0.01561758,\n",
       "         -0.02404902,  0.00484791],\n",
       "        [ 0.00962214,  0.05815508,  0.02876431, ..., -0.01578763,\n",
       "         -0.01768532, -0.01353296],\n",
       "        [ 0.04160998,  0.05566163, -0.06045888, ..., -0.04044367,\n",
       "          0.02588542,  0.05591514],\n",
       "        ...,\n",
       "        [ 0.09206723, -0.00655904, -0.00282526, ..., -0.06398024,\n",
       "         -0.05080422,  0.06562621],\n",
       "        [ 0.00476659, -0.01276326, -0.06191447, ...,  0.00530164,\n",
       "         -0.03213973, -0.02985386],\n",
       "        [ 0.0200663 ,  0.01595821, -0.06984008, ..., -0.03426492,\n",
       "          0.05033324,  0.0783935 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_91_1/bias:0' shape=(20,) dtype=float32, numpy=\n",
       " array([ 0.005835  , -0.00596507,  0.00147384, -0.00054252, -0.02727936,\n",
       "         0.00847889, -0.00048217, -0.01216589, -0.00139977, -0.00922385,\n",
       "         0.00526728,  0.02018436,  0.00739786,  0.00179655, -0.00392976,\n",
       "        -0.00871166,  0.01200207,  0.01996418, -0.01012331, -0.00982745],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_253_1/gamma:0' shape=(20,) dtype=float32, numpy=\n",
       " array([1.0260072 , 1.0223162 , 1.0300529 , 1.0317101 , 1.0334682 ,\n",
       "        1.020658  , 0.9955607 , 0.98868316, 0.99532115, 1.0237337 ,\n",
       "        1.0348066 , 1.0262543 , 1.0313947 , 1.0356615 , 0.99503124,\n",
       "        1.0198082 , 1.0200044 , 1.0432831 , 1.0317796 , 1.0112538 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_253_1/beta:0' shape=(20,) dtype=float32, numpy=\n",
       " array([-0.04179243, -0.04216946, -0.03859504, -0.04131984, -0.04142517,\n",
       "        -0.04254702, -0.04139746,  0.04165493, -0.040511  ,  0.0378389 ,\n",
       "         0.03711302, -0.04178489,  0.04159493,  0.04190646,  0.0401951 ,\n",
       "        -0.04103273, -0.04173254,  0.04161543, -0.04261713, -0.04052645],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_92_1/kernel:0' shape=(20, 20) dtype=float32, numpy=\n",
       " array([[ 2.99599916e-01, -2.73134381e-01, -4.06697780e-01,\n",
       "          4.72388417e-01, -1.46952599e-01, -1.91827238e-01,\n",
       "          1.74954385e-01, -4.26740080e-01,  6.10167794e-02,\n",
       "         -2.56492108e-01, -4.33208235e-02, -2.69241661e-01,\n",
       "          6.27774596e-02, -4.28875275e-02,  2.99391866e-01,\n",
       "         -2.05162778e-01, -9.27182008e-03, -2.49004960e-01,\n",
       "          4.66867805e-01,  2.16461703e-01],\n",
       "        [ 1.33018151e-01, -3.75863642e-01, -1.80779815e-01,\n",
       "         -3.08480769e-01,  3.36188257e-01,  4.84300591e-02,\n",
       "          2.21055061e-01, -1.21558970e-02,  1.35197369e-02,\n",
       "          2.89225936e-01, -4.06939924e-01,  2.36521006e-01,\n",
       "          4.27917421e-01,  1.02636382e-01,  2.14320898e-01,\n",
       "          3.64725408e-03,  2.90411681e-01,  2.90761665e-02,\n",
       "         -8.30228031e-02,  1.00582838e-03],\n",
       "        [ 3.02828610e-01, -1.06324337e-01,  3.40818077e-01,\n",
       "          2.12999940e-01, -4.16552238e-02,  5.70539124e-02,\n",
       "          6.14924058e-02,  1.05800681e-01, -4.92577255e-02,\n",
       "         -3.12945247e-01, -2.70478964e-01, -2.07692042e-01,\n",
       "          4.00464892e-01, -1.68190166e-01, -6.27418533e-02,\n",
       "         -1.68293640e-01, -4.20632899e-01, -4.07618999e-01,\n",
       "          1.01577364e-01, -8.14381894e-03],\n",
       "        [-3.30091894e-01, -4.51181620e-01, -3.49830091e-01,\n",
       "          1.96558580e-01, -3.66561383e-01, -9.77515951e-02,\n",
       "          3.35935384e-01, -1.63142920e-01,  7.07920864e-02,\n",
       "         -2.03003660e-01, -2.82687843e-01,  1.93242520e-01,\n",
       "          3.32783610e-01, -4.83936481e-02, -3.56034219e-01,\n",
       "          7.43166804e-02, -2.80525178e-01, -3.08047235e-02,\n",
       "          1.14341654e-01,  4.07730550e-01],\n",
       "        [-3.23909432e-01,  1.77694649e-01, -1.35667861e-01,\n",
       "          7.87703544e-02, -2.95743942e-01, -9.72761512e-02,\n",
       "          1.99221820e-01, -6.43795952e-02,  3.69074456e-02,\n",
       "         -3.15872192e-01, -8.80443901e-02, -1.54430106e-01,\n",
       "         -2.26384532e-02, -1.40667766e-01, -2.42293719e-02,\n",
       "         -2.70222217e-01, -2.10120469e-01,  1.45511791e-01,\n",
       "         -1.83593899e-01,  1.34862006e-01],\n",
       "        [ 1.58552695e-02, -1.34397164e-01,  1.86190963e-01,\n",
       "          7.46620819e-02,  4.12022591e-01, -3.22353870e-01,\n",
       "          1.10812582e-01, -3.41550112e-01,  2.06524059e-01,\n",
       "         -6.44949973e-02,  8.51373374e-02, -1.01333268e-01,\n",
       "          1.37194440e-01, -6.66373298e-02, -1.58831552e-01,\n",
       "          4.60253693e-02, -3.79694551e-01, -1.09755762e-01,\n",
       "         -1.83818804e-03,  3.24807823e-01],\n",
       "        [-1.14777729e-01, -1.02372281e-01, -2.57812440e-01,\n",
       "          2.67992914e-01, -3.76671582e-01,  6.18517697e-02,\n",
       "         -2.74833411e-01, -3.92653614e-01, -7.66408145e-02,\n",
       "          1.75409332e-01,  5.64987026e-03,  1.22065477e-01,\n",
       "          1.06465518e-01,  4.64581996e-02, -9.66835991e-02,\n",
       "          1.19479358e-01,  2.77958542e-01, -3.27194333e-01,\n",
       "         -8.12570751e-02, -4.36380366e-03],\n",
       "        [-4.23274487e-01,  3.34854096e-01, -1.51443794e-01,\n",
       "         -2.12288961e-01,  1.90088093e-01,  3.13372426e-02,\n",
       "         -4.60065067e-01,  7.01170489e-02, -4.69130546e-01,\n",
       "         -7.13685900e-02,  1.62651703e-01, -1.13034986e-01,\n",
       "         -2.94327736e-01, -2.41295691e-03,  1.44040622e-02,\n",
       "          2.67078757e-01,  2.09789854e-02,  1.24401778e-01,\n",
       "          2.30498388e-01,  1.88573942e-01],\n",
       "        [-4.62124534e-02,  6.50997981e-02,  1.78328887e-01,\n",
       "          4.91204828e-01, -3.17882717e-01,  4.37086940e-01,\n",
       "          2.74932444e-01,  2.08560318e-01, -2.51891892e-02,\n",
       "         -1.19307354e-01, -2.91085869e-01, -3.66291165e-01,\n",
       "         -2.00023472e-01, -1.58861816e-01,  1.76564101e-02,\n",
       "         -2.70787664e-02,  2.21220292e-02,  3.84220332e-01,\n",
       "          3.32995862e-01,  3.87204856e-01],\n",
       "        [-4.22428280e-01,  7.77456611e-02, -2.48735934e-01,\n",
       "          6.48518503e-02,  1.29164442e-01, -1.08281210e-01,\n",
       "         -1.58385739e-01, -1.35851741e-01, -1.50341354e-02,\n",
       "          1.48870692e-01,  3.28828722e-01,  1.70669094e-01,\n",
       "         -2.90140174e-02, -1.18238561e-01,  6.30835891e-02,\n",
       "          8.50695651e-03,  5.07044941e-02,  4.70533445e-02,\n",
       "         -1.15768760e-01, -3.04502249e-01],\n",
       "        [-1.26281947e-01, -3.57319593e-01,  3.99587929e-01,\n",
       "          3.21240515e-01, -2.32160673e-01,  3.17092389e-01,\n",
       "          1.64929554e-01, -1.68221354e-01, -1.29195139e-01,\n",
       "          4.08921055e-02, -1.02015920e-01,  6.65706694e-02,\n",
       "         -1.45824449e-02,  4.92834091e-01, -8.89570042e-02,\n",
       "         -2.48078108e-01,  2.98042059e-01,  1.06556058e-01,\n",
       "          4.46292102e-01,  6.21193573e-02],\n",
       "        [ 3.23827684e-01, -2.51074910e-01,  3.21160346e-01,\n",
       "         -1.25917301e-01, -1.72094882e-01, -1.34836659e-01,\n",
       "         -9.23023745e-03,  2.66747177e-01,  1.43714786e-01,\n",
       "          1.61287021e-02, -3.66878770e-02,  2.21647248e-01,\n",
       "          1.12739526e-01, -3.12222838e-01,  4.65259671e-01,\n",
       "          3.65342110e-01,  8.79125744e-02,  2.34022960e-01,\n",
       "          1.59147382e-02,  8.87308717e-02],\n",
       "        [ 3.10066760e-01,  1.25016585e-01,  2.43060187e-01,\n",
       "         -1.06794141e-01,  1.11823864e-01,  4.19204295e-01,\n",
       "         -3.95935029e-02,  1.74473196e-01, -1.37178645e-01,\n",
       "         -9.45263579e-02,  3.04615289e-01, -9.39097777e-02,\n",
       "          4.30877507e-02,  2.84977168e-01, -4.90389317e-01,\n",
       "          1.78002879e-01, -2.60390401e-01, -4.36757207e-01,\n",
       "          3.10625851e-01,  3.50128114e-03],\n",
       "        [-2.24359930e-02,  1.97580159e-01, -4.01191145e-01,\n",
       "         -1.60192415e-01, -3.39163363e-01,  5.21971360e-02,\n",
       "         -4.28944200e-01, -4.94456701e-02,  7.81828165e-02,\n",
       "         -7.92436302e-02,  1.52372733e-01, -3.75381321e-01,\n",
       "          4.24793325e-02,  4.05663788e-01, -2.17345104e-01,\n",
       "         -1.64412156e-01,  1.78612843e-01,  2.21970960e-01,\n",
       "          5.77402487e-02,  4.89510037e-02],\n",
       "        [ 8.36248770e-02,  3.12338173e-01,  7.18631595e-02,\n",
       "         -4.62243915e-01, -2.29932904e-01,  1.28200531e-01,\n",
       "         -6.61311448e-02, -2.00959429e-01,  3.77116054e-01,\n",
       "         -2.66955376e-01, -4.90259677e-01,  1.17273875e-01,\n",
       "          1.14477262e-01,  1.26999661e-01, -3.23949844e-01,\n",
       "         -2.26480231e-01, -3.58969420e-01,  1.29982218e-01,\n",
       "          2.38661408e-01,  1.36646762e-01],\n",
       "        [ 2.93212384e-01, -1.81641251e-01, -4.02715832e-01,\n",
       "          3.39606702e-01, -3.31700593e-02, -6.24993667e-02,\n",
       "         -2.77108878e-01,  7.62630533e-03,  1.17902957e-01,\n",
       "          4.93169576e-01, -3.67985547e-01, -2.38725245e-01,\n",
       "          2.68760234e-01, -1.92781344e-01,  8.88125878e-03,\n",
       "          2.40026802e-01,  2.75674164e-01, -7.12501183e-02,\n",
       "          3.18734616e-01,  4.27052081e-01],\n",
       "        [ 1.83172241e-01,  1.79302588e-01, -1.41301066e-01,\n",
       "          1.98317185e-01, -2.70613372e-01, -1.82698503e-01,\n",
       "          3.24099511e-01,  8.61837938e-02,  5.39500453e-03,\n",
       "          3.67110163e-01,  1.38997704e-01, -4.60291088e-01,\n",
       "         -4.63579595e-03,  2.12024242e-01, -2.57564157e-01,\n",
       "          1.03451009e-03,  1.14634059e-01, -1.46756366e-01,\n",
       "          2.10598081e-01, -2.12853588e-03],\n",
       "        [ 2.81699687e-01,  4.44486290e-02,  5.38320243e-01,\n",
       "          8.70354325e-02,  1.61969274e-01,  2.38970667e-01,\n",
       "         -8.01527053e-02,  1.63299501e-01, -2.78860837e-01,\n",
       "          1.24063306e-01,  3.05478007e-01, -1.12916537e-01,\n",
       "         -1.41824126e-01, -2.00520039e-01, -1.82932708e-04,\n",
       "         -2.20972791e-01, -2.47263640e-01, -1.63838327e-01,\n",
       "         -1.18211873e-01, -1.28540605e-01],\n",
       "        [ 1.47211641e-01, -2.96687037e-01,  8.34182650e-02,\n",
       "          3.98750193e-02,  1.60176709e-01, -1.66421175e-01,\n",
       "          1.65672526e-01, -2.36915290e-01, -7.81371370e-02,\n",
       "         -4.31378074e-02,  2.44673520e-01, -3.89729500e-01,\n",
       "          3.65015745e-01, -2.21627980e-01, -3.04115172e-02,\n",
       "         -4.53926474e-02,  1.85000122e-01,  8.84144660e-03,\n",
       "         -1.23869099e-01,  2.94539961e-03],\n",
       "        [-1.68392196e-01,  9.21700597e-02, -1.69607639e-01,\n",
       "          3.28257263e-01, -6.13275319e-02,  2.51490176e-01,\n",
       "          3.49042505e-01,  5.84801193e-03,  1.31148696e-01,\n",
       "          9.43008065e-02,  2.11534873e-01, -1.18140668e-01,\n",
       "         -2.21414223e-01, -3.67708355e-01, -1.90030560e-01,\n",
       "          3.26367654e-03,  2.06575245e-02,  1.57077566e-01,\n",
       "         -7.29260445e-02, -3.35043631e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_92_1/bias:0' shape=(20,) dtype=float32, numpy=\n",
       " array([ 0.04163145,  0.0424313 ,  0.03932239, -0.04048116,  0.04493926,\n",
       "         0.04437481, -0.04125374, -0.03716297, -0.04571662,  0.03248229,\n",
       "         0.04089603,  0.04193347, -0.04243973,  0.04086624, -0.01354346,\n",
       "        -0.04182826, -0.03560619, -0.03794827,  0.02598363, -0.04027464],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_93_1/kernel:0' shape=(20, 1) dtype=float32, numpy=\n",
       " array([[ 0.06549514],\n",
       "        [ 0.06548209],\n",
       "        [ 0.19249259],\n",
       "        [-0.13684149],\n",
       "        [ 0.02536809],\n",
       "        [ 0.02907612],\n",
       "        [-0.09040824],\n",
       "        [-0.02064584],\n",
       "        [-0.03878889],\n",
       "        [-0.00501134],\n",
       "        [ 0.07914264],\n",
       "        [ 0.03651865],\n",
       "        [-0.05365163],\n",
       "        [ 0.08613516],\n",
       "        [-0.01720366],\n",
       "        [-0.0727512 ],\n",
       "        [-0.01283225],\n",
       "        [-0.01932631],\n",
       "        [-0.0084159 ],\n",
       "        [-0.13415384]], dtype=float32)>,\n",
       " <tf.Variable 'dense_93_1/bias:0' shape=(1,) dtype=float32, numpy=array([0.03977264], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_246_1/moving_mean:0' shape=(10,) dtype=float32, numpy=\n",
       " array([-1.9394011e-03,  6.5676626e-03, -3.0744933e-03,  1.6120675e-03,\n",
       "         2.7616338e-03, -4.5280424e-03, -7.2699571e-03,  7.1180140e-05,\n",
       "         2.9944615e-03,  4.5653118e-04], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_246_1/moving_variance:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.66981816, 0.66968334, 0.66985476, 0.66994005, 0.6692672 ,\n",
       "        0.6695408 , 0.6694257 , 0.67015505, 0.66956013, 0.67049336],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_247_1/moving_mean:0' shape=(20,) dtype=float32, numpy=\n",
       " array([ 0.02320888,  0.00119234,  0.01103519, -0.02204275,  0.00114479,\n",
       "         0.01997797, -0.03331695,  0.00912547, -0.01028076,  0.00296711,\n",
       "         0.04372228,  0.04560302, -0.01411749,  0.02751859,  0.00152295,\n",
       "         0.0056313 ,  0.00965947, -0.00943227,  0.04061076,  0.03658664],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_247_1/moving_variance:0' shape=(20,) dtype=float32, numpy=\n",
       " array([0.7941357 , 0.80539536, 0.8162422 , 1.0574975 , 0.7305754 ,\n",
       "        0.8919972 , 0.89699066, 0.8758905 , 0.7930839 , 0.8168984 ,\n",
       "        0.8905547 , 0.92217135, 0.83876693, 0.75957054, 0.7470627 ,\n",
       "        0.81294066, 0.80272686, 0.915586  , 0.8367836 , 0.76386935],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_248_1/moving_mean:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.04688541, -0.00420344,  0.08072429,  0.05427508,  0.07498758,\n",
       "        -0.00758899, -0.0193714 , -0.00884765,  0.03826338,  0.01565486],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_248_1/moving_variance:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.98662394, 1.0902193 , 1.036755  , 0.96188647, 1.075315  ,\n",
       "        1.5192846 , 1.324617  , 0.9831705 , 0.86818933, 1.1354446 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_249_1/moving_mean:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.04117984,  0.06483054,  0.01762968,  0.01609576, -0.00474573,\n",
       "         0.04773308,  0.04909327,  0.04584774,  0.03018713,  0.02709959],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_249_1/moving_variance:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.8711536 , 0.8559602 , 0.8900384 , 2.071681  , 1.5578189 ,\n",
       "        0.8050348 , 0.85339046, 0.8622375 , 0.8862746 , 1.4472008 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_250_1/moving_mean:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.0657252 , 0.04822057, 0.04766611, 0.06729601, 0.04711656,\n",
       "        0.10427711, 0.03294663, 0.05745428, 0.04116364, 0.04767036],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_250_1/moving_variance:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.85310245, 0.7784063 , 0.753104  , 0.84719384, 0.9923937 ,\n",
       "        1.1230441 , 1.2785518 , 0.84159225, 0.89087677, 0.8092762 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_251_1/moving_mean:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.10666236, 0.10472652, 0.12745905, 0.15674022, 0.12762395,\n",
       "        0.11009295, 0.1082961 , 0.1370659 , 0.10480997, 0.10489315],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_251_1/moving_variance:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.8387572 , 0.8790204 , 0.935405  , 1.6025075 , 0.8837194 ,\n",
       "        1.0779358 , 0.9261465 , 1.3497232 , 0.96305126, 0.9070433 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_252_1/moving_mean:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.19127442, 0.2076104 , 0.20707585, 0.18812068, 0.32215562,\n",
       "        0.24842939, 0.18262662, 0.2079789 , 0.2627139 , 0.24776393],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_252_1/moving_variance:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.8686013 , 1.0528005 , 0.90167344, 0.8127699 , 1.1835014 ,\n",
       "        1.1651387 , 0.8897972 , 0.9255455 , 1.2347124 , 1.5186111 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_253_1/moving_mean:0' shape=(20,) dtype=float32, numpy=\n",
       " array([ 0.03885742, -0.05981798, -0.02331911, -0.04693062,  0.00581599,\n",
       "         0.02036424, -0.00773874,  0.05292863, -0.01915769, -0.017059  ,\n",
       "         0.03897826, -0.02728937, -0.03147633,  0.00087034,  0.00684528,\n",
       "        -0.00420183,  0.05794048,  0.01339531,  0.05333511,  0.03484641],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_253_1/moving_variance:0' shape=(20,) dtype=float32, numpy=\n",
       " array([1.1118042 , 1.0466352 , 1.066351  , 1.082121  , 1.0597026 ,\n",
       "        1.1042202 , 1.0175657 , 1.1365969 , 0.96844643, 1.0403498 ,\n",
       "        1.1054975 , 1.1156838 , 1.0050486 , 1.131593  , 1.0983351 ,\n",
       "        1.1673137 , 1.132628  , 1.041215  , 1.0566562 , 1.1330907 ],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnns[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45693 [00:00<?, ?it/s]\n",
      "  0%|          | 0/43033 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev:  0 , now:  2000 , size 2000\n",
      "[383, 383, 383, 383, 383, 85]\n",
      "Lambda: 0\n",
      "0 383\n",
      "0 0\n",
      "383 766\n",
      "0 0\n",
      "766 1149\n",
      "0 0\n",
      "1149 1532\n",
      "0 0\n",
      "1532 1915\n",
      "0 0\n",
      "1915 2000\n",
      "0 85\n",
      "validating\n",
      "2000 2660\n",
      "Lambda: 0.001\n",
      "0 383\n",
      "0 0\n",
      "383 766\n",
      "0 0\n",
      "766 1149\n",
      "0 0\n",
      "1149 1532\n",
      "0 0\n",
      "1532 1915\n",
      "0 0\n",
      "1915 2000\n",
      "0 85\n",
      "validating\n",
      "2000 2660\n",
      "Test\n",
      "2660 48353\n",
      "prev:  2000 , now:  4000 , size 2000\n",
      "[383, 383, 383, 383, 383, 85]\n",
      "Lambda: 0\n",
      "2000 2383\n",
      "0 0\n",
      "2383 2766\n",
      "0 0\n",
      "2766 3149\n",
      "0 0\n",
      "3149 3532\n",
      "0 0\n",
      "3532 3915\n",
      "0 0\n",
      "3915 4000\n",
      "0 85\n",
      "validating\n",
      "4000 5320\n",
      "Lambda: 0.001\n",
      "2000 2383\n",
      "0 0\n",
      "2383 2766\n",
      "0 0\n",
      "2766 3149\n",
      "0 0\n",
      "3149 3532\n",
      "0 0\n",
      "3532 3915\n",
      "0 0\n",
      "3915 4000\n",
      "0 85\n",
      "validating\n",
      "4000 5320\n",
      "Test\n",
      "5320 48353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CNN: support batching\n",
    "prev_sample = 0\n",
    "# number_samples = [120, 200, 700]\n",
    "lambda_vec = [0, 0.001]  #0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "for cnn in cnns:\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "for number_sample in number_samples:\n",
    "    current_sample = number_sample - prev_sample\n",
    "    print(\"prev: \", prev_sample, \", now: \", number_sample, \", size\", current_sample) \n",
    "    train_samples = [batch_size] * (current_sample//batch_size) + ([current_sample%batch_size] if \n",
    "                                                                    current_sample%batch_size else [])\n",
    "    print(train_samples)\n",
    "    \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb_idx, lamb in enumerate(lambda_vec):\n",
    "        print(\"Lambda:\", lamb)\n",
    "#         cnn = cnn_model(10, lamb, 0)\n",
    "#         cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "        # training on all batches\n",
    "                                    \n",
    "        for i, train_sample in enumerate(train_samples):\n",
    "            for image_num in range(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample):\n",
    "                print(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample)\n",
    "                print((prev_sample + i * batch_size - prev_sample) % batch_size, \n",
    "                      (prev_sample + i * batch_size + train_sample - prev_sample)% batch_size)\n",
    "                break\n",
    "\n",
    "        \n",
    "        # validating\n",
    "        print(\"validating\")\n",
    "        val_size = math.ceil(number_sample * validation_size)\n",
    "        for image_num in range(val_size):\n",
    "            print(number_sample, val_size + number_sample)\n",
    "            break\n",
    "     \n",
    "    print(\"Test\") \n",
    "    \n",
    "    # evaluating test images\n",
    "\n",
    "    \n",
    "    for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "        print(number_sample + val_size, data_reg.shape[0])\n",
    "        break\n",
    "    prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + 'best_cnn_4000samples' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                 dtime + \".dat\", \"wb\") # file for saving results\n",
    "pickle.dump(best_model, file=var_f)\n",
    "var_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:57, 57.66s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [02:23, 143.92s/it]\u001b[A\n",
      "2it [04:46, 143.57s/it]\u001b[A\n",
      "3it [07:09, 143.27s/it]\u001b[A\n",
      "4it [09:32, 143.17s/it]\u001b[A\n",
      "5it [10:23, 124.68s/it]\u001b[A\n",
      " 17%|█▋        | 1/6 [11:23<56:58, 683.79s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.211368327594533\n",
      "Lambda: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:56, 56.09s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [02:19, 139.20s/it]\u001b[A\n",
      "2it [04:38, 139.22s/it]\u001b[A\n",
      "3it [06:57, 139.21s/it]\u001b[A\n",
      "4it [09:18, 139.72s/it]\u001b[A\n",
      "5it [10:08, 121.72s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [22:31<45:15, 678.85s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.379879925942782\n",
      "Lambda: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:58, 58.13s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [02:24, 144.03s/it]\u001b[A\n",
      "2it [04:48, 144.30s/it]\u001b[A\n",
      "3it [07:14, 144.74s/it]\u001b[A\n",
      "4it [09:39, 144.71s/it]\u001b[A\n",
      "5it [10:31, 126.24s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [34:03<34:08, 682.78s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.986079897483191\n",
      "Lambda: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:56, 56.09s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [02:18, 138.72s/it]\u001b[A\n",
      "2it [04:37, 138.66s/it]\u001b[A\n",
      "3it [06:56, 138.75s/it]\u001b[A\n",
      "4it [09:14, 138.70s/it]\u001b[A\n",
      "5it [10:04, 120.90s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [45:06<22:33, 676.92s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.314812567979636\n",
      "Lambda: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:55, 55.93s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [02:18, 138.30s/it]\u001b[A\n",
      "2it [04:36, 138.31s/it]\u001b[A\n",
      "3it [06:54, 138.26s/it]\u001b[A\n",
      "4it [09:12, 138.16s/it]\u001b[A\n",
      "5it [10:02, 120.43s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [56:06<11:12, 672.05s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.257873288155691\n",
      "Lambda: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:56, 56.58s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [02:20, 140.02s/it]\u001b[A\n",
      "2it [04:40, 140.21s/it]\u001b[A\n",
      "3it [07:00, 140.04s/it]\u001b[A\n",
      "4it [09:20, 139.96s/it]\u001b[A\n",
      "5it [10:10, 122.09s/it]\u001b[A\n",
      "100%|██████████| 6/6 [1:07:16<00:00, 672.77s/it]\n",
      "  0%|          | 27/41779 [00:00<02:35, 269.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.043452635827206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41779/41779 [02:38<00:00, 263.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_samples:  2000 , average_error:  6.545  fp_average_error:  3.067\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## use self-training\n",
    "unlabeled_train_samples = [batch_size] * (len(y_test_p)//batch_size) + ([len(y_test_p)%batch_size] if len(y_test_p)%batch_size else [])\n",
    "labeled_train_samples = [batch_size] * (number_sample//batch_size) + ([number_sample%batch_size] if number_sample%batch_size else [])   \n",
    "min_min_error = float('inf')\n",
    "best_best_model, best_best_lam = None, None\n",
    "for lamb in tqdm.tqdm(lambda_vec):\n",
    "    print(\"Lambda:\", lamb)\n",
    "    cnn = cnn_model(10, lamb, 0)\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#     cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "    # training on all batches\n",
    "    # training on all batches\n",
    "    for i, train_sample in tqdm.tqdm(enumerate(labeled_train_samples)):\n",
    "        x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "        y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "        for image_num in range(i * batch_size, i * batch_size + train_sample):\n",
    "            x_train[image_num % batch_size] = read_image(image_num)\n",
    "            y_train[image_num % batch_size] = np.asarray(data_reg[image_num][-1], dtype=float_memory_used)\n",
    "        cnn.fit(x_train, y_train, epochs=6, verbose=0, batch_size=1, validation_split=0.0)\n",
    "        del x_train, y_train\n",
    "            \n",
    "    for i, train_sample in tqdm.tqdm(enumerate(unlabeled_train_samples)):\n",
    "        x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "        y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "        for image_num in range(i * batch_size + number_sample + val_size, i * batch_size + number_sample + val_size + train_sample):\n",
    "            x_train[(image_num-number_sample - val_size) % batch_size] = read_image(image_num)\n",
    "            y_train[(image_num-number_sample - val_size) % batch_size] = np.asarray(y_test_p[image_num-(number_sample + val_size)], dtype=float_memory_used)\n",
    "        cnn.fit(x_train, y_train, epochs=3, verbose=0, batch_size=1, validation_split=0.0)\n",
    "        del x_train, y_train\n",
    "        \n",
    "    # validating\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "    val_mae, val_fp_mae = 0.0, 0.0\n",
    "    for image_num in range(val_size):\n",
    "        val_y = data_reg[image_num + number_sample][-1]\n",
    "        image = read_image(image_num + number_sample)\n",
    "        val_yp = cnn.predict(image)[0][0]\n",
    "        val_mae += abs(val_y - val_yp)\n",
    "        if val_yp > val_y:\n",
    "            val_fp_mae += abs(val_yp - val_y)\n",
    "    val_mae /= val_size\n",
    "    val_fp_mae /= val_size\n",
    "    print(val_mae)\n",
    "    if val_mae < min_min_error:\n",
    "        min_min_error = val_mae\n",
    "        best_best_model = cnn\n",
    "        best_best_lam = lamb\n",
    "    sum_mae, sum_fp_mae = 0, 0\n",
    "    test_size = 0\n",
    "    \n",
    "for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "    test_size += 1\n",
    "    test_image = read_image(test_num)\n",
    "    test_y = data_reg[test_num][-1]\n",
    "    test_yp = best_best_model.predict(test_image)[0][0]\n",
    "#     y_test_p[test_num - (number_sample + val_size)] = test_yp\n",
    "    sum_mae += abs(test_yp - test_y)\n",
    "    if test_yp > test_y:\n",
    "        sum_fp_mae += abs(test_yp - test_y)\n",
    "fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "print('number_samples: ', number_sample, ', average_error: ', average_diff_power[-1], ' fp_average_error: ', \n",
    "      fp_mean_power[-1])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6.285, 6.366, 6.45, 6.454, 6.382, 6.26, 6.49, 6.224, 6.052, 5.87, 4.915, 4.836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "prev_sample = 0\n",
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1]\n",
    "max_train_samples = math.ceil(number_samples[-1] * (1 + validation_size))\n",
    "x_train = np.empty((max_train_samples, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "# x_train1 = np.empty((max_train_samples, 1, max_x, max_y), dtype=float_memory_used)\n",
    "# x_train2 = np.empty((max_train_samples, 1, max_x, max_y), dtype=float_memory_used)\n",
    "y_train = np.empty((max_train_samples), dtype=float_memory_used)\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "for number_sample in number_samples:\n",
    "    sample = math.ceil(number_sample * (1 + validation_size))\n",
    "    for image_num in range(prev_sample, sample):\n",
    "        prev_sample = sample\n",
    "        if style == \"image_intensity\":\n",
    "            image = plt.imread(image_dir + '/image' + str(image_num)+'.png')\n",
    "            image = np.swapaxes(image, 0, 2)\n",
    "            x_train[image_num] = np.array(image[:number_image_channels], dtype=float_memory_used).reshape(1, number_image_channels, max_x, max_y)\n",
    "            del image\n",
    "        elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "            x_train[image_num] = np.load(image_dir + '/image' + str(image_num)+'.npy')\n",
    "#             image = np.load(image_dir + '/image' + str(image_num)+'.npy')\n",
    "#             x_train1[image_num][0] = image[0][0]\n",
    "#             x_train2[image_num][0] = image[0][1]\n",
    "        y_train[image_num] = np.asarray(data_reg[image_num][-1], dtype=float_memory_used)\n",
    "        if image_num + 1 % 100 == 0:\n",
    "            print(image_num)\n",
    "#     cnn = cnn_model(7, 0, 0)\n",
    "#     cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#     cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "#             (validation_size + 1))\n",
    "    \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb in lambda_vec:\n",
    "        print(\"Lambda:\", lamb)\n",
    "        cnn = cnn_model(10, lamb, 0)\n",
    "        cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#         cnn.fit([x_train1[:sample], x_train2[:sample]], y_train[:sample], epochs=6, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "#                 (validation_size + 1))\n",
    "        cnn.fit(x_train[:sample], y_train[:sample], epochs=6, verbose=0, batch_size=1, validation_split=validation_size/\n",
    "                (validation_size + 1))\n",
    "        if cnn.history.history['val_mean_absolute_error'][-1] < min_error:\n",
    "            min_error = cnn.history.history['val_mean_absolute_error'][-1]\n",
    "            best_model = cnn\n",
    "            best_lam = lamb\n",
    "    print(\"best_lambda, \", best_lam, \"min_error\", min_error)    \n",
    "    # evaluating test images\n",
    "    sum_mae, sum_fp_mae = 0, 0\n",
    "    test_size = 0\n",
    "#     for test_num in range(max_train_samples, data_reg.shape[0]):\n",
    "    for test_num in range(sample, data_reg.shape[0]):\n",
    "        test_size += 1\n",
    "        if style == \"image_intensity\":\n",
    "            test_image = plt.imread(image_dir + '/image' + str(test_num) + '.png')\n",
    "            test_image = np.swapaxes(test_image, 0, 2)\n",
    "            test_image = np.array(test_image[:number_image_channels]).reshape(1, number_image_channels, max_x, max_y)\n",
    "        elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "            test_image = np.load(image_dir + '/image' + str(test_num)+'.npy')\n",
    "        test_y = data_reg[test_num][-1]\n",
    "        test_yp = best_model.predict(test_image)[0][0]\n",
    "        sum_mae += abs(test_yp - test_y)\n",
    "        if test_yp > test_y:\n",
    "            sum_fp_mae += abs(test_yp - test_y)\n",
    "        if test_num % 500 == 0:\n",
    "            print('test: ', test_num)\n",
    "    fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "    average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "    print('number_samples: ', number_sample, ', average_error: ', average_diff_power[-1], ' fp_average_error: ', fp_mean_power[-1])\n",
    "    print(\"\\n\")\n",
    "    var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + dtime + \".dat\", \"wb\") # file for saving results\n",
    "    pickle.dump([average_diff_power, fp_mean_power, number_samples], file=var_f)\n",
    "    var_f.close()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power[8], average_diff_power[9] = average_diff_power[9], average_diff_power[8]\n",
    "# fp_mean_power = fp_mean_power[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapee = Input(shape=(number_image_channels, max_x, max_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapee[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(1, 0)\n",
    "cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnn.history.history['val_mean_absolute_error'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(10, 0, 0)\n",
    "cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "            (validation_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3]\n",
    "min_error = float('inf')\n",
    "best_model, best_lam = None, None\n",
    "for lamb in lambda_vec:\n",
    "    print(\"Lambda:\", lamb)\n",
    "    cnn = cnn_model(15, lamb, 0)\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "    cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "            (validation_size + 1))\n",
    "    if cnn.history.history['val_mean_absolute_error'][-1] < min_error:\n",
    "        min_error = cnn.history.history['val_mean_absolute_error'][-1]\n",
    "        best_model = cnn\n",
    "        best_lam = lamb\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_lam)\n",
    "print(best_model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just run to dispaly the image. First change return line from create_image\n",
    "aa = np.swapaxes(np.append(np.array(x_train[50]), np.zeros((2,max_x, max_y), dtype=float_memory_used), axis=0), 0, 2)\n",
    "plt.imshow(aa)\n",
    "# plt.imsave('image.png', aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to read saved variables\n",
    "var_ff = open('ML/data/pictures_1000_1000/log_201912_0705_37.txt', 'rb')\n",
    "[average_diff_power_1, fp_mean_power_1, number_samples_1] = pickle.load(var_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_mean_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power[-1]*(data_reg.shape[0] - max_train_samples)/(300-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_fp_mae/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_mean_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pydotplus\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "keras.utils.vis_utils.pydot = pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARALLEL CNN\n",
    "def cnn_model(num_filters, kernel_lam, bias_lam):\n",
    "#     num_filters, lam = 5, 5\n",
    "    data_format = 'channels_first'\n",
    "    convolution_filter, dense_filter = 'selu', 'linear' #softsign, sigmoid; relu, linear\n",
    "    filter_shape, pool_size = (3, 3), (2,2)\n",
    "    # CNN for PU image\n",
    "    input1  = layers.Input(shape=(number_image_channels - 1, max_x, max_y), name='pus_input')\n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(input1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    \n",
    "    # CNN for SU\n",
    "    input2  = layers.Input(shape=(1, max_x, max_y), name='su_input')\n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(input2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    \n",
    "    # concatanate two CNN outputs\n",
    "    x = layers.concatenate([x1, x2])\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    x = layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    out = layers.Dense(1, activation=dense_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    \n",
    "    model = models.Model(inputs=[input1, input2], outputs=out)\n",
    "#     plot_model(model, to_file='model.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'square'\n",
    "# style = \"image_intensity\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# average_diff_power = [9.110476626067186, 21.070721128267266, 9.389938883165568, 10.886098907990405,\n",
    "#                                        7.697396928362106, 7.522477509027216, 9.493729427772132, 8.198866980620753,\n",
    "#                                        7.781910785203122, 9.41743984825801, 8.499455442627129, 9.86776958065812,\n",
    "#                                        9.033719411254367, 8.150143941293027, 8.963829050517273, 8.708150642874065,\n",
    "#                                        7.468060397898071, 8.233182799553932,8.206, 7.768]\n",
    "# fp_mean_power =  [8.174990557021465, 0.18043087058937837, 1.5141939559853392, 10.273307557711494,\n",
    "#                                    3.2306742061521443, 4.423113329284006, 8.674172526579392, 2.38235061342411,\n",
    "#                                    5.014172646429496, 6.884079514994618, 3.4544130456368367, 7.81721202679044,\n",
    "#                                    6.438635364829745, 4.069245107144559, 5.202978504937615, 3.405858414831347,\n",
    "#                                    4.117573271657338, 2.8100743146184377, 3.951, 3.502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAX_POWER ANAlysis\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# pu_shape, su_shape = 'circle', 'circle'\n",
    "# style = \"image_intensity\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# test_size = 3670\n",
    "# average_diff_power = [7.811849328268183, 9.178415418536536, 8.11891504382307, 7.881934146750136, 7.918868224324312,\n",
    "#                       7.709452054502398, 7.471729821563216, 8.63783455122861, 7.7635068514166345, 8.557134470036884,\n",
    "#                       8.103793715416188, 9.189284948409279, 11.977416480154307, 8.291134394492891, 8.960065032512803,\n",
    "#                       9.992745143323642, 8.475335283779392, 8.051642160173987, 7.322538645284376, 7.768582958795206]\n",
    "# fp_mean_power = [6.1844398077234635, 1.6157812496465958, 6.5620574110067595, 2.898169187355567, 6.262096880097353,\n",
    "#                  2.5478307871639267, 3.5784209073932067, 7.416731632966506, 5.5822838290638135, 5.800529848947965,\n",
    "#                  4.6984887763519785, 2.337296353076653, 9.85739104089764, 3.710259461284922, 5.323224159423669, \n",
    "#                  6.198328912769283, 2.302462751745074, 4.023802978234984, 3.781413967880959, 3.2793608103510508]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle'\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# num_pus = 15\n",
    "average_diff_power = [9.711, 7.867, 8.958, 7.571, 7.509, 7.891, 8.272, 7.118, 7.696, 7.689, 8.026, 9.674, 7.51, 7.771, 8.17,\n",
    "                      7.938, 7.869, 7.833, 9.434, 8.501]\n",
    "fp_mean_power = [9.229, 5.101, 8.037, 3.993, 5.095, 2.491, 2.298, 4.654, 3.787, 2.685, 5.676, 8.033, 3.911, 4.235, 3.278,\n",
    "                 5.809, 3.586, 4.257, 4.377, 5.015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "\n",
    "# number_samples = [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 8001, 1000))\n",
    "\n",
    "\n",
    "# cnn_type = \"classification\"  # {\"classification\", \"regression\"}\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 200, 200, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# else:\n",
    "#     su_param = None\n",
    "# sensors = False\n",
    "# if sensors:\n",
    "#     sensors_num = 50\n",
    "#     sensors_file_path = \"rsc/\" + str(sensors_num) + \"/sensors\"\n",
    "    \n",
    "average_diff_power = [6.779, 5.645, 5.473, 4.982, 4.481, 4.071, 4.05, 3.639, 2.813, 2.343, 2.21, 2.372, 2.005, 1.997,\n",
    "                      1.937, 1.901]\n",
    "\n",
    "fp_mean_power = [4.073, 2.409, 3.424, 3.163, 2.833, 2.663, 2.857, 2.744, 1.744, 1.33, 1.184, 1.55, 0.579, 1.216, 1.492, 1.266]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "\n",
    "number_samples = [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 6001, 1000)) + [8000]\n",
    "# dataframe = pd.read_csv('ML/data/dynamic_pus_using_pus50000_15PUs_201912_3000_40_200.txt', delimiter=',', header=None)\n",
    "# dataframe_max = pd.read_csv('ML/data/dynamic_pus_max_power50000_15PUs_201912_3000_40_200.txt', delimiter=',', header=None)\n",
    "\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 200, 200, 4, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 5\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# else:\n",
    "#     su_param = None\n",
    "# sensors = False\n",
    "    \n",
    "average_diff_power = [12.742, 12.906, 12.731, 12.595, 12.859, 13.272, 12.632, 12.647, 11.309, 7.455, 7.131, 5.677,\n",
    "                      5.645, 5.292, 4.445]\n",
    "\n",
    "fp_mean_power = [5.963, 5.861, 8.957, 8.821, 8.215, 9.518, 8.633, 6.644, 6.605, 3.919, 2.539, 3.866, 1.96, 2.717, 1.671]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_diff_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_width = 5\n",
    "marker_size = 12\n",
    "reg_style = 'solid'\n",
    "class_reg = 'dashed'\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, average_diff_power, color='r', linewidth=line_width, markersize=marker_size, linestyle=class_reg)\n",
    "plt.plot(number_samples, fp_mean_power, color='midnightblue', linewidth=line_width, markersize=marker_size, linestyle=class_reg)\n",
    "plt.xlabel('# of Training Samples', fontsize=47)\n",
    "plt.ylabel('Avg. Diff. wrt Opt. (dB)', fontsize=45)\n",
    "plt.title('Dynamic PUs(200m*200m)')\n",
    "plt.grid(True)\n",
    "\n",
    "ax.set_yticks(np.arange(0,14, 2))\n",
    "# ax.set_xticks(np.arange(100,7000, 1500))\n",
    "plt.rcParams.update({'font.size': 42})\n",
    "ax.tick_params(axis='x', labelsize=46)\n",
    "ax.tick_params(axis='y', labelsize=45)\n",
    "\n",
    "# matplotlib.rcParams.update({'font.size': 22})\n",
    "\n",
    "ax.set_ylim([0, 14])\n",
    "ax.set_xlim([0, 8000])\n",
    "plt.legend(['Total', 'False-Positive'], ncol=2, loc='best', handletextpad=0.1,borderpad=0, columnspacing=0.2, borderaxespad=0.2)\n",
    "# plt.legend(handletextpad=0.1)\n",
    "plt.savefig('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + dtime + \".png\", \n",
    "            bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(image_dir + '/image10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/'.join(image_dir.split('/')[:-1]) + '/log_5__202001_1519_01.dat', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/home/shahrokh/projects/research/MLSpectrumAllocation/ML/data/pictures_1000_1000/log/noisy_std_1/' +\n",
    "            'pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/log_3__202003_2919_03.dat', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "[average1,fp1, samples1] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2048, 4096]\n",
      "[6.988, 6.984]\n",
      "[4.007, 4.434]\n"
     ]
    }
   ],
   "source": [
    "print(samples1)\n",
    "print(average1)\n",
    "print(fp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fp1, fp2, fp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples1, samples2, samples3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
