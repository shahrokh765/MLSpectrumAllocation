{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datetime, time\n",
    "import os, sys\n",
    "import tqdm\n",
    "import gc\n",
    "from multiprocessing import Process\n",
    "Point = namedtuple('Point', ('x', 'y'))\n",
    "Circle = namedtuple('Circle', ('r'))\n",
    "Square = namedtuple('Square', ('side'))\n",
    "Rectangle = namedtuple('Rectangle', ('length', 'width'))\n",
    "PointWithDistance = namedtuple('PointWithDistance', ('p', 'dist'))\n",
    "float_memory_used = 'float16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "# PART 1\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 10001, 1000))\n",
    "number_samples = [8192] \n",
    "# number_samples = [4096, 4915, 5734, 6554, 7373, 8192]\n",
    "\n",
    "# cnn_type = \"classification\"  # {\"classification\", \"regression\"}\n",
    "validation_size, noise_floor = 0.33, -110.0\n",
    "su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "max_x, max_y, number_image_channels, su_szie = 100, 100, 7, 10  # su_size:30 for 1000, 10 for 100\n",
    "pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "intensity_degradation, slope = 'log', 5  # 'log', 'linear', slope 3 for 1000, 5 for 100\n",
    "max_pus_num, max_sus_num = 20, 1\n",
    "propagation_model = 'splat' # 'splat', 'log', 'testbed'\n",
    "noise, std = False, 1 # False for splat\n",
    "if su_shape == 'circle':\n",
    "    su_param = Circle(su_szie)\n",
    "elif su_shape == 'square':\n",
    "    su_param = Square(su_szie)\n",
    "else:\n",
    "    su_param = None\n",
    "    \n",
    "sensors = True\n",
    "if sensors:\n",
    "    sensors_num = 49\n",
    "    sensors_file_path = \"../../java_workspace/research/commons/resources/sensors/square\" \\\n",
    "    + str(max(max_x, max_y)) + \"/placement/terrain-based/himanshu/\" + str(sensors_num) + \"/sensors.txt\"\n",
    "# num_pus = (data_reg.shape[1] - 3)//3\n",
    "\n",
    "# PART 2\n",
    "number_of_proccessors = 10\n",
    "memory_size_allowed = 4 # in Gigabyte\n",
    "float_size = 0\n",
    "if float_memory_used == \"float16\":\n",
    "    float_size = 16\n",
    "elif float_memory_used == \"float\" or \"float32\":\n",
    "    float_size = 32\n",
    "elif float_memory_used == \"float8\":\n",
    "    float_size = 8\n",
    "\n",
    "\n",
    "batch_size = int(memory_size_allowed / (max_x * max_y * number_image_channels * float_size/(8 * 1024 ** 3)))\n",
    "\n",
    "\n",
    "dtime = datetime.datetime.now().strftime('_%Y%m_%d%H_%M')\n",
    "color = \"color\" if number_image_channels > 1 else \"gray\"\n",
    "image_dir = 'ML/data/pictures_' + str(max_x) + '_' + str(max_y) + '/' + propagation_model + (\n",
    "    \"/noisy_std_\" + str(std) if noise else \"\") + '/pu_' + pu_shape + '_su_' + su_shape + '_' + (\n",
    "    \"\" if su_shape == 'point' else str(su_szie)) + \"/\" + style + \"/\" + color +'/' + (\n",
    "    \"\" if pu_shape == 'point' and su_shape == 'point' else (intensity_degradation + '_' + str(slope))) + (\n",
    "    \"/\" + str(sensors_num) + \"sensors\" if sensors else \"/pus\") + \"/images\"\n",
    "\n",
    "if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/images'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "num_columns = (sensors_num if sensors else max_pus_num * 3 + 1) + max_sus_num * 3 + 2\n",
    "cols = [i for i in range(num_columns)]\n",
    "dataset_name = \"dynamic_pus_49sensorTerrainHimanshu_50000_min10_max20PUs_1SUs_square100grid_splat_2020_10_13_23_09.txt\"\n",
    "max_dataset_name = \"dynamic_pus_max_power_50000_min10_max20PUs_1SUs_square100grid_splat_2020_10_13_23_09.txt\"\n",
    "with open('/'.join(image_dir.split('/')[:-1]) + '/datasets' + dtime + '.txt', 'w') as set_file:\n",
    "    set_file.write(dataset_name + \"\\n\")\n",
    "    set_file.write(max_dataset_name)\n",
    "\n",
    "dataframe = pd.read_csv('../../java_workspace/research/spectrum_allocation/resources/data/placement/'\n",
    "                        + str(sensors_num) + \"Sensors/\" + dataset_name, delimiter=',', header=None, names=cols)\n",
    "dataframe_max = pd.read_csv('../../java_workspace/research/spectrum_allocation/resources/data/placement/'\n",
    "                            + str(sensors_num) + \"Sensors/\" + max_dataset_name, delimiter=',', header=None)\n",
    "\n",
    "dataframe.reset_index(drop=True, inplace=True)\n",
    "dataframe_max.reset_index(drop=True, inplace=True)\n",
    "dataframe_max[dataframe_max.shape[1] - 1] = dataframe_max[dataframe_max.shape[1] - 1].astype(float)\n",
    "\n",
    "dataframe_tot = pd.concat([dataframe, dataframe_max.iloc[:, dataframe_max.columns.values[-1:]]], axis=1,\n",
    "                        ignore_index=True)\n",
    "\n",
    "idx = dataframe_tot[dataframe_tot[dataframe_tot.columns[-1]] == -float('inf')].index\n",
    "dataframe_tot.drop(idx, inplace=True)\n",
    "\n",
    "data_reg = dataframe_tot.values\n",
    "data_reg[data_reg < noise_floor] = noise_floor\n",
    "# data_reg = np.concatenate((dataframe_tot.values[:, 0:dataframe_tot.shape[1]-3], \n",
    "#                            dataframe_tot.values[:, dataframe_tot.shape[1]-1:dataframe_tot.shape[1]]), axis=1)\n",
    "# data_class = dataframe_tot.values[:, 0:dataframe_tot.shape[1]-1]\n",
    "# y_class_power = dataframe_tot.values[:, -1]\n",
    "\n",
    "if sensors:\n",
    "    sensors_location = []\n",
    "    with open(sensors_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.split(',')\n",
    "            sensors_location.append(Point(int(float(line[0])), int(float(line[1]))))\n",
    "del dataframe, dataframe_tot, dataframe_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 55)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = np.concatenate((data_reg[:,:2500], np.ones((4000, 1)), data_reg[:, 2500:2504],\n",
    "               data_reg[:, 2505:]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.   ,  75.   ,  31.   , -25.276,   1.   ,   5.966])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg[0, sensors_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = data_reg[:][:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg[512:1024, :] = data_reg[:512, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sensors_num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2d7ac49ee5f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_reg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensors_num\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_reg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensors_num\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sensors_num' is not defined"
     ]
    }
   ],
   "source": [
    "data_reg[4096:8192, sensors_num:] = data_reg[:4096, sensors_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.     62.     30.    -19.362  71.     26.    -23.844  24.     53.\n",
      "  -7.168  90.     75.     -8.733  34.     13.    -23.463  12.      9.\n",
      "  -7.096   4.     22.    -12.819  66.     65.    -10.794   7.     20.\n",
      "  -7.626   4.     36.    -28.694   1.     56.     17.    -16.531   1.\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan   2.312]\n",
      "[ 10.     62.     30.    -19.362  71.     26.    -23.844  24.     53.\n",
      "  -7.168  90.     75.     -8.733  34.     13.    -23.463  12.      9.\n",
      "  -7.096   4.     22.    -12.819  66.     65.    -10.794   7.     20.\n",
      "  -7.626   4.     36.    -28.694   1.     56.     17.    -16.531   1.\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan   2.312]\n"
     ]
    }
   ],
   "source": [
    "print(data_reg[10, :])\n",
    "print(data_reg[266, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(p1: Point, p2: Point):\n",
    "    return ((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2) ** 0.5\n",
    "\n",
    "def calculate_mu_sigma(data, num_pus):\n",
    "    sum_non_noise = 0\n",
    "    for pu_n in range(num_pus): # calculate mu\n",
    "        sum_non_noise += data[pu_n*3+2]\n",
    "    mu = ((max_x * max_y - num_pus) * noise_floor + sum_non_noise)/(max_x * max_y)\n",
    "    sum_square = 0\n",
    "    for pu_n in range(num_pus): # calculate sigma\n",
    "        sum_square += (data[pu_n*3+2]-mu)**2\n",
    "    sum_square += (max_x * max_y - num_pus) * (noise_floor - mu)**2\n",
    "    sigma = math.sqrt(sum_square/(max_x * max_y))\n",
    "    return mu, sigma\n",
    "\n",
    "def get_pu_param(pu_shape: str, intensity_degradation: str, pu_p: float, noise_floor: float, slope: float):\n",
    "    pu_param = None\n",
    "    if pu_shape == 'circle':\n",
    "        if intensity_degradation == \"linear\":\n",
    "            pu_param = Circle(int((pu_p - noise_floor) / slope)) # linear\n",
    "        elif intensity_degradation == \"log\":\n",
    "            pu_param = Circle(int(10 ** ((pu_p - noise_floor) / (10 *slope)))) # log_based\n",
    "    elif pu_shape == 'square':\n",
    "        if intensity_degradation == \"linear\":\n",
    "            pu_param = Square(int(2 ** 0.5 * (pu_p - noise_floor) / slope)) # linear\n",
    "        elif intensity_degradation == \"log\":\n",
    "            pu_param = Square(int(2 ** 0.5 * 10 ** ((pu_p - noise_floor) / (10 *slope)))) # log_based\n",
    "    elif pu_shape == 'point':\n",
    "        pu_param = None\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported PU shape(create_image)! \", pu_shape)\n",
    "    return pu_param\n",
    "\n",
    "def create_image(data, slope, sensors_num, style=\"raw_power_z_score\", noise_floor=-90, pu_shape= 'circle', pu_param=None, \n",
    "                 su_shape='circle', su_param=None, intensity_degradation=\"log\", max_pu_power: float=0):  \n",
    "    # style = {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "    # intensity_degradation= {\"log\", \"linear\"}\n",
    "    # if param is None, it's automatically calculated. Highest brightness(or power value) (255 or 1.) would\n",
    "    # assigned to the center(PU location) and radius(side) would be calculated based on its power, slope, and noise floor.\n",
    "    # If it is given, intensity(power) of pixel beside center would be calculated in the same fashin with an exception that \n",
    "    # intensity below zero(noise_floor) would be replaced by zero(noise_floor)\n",
    "    if style == \"raw_power_min_max_norm\":\n",
    "        # In this way, PUs' location are replaced with their power(dBm) and the power would fade with \n",
    "        # slope till gets noise_floor(in circle shape)\n",
    "        \n",
    "        # creating pu matrix\n",
    "        image = np.zeros((1,number_image_channels,max_x, max_y), dtype=float_memory_used)\n",
    "        if not sensors:\n",
    "            pus_num = int(data[0])\n",
    "#             print(pus_num)\n",
    "            for pu_i in range(pus_num):\n",
    "                pu_x = max(0, min(max_x-1, int(data[pu_i * 3 + 1]))) \n",
    "                pu_y = max(0, min(max_x-1, int(data[pu_i * 3 + 2])))\n",
    "                pu_p = data[pu_i * 3 + 3]\n",
    "#                 print(pu_x, pu_y, pu_p)\n",
    "                if pu_param is None:\n",
    "                    pu_param_p = get_pu_param(pu_shape, intensity_degradation, pu_p, noise_floor, slope)\n",
    "                else:\n",
    "                    pu_param_p = pu_param\n",
    "                points = points_inside_shape(center=Point(pu_x, pu_y), shape=pu_shape, param=pu_param_p)\n",
    "                for point in points:\n",
    "                    if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                        if intensity_degradation == \"linear\":\n",
    "                            image[0][int(abs(pu_p))//5][point.p.x][point.p.y] += (pu_p - slope * point.dist - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                        elif intensity_degradation == \"log\":\n",
    "                            if point.dist < 1:\n",
    "                                image[0][int(abs(pu_p))//5][point.p.x][point.p.y] += (pu_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                            else:\n",
    "                                image[0][int(abs(pu_p))//5][point.p.x][point.p.y] += (pu_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                    max_pu_power - noise_floor)\n",
    "        else:\n",
    "            ss_param, ss_shape = pu_param, pu_shape\n",
    "            for ss_i in range(sensors_num):\n",
    "                ss_x, ss_y, ss_p = max(0, min(max_x-1, int(sensors_location[ss_i].x))), max(0, min(max_x-1, int(\n",
    "                    sensors_location[ss_i].y))), max(noise_floor, data[ss_i])\n",
    "                ss_channel = 0 \n",
    "                if -62.5 <= ss_p < -50.0:\n",
    "                    ss_channel = 1\n",
    "                elif -75.0 <= ss_p < -62.6:\n",
    "                    ss_channel = 2\n",
    "                elif -87.5 <= ss_p < -75.0:\n",
    "                    ss_channel = 3\n",
    "                elif -100.0 <= ss_p < -87.5:\n",
    "                    ss_channel = 4\n",
    "#                 elif -70.0 <= ss_p < -65.0:\n",
    "#                     ss_channel = 5\n",
    "                elif ss_p < -100.0:\n",
    "                    ss_channel = 5\n",
    "                if ss_param is None:\n",
    "                    ss_param_p = get_pu_param(ss_shape, intensity_degradation, ss_p, noise_floor, slope)\n",
    "                else:\n",
    "                    ss_param_p = ss_param\n",
    "                points = points_inside_shape(center=Point(ss_x, ss_y), shape=ss_shape, param=ss_param_p)\n",
    "                for point in points:\n",
    "                    if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                        if intensity_degradation == \"linear\":\n",
    "                            image[0][ss_channel][point.p.x][point.p.y] += (ss_p - slope * point.dist - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                        elif intensity_degradation == \"log\":\n",
    "                            if point.dist < 1:\n",
    "                                image[0][ss_channel][point.p.x][point.p.y] += (ss_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                            else:\n",
    "                                image[0][ss_channel][point.p.x][point.p.y] += (ss_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                    max_pu_power - noise_floor)\n",
    "        del points\n",
    "        # creating su matrix\n",
    "        su_num_idx = sensors_num if sensors else (pus_num * 3 + 1)\n",
    "        su_num = int(data[su_num_idx])\n",
    "#         print(su_num)\n",
    "#         su_num = (len(data) - pus_num * (3 if not sensors else 1)) // 2\n",
    "#         if not (len(data) - pus_num * (3 if not sensors else 1)) % 2:\n",
    "#             raise ValueError(\"Data provided is not correct; can't get SUs' information(create_image)\")\n",
    "        if su_param is None:\n",
    "            # if su_param is unavailable, a circle(square) with radius(side) 1 is created\n",
    "            if su_shape == 'circle':\n",
    "                su_param = Circle(1)\n",
    "            elif su_shape == 'square':\n",
    "                su_param = Square(1)\n",
    "            elif su_shape == 'point':\n",
    "                su_param = None\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported SU shape(create_image)! \", su_shape)\n",
    "        \n",
    "        for su_i in range(su_num - 1):\n",
    "            su_x = max(0, min(max_x-1, int(data[su_num_idx + su_i * 3 + 1])))\n",
    "            su_y = max(0, min(max_x-1, int(data[su_num_idx + su_i * 3 + 2])))\n",
    "            su_p = data[su_num_idx + su_i * 3 + 3]\n",
    "#             su_p = su_intensity\n",
    "            points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "            su_channel = 0 if number_image_channels == 1 else -1\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if intensity_degradation == \"linear\":\n",
    "                            su_val = (su_p - slope * point.dist - noise_floor)/(max_pu_power - noise_floor)\n",
    "                    elif intensity_degradation == \"log\":\n",
    "                        if point.dist < 1:\n",
    "                            su_val = (su_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                        else:\n",
    "                            su_val = (su_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                    image[0][su_channel][point.p.x][point.p.y] += su_val\n",
    "            del points\n",
    "        # the last and  target SU\n",
    "        su_intensity = 1.\n",
    "        su_x = max(0, min(max_x-1, int(data[su_num_idx + (su_num - 1) * 3 + 1])))\n",
    "        su_y = max(0, min(max_x-1, int(data[su_num_idx + (su_num - 1) * 3 + 2])))\n",
    "#         print(su_x, su_y)\n",
    "        points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "        su_channel = 0 if number_image_channels == 1 else -1\n",
    "        for point in points:\n",
    "            if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                image[0][su_channel][point.p.x][point.p.y] += su_intensity\n",
    "        del points\n",
    "        return image\n",
    "        \n",
    "#         pu_image = [[(noise_floor - mu)/sigma] * max_y for _ in range(max_x)]\n",
    "    elif style == \"image_intensity\":\n",
    "        # creating PU image\n",
    "        image = np.zeros((1,number_image_channels,max_x, max_y), dtype=float_memory_used)\n",
    "        for pu_i in range(pus_num):\n",
    "            pu_x, pu_y, pu_p = max(0, min(max_x-1, int(data[pu_i*3]))), max(0, min(max_x-1, int(data[pu_i*3+1]))), data[pu_i*3+2]\n",
    "            if pu_param is None:\n",
    "                pu_param_p = get_pu_param(pu_shape, intensity_degradation, pu_p, noise_floor, slope)\n",
    "            else:\n",
    "                pu_param_p = pu_param\n",
    "            points = points_inside_shape(center=Point(pu_x, pu_y), shape=pu_shape, param=pu_param_p)\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if intensity_degradation == \"linear\":\n",
    "                        image[0][0][point.p.x][point.p.y] += max((pu_p - slope * point.dist + abs(noise_floor))\n",
    "                                                              /(pu_p + abs(noise_floor)), 0)\n",
    "                    elif intensity_degradation == \"log\":\n",
    "                        if point.dist < 1:\n",
    "                            image[0][0][point.p.x][point.p.y] = 1\n",
    "                        else:\n",
    "                            image[0][0][point.p.x][point.p.y] += max((pu_p - slope * 10*math.log10(point.dist) + abs(noise_floor))\n",
    "                                                                 /(pu_p + abs(noise_floor)), 0)\n",
    "                    image[0][0][point.p.x][point.p.y] = min(image[0][0][point.p.x][point.p.y], 1.0)\n",
    "                        \n",
    "        # creating SU image\n",
    "        su_num = (len(data) - pus_num * 3) // 2\n",
    "        if not (len(data) - pus_num * 3) % 2:\n",
    "            raise ValueError(\"Data provided is not correct; can't get SUs' information(create_image)\")\n",
    "#         su_image = np.zeros((max_x, max_y), dtype=float_memory_used)\n",
    "        if su_param is None:\n",
    "            # if su_param is unavailable, a circle(square) with radius(side) 1 is created\n",
    "            if su_shape == 'circle':\n",
    "                su_param = Circle(1)\n",
    "            elif su_shape == 'square':\n",
    "                su_param = Square(1)\n",
    "            elif su_shape == 'point':\n",
    "                su_param = None\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported SU shape(create_image)! \", su_shape)\n",
    "        su_intensity = 1.\n",
    "        for su_i in range(su_num):\n",
    "            su_x, su_y, su_p = max(0, min(max_x-1, int(data[pus_num * (3 if not sensors else 1) +su_i*2]))\n",
    "                                  ), max(0, min(max_x-1, int(data[pus_num * (3 if not sensors else 1) + su_i*2+1]))), su_intensity\n",
    "            points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if number_image_channels > 1:\n",
    "                        image[0][1][point.p.x][point.p.y] = su_intensity\n",
    "                    elif number_image_channels == 1:\n",
    "                        image[0][0][point.p.x][point.p.y] = su_intensity\n",
    "#         return np.array([pu_image, su_image, [[0.] * max_y for _ in range(max_x)]], dtype='float32') # return like this to be able to display as an RGB image with pyplot.imshow(imsave)\n",
    "#         return np.append(pu_image, su_image, axis=0)\n",
    "        return image\n",
    "        \n",
    "            \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported style(create_image)! \", style)\n",
    "        \n",
    "def points_inside_shape(center: Point, shape: str, param)-> list:\n",
    "    # This function returns points+distance around center with defined shape\n",
    "    if shape == 'circle':\n",
    "        # First creates points inside a square(around orgigin) with 2*r side and then remove those with distance > r.\n",
    "        # Shift all remaining around center. O(4r^2)\n",
    "        r, origin = param.r, Point(0, 0)\n",
    "        square_points = set((Point(x, y) for x in range(max(-r, -max_x), min(r, max_x) + 1) \n",
    "                             for y in range(max(-r, -max_y), min(r, max_y) + 1)))\n",
    "        points = []\n",
    "        while square_points:\n",
    "            p = square_points.pop()\n",
    "            dist = euclidian_distance(p, origin)\n",
    "            if dist <= r:\n",
    "                points.append(PointWithDistance(Point(p.x + center.x, p.y + center.y), dist))\n",
    "                if p.x != 0:\n",
    "                    points.append(PointWithDistance(Point(-p.x + center.x, p.y + center.y), dist))\n",
    "                    square_points.remove(Point(-p.x, p.y))\n",
    "                if p.y != 0:\n",
    "                    points.append(PointWithDistance(Point(p.x + center.x, -p.y + center.y), dist))\n",
    "                    square_points.remove(Point(p.x, -p.y))\n",
    "                if p.x != 0 and p.y != 0:\n",
    "                    points.append(PointWithDistance(Point(-p.x + center.x, -p.y + center.y), dist))\n",
    "                    square_points.remove(Point(-p.x, -p.y))\n",
    "        del square_points\n",
    "        return points\n",
    "    elif shape == 'square':\n",
    "        half_side = param.side // 2\n",
    "        return [PointWithDistance(Point(x, y), euclidian_distance(Point(x, y), center)) for x in range(-half_side + center.x,\n",
    "                                                                                               half_side + center.x+1) \n",
    "                         for y in range(-half_side + center.y, half_side + center.y + 1)]\n",
    "    elif shape == 'point':\n",
    "        return [PointWithDistance(center, 0)]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported shape(points_inside_shape)! \", shape)\n",
    "        \n",
    "def read_image(image_num):\n",
    "    if style == \"image_intensity\":\n",
    "        image = plt.imread(image_dir + '/image' + str(image_num)+'.png')\n",
    "        image = np.swapaxes(image, 0, 2)\n",
    "        image = np.array(image[:number_image_channels], dtype=float_memory_used).reshape(1, number_image_channels, max_x, max_y)\n",
    "    elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "        suffix = 'npz'  # npy, npz\n",
    "        image = np.load(image_dir + '/image' + str(image_num) + '.' + suffix)  \n",
    "        if type(image) == np.lib.npyio.NpzFile:\n",
    "            image = image['a']\n",
    "    \n",
    "    return image\n",
    "    \n",
    "# TODO: Consider using min_max normalization becasue difference between values using\n",
    "# z-score is huge since most of the pixels have the same value, noise floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 0.000e+00, 2.000e+00, 2.000e+00, 2.000e+00, 2.000e+00,\n",
       "        4.000e+00, 2.000e+00, 4.000e+00, 1.100e+01, 1.200e+01, 1.000e+01,\n",
       "        1.100e+01, 2.100e+01, 2.900e+01, 2.600e+01, 3.500e+01, 5.000e+01,\n",
       "        5.600e+01, 6.100e+01, 5.900e+01, 8.000e+01, 8.900e+01, 8.700e+01,\n",
       "        1.100e+02, 1.040e+02, 1.230e+02, 1.310e+02, 1.300e+02, 1.520e+02,\n",
       "        1.640e+02, 1.520e+02, 1.530e+02, 1.450e+02, 1.480e+02, 1.580e+02,\n",
       "        1.710e+02, 1.910e+02, 1.820e+02, 1.960e+02, 2.220e+02, 2.590e+02,\n",
       "        3.030e+02, 3.360e+02, 3.790e+02, 3.740e+02, 4.740e+02, 5.290e+02,\n",
       "        5.290e+02, 5.360e+02, 6.420e+02, 5.880e+02, 7.400e+02, 7.520e+02,\n",
       "        8.070e+02, 9.160e+02, 9.610e+02, 1.071e+03, 1.111e+03, 1.251e+03,\n",
       "        1.273e+03, 1.338e+03, 1.360e+03, 1.382e+03, 1.398e+03, 1.435e+03,\n",
       "        1.459e+03, 1.497e+03, 1.504e+03, 1.532e+03, 1.491e+03, 1.478e+03,\n",
       "        1.392e+03, 1.283e+03, 1.194e+03, 1.172e+03, 1.048e+03, 9.430e+02,\n",
       "        8.290e+02, 8.210e+02, 7.300e+02, 6.580e+02, 5.710e+02, 4.880e+02,\n",
       "        4.860e+02, 3.710e+02, 4.140e+02, 3.900e+02, 3.280e+02, 2.680e+02,\n",
       "        2.510e+02, 2.350e+02, 2.010e+02, 2.080e+02, 2.240e+02, 2.500e+02,\n",
       "        1.930e+02, 1.700e+02, 1.160e+02, 8.900e+01, 5.500e+01, 4.300e+01,\n",
       "        2.400e+01, 3.600e+01, 9.000e+01, 8.900e+01, 7.200e+01, 4.600e+01,\n",
       "        1.600e+01, 1.400e+01, 6.000e+00, 2.300e+01, 2.500e+01, 1.200e+01,\n",
       "        9.000e+00, 5.000e+00, 2.000e+00, 1.000e+00, 5.400e+01, 5.600e+01,\n",
       "        6.400e+01, 1.430e+02, 1.870e+02, 4.700e+01, 1.900e+01, 1.100e+01,\n",
       "        6.000e+00, 9.600e+01, 4.400e+01, 5.600e+01, 3.000e+01, 5.100e+01,\n",
       "        5.000e+00, 3.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "        0.000e+00, 1.000e+00, 0.000e+00, 2.000e+00, 1.000e+00, 0.000e+00,\n",
       "        2.000e+00, 7.400e+01, 3.000e+00, 0.000e+00, 0.000e+00, 7.800e+01,\n",
       "        1.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        3.500e+01, 4.100e+01, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([-80.082     , -79.83995783, -79.59791566, -79.35587349,\n",
       "        -79.11383133, -78.87178916, -78.62974699, -78.38770482,\n",
       "        -78.14566265, -77.90362048, -77.66157831, -77.41953614,\n",
       "        -77.17749398, -76.93545181, -76.69340964, -76.45136747,\n",
       "        -76.2093253 , -75.96728313, -75.72524096, -75.4831988 ,\n",
       "        -75.24115663, -74.99911446, -74.75707229, -74.51503012,\n",
       "        -74.27298795, -74.03094578, -73.78890361, -73.54686145,\n",
       "        -73.30481928, -73.06277711, -72.82073494, -72.57869277,\n",
       "        -72.3366506 , -72.09460843, -71.85256627, -71.6105241 ,\n",
       "        -71.36848193, -71.12643976, -70.88439759, -70.64235542,\n",
       "        -70.40031325, -70.15827108, -69.91622892, -69.67418675,\n",
       "        -69.43214458, -69.19010241, -68.94806024, -68.70601807,\n",
       "        -68.4639759 , -68.22193373, -67.97989157, -67.7378494 ,\n",
       "        -67.49580723, -67.25376506, -67.01172289, -66.76968072,\n",
       "        -66.52763855, -66.28559639, -66.04355422, -65.80151205,\n",
       "        -65.55946988, -65.31742771, -65.07538554, -64.83334337,\n",
       "        -64.5913012 , -64.34925904, -64.10721687, -63.8651747 ,\n",
       "        -63.62313253, -63.38109036, -63.13904819, -62.89700602,\n",
       "        -62.65496386, -62.41292169, -62.17087952, -61.92883735,\n",
       "        -61.68679518, -61.44475301, -61.20271084, -60.96066867,\n",
       "        -60.71862651, -60.47658434, -60.23454217, -59.9925    ,\n",
       "        -59.75045783, -59.50841566, -59.26637349, -59.02433133,\n",
       "        -58.78228916, -58.54024699, -58.29820482, -58.05616265,\n",
       "        -57.81412048, -57.57207831, -57.33003614, -57.08799398,\n",
       "        -56.84595181, -56.60390964, -56.36186747, -56.1198253 ,\n",
       "        -55.87778313, -55.63574096, -55.3936988 , -55.15165663,\n",
       "        -54.90961446, -54.66757229, -54.42553012, -54.18348795,\n",
       "        -53.94144578, -53.69940361, -53.45736145, -53.21531928,\n",
       "        -52.97327711, -52.73123494, -52.48919277, -52.2471506 ,\n",
       "        -52.00510843, -51.76306627, -51.5210241 , -51.27898193,\n",
       "        -51.03693976, -50.79489759, -50.55285542, -50.31081325,\n",
       "        -50.06877108, -49.82672892, -49.58468675, -49.34264458,\n",
       "        -49.10060241, -48.85856024, -48.61651807, -48.3744759 ,\n",
       "        -48.13243373, -47.89039157, -47.6483494 , -47.40630723,\n",
       "        -47.16426506, -46.92222289, -46.68018072, -46.43813855,\n",
       "        -46.19609639, -45.95405422, -45.71201205, -45.46996988,\n",
       "        -45.22792771, -44.98588554, -44.74384337, -44.5018012 ,\n",
       "        -44.25975904, -44.01771687, -43.7756747 , -43.53363253,\n",
       "        -43.29159036, -43.04954819, -42.80750602, -42.56546386,\n",
       "        -42.32342169, -42.08137952, -41.83933735, -41.59729518,\n",
       "        -41.35525301, -41.11321084, -40.87116867, -40.62912651,\n",
       "        -40.38708434, -40.14504217, -39.903     ]),\n",
       " <a list of 166 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data_reg[:,0:1:sensors_num], bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving images once to save time\n",
    "# run this cell just for creating images\n",
    "def creating_image(start, end):\n",
    "    # for image_num in range(115, data_reg.shape[0]):\n",
    "    # for image_num in range(1625, 5000):\n",
    "    for image_num in tqdm.tqdm(range(start, end+1)):  #4463, data_reg.shape[0]\n",
    "        image = create_image(data=data_reg[image_num], slope=slope, style=style, \n",
    "                             noise_floor=noise_floor,\n",
    "                             pu_shape=pu_shape, su_shape=su_shape, su_param=su_param, \n",
    "                             sensors_num=(sensors_num if sensors else 0), \n",
    "                             intensity_degradation=intensity_degradation, \n",
    "                             max_pu_power=-50.0)\n",
    "        if style == \"image_intensity\":\n",
    "            if number_image_channels != 3:\n",
    "                image = np.append(np.array(image[0]), np.zeros((3-number_image_channels,max_x, max_y), \n",
    "                                                               dtype=float_memory_used), axis=0)\n",
    "            image_save = np.swapaxes(image, 0, 2)\n",
    "            plt.imsave(image_dir + '/image' + str(image_num)+'.png', image_save)\n",
    "        elif style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "    #         np.save(image_dir + '/image' + str(image_num), image)\n",
    "            np.savez_compressed(image_dir + '/image' + str(image_num), a=image)\n",
    "        del image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [17:03<00:00,  4.88it/s]\n",
      "100%|██████████| 5000/5000 [17:08<00:00,  4.86it/s]\n",
      " 99%|█████████▉| 4974/5000 [17:09<00:05,  4.90it/s]\n",
      "100%|██████████| 5000/5000 [17:13<00:00,  4.84it/s]\n",
      "100%|██████████| 5000/5000 [17:13<00:00,  4.84it/s]\n",
      "100%|██████████| 5000/5000 [17:13<00:00,  4.84it/s]\n",
      "100%|██████████| 5000/5000 [17:13<00:00,  4.84it/s]\n",
      "100%|██████████| 5000/5000 [17:13<00:00,  4.84it/s]\n",
      "100%|██████████| 5000/5000 [17:14<00:00,  4.83it/s]\n",
      "100%|██████████| 5000/5000 [17:15<00:00,  4.83it/s]\n"
     ]
    }
   ],
   "source": [
    "jobs = []\n",
    "proc_sizes = [data_reg.shape[0]//number_of_proccessors] * (number_of_proccessors)\n",
    "proc_sizes[-1] += data_reg.shape[0]%number_of_proccessors\n",
    "proc_idx = [(sum(proc_sizes[:i]), sum(proc_sizes[:i+1])-1) for i in range(number_of_proccessors)]\n",
    "\n",
    "for i in range(number_of_proccessors):\n",
    "    p = Process(target=creating_image, args=(proc_idx[i][0], proc_idx[i][1]))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "for i in range(number_of_proccessors):\n",
    "    jobs[i].join()\n",
    "\n",
    "for i in range(number_of_proccessors):\n",
    "    jobs[i].terminate()\n",
    "    jobs[i].close()\n",
    "del jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, point in enumerate(sensors_location):\n",
    "    print(idx+1, point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, point in enumerate(sensors_location):\n",
    "    print(idx+1, point,\"close\") if math.sqrt((point.x-917)**2+(point.y-415)**2)<=1.5 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [0, 0, 0, 0]\n",
    "idxx = [[],[],[],[]]\n",
    "for i in range(data_reg.shape[0]):\n",
    "    pus_c = int(data_reg[i][0]) * 3 + 1\n",
    "    idx = int(data_reg[i][pus_c]) - 1\n",
    "    count[idx] += 1\n",
    "    idxx[idx].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(count)\n",
    "print(idxx[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm = read_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8868f8f41dfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'imm' is not defined"
     ]
    }
   ],
   "source": [
    "imm[300].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg[:,-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-69.964, -68.283, -71.047, -68.401, -68.794, -72.977, -70.665,\n",
       "       -67.974, -67.816, -70.051, -72.124, -70.887, -70.706, -69.345,\n",
       "       -66.843, -70.199, -78.215, -70.364, -68.533, -69.694, -78.479,\n",
       "       -79.441, -68.444, -70.45 , -69.817, -60.657, -68.349, -69.696,\n",
       "       -60.333, -70.026, -73.027, -70.18 , -68.468, -67.416, -70.342,\n",
       "       -69.063, -71.598, -69.001, -71.366, -70.186, -65.537, -72.317,\n",
       "       -71.013, -70.976, -71.618, -67.04 , -68.345, -60.672, -68.724,\n",
       "         1.   ,  67.   ,   7.   ,  46.545,   0.   ,   5.27 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fae5b2c7590>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 4320x4320 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(60,60))         # Sample figsize in inches\n",
    "sns.heatmap(imm[0][-1], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(num_filters, kernel_lam, bias_lam):\n",
    "#     num_filters, lam = 5, 5\n",
    "    data_format = 'channels_first'\n",
    "    convolution_init, dense_init = \"lecun_normal\", \"RandomNormal\"\n",
    "    convolution_filter, dense_filter = 'selu', 'linear' #softsign, sigmoid; relu, linear\n",
    "    filter_shape, pool_size = (3, 3), (2,2)\n",
    "    cnn = models.Sequential()\n",
    "    cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size=pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(2*num_filters, filter_shape,padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size=pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(2*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "#                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                          kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "# from here for 1000\n",
    "    if max(max_x, max_y) == 1000:\n",
    "        cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                             kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                             kernel_initializer=convolution_init))\n",
    "    #     cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "    #                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "    #                          kernel_initializer='lecun_normal'))\n",
    "        cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "        cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Dropout(0.25))\n",
    "\n",
    "        cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                             kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam), \n",
    "                             kernel_initializer=convolution_init))\n",
    "    #     cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Conv2D(2*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "    #                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "    #                          kernel_initializer='lecun_normal'))\n",
    "        cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "        cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Dropout(0.25))\n",
    "\n",
    "        cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                             kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam), \n",
    "                             kernel_initializer=convolution_init))\n",
    "    #     cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "    #                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "    #                          kernel_initializer='lecun_normal'))\n",
    "        cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "        cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Flatten())\n",
    "    cnn.add(layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=convolution_init))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization())\n",
    "    cnn.add(layers.Dense(1, activation=dense_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=dense_init))\n",
    "    return cnn\n",
    "\n",
    "\n",
    "class DataBatchGenerator(Sequence):\n",
    "    def __init__(self, dataset:np.ndarray, batch_size:int, start_idx:int,\n",
    "                 number_image_channels:int,\n",
    "                 max_x, max_y, float_memory_used, conserve=0):\n",
    "#         print(dataset.shape[0])\n",
    "        self.dataset, self.batch_size, self.start_idx = dataset, batch_size, start_idx\n",
    "        self.number_image_channels, self.max_x, self.max_y = number_image_channels, max_x, max_y\n",
    "        self.float_memory_used = float_memory_used\n",
    "        self.conserve = conserve\n",
    "    \n",
    "    def __len__(self):\n",
    "        return np.ceil(self.dataset.shape[0] / self.batch_size).astype(np.int)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        size = min(self.dataset.shape[0] - idx * self.batch_size, self.batch_size)\n",
    "        batch_x = np.empty((size, self.number_image_channels, self.max_x, self.max_y), dtype=self.float_memory_used)\n",
    "        batch_y = np.empty((size), dtype=self.float_memory_used)\n",
    "        for i in range(size):\n",
    "            batch_x[i] = read_image(self.start_idx + idx * self.batch_size + i)\n",
    "            batch_y[i] = self.dataset[idx * self.batch_size + i][- 1 - self.conserve]\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "def custom_loss(fp_penalty_coef, fn_penalty_coef):\n",
    "    # custom loss function that penalize false positive and negative differently\n",
    "    def loss(y_true, y_pred):\n",
    "        res = y_pred - y_true\n",
    "        res = tf.where(res > 0, res * fp_penalty_coef, res * fn_penalty_coef)\n",
    "        return K.mean(K.square(res))\n",
    "    return loss\n",
    "\n",
    "def fp_mae(y_true, y_pred):\n",
    "    # custom metric that replace false negative with zero and return the mean of new vector\n",
    "    res = y_pred - y_true\n",
    "    res = tf.nn.relu(res)\n",
    "#     res = tf.where(res <= 0, 0, res)\n",
    "    return K.mean(res)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(10, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 10, 100, 100)      640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 50, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 10, 50, 50)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 50, 50)        1820      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, 25, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20, 25, 25)        80        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 25, 25)        5430      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 12, 12)        120       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 40, 12, 12)        10840     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 40, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 40, 6, 6)          160       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                28820     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 48,471\n",
      "Trainable params: 48,231\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_samples: 8192 , New samples: 8192\n",
      "Validation size: 2704 , starts: 8192 , ends: 10895\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 26.67856, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00002: val_mae improved from 26.67856 to 25.88350, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00003: val_mae improved from 25.88350 to 24.58063, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00004: val_mae improved from 24.58063 to 24.39501, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00005: val_mae improved from 24.39501 to 21.50678, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00006: val_mae improved from 21.50678 to 16.88744, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00007: val_mae improved from 16.88744 to 13.91781, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 13.91781 to 10.11935, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 10.11935 to 7.31125, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 7.31125 to 6.27242, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 6.27242\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 6.27242\n",
      "\n",
      "Epoch 00013: val_mae improved from 6.27242 to 5.83416, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 5.83416\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 5.83416\n",
      "\n",
      "Epoch 00016: val_mae improved from 5.83416 to 5.78422, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 5.78422\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 5.78422\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 5.78422\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 5.78422\n",
      "\n",
      "Epoch 00021: val_mae improved from 5.78422 to 5.62770, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 5.62770 to 5.62363, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00032: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 5.62363\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 5.62363\n",
      "\n",
      "Lambda: 0.001 , Time: 0:08:39\n",
      "Train Error(all epochs): 2.7698028087615967 \n",
      " [26.956, 26.488, 25.546, 23.729, 20.778, 16.963, 13.07, 9.615, 7.199, 5.99, 5.495, 5.346, 5.218, 5.128, 5.058, 5.057, 4.938, 4.897, 4.904, 4.82, 4.772, 4.685, 4.664, 4.564, 4.592, 4.467, 4.399, 4.362, 4.228, 4.186, 4.09, 4.02, 3.967, 4.032, 3.835, 3.707, 3.648, 3.589, 3.507, 3.427, 3.454, 3.341, 3.218, 3.11, 3.083, 3.098, 3.075, 2.99, 2.919, 2.77]\n",
      "Train FP Error(all epochs): 0.036908917129039764 \n",
      " [0.037, 0.039, 0.043, 0.055, 0.085, 0.175, 0.381, 0.714, 1.183, 1.702, 2.057, 2.255, 2.319, 2.326, 2.405, 2.394, 2.372, 2.334, 2.372, 2.311, 2.314, 2.229, 2.264, 2.207, 2.251, 2.13, 2.152, 2.159, 2.048, 2.042, 1.989, 1.97, 1.896, 2.019, 1.866, 1.798, 1.779, 1.786, 1.708, 1.693, 1.708, 1.648, 1.575, 1.523, 1.502, 1.532, 1.544, 1.454, 1.436, 1.349]\n",
      "Val Error(all epochs): 5.62363338470459 \n",
      " [26.679, 25.884, 24.581, 24.395, 21.507, 16.887, 13.918, 10.119, 7.311, 6.272, 6.353, 6.744, 5.834, 6.244, 6.015, 5.784, 5.881, 7.019, 5.79, 6.34, 5.628, 5.624, 7.962, 6.622, 6.471, 7.724, 6.151, 6.753, 6.156, 6.165, 6.439, 6.408, 6.171, 6.351, 6.32, 6.605, 6.501, 7.45, 6.64, 6.489, 6.95, 7.195, 6.585, 6.817, 6.625, 6.607, 6.43, 7.52, 6.66, 6.875]\n",
      "Val FP Error(all epochs): 0.0346452035009861 \n",
      " [0.035, 0.038, 0.043, 0.043, 0.071, 0.198, 0.364, 0.726, 1.303, 1.693, 1.716, 1.426, 3.101, 1.665, 2.704, 3.238, 1.891, 1.409, 3.462, 1.779, 3.327, 2.25, 6.274, 4.804, 3.689, 5.524, 2.31, 1.992, 2.248, 2.48, 2.939, 2.612, 3.582, 2.646, 2.943, 3.501, 3.804, 1.811, 4.526, 4.212, 2.866, 2.088, 2.673, 2.603, 4.167, 2.994, 3.289, 2.765, 4.021, 3.626]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 26.52279, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00002: val_mae improved from 26.52279 to 25.87799, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00003: val_mae improved from 25.87799 to 23.06488, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00004: val_mae improved from 23.06488 to 19.49931, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00005: val_mae improved from 19.49931 to 16.28680, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00006: val_mae improved from 16.28680 to 10.83994, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00007: val_mae improved from 10.83994 to 9.96607, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 9.96607\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 9.96607\n",
      "\n",
      "Epoch 00010: val_mae improved from 9.96607 to 8.49378, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_mae did not improve from 8.49378\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 8.49378\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 8.49378\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 8.49378\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 8.49378\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 8.49378\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 8.49378\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 8.49378\n",
      "\n",
      "Epoch 00019: val_mae improved from 8.49378 to 7.45179, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 7.45179\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 7.45179\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 7.45179\n",
      "\n",
      "Epoch 00023: val_mae improved from 7.45179 to 7.11438, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 7.11438\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 7.11438\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 7.11438\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 7.11438\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 7.11438\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 7.11438\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 7.11438\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 7.11438\n",
      "\n",
      "Epoch 00032: val_mae improved from 7.11438 to 6.86776, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 6.86776\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 6.86776\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 6.86776\n",
      "\n",
      "Epoch 00036: val_mae improved from 6.86776 to 6.44693, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 6.44693\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 6.44693\n",
      "\n",
      "Epoch 00039: val_mae improved from 6.44693 to 6.21156, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 6.21156\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 6.21156\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 6.21156\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 6.21156\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 6.21156\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 6.21156\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 6.21156\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 6.21156\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 6.21156\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 6.21156\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 6.21156\n",
      "\n",
      "Lambda: 0.01 , Time: 0:08:38\n",
      "Train Error(all epochs): 2.4971182346343994 \n",
      " [26.85, 26.183, 24.723, 22.11, 18.423, 14.213, 10.242, 7.44, 5.996, 5.505, 5.348, 5.286, 5.233, 5.207, 5.099, 5.047, 5.012, 4.967, 4.881, 4.8, 4.706, 4.732, 4.58, 4.446, 4.352, 4.27, 4.279, 4.17, 4.077, 4.005, 3.934, 3.697, 3.676, 3.504, 3.442, 3.307, 3.229, 3.156, 3.107, 3.066, 2.986, 2.999, 2.928, 2.862, 2.718, 2.717, 2.675, 2.581, 2.561, 2.497]\n",
      "Train FP Error(all epochs): 0.03830251097679138 \n",
      " [0.038, 0.041, 0.051, 0.076, 0.143, 0.34, 0.678, 1.174, 1.74, 2.124, 2.376, 2.46, 2.429, 2.478, 2.415, 2.411, 2.435, 2.329, 2.318, 2.33, 2.286, 2.252, 2.194, 2.166, 2.088, 2.079, 2.101, 2.013, 1.954, 1.943, 1.904, 1.75, 1.804, 1.687, 1.664, 1.614, 1.579, 1.554, 1.518, 1.495, 1.467, 1.477, 1.451, 1.391, 1.351, 1.327, 1.302, 1.279, 1.266, 1.226]\n",
      "Val Error(all epochs): 6.211560249328613 \n",
      " [26.523, 25.878, 23.065, 19.499, 16.287, 10.84, 9.966, 11.817, 11.409, 8.494, 8.67, 10.583, 12.183, 10.69, 11.088, 11.613, 12.894, 12.932, 7.452, 8.777, 14.659, 9.543, 7.114, 10.408, 10.139, 7.454, 9.204, 11.256, 12.243, 9.311, 8.877, 6.868, 8.897, 7.003, 7.99, 6.447, 7.664, 7.658, 6.212, 6.43, 6.939, 7.426, 6.677, 6.759, 6.703, 7.144, 8.2, 7.06, 7.195, 7.091]\n",
      "Val FP Error(all epochs): 0.03426531329751015 \n",
      " [0.034, 0.037, 0.056, 0.135, 0.294, 1.143, 1.585, 0.618, 0.598, 1.051, 1.056, 0.651, 0.498, 0.637, 0.583, 0.546, 0.426, 0.475, 1.24, 1.052, 0.339, 0.848, 1.504, 0.71, 0.823, 1.756, 1.034, 0.689, 0.633, 1.072, 1.205, 2.292, 1.511, 2.209, 1.645, 3.495, 1.886, 2.063, 3.329, 3.111, 5.133, 3.257, 4.01, 4.357, 2.973, 3.522, 2.17, 4.206, 3.862, 4.205]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 26.41135, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00002: val_mae improved from 26.41135 to 26.28188, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00003: val_mae improved from 26.28188 to 25.29494, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00004: val_mae improved from 25.29494 to 23.73883, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00005: val_mae improved from 23.73883 to 17.29537, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00006: val_mae improved from 17.29537 to 14.50004, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00007: val_mae improved from 14.50004 to 9.82509, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 9.82509 to 7.52837, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 7.52837 to 7.50756, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 7.50756 to 7.35672, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 7.35672\n",
      "\n",
      "Epoch 00012: val_mae improved from 7.35672 to 6.69037, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 6.69037 to 6.67856, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 6.67856 to 6.62853, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 6.62853 to 6.04108, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 6.04108\n",
      "\n",
      "Epoch 00017: val_mae improved from 6.04108 to 5.92432, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 5.92432\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 5.92432\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 5.92432\n",
      "\n",
      "Epoch 00021: val_mae improved from 5.92432 to 5.59944, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 5.59944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00026: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00032: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 5.59944\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 5.59944\n",
      "\n",
      "Lambda: 0.1 , Time: 0:08:40\n",
      "Train Error(all epochs): 3.0676662921905518 \n",
      " [26.858, 26.255, 25.007, 22.743, 18.983, 14.169, 9.89, 7.152, 6.23, 5.889, 5.567, 5.473, 5.422, 5.425, 5.394, 5.305, 5.301, 5.257, 5.208, 5.145, 5.096, 5.061, 4.971, 4.939, 4.846, 4.759, 4.834, 4.748, 4.632, 4.508, 4.472, 4.344, 4.291, 4.157, 4.143, 4.053, 3.94, 3.889, 3.708, 3.64, 3.572, 3.421, 3.439, 3.421, 3.316, 3.26, 3.174, 3.142, 3.09, 3.068]\n",
      "Train FP Error(all epochs): 0.038213104009628296 \n",
      " [0.038, 0.041, 0.047, 0.066, 0.14, 0.358, 0.763, 1.417, 2.065, 2.385, 2.367, 2.481, 2.466, 2.538, 2.424, 2.54, 2.517, 2.537, 2.437, 2.46, 2.439, 2.37, 2.337, 2.335, 2.361, 2.3, 2.292, 2.282, 2.113, 2.185, 2.092, 2.029, 2.052, 1.947, 1.999, 1.96, 1.89, 1.848, 1.759, 1.761, 1.67, 1.661, 1.619, 1.63, 1.591, 1.599, 1.498, 1.572, 1.503, 1.442]\n",
      "Val Error(all epochs): 5.599442958831787 \n",
      " [26.411, 26.282, 25.295, 23.739, 17.295, 14.5, 9.825, 7.528, 7.508, 7.357, 9.702, 6.69, 6.679, 6.629, 6.041, 9.442, 5.924, 10.405, 7.307, 6.249, 5.599, 5.809, 5.857, 5.864, 6.262, 7.628, 7.564, 8.148, 8.942, 8.098, 7.529, 5.807, 6.333, 8.56, 6.209, 6.708, 7.801, 7.124, 7.489, 6.366, 6.49, 6.499, 6.054, 6.42, 6.765, 7.559, 7.042, 8.577, 6.938, 9.314]\n",
      "Val FP Error(all epochs): 0.035186342895030975 \n",
      " [0.035, 0.036, 0.039, 0.047, 0.211, 0.345, 0.864, 2.147, 2.51, 1.151, 0.766, 1.969, 1.381, 3.979, 1.708, 0.833, 2.099, 0.808, 1.258, 1.858, 2.339, 2.205, 3.249, 2.2, 4.099, 3.294, 5.93, 6.563, 6.302, 1.069, 1.228, 2.628, 1.777, 1.01, 3.021, 1.965, 1.477, 1.493, 1.677, 3.795, 2.198, 3.142, 3.858, 4.765, 4.234, 2.39, 2.614, 1.639, 2.695, 1.171]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 26.71228, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00002: val_mae improved from 26.71228 to 26.66008, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 26.66008\n",
      "\n",
      "Epoch 00004: val_mae improved from 26.66008 to 25.84995, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00005: val_mae improved from 25.84995 to 21.21744, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00006: val_mae improved from 21.21744 to 18.25598, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00007: val_mae improved from 18.25598 to 17.09884, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 17.09884 to 13.16801, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 13.16801 to 8.27773, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 8.27773\n",
      "\n",
      "Epoch 00011: val_mae improved from 8.27773 to 6.42561, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 6.42561 to 5.80893, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 5.80893\n",
      "\n",
      "Epoch 00014: val_mae improved from 5.80893 to 5.37866, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 5.37866\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 5.37866\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 5.37866\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 5.37866\n",
      "\n",
      "Epoch 00019: val_mae improved from 5.37866 to 5.13882, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/49sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00032: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 5.13882\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 5.13882\n",
      "\n",
      "Lambda: 1 , Time: 0:08:40\n",
      "Train Error(all epochs): 5.030373573303223 \n",
      " [27.031, 26.682, 25.958, 24.448, 21.761, 18.29, 14.69, 11.445, 8.874, 7.109, 6.142, 5.676, 5.486, 5.425, 5.398, 5.355, 5.324, 5.347, 5.364, 5.34, 5.312, 5.287, 5.293, 5.296, 5.257, 5.292, 5.278, 5.247, 5.206, 5.23, 5.232, 5.241, 5.176, 5.21, 5.21, 5.183, 5.148, 5.163, 5.136, 5.141, 5.125, 5.137, 5.107, 5.095, 5.091, 5.084, 5.067, 5.062, 5.035, 5.03]\n",
      "Train FP Error(all epochs): 0.03693150728940964 \n",
      " [0.037, 0.038, 0.041, 0.05, 0.078, 0.145, 0.298, 0.545, 0.849, 1.222, 1.564, 1.849, 2.067, 2.157, 2.228, 2.207, 2.282, 2.279, 2.272, 2.271, 2.268, 2.301, 2.298, 2.324, 2.303, 2.285, 2.328, 2.306, 2.331, 2.31, 2.315, 2.324, 2.346, 2.36, 2.27, 2.377, 2.323, 2.331, 2.343, 2.335, 2.3, 2.299, 2.364, 2.34, 2.308, 2.349, 2.326, 2.283, 2.369, 2.256]\n",
      "Val Error(all epochs): 5.138820171356201 \n",
      " [26.712, 26.66, 26.771, 25.85, 21.217, 18.256, 17.099, 13.168, 8.278, 8.775, 6.426, 5.809, 6.486, 5.379, 7.037, 5.458, 5.924, 5.477, 5.139, 5.762, 5.289, 5.316, 5.933, 8.31, 5.792, 5.785, 5.494, 5.649, 5.589, 5.448, 6.705, 5.864, 5.341, 5.261, 6.118, 5.742, 5.5, 6.014, 5.43, 6.108, 6.007, 5.383, 7.019, 5.75, 7.153, 5.684, 5.824, 5.887, 5.754, 5.399]\n",
      "Val FP Error(all epochs): 0.0337865948677063 \n",
      " [0.034, 0.034, 0.034, 0.037, 0.067, 0.144, 0.189, 0.426, 1.192, 0.94, 1.772, 2.678, 1.374, 2.184, 5.233, 2.228, 1.637, 3.734, 3.033, 4.153, 2.172, 3.645, 2.409, 7.746, 1.848, 1.794, 2.419, 2.059, 1.966, 2.235, 1.39, 2.274, 2.834, 2.628, 1.803, 1.913, 2.035, 1.814, 2.723, 1.77, 1.721, 2.246, 1.328, 2.036, 1.348, 1.932, 2.768, 2.014, 2.073, 3.109]\n",
      "\n",
      "Trainig set size: 8192 , Time: 0:34:38 , best_lambda: 1 , min_  error: 5.139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test starts:  10896 , ends:  49999\n",
      "153/153 [==============================] - 36s 238ms/step - loss: 92.6248 - mse: 55.6897 - mae: 5.1753 - fp_mae: 2.9425\n",
      "average_error:  5.175 , fp_average_error:  2.942\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CNN: support batching\n",
    "TEST, CONSERVE = True, False\n",
    "mini_batch = 16 if max(max_x, max_y) == 1000 else 256\n",
    "epochs = 35 if max(max_x, max_y) == 1000 else 50\n",
    "MAX_QUEUE_SIZE, WORKERS = 6, 1\n",
    "fp_penalty_coef, fn_penalty_coef = 1, 1\n",
    "hyper_metric, mode = \"val_mae\", 'min'  # the metric that hyper parameters are tuned with\n",
    "prev_sample = 0\n",
    "lambda_vec = [0.001, 0.01, 0.1, 1]  #0.003, 0.01, 0.03, 0.1, 0.3, 1, 3\n",
    "# lambda_vec = [0.01, 0.1, 1]\n",
    "# lambda_vec = [10]\n",
    "# MODEL_PATH = 'models/'\n",
    "average_diff_power, fp_mean_power = [],[] #[7.177, 8.088, 8.183], [3.438, 3.506, 2.662]\n",
    "best_lambda = []\n",
    "average_diff_power_conserve, fp_mean_power_conserve = [], []\n",
    "all_cnns = []\n",
    "if CONSERVE: # for conservative\n",
    "    prev_number_samples = [0] + number_samples[:-1]\n",
    "\n",
    "for num_sample_idx, number_sample in enumerate(number_samples):\n",
    "#     if num_sample_idx < 3:\n",
    "#         continue\n",
    "#     if num_sample_idx == 0:\n",
    "    if CONSERVE:\n",
    "        data_reg[prev_number_samples[num_sample_idx]:number_sample, -1] = data_reg[\n",
    "            prev_number_samples[num_sample_idx]:number_sample, -1] - 1 # conserv value\n",
    "    MODEL_PATH = '/'.join(image_dir.split('/')[:-1]) + '/models/' + str(number_sample)\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.makedirs(MODEL_PATH)\n",
    "    MODEL_PATH += \"/best_model_lambda_\"\n",
    "    if True:\n",
    "        cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "        for cnn in cnns:\n",
    "#             cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae', fp_mean])\n",
    "            cnn.compile(loss=custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                        optimizer='adam', \n",
    "                        metrics=['mse', 'mae', fp_mae])\n",
    "        checkpointers = [ModelCheckpoint(filepath=MODEL_PATH + str(lamb_idx)+ '.h5',\n",
    "                                         verbose=1, save_best_only=True, \n",
    "                                         monitor=hyper_metric,\n",
    "                                         mode=mode)\n",
    "                         for lamb_idx in range(len(lambda_vec))]\n",
    "    else:\n",
    "        cnns = []\n",
    "        cnns = [models.load_model(MODEL_PATH + str(lamb_idx) + '.h5', \n",
    "                                  custom_objects={ 'loss': custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                                                  'fp_mae': fp_mae }) \n",
    "                for lamb_idx in range(len(lambda_vec))]\n",
    "    number_start = time.time()\n",
    "    train_generator = DataBatchGenerator(dataset=data_reg[prev_sample:number_sample], batch_size=mini_batch,\n",
    "                                         start_idx=prev_sample, number_image_channels=number_image_channels,\n",
    "                                         max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "    \n",
    "\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "    val_generator = DataBatchGenerator(dataset=data_reg[number_sample:number_sample+val_size], \n",
    "                                       batch_size=mini_batch,\n",
    "                                       start_idx=number_sample,\n",
    "                                       number_image_channels=number_image_channels,\n",
    "                                       max_x=max_x, max_y=max_y, \n",
    "                                       float_memory_used=float_memory_used)\n",
    "  \n",
    "    print('number_samples:', number_sample, \", New samples:\", number_sample - prev_sample)\n",
    "    print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", number_sample + val_size - 1)\n",
    "    \n",
    "    for lamb_idx, lamb in enumerate(lambda_vec):\n",
    "#     for lamb_idx, lamb in enumerate(lambda_vec[:len(lambda_vec) - num_sample_idx//2]):\n",
    "#         if num_sample_idx == 3 and lamb_idx < 4:\n",
    "#             continue\n",
    "        lambda_start = time.time()\n",
    "        cnns[lamb_idx].fit(train_generator, epochs=epochs, verbose=0,\n",
    "                           validation_data=val_generator, \n",
    "                           shuffle=True, callbacks=[checkpointers[lamb_idx]], \n",
    "                           workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, \n",
    "                           use_multiprocessing=False)\n",
    "        \n",
    "        print(\"\\nLambda:\", lamb, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - lambda_start))))\n",
    "        print(\"Train Error(all epochs):\", min(cnns[lamb_idx].history.history['mae']), '\\n', \n",
    "              [round(val, 3) for val in cnns[lamb_idx].history.history['mae']])\n",
    "        print(\"Train FP Error(all epochs):\", min(cnns[lamb_idx].history.history['fp_mae']), '\\n',\n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['fp_mae']])\n",
    "        print(\"Val Error(all epochs):\", min(cnns[lamb_idx].history.history['val_mae']), '\\n', \n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['val_mae']])\n",
    "        print(\"Val FP Error(all epochs):\", min(cnns[lamb_idx].history.history['val_fp_mae']), '\\n',\n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['val_fp_mae']])\n",
    "#     if num_sample_idx == 3:    \n",
    "#         models_min_mae = [8.27781, 8.23545, 8.20838, 7.74743]\n",
    "#         models_min_mae += [min(cnns[lamb_idx].history.history[hyper_metric]) for lamb_idx in range(4,lamb_idx+1)]\n",
    "#     else:\n",
    "    models_min_mae = [min(cnns[lam_idx].history.history[hyper_metric]) for\n",
    "                      lam_idx,_ in enumerate(lambda_vec)]\n",
    "    best_lamb_idx = models_min_mae.index(min(models_min_mae))\n",
    "    best_lambda.append(lambda_vec[best_lamb_idx])\n",
    "    print(\"\\nTrainig set size:\", number_sample, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - \n",
    "                                                                                              number_start))),\n",
    "          \", best_lambda:\", lambda_vec[best_lamb_idx], \", min_\" , (\"fp_\" if hyper_metric == \"val_fp_mae\" else \"\"),\n",
    "          \"error:\", round(min(models_min_mae), 3))\n",
    "    all_cnns.append(cnns)\n",
    "    del cnns, train_generator, val_generator, checkpointers\n",
    "    \n",
    "    if TEST:\n",
    "        # evaluating test images\n",
    "        best_model = None\n",
    "        best_model = models.load_model(MODEL_PATH + str(best_lamb_idx) + '.h5', \n",
    "                                       custom_objects={ 'loss': custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                                                       'fp_mae': fp_mae,\n",
    "                                                      'mae':'mae', 'mse':'mse'})\n",
    "        test_generator = DataBatchGenerator(dataset=data_reg[number_sample + val_size:], \n",
    "                                            batch_size=mini_batch,\n",
    "                                            start_idx=number_sample + val_size, \n",
    "                                            number_image_channels=number_image_channels,\n",
    "                                            max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "\n",
    "        print(\"Test starts: \", number_sample + val_size, \", ends: \", data_reg.shape[0] - 1)\n",
    "        time.sleep(1)\n",
    "        test_res = best_model.evaluate(test_generator, verbose=1, \n",
    "                                       workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, use_multiprocessing=False)\n",
    "        \n",
    "        test_mae_idx, test_fp_mae_idx = [best_model.metrics_names.index(mtrc) \n",
    "                                         for mtrc in ['mae','fp_mae']]\n",
    "        test_mae, test_fp_mae = test_res[test_mae_idx], test_res[test_fp_mae_idx]\n",
    "        average_diff_power.append(round(test_mae, 3))\n",
    "        fp_mean_power.append(round(test_fp_mae, 3))\n",
    "        print('average_error: ', average_diff_power[-1], ', fp_average_error: ', \n",
    "              fp_mean_power[-1])\n",
    "        \n",
    "        if False:\n",
    "            test_generator_conserve = DataBatchGenerator(dataset=data_reg[number_sample + val_size:], \n",
    "                                                         batch_size=mini_batch,\n",
    "                                                         start_idx=number_sample + val_size, \n",
    "                                                         number_image_channels=number_image_channels,\n",
    "                                                         max_x=max_x, max_y=max_y, \n",
    "                                                         float_memory_used=float_memory_used, \n",
    "                                                         conserve=1)\n",
    "            test_res_conserve = best_model.evaluate(test_generator_conserve, verbose=1, \n",
    "                                                    workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, \n",
    "                                                    use_multiprocessing=False)\n",
    "            test_mae_cons, test_fp_mae_cons = test_res_conserve[test_mae_idx], test_res_conserve[test_fp_mae_idx]\n",
    "            average_diff_power_conserve.append(round(test_mae_cons, 3))\n",
    "            fp_mean_power_conserve.append(round(test_fp_mae_cons, 3))\n",
    "            print('Conserve, average_error: ', average_diff_power_conserve[-1], ', fp_average_error: ',\n",
    "                 fp_mean_power_conserve[-1])\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        \n",
    "        var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                     dtime + \".dat\", \"wb\") # file for saving results\n",
    "        pickle.dump([average_diff_power, fp_mean_power, number_samples, best_lambda, \n",
    "                     dataset_name, max_dataset_name, average_diff_power_conserve, fp_mean_power_conserve],\n",
    "                    file=var_f)\n",
    "        var_f.close()\n",
    "        del best_model, test_generator\n",
    "#     prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4096, 8192]\n",
      "[4.649, 3.681]\n",
      "[2.898, 2.232]\n",
      "[]\n",
      "[]\n",
      "[1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(number_samples)\n",
    "print(average_diff_power)\n",
    "print(fp_mean_power)\n",
    "# print(best_lambda)\n",
    "print(average_diff_power_conserve)\n",
    "print(fp_mean_power_conserve)\n",
    "print(best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [34.280517578125,\n",
       "  32.139129638671875,\n",
       "  30.026790618896484,\n",
       "  26.77768898010254,\n",
       "  22.154972076416016,\n",
       "  16.8223819732666,\n",
       "  12.144721984863281,\n",
       "  9.570384979248047,\n",
       "  7.8615312576293945,\n",
       "  6.511453151702881,\n",
       "  5.97813606262207,\n",
       "  5.705277919769287,\n",
       "  5.531862258911133,\n",
       "  5.38530158996582,\n",
       "  5.206046104431152,\n",
       "  5.079604148864746,\n",
       "  4.93232536315918,\n",
       "  4.80665922164917,\n",
       "  4.676588535308838,\n",
       "  4.540332794189453,\n",
       "  4.43764066696167,\n",
       "  4.290816307067871,\n",
       "  4.191329002380371,\n",
       "  4.067809104919434,\n",
       "  4.628100395202637,\n",
       "  6.274977684020996,\n",
       "  5.784174919128418,\n",
       "  5.09354829788208,\n",
       "  4.657415866851807,\n",
       "  4.24078369140625,\n",
       "  3.9520764350891113,\n",
       "  3.7179880142211914,\n",
       "  3.524243116378784,\n",
       "  3.3813459873199463,\n",
       "  3.3246569633483887,\n",
       "  3.348724126815796,\n",
       "  3.2289745807647705,\n",
       "  3.259772300720215,\n",
       "  3.4742321968078613,\n",
       "  3.3629093170166016,\n",
       "  3.278648853302002,\n",
       "  3.1227707862854004,\n",
       "  3.1056971549987793,\n",
       "  3.05012845993042,\n",
       "  2.9284372329711914,\n",
       "  2.980515241622925,\n",
       "  3.0709378719329834,\n",
       "  2.9922614097595215,\n",
       "  2.940444231033325,\n",
       "  2.8742055892944336,\n",
       "  2.7167561054229736,\n",
       "  2.77622652053833,\n",
       "  2.7793784141540527,\n",
       "  2.6848957538604736,\n",
       "  2.6082096099853516,\n",
       "  2.555168390274048,\n",
       "  2.5030012130737305,\n",
       "  2.427560806274414,\n",
       "  2.3778016567230225,\n",
       "  2.3583602905273438,\n",
       "  2.316555976867676,\n",
       "  2.3370628356933594,\n",
       "  2.3684959411621094,\n",
       "  2.5095138549804688,\n",
       "  2.6002492904663086,\n",
       "  2.6764237880706787,\n",
       "  2.713268756866455,\n",
       "  2.6889007091522217,\n",
       "  2.6353466510772705,\n",
       "  2.4244720935821533,\n",
       "  2.2964820861816406,\n",
       "  2.2210073471069336,\n",
       "  2.2414896488189697,\n",
       "  2.1672468185424805,\n",
       "  2.071078300476074],\n",
       " 'mse': [138.95742797851562,\n",
       "  139.4345245361328,\n",
       "  139.73812866210938,\n",
       "  140.0347900390625,\n",
       "  141.56851196289062,\n",
       "  141.51560974121094,\n",
       "  141.60562133789062,\n",
       "  141.06564331054688,\n",
       "  142.76235961914062,\n",
       "  137.42697143554688,\n",
       "  131.61819458007812,\n",
       "  127.66020202636719,\n",
       "  123.37792205810547,\n",
       "  119.57726287841797,\n",
       "  115.3846435546875,\n",
       "  111.5514907836914,\n",
       "  107.3299331665039,\n",
       "  103.61212158203125,\n",
       "  99.46189880371094,\n",
       "  95.27288818359375,\n",
       "  91.22123718261719,\n",
       "  86.87760162353516,\n",
       "  82.57862091064453,\n",
       "  78.5640869140625,\n",
       "  78.25345611572266,\n",
       "  90.71188354492188,\n",
       "  98.90522003173828,\n",
       "  95.09429931640625,\n",
       "  90.563720703125,\n",
       "  83.42247772216797,\n",
       "  76.28433227539062,\n",
       "  69.02035522460938,\n",
       "  62.48311996459961,\n",
       "  57.880950927734375,\n",
       "  54.20793151855469,\n",
       "  53.020755767822266,\n",
       "  51.203853607177734,\n",
       "  49.65223693847656,\n",
       "  51.83290100097656,\n",
       "  51.98475646972656,\n",
       "  50.03435516357422,\n",
       "  47.88712692260742,\n",
       "  45.68757629394531,\n",
       "  44.05602264404297,\n",
       "  42.191627502441406,\n",
       "  41.27357864379883,\n",
       "  43.198917388916016,\n",
       "  42.454933166503906,\n",
       "  40.829612731933594,\n",
       "  39.660850524902344,\n",
       "  36.852935791015625,\n",
       "  35.93998336791992,\n",
       "  35.903038024902344,\n",
       "  34.98988723754883,\n",
       "  33.64731979370117,\n",
       "  31.835708618164062,\n",
       "  31.012672424316406,\n",
       "  28.438907623291016,\n",
       "  27.509937286376953,\n",
       "  26.83949089050293,\n",
       "  25.925865173339844,\n",
       "  25.67839813232422,\n",
       "  25.363515853881836,\n",
       "  27.992380142211914,\n",
       "  30.31098175048828,\n",
       "  30.659076690673828,\n",
       "  33.82777404785156,\n",
       "  33.3546028137207,\n",
       "  32.89173126220703,\n",
       "  29.846450805664062,\n",
       "  26.9140682220459,\n",
       "  23.964824676513672,\n",
       "  23.839977264404297,\n",
       "  23.498361587524414,\n",
       "  21.193939208984375],\n",
       " 'mae': [9.568568229675293,\n",
       "  9.60628890991211,\n",
       "  9.628937721252441,\n",
       "  9.644261360168457,\n",
       "  9.67042064666748,\n",
       "  9.650049209594727,\n",
       "  9.664739608764648,\n",
       "  9.68792724609375,\n",
       "  9.712377548217773,\n",
       "  9.602705001831055,\n",
       "  9.444931983947754,\n",
       "  9.319391250610352,\n",
       "  9.175576210021973,\n",
       "  9.040199279785156,\n",
       "  8.890301704406738,\n",
       "  8.727949142456055,\n",
       "  8.559429168701172,\n",
       "  8.404231071472168,\n",
       "  8.235840797424316,\n",
       "  8.060441017150879,\n",
       "  7.892435550689697,\n",
       "  7.694075107574463,\n",
       "  7.503599166870117,\n",
       "  7.321473598480225,\n",
       "  7.275202751159668,\n",
       "  7.773203372955322,\n",
       "  8.196409225463867,\n",
       "  8.121919631958008,\n",
       "  7.985069751739502,\n",
       "  7.685394763946533,\n",
       "  7.353413105010986,\n",
       "  6.9830851554870605,\n",
       "  6.620302677154541,\n",
       "  6.319255828857422,\n",
       "  6.087718486785889,\n",
       "  5.990026473999023,\n",
       "  5.896487236022949,\n",
       "  5.777924060821533,\n",
       "  5.8873090744018555,\n",
       "  5.9037675857543945,\n",
       "  5.815201759338379,\n",
       "  5.729607105255127,\n",
       "  5.560135841369629,\n",
       "  5.423348903656006,\n",
       "  5.342309951782227,\n",
       "  5.271992206573486,\n",
       "  5.388915061950684,\n",
       "  5.355019569396973,\n",
       "  5.264732837677002,\n",
       "  5.205231189727783,\n",
       "  5.012448310852051,\n",
       "  4.900557041168213,\n",
       "  4.9147186279296875,\n",
       "  4.854438304901123,\n",
       "  4.784154891967773,\n",
       "  4.61916446685791,\n",
       "  4.553294658660889,\n",
       "  4.366307735443115,\n",
       "  4.25223445892334,\n",
       "  4.19352912902832,\n",
       "  4.1321516036987305,\n",
       "  4.103394508361816,\n",
       "  4.080540180206299,\n",
       "  4.319300174713135,\n",
       "  4.517905235290527,\n",
       "  4.534417152404785,\n",
       "  4.761448860168457,\n",
       "  4.753091335296631,\n",
       "  4.7662739753723145,\n",
       "  4.548783779144287,\n",
       "  4.300647258758545,\n",
       "  4.032342910766602,\n",
       "  3.9714109897613525,\n",
       "  3.974112033843994,\n",
       "  3.7625133991241455],\n",
       " 'fp_mae': [0.8757335543632507,\n",
       "  0.8362340927124023,\n",
       "  0.7910929322242737,\n",
       "  0.7265692353248596,\n",
       "  0.6322803497314453,\n",
       "  0.5046727061271667,\n",
       "  0.37385767698287964,\n",
       "  0.2594864070415497,\n",
       "  0.17712929844856262,\n",
       "  0.08700224757194519,\n",
       "  0.04615789279341698,\n",
       "  0.0286738108843565,\n",
       "  0.023867575451731682,\n",
       "  0.02009620890021324,\n",
       "  0.013288630172610283,\n",
       "  0.013877389021217823,\n",
       "  0.01204006839543581,\n",
       "  0.01277848519384861,\n",
       "  0.014464703388512135,\n",
       "  0.015045681968331337,\n",
       "  0.02172103151679039,\n",
       "  0.02018497698009014,\n",
       "  0.02581704407930374,\n",
       "  0.02792665734887123,\n",
       "  0.07724101096391678,\n",
       "  0.17399320006370544,\n",
       "  0.11896859854459763,\n",
       "  0.06565311551094055,\n",
       "  0.044544022530317307,\n",
       "  0.019941510632634163,\n",
       "  0.01081253495067358,\n",
       "  0.011223874986171722,\n",
       "  0.01651868224143982,\n",
       "  0.019244013354182243,\n",
       "  0.029722880572080612,\n",
       "  0.03894929587841034,\n",
       "  0.03340519219636917,\n",
       "  0.039644915610551834,\n",
       "  0.05869905278086662,\n",
       "  0.04865427687764168,\n",
       "  0.043211717158555984,\n",
       "  0.03212028741836548,\n",
       "  0.03515591844916344,\n",
       "  0.04212021455168724,\n",
       "  0.03073122724890709,\n",
       "  0.044389329850673676,\n",
       "  0.050836432725191116,\n",
       "  0.04328303784132004,\n",
       "  0.038926221430301666,\n",
       "  0.03935988247394562,\n",
       "  0.028175583109259605,\n",
       "  0.03954663872718811,\n",
       "  0.04407496005296707,\n",
       "  0.03602404147386551,\n",
       "  0.028622223064303398,\n",
       "  0.03277350962162018,\n",
       "  0.026339637115597725,\n",
       "  0.02931462600827217,\n",
       "  0.02785148099064827,\n",
       "  0.029781240969896317,\n",
       "  0.027893854305148125,\n",
       "  0.033705566078424454,\n",
       "  0.0444902703166008,\n",
       "  0.053840674459934235,\n",
       "  0.050547145307064056,\n",
       "  0.05854751914739609,\n",
       "  0.04866339638829231,\n",
       "  0.04817085713148117,\n",
       "  0.04092201963067055,\n",
       "  0.025672009214758873,\n",
       "  0.021238161250948906,\n",
       "  0.02465384639799595,\n",
       "  0.03125966340303421,\n",
       "  0.024158567190170288,\n",
       "  0.01754622533917427],\n",
       " 'val_loss': [27.701032638549805,\n",
       "  27.114723205566406,\n",
       "  25.555381774902344,\n",
       "  23.660282135009766,\n",
       "  16.630056381225586,\n",
       "  14.22280502319336,\n",
       "  14.467507362365723,\n",
       "  14.206449508666992,\n",
       "  15.25165843963623,\n",
       "  16.547962188720703,\n",
       "  16.518856048583984,\n",
       "  17.636119842529297,\n",
       "  16.603595733642578,\n",
       "  16.440916061401367,\n",
       "  15.279376029968262,\n",
       "  14.711442947387695,\n",
       "  14.447875022888184,\n",
       "  13.657086372375488,\n",
       "  13.080232620239258,\n",
       "  12.993061065673828,\n",
       "  12.458075523376465,\n",
       "  11.768416404724121,\n",
       "  11.573246002197266,\n",
       "  11.44144058227539,\n",
       "  11.878591537475586,\n",
       "  12.830615997314453,\n",
       "  11.252320289611816,\n",
       "  12.575824737548828,\n",
       "  13.753491401672363,\n",
       "  13.651358604431152,\n",
       "  13.819133758544922,\n",
       "  16.028156280517578,\n",
       "  15.607954978942871,\n",
       "  16.888216018676758,\n",
       "  17.165435791015625,\n",
       "  22.438262939453125,\n",
       "  20.497806549072266,\n",
       "  29.523338317871094,\n",
       "  33.77013397216797,\n",
       "  29.01215171813965,\n",
       "  37.24893569946289,\n",
       "  31.790571212768555,\n",
       "  35.257205963134766,\n",
       "  43.21108627319336,\n",
       "  35.294944763183594,\n",
       "  33.65171813964844,\n",
       "  25.89348602294922,\n",
       "  27.556808471679688,\n",
       "  23.253582000732422,\n",
       "  30.200891494750977,\n",
       "  33.268856048583984,\n",
       "  31.737709045410156,\n",
       "  38.988990783691406,\n",
       "  30.693267822265625,\n",
       "  41.60560607910156,\n",
       "  31.8389892578125,\n",
       "  38.68429946899414,\n",
       "  39.64955520629883,\n",
       "  41.06806182861328,\n",
       "  32.145912170410156,\n",
       "  43.99365997314453,\n",
       "  37.36620330810547,\n",
       "  39.24705123901367,\n",
       "  40.77823257446289,\n",
       "  29.055973052978516,\n",
       "  38.17567825317383,\n",
       "  31.208189010620117,\n",
       "  33.73896789550781,\n",
       "  45.55735778808594,\n",
       "  39.96580123901367,\n",
       "  41.07185745239258,\n",
       "  63.05266571044922,\n",
       "  42.36210632324219,\n",
       "  37.91758346557617,\n",
       "  38.38783264160156],\n",
       " 'val_mse': [131.5735321044922,\n",
       "  132.94903564453125,\n",
       "  137.59432983398438,\n",
       "  144.00941467285156,\n",
       "  190.94908142089844,\n",
       "  254.15472412109375,\n",
       "  342.9757385253906,\n",
       "  326.5900573730469,\n",
       "  401.8948669433594,\n",
       "  449.29193115234375,\n",
       "  451.7496643066406,\n",
       "  490.8843994140625,\n",
       "  455.33135986328125,\n",
       "  452.0580749511719,\n",
       "  411.7303466796875,\n",
       "  391.2557373046875,\n",
       "  383.2771911621094,\n",
       "  352.2546081542969,\n",
       "  333.18243408203125,\n",
       "  326.4960021972656,\n",
       "  300.8323669433594,\n",
       "  279.1268005371094,\n",
       "  263.6731872558594,\n",
       "  258.8364562988281,\n",
       "  181.84121704101562,\n",
       "  181.14381408691406,\n",
       "  204.1774444580078,\n",
       "  187.20458984375,\n",
       "  125.48226928710938,\n",
       "  124.85722351074219,\n",
       "  119.20436096191406,\n",
       "  96.94213104248047,\n",
       "  98.06595611572266,\n",
       "  90.61659240722656,\n",
       "  87.44786071777344,\n",
       "  72.6369400024414,\n",
       "  78.33419799804688,\n",
       "  72.42845916748047,\n",
       "  57.234928131103516,\n",
       "  60.011024475097656,\n",
       "  54.26087951660156,\n",
       "  57.54944610595703,\n",
       "  57.3054313659668,\n",
       "  50.18709945678711,\n",
       "  53.81249237060547,\n",
       "  57.4285888671875,\n",
       "  71.0619888305664,\n",
       "  67.78023529052734,\n",
       "  77.804931640625,\n",
       "  58.76274871826172,\n",
       "  56.100868225097656,\n",
       "  60.2158203125,\n",
       "  53.759498596191406,\n",
       "  60.11495590209961,\n",
       "  48.341922760009766,\n",
       "  57.5165901184082,\n",
       "  51.54823303222656,\n",
       "  49.06593322753906,\n",
       "  48.88787841796875,\n",
       "  53.773990631103516,\n",
       "  49.05105209350586,\n",
       "  51.692256927490234,\n",
       "  52.831233978271484,\n",
       "  54.50913619995117,\n",
       "  64.28040313720703,\n",
       "  54.52835464477539,\n",
       "  62.04332733154297,\n",
       "  59.839786529541016,\n",
       "  48.87601852416992,\n",
       "  54.01548767089844,\n",
       "  50.23514938354492,\n",
       "  44.680789947509766,\n",
       "  49.095096588134766,\n",
       "  51.98741912841797,\n",
       "  50.680381774902344],\n",
       " 'val_mae': [9.298479080200195,\n",
       "  9.36836051940918,\n",
       "  9.582399368286133,\n",
       "  9.865554809570312,\n",
       "  11.756539344787598,\n",
       "  13.980988502502441,\n",
       "  16.68907356262207,\n",
       "  16.17669105529785,\n",
       "  18.399377822875977,\n",
       "  19.655776977539062,\n",
       "  19.732574462890625,\n",
       "  20.723745346069336,\n",
       "  19.83918571472168,\n",
       "  19.804880142211914,\n",
       "  18.795761108398438,\n",
       "  18.289033889770508,\n",
       "  18.102792739868164,\n",
       "  17.260740280151367,\n",
       "  16.76466941833496,\n",
       "  16.533395767211914,\n",
       "  15.797470092773438,\n",
       "  15.201926231384277,\n",
       "  14.708893775939941,\n",
       "  14.609565734863281,\n",
       "  11.82087516784668,\n",
       "  11.773801803588867,\n",
       "  12.726445198059082,\n",
       "  11.887100219726562,\n",
       "  9.594481468200684,\n",
       "  9.609915733337402,\n",
       "  9.422100067138672,\n",
       "  8.362160682678223,\n",
       "  8.434253692626953,\n",
       "  8.050840377807617,\n",
       "  7.827771186828613,\n",
       "  7.059072494506836,\n",
       "  7.328733921051025,\n",
       "  6.937481880187988,\n",
       "  6.086619853973389,\n",
       "  6.293088436126709,\n",
       "  5.938018798828125,\n",
       "  6.180086135864258,\n",
       "  6.119192123413086,\n",
       "  5.65084981918335,\n",
       "  5.933087348937988,\n",
       "  6.110011577606201,\n",
       "  6.9567670822143555,\n",
       "  6.753399848937988,\n",
       "  7.319133758544922,\n",
       "  6.233630180358887,\n",
       "  6.090268611907959,\n",
       "  6.303443908691406,\n",
       "  5.869543075561523,\n",
       "  6.318245887756348,\n",
       "  5.612604141235352,\n",
       "  6.176711559295654,\n",
       "  5.774494171142578,\n",
       "  5.6121673583984375,\n",
       "  5.649049282073975,\n",
       "  5.957334041595459,\n",
       "  5.6253581047058105,\n",
       "  5.805909156799316,\n",
       "  5.881579875946045,\n",
       "  5.94459867477417,\n",
       "  6.577937126159668,\n",
       "  5.917793273925781,\n",
       "  6.431214332580566,\n",
       "  6.291696071624756,\n",
       "  5.63870906829834,\n",
       "  5.911204814910889,\n",
       "  5.713443279266357,\n",
       "  5.309280872344971,\n",
       "  5.63872766494751,\n",
       "  5.849617958068848,\n",
       "  5.7642621994018555],\n",
       " 'val_fp_mae': [0.7785448431968689,\n",
       "  0.7557740211486816,\n",
       "  0.6990954875946045,\n",
       "  0.6374534368515015,\n",
       "  0.3499869108200073,\n",
       "  0.17726540565490723,\n",
       "  0.08151146024465561,\n",
       "  0.09042427688837051,\n",
       "  0.04333247244358063,\n",
       "  0.026314059272408485,\n",
       "  0.023008033633232117,\n",
       "  0.015303527005016804,\n",
       "  0.01988721638917923,\n",
       "  0.019194476306438446,\n",
       "  0.026645764708518982,\n",
       "  0.029987340793013573,\n",
       "  0.029973573982715607,\n",
       "  0.03915213420987129,\n",
       "  0.04230624437332153,\n",
       "  0.04284100607037544,\n",
       "  0.05878112092614174,\n",
       "  0.06337492167949677,\n",
       "  0.07584269344806671,\n",
       "  0.08386609703302383,\n",
       "  0.19398874044418335,\n",
       "  0.23028625547885895,\n",
       "  0.16068993508815765,\n",
       "  0.21382765471935272,\n",
       "  0.3501199781894684,\n",
       "  0.3496076166629791,\n",
       "  0.36181017756462097,\n",
       "  0.4604138433933258,\n",
       "  0.44616374373435974,\n",
       "  0.506967306137085,\n",
       "  0.5131387710571289,\n",
       "  0.724962055683136,\n",
       "  0.6332568526268005,\n",
       "  0.9380209445953369,\n",
       "  1.131161093711853,\n",
       "  1.031607747077942,\n",
       "  1.2321544885635376,\n",
       "  1.0980838537216187,\n",
       "  1.180215835571289,\n",
       "  1.4021376371383667,\n",
       "  1.1933064460754395,\n",
       "  1.100930094718933,\n",
       "  0.832655668258667,\n",
       "  0.9237565398216248,\n",
       "  0.7059701085090637,\n",
       "  1.0472887754440308,\n",
       "  1.0938546657562256,\n",
       "  1.032322645187378,\n",
       "  1.2932273149490356,\n",
       "  1.040101170539856,\n",
       "  1.4429906606674194,\n",
       "  1.124444603919983,\n",
       "  1.3082584142684937,\n",
       "  1.3665471076965332,\n",
       "  1.4357147216796875,\n",
       "  1.140723466873169,\n",
       "  1.5076793432235718,\n",
       "  1.2952944040298462,\n",
       "  1.3526383638381958,\n",
       "  1.375780701637268,\n",
       "  0.981248676776886,\n",
       "  1.2827385663986206,\n",
       "  1.0603300333023071,\n",
       "  1.15763521194458,\n",
       "  1.5314626693725586,\n",
       "  1.3450216054916382,\n",
       "  1.3932299613952637,\n",
       "  2.0574522018432617,\n",
       "  1.4187321662902832,\n",
       "  1.280022144317627,\n",
       "  1.2936455011367798]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cnns[0][0].history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = all_cnns[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_samples: 8192 , New samples: 8192\n",
      "Validation size: 2704 , starts: 8192 , ends: 10895\n",
      "\n",
      "Epoch 00061: val_mae improved from inf to 4.03655, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/8192/best_model_lambda_0new.h5\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 4.03655\n",
      "Train Error(all epochs): 2.7838029861450195 \n",
      " [3.146, 3.051, 3.077, 3.16, 3.025, 3.048, 3.075, 3.047, 2.933, 2.916, 2.954, 2.952, 2.843, 2.839, 2.855, 2.931, 2.881, 2.853, 2.784, 2.87]\n",
      "Train FP Error(all epochs): 1.395856499671936 \n",
      " [1.565, 1.509, 1.525, 1.594, 1.505, 1.514, 1.543, 1.499, 1.472, 1.458, 1.471, 1.466, 1.421, 1.429, 1.414, 1.447, 1.427, 1.423, 1.396, 1.423]\n",
      "Val Error(all epochs): 4.036548614501953 \n",
      " [4.037, 5.122, 4.407, 4.095, 5.374, 4.484, 4.181, 4.058, 5.237, 6.0, 4.326, 4.051, 4.319, 4.129, 4.174, 4.58, 4.328, 4.15, 4.372, 4.068]\n",
      "Val FP Error(all epochs): 0.6289845108985901 \n",
      " [1.809, 0.989, 1.929, 2.832, 0.842, 1.47, 1.915, 2.469, 0.917, 0.629, 1.431, 2.745, 1.351, 1.903, 1.793, 1.255, 1.595, 1.794, 1.674, 2.165]\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    checkpointers = ModelCheckpoint(filepath=MODEL_PATH + str(0)+ 'new.h5',\n",
    "                                         verbose=1, save_best_only=True, \n",
    "                                         monitor=hyper_metric,\n",
    "                                         mode=mode)\n",
    "    number_start = time.time()\n",
    "    train_generator = DataBatchGenerator(dataset=data_reg[prev_sample:number_sample], batch_size=mini_batch,\n",
    "                                         start_idx=prev_sample, number_image_channels=number_image_channels,\n",
    "                                         max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "    \n",
    "\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "    val_generator = DataBatchGenerator(dataset=data_reg[number_sample:number_sample+val_size], \n",
    "                                       batch_size=mini_batch,\n",
    "                                       start_idx=number_sample,\n",
    "                                       number_image_channels=number_image_channels,\n",
    "                                       max_x=max_x, max_y=max_y, \n",
    "                                       float_memory_used=float_memory_used)\n",
    "  \n",
    "    print('number_samples:', number_sample, \", New samples:\", number_sample - prev_sample)\n",
    "    print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", number_sample + val_size - 1)\n",
    "    best_model.fit(train_generator, epochs=80, verbose=0,\n",
    "                   validation_data=val_generator, shuffle=True, callbacks=[checkpointers], \n",
    "                   workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, \n",
    "                   use_multiprocessing=False, initial_epoch=60)\n",
    "    print(\"Train Error(all epochs):\", min(best_model.history.history['mae']), '\\n',\n",
    "          [round(val, 3) for val in best_model.history.history['mae']])\n",
    "    print(\"Train FP Error(all epochs):\", min(best_model.history.history['fp_mae']), '\\n',\n",
    "          [round(val,3) for val in best_model.history.history['fp_mae']])\n",
    "    print(\"Val Error(all epochs):\", min(best_model.history.history['val_mae']), '\\n', \n",
    "          [round(val,3) for val in best_model.history.history['val_mae']])\n",
    "    print(\"Val FP Error(all epochs):\", min(best_model.history.history['val_fp_mae']), '\\n',\n",
    "          [round(val,3) for val in best_model.history.history['val_fp_mae']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test starts:  10896 , ends:  34263\n",
      "92/92 [==============================] - 22s 234ms/step - loss: 38.6681 - mse: 27.7563 - mae: 4.0863 - fp_mae: 1.7810\n"
     ]
    }
   ],
   "source": [
    "best_best_model = models.load_model(MODEL_PATH + str(0) + 'new.h5', \n",
    "                               custom_objects={ 'loss': custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                                               'fp_mae': fp_mae,\n",
    "                                               'mae':'mae', 'mse':'mse'})\n",
    "test_generator = DataBatchGenerator(dataset=data_reg[number_sample + val_size:], \n",
    "                                            batch_size=mini_batch,\n",
    "                                            start_idx=number_sample + val_size, \n",
    "                                            number_image_channels=number_image_channels,\n",
    "                                            max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "\n",
    "print(\"Test starts: \", number_sample + val_size, \", ends: \", data_reg.shape[0] - 1)\n",
    "time.sleep(1)\n",
    "test_res = best_best_model.evaluate(test_generator, verbose=1, \n",
    "                                    workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE,\n",
    "                                    use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[496.0564270019531, 56.21223449707031, 5.682240009307861, 1.5113146305084229]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [105.50102233886719,\n",
       "  100.78263854980469,\n",
       "  99.25178527832031,\n",
       "  104.09859466552734,\n",
       "  104.50546264648438],\n",
       " 'mse': [44.08177185058594,\n",
       "  41.80543518066406,\n",
       "  41.379180908203125,\n",
       "  44.375244140625,\n",
       "  44.21040725708008],\n",
       " 'mae': [5.269191265106201,\n",
       "  5.1021318435668945,\n",
       "  5.071562767028809,\n",
       "  5.278663635253906,\n",
       "  5.268550872802734],\n",
       " 'fp_mae': [0.19422784447669983,\n",
       "  0.1903233528137207,\n",
       "  0.19018331170082092,\n",
       "  0.2034783661365509,\n",
       "  0.19720497727394104],\n",
       " 'val_loss': [396.6565246582031,\n",
       "  401.5822448730469,\n",
       "  435.2545166015625,\n",
       "  567.9744262695312,\n",
       "  345.01153564453125],\n",
       " 'val_mse': [120.43984985351562,\n",
       "  76.076171875,\n",
       "  161.7263946533203,\n",
       "  71.23866271972656,\n",
       "  77.79705047607422],\n",
       " 'val_mae': [9.087770462036133,\n",
       "  6.748907089233398,\n",
       "  10.751054763793945,\n",
       "  6.494345188140869,\n",
       "  6.804019927978516],\n",
       " 'val_fp_mae': [0.6868877410888672,\n",
       "  0.9997519850730896,\n",
       "  0.640586793422699,\n",
       "  1.5676021575927734,\n",
       "  0.9557649493217468]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fac19dcf810>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(train_generator, epochs=15, verbose=0,\n",
    "               validation_data=val_generator, shuffle=True, callbacks=[checkpointers], \n",
    "               workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, \n",
    "               use_multiprocessing=False, initial_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_min_mae = [8.27781, 8.23545, 8.20838]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power = [8.166, 7.844, 7.592]\n",
    "fp_mean_power = [4.56, 4.42, 4.37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CNN: support batching\n",
    "TEST = True\n",
    "mini_batch, epochs = 16, 30\n",
    "batch_size = (batch_size // mini_batch) * mini_batch\n",
    "prev_sample = 0\n",
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]  #, 0.3, 1, 3, 10\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "for cnn in cnns:\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "for number_sample in number_samples:\n",
    "    number_start = time.time()\n",
    "    current_sample = number_sample - prev_sample\n",
    "    train_samples = [batch_size] * (current_sample//batch_size) + ([current_sample%batch_size] if \n",
    "                                                                    current_sample%batch_size else [])\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "#     val_samples = [batch_size] * (val_size//batch_size) + ([val_size%batch_size] if \n",
    "#                                                                val_size%batch_size else [])\n",
    "    \n",
    "    print('number_samples:', number_sample)\n",
    "    print(\"Train batches:\", train_samples)\n",
    "    for i, train_sample in enumerate(train_samples):\n",
    "        print(\"Train batch#:\", i, \", batch size:\", train_sample, \", starts:\", prev_sample + i * batch_size,\n",
    "                      \", ends:\", prev_sample + i * batch_size + train_sample - 1)\n",
    "    print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", number_sample + val_size - 1)\n",
    "#     print(\"Validation Batches:\", val_samples)\n",
    "#     for i, val_sample in enumerate(val_samples):\n",
    "#         print(\"Validation batch#:\", i, \", batch size:\", val_sample, \", starts:\", number_sample + i * batch_size,\n",
    "#                       \", ends:\", number_sample + i * batch_size + val_sample - 1)\n",
    "        \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb_idx, lamb in enumerate(lambda_vec):\n",
    "        lambda_start = time.time()\n",
    "        \n",
    "#         cnn = cnn_model(10, lamb, 0)\n",
    "#         cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "        # training on all batches\n",
    "        for i, train_sample in enumerate(train_samples):\n",
    "#             if lamb_idx == 0:\n",
    "#                 print(\"Train batch#:\", i, \", batch size:\", train_sample, \", starts:\", prev_sample + i * batch_size,\n",
    "#                       \", ends:\", prev_sample + i * batch_size + train_sample - 1)\n",
    "            x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "            y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "            for image_num in range(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample):\n",
    "                x_train[(image_num - prev_sample) % batch_size] = read_image(image_num)\n",
    "                y_train[(image_num - prev_sample) % batch_size] = np.asarray(data_reg[image_num][-1], \n",
    "                                                                             dtype=float_memory_used)\n",
    "            cnns[lamb_idx].fit(x_train, y_train, epochs=epochs, verbose=2, batch_size=mini_batch,\n",
    "                               validation_split=0.2, \n",
    "                               shuffle=True)\n",
    "            del x_train, y_train\n",
    "#         if lamb_idx == 0:\n",
    "#             print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", \n",
    "#                   number_sample + val_size - 1)\n",
    "        print(\"\\nLambda:\", lamb)\n",
    "        print(\"Train Error(all epochs): \", cnns[lamb_idx].history.history['mae'])\n",
    "        \n",
    "        # validating\n",
    "        val_mae, val_fp_mae = 0.0, 0.0\n",
    "#         for i, val_sample in enumerate(val_samples):\n",
    "#             x_val = np.empty((val_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "#             for image_num in range(val_sample):\n",
    "#                 x_val[image_num] = read_image(image_num + number_sample + i * batch_size)\n",
    "#             yp_val = cnns[lamb_idx].predict(x_val)\n",
    "        for image_num in range(val_size):\n",
    "            val_y = data_reg[image_num + number_sample][-1]\n",
    "            image = read_image(image_num + number_sample)\n",
    "            val_yp = cnns[lamb_idx].predict(image)[0][0]\n",
    "#             for image_num in range(val_sample):\n",
    "#                 val_yp = yp_val[image_num][0]\n",
    "#                 val_y = data_reg[image_num + number_sample + i * batch_size][-1]\n",
    "            val_mae += abs(val_y - val_yp)\n",
    "            if val_yp > val_y:\n",
    "                val_fp_mae += abs(val_yp - val_y)\n",
    "        val_mae /= val_size\n",
    "        val_fp_mae /= val_size\n",
    "        print(\"Val Error:\", round(val_mae, 3), \", Time:\", str(datetime.timedelta(seconds=int(time.time() - lambda_start))))\n",
    "        if val_mae < min_error:\n",
    "            min_error = val_mae\n",
    "            best_model = cnns[lamb_idx]\n",
    "            best_lam = lamb\n",
    "            best_lam_idx = lamb_idx\n",
    "    print(\"\\nTrainig set size:\", number_sample, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - number_start)))\n",
    "          ,\", best_lambda:\", best_lam, \", min_error:\", round(min_error, 3))\n",
    "    \n",
    "    \n",
    "    if TEST:\n",
    "        # evaluating test images\n",
    "        sum_mae, sum_fp_mae = 0, 0\n",
    "        test_size = 0\n",
    "\n",
    "        y_test_p = np.empty((data_reg.shape[0] - (number_sample + val_size)), dtype=float_memory_used)\n",
    "    #     test_size = data_reg.shape[0] - (number_sample + val_size)\n",
    "    #     test_samples = [batch_size] * (test_size//batch_size) + ([test_size%batch_size] if \n",
    "    #                                                              test_size%batch_size else [])\n",
    "        print(\"Test starts: \", number_sample + val_size, \", ends: \", data_reg.shape[0] - 1)\n",
    "        time.sleep(1)\n",
    "    #     for i, test_sample in tqdm.tqdm(enumerate(test_samples)):\n",
    "    #         x_test = np.empty((test_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "    #         for image_num in range(test_sample):\n",
    "    #             x_test[image_num] = read_image(number_sample + val_size + i * batch_size)\n",
    "    #         yp_test = cnns[best_lam_idx].predict(x_test)\n",
    "    #         for image_num in range(test_sample):\n",
    "    #             test_y = data_reg[number_sample + val_size + i * batch_size][-1]\n",
    "    #             test_yp = yp_test[image_num][0]\n",
    "    #             sum_mae += abs(test_yp - test_y)\n",
    "    #             if test_yp > test_y:\n",
    "    #                 sum_fp_mae += abs(test_yp - test_y)\n",
    "\n",
    "        for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "            test_size += 1\n",
    "            test_image = read_image(test_num)\n",
    "            test_y = data_reg[test_num][-1]\n",
    "            test_yp = best_model.predict(test_image)[0][0]\n",
    "            y_test_p[test_num - (number_sample + val_size)] = test_yp\n",
    "            sum_mae += abs(test_yp - test_y)\n",
    "            if test_yp > test_y:\n",
    "                sum_fp_mae += abs(test_yp - test_y)\n",
    "        fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "        average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "        print('average_error: ', average_diff_power[-1], ', fp_average_error: ', \n",
    "              fp_mean_power[-1])\n",
    "        print(\"\\n\\n\")\n",
    "        var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                     dtime + \".dat\", \"wb\") # file for saving results\n",
    "        pickle.dump([average_diff_power, fp_mean_power, number_samples], file=var_f)\n",
    "        var_f.close()\n",
    "    prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnns[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CNN: support batching\n",
    "prev_sample = 0\n",
    "# number_samples = [120, 200, 700]\n",
    "lambda_vec = [0, 0.001]  #0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "for cnn in cnns:\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "for number_sample in number_samples:\n",
    "    current_sample = number_sample - prev_sample\n",
    "    print(\"prev: \", prev_sample, \", now: \", number_sample, \", size\", current_sample) \n",
    "    train_samples = [batch_size] * (current_sample//batch_size) + ([current_sample%batch_size] if \n",
    "                                                                    current_sample%batch_size else [])\n",
    "    print(train_samples)\n",
    "    \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb_idx, lamb in enumerate(lambda_vec):\n",
    "        print(\"Lambda:\", lamb)\n",
    "#         cnn = cnn_model(10, lamb, 0)\n",
    "#         cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "        # training on all batches\n",
    "                                    \n",
    "        for i, train_sample in enumerate(train_samples):\n",
    "            for image_num in range(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample):\n",
    "                print(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample)\n",
    "                print((prev_sample + i * batch_size - prev_sample) % batch_size, \n",
    "                      (prev_sample + i * batch_size + train_sample - prev_sample)% batch_size)\n",
    "                break\n",
    "\n",
    "        \n",
    "        # validating\n",
    "        print(\"validating\")\n",
    "        val_size = math.ceil(number_sample * validation_size)\n",
    "        for image_num in range(val_size):\n",
    "            print(number_sample, val_size + number_sample)\n",
    "            break\n",
    "     \n",
    "    print(\"Test\") \n",
    "    \n",
    "    # evaluating test images\n",
    "\n",
    "    \n",
    "    for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "        print(number_sample + val_size, data_reg.shape[0])\n",
    "        break\n",
    "    prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + 'best_cnn_4000samples' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                 dtime + \".dat\", \"wb\") # file for saving results\n",
    "pickle.dump(best_model, file=var_f)\n",
    "var_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use self-training\n",
    "unlabeled_train_samples = [batch_size] * (len(y_test_p)//batch_size) + ([len(y_test_p)%batch_size] if len(y_test_p)%batch_size else [])\n",
    "labeled_train_samples = [batch_size] * (number_sample//batch_size) + ([number_sample%batch_size] if number_sample%batch_size else [])   \n",
    "min_min_error = float('inf')\n",
    "best_best_model, best_best_lam = None, None\n",
    "for lamb in tqdm.tqdm(lambda_vec):\n",
    "    print(\"Lambda:\", lamb)\n",
    "    cnn = cnn_model(10, lamb, 0)\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#     cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "    # training on all batches\n",
    "    # training on all batches\n",
    "    for i, train_sample in tqdm.tqdm(enumerate(labeled_train_samples)):\n",
    "        x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "        y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "        for image_num in range(i * batch_size, i * batch_size + train_sample):\n",
    "            x_train[image_num % batch_size] = read_image(image_num)\n",
    "            y_train[image_num % batch_size] = np.asarray(data_reg[image_num][-1], dtype=float_memory_used)\n",
    "        cnn.fit(x_train, y_train, epochs=6, verbose=0, batch_size=1, validation_split=0.0)\n",
    "        del x_train, y_train\n",
    "            \n",
    "    for i, train_sample in tqdm.tqdm(enumerate(unlabeled_train_samples)):\n",
    "        x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "        y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "        for image_num in range(i * batch_size + number_sample + val_size, i * batch_size + number_sample + val_size + train_sample):\n",
    "            x_train[(image_num-number_sample - val_size) % batch_size] = read_image(image_num)\n",
    "            y_train[(image_num-number_sample - val_size) % batch_size] = np.asarray(y_test_p[image_num-(number_sample + val_size)], dtype=float_memory_used)\n",
    "        cnn.fit(x_train, y_train, epochs=3, verbose=0, batch_size=1, validation_split=0.0)\n",
    "        del x_train, y_train\n",
    "        \n",
    "    # validating\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "    val_mae, val_fp_mae = 0.0, 0.0\n",
    "    for image_num in range(val_size):\n",
    "        val_y = data_reg[image_num + number_sample][-1]\n",
    "        image = read_image(image_num + number_sample)\n",
    "        val_yp = cnn.predict(image)[0][0]\n",
    "        val_mae += abs(val_y - val_yp)\n",
    "        if val_yp > val_y:\n",
    "            val_fp_mae += abs(val_yp - val_y)\n",
    "    val_mae /= val_size\n",
    "    val_fp_mae /= val_size\n",
    "    print(val_mae)\n",
    "    if val_mae < min_min_error:\n",
    "        min_min_error = val_mae\n",
    "        best_best_model = cnn\n",
    "        best_best_lam = lamb\n",
    "    sum_mae, sum_fp_mae = 0, 0\n",
    "    test_size = 0\n",
    "    \n",
    "for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "    test_size += 1\n",
    "    test_image = read_image(test_num)\n",
    "    test_y = data_reg[test_num][-1]\n",
    "    test_yp = best_best_model.predict(test_image)[0][0]\n",
    "#     y_test_p[test_num - (number_sample + val_size)] = test_yp\n",
    "    sum_mae += abs(test_yp - test_y)\n",
    "    if test_yp > test_y:\n",
    "        sum_fp_mae += abs(test_yp - test_y)\n",
    "fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "print('number_samples: ', number_sample, ', average_error: ', average_diff_power[-1], ' fp_average_error: ', \n",
    "      fp_mean_power[-1])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6.285, 6.366, 6.45, 6.454, 6.382, 6.26, 6.49, 6.224, 6.052, 5.87, 4.915, 4.836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "prev_sample = 0\n",
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1]\n",
    "max_train_samples = math.ceil(number_samples[-1] * (1 + validation_size))\n",
    "x_train = np.empty((max_train_samples, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "# x_train1 = np.empty((max_train_samples, 1, max_x, max_y), dtype=float_memory_used)\n",
    "# x_train2 = np.empty((max_train_samples, 1, max_x, max_y), dtype=float_memory_used)\n",
    "y_train = np.empty((max_train_samples), dtype=float_memory_used)\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "for number_sample in number_samples:\n",
    "    sample = math.ceil(number_sample * (1 + validation_size))\n",
    "    for image_num in range(prev_sample, sample):\n",
    "        prev_sample = sample\n",
    "        if style == \"image_intensity\":\n",
    "            image = plt.imread(image_dir + '/image' + str(image_num)+'.png')\n",
    "            image = np.swapaxes(image, 0, 2)\n",
    "            x_train[image_num] = np.array(image[:number_image_channels], dtype=float_memory_used).reshape(1, number_image_channels, max_x, max_y)\n",
    "            del image\n",
    "        elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "            x_train[image_num] = np.load(image_dir + '/image' + str(image_num)+'.npy')\n",
    "#             image = np.load(image_dir + '/image' + str(image_num)+'.npy')\n",
    "#             x_train1[image_num][0] = image[0][0]\n",
    "#             x_train2[image_num][0] = image[0][1]\n",
    "        y_train[image_num] = np.asarray(data_reg[image_num][-1], dtype=float_memory_used)\n",
    "        if image_num + 1 % 100 == 0:\n",
    "            print(image_num)\n",
    "#     cnn = cnn_model(7, 0, 0)\n",
    "#     cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#     cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "#             (validation_size + 1))\n",
    "    \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb in lambda_vec:\n",
    "        print(\"Lambda:\", lamb)\n",
    "        cnn = cnn_model(10, lamb, 0)\n",
    "        cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#         cnn.fit([x_train1[:sample], x_train2[:sample]], y_train[:sample], epochs=6, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "#                 (validation_size + 1))\n",
    "        cnn.fit(x_train[:sample], y_train[:sample], epochs=6, verbose=0, batch_size=1, validation_split=validation_size/\n",
    "                (validation_size + 1))\n",
    "        if cnn.history.history['val_mean_absolute_error'][-1] < min_error:\n",
    "            min_error = cnn.history.history['val_mean_absolute_error'][-1]\n",
    "            best_model = cnn\n",
    "            best_lam = lamb\n",
    "    print(\"best_lambda, \", best_lam, \"min_error\", min_error)    \n",
    "    # evaluating test images\n",
    "    sum_mae, sum_fp_mae = 0, 0\n",
    "    test_size = 0\n",
    "#     for test_num in range(max_train_samples, data_reg.shape[0]):\n",
    "    for test_num in range(sample, data_reg.shape[0]):\n",
    "        test_size += 1\n",
    "        if style == \"image_intensity\":\n",
    "            test_image = plt.imread(image_dir + '/image' + str(test_num) + '.png')\n",
    "            test_image = np.swapaxes(test_image, 0, 2)\n",
    "            test_image = np.array(test_image[:number_image_channels]).reshape(1, number_image_channels, max_x, max_y)\n",
    "        elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "            test_image = np.load(image_dir + '/image' + str(test_num)+'.npy')\n",
    "        test_y = data_reg[test_num][-1]\n",
    "        test_yp = best_model.predict(test_image)[0][0]\n",
    "        sum_mae += abs(test_yp - test_y)\n",
    "        if test_yp > test_y:\n",
    "            sum_fp_mae += abs(test_yp - test_y)\n",
    "        if test_num % 500 == 0:\n",
    "            print('test: ', test_num)\n",
    "    fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "    average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "    print('number_samples: ', number_sample, ', average_error: ', average_diff_power[-1], ' fp_average_error: ', fp_mean_power[-1])\n",
    "    print(\"\\n\")\n",
    "    var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + dtime + \".dat\", \"wb\") # file for saving results\n",
    "    pickle.dump([average_diff_power, fp_mean_power, number_samples], file=var_f)\n",
    "    var_f.close()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power[8], average_diff_power[9] = average_diff_power[9], average_diff_power[8]\n",
    "# fp_mean_power = fp_mean_power[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapee = Input(shape=(number_image_channels, max_x, max_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapee[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(1, 0)\n",
    "cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnn.history.history['val_mean_absolute_error'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(10, 0, 0)\n",
    "cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "            (validation_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3]\n",
    "min_error = float('inf')\n",
    "best_model, best_lam = None, None\n",
    "for lamb in lambda_vec:\n",
    "    print(\"Lambda:\", lamb)\n",
    "    cnn = cnn_model(15, lamb, 0)\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "    cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "            (validation_size + 1))\n",
    "    if cnn.history.history['val_mean_absolute_error'][-1] < min_error:\n",
    "        min_error = cnn.history.history['val_mean_absolute_error'][-1]\n",
    "        best_model = cnn\n",
    "        best_lam = lamb\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_lam)\n",
    "print(best_model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just run to dispaly the image. First change return line from create_image\n",
    "aa = np.swapaxes(np.append(np.array(x_train[50]), np.zeros((2,max_x, max_y), dtype=float_memory_used), axis=0), 0, 2)\n",
    "plt.imshow(aa)\n",
    "# plt.imsave('image.png', aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to read saved variables\n",
    "var_ff = open('ML/data/pictures_1000_1000/log_201912_0705_37.txt', 'rb')\n",
    "[average_diff_power_1, fp_mean_power_1, number_samples_1] = pickle.load(var_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_mean_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power[-1]*(data_reg.shape[0] - max_train_samples)/(300-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_fp_mae/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_mean_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pydotplus\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "keras.utils.vis_utils.pydot = pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARALLEL CNN\n",
    "def cnn_model(num_filters, kernel_lam, bias_lam):\n",
    "#     num_filters, lam = 5, 5\n",
    "    data_format = 'channels_first'\n",
    "    convolution_filter, dense_filter = 'selu', 'linear' #softsign, sigmoid; relu, linear\n",
    "    filter_shape, pool_size = (3, 3), (2,2)\n",
    "    # CNN for PU image\n",
    "    input1  = layers.Input(shape=(number_image_channels - 1, max_x, max_y), name='pus_input')\n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(input1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    \n",
    "    # CNN for SU\n",
    "    input2  = layers.Input(shape=(1, max_x, max_y), name='su_input')\n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(input2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    \n",
    "    # concatanate two CNN outputs\n",
    "    x = layers.concatenate([x1, x2])\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    x = layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    out = layers.Dense(1, activation=dense_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    \n",
    "    model = models.Model(inputs=[input1, input2], outputs=out)\n",
    "#     plot_model(model, to_file='model.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'square'\n",
    "# style = \"image_intensity\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# average_diff_power = [9.110476626067186, 21.070721128267266, 9.389938883165568, 10.886098907990405,\n",
    "#                                        7.697396928362106, 7.522477509027216, 9.493729427772132, 8.198866980620753,\n",
    "#                                        7.781910785203122, 9.41743984825801, 8.499455442627129, 9.86776958065812,\n",
    "#                                        9.033719411254367, 8.150143941293027, 8.963829050517273, 8.708150642874065,\n",
    "#                                        7.468060397898071, 8.233182799553932,8.206, 7.768]\n",
    "# fp_mean_power =  [8.174990557021465, 0.18043087058937837, 1.5141939559853392, 10.273307557711494,\n",
    "#                                    3.2306742061521443, 4.423113329284006, 8.674172526579392, 2.38235061342411,\n",
    "#                                    5.014172646429496, 6.884079514994618, 3.4544130456368367, 7.81721202679044,\n",
    "#                                    6.438635364829745, 4.069245107144559, 5.202978504937615, 3.405858414831347,\n",
    "#                                    4.117573271657338, 2.8100743146184377, 3.951, 3.502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAX_POWER ANAlysis\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# pu_shape, su_shape = 'circle', 'circle'\n",
    "# style = \"image_intensity\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# test_size = 3670\n",
    "# average_diff_power = [7.811849328268183, 9.178415418536536, 8.11891504382307, 7.881934146750136, 7.918868224324312,\n",
    "#                       7.709452054502398, 7.471729821563216, 8.63783455122861, 7.7635068514166345, 8.557134470036884,\n",
    "#                       8.103793715416188, 9.189284948409279, 11.977416480154307, 8.291134394492891, 8.960065032512803,\n",
    "#                       9.992745143323642, 8.475335283779392, 8.051642160173987, 7.322538645284376, 7.768582958795206]\n",
    "# fp_mean_power = [6.1844398077234635, 1.6157812496465958, 6.5620574110067595, 2.898169187355567, 6.262096880097353,\n",
    "#                  2.5478307871639267, 3.5784209073932067, 7.416731632966506, 5.5822838290638135, 5.800529848947965,\n",
    "#                  4.6984887763519785, 2.337296353076653, 9.85739104089764, 3.710259461284922, 5.323224159423669, \n",
    "#                  6.198328912769283, 2.302462751745074, 4.023802978234984, 3.781413967880959, 3.2793608103510508]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle'\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# num_pus = 15\n",
    "average_diff_power = [9.711, 7.867, 8.958, 7.571, 7.509, 7.891, 8.272, 7.118, 7.696, 7.689, 8.026, 9.674, 7.51, 7.771, 8.17,\n",
    "                      7.938, 7.869, 7.833, 9.434, 8.501]\n",
    "fp_mean_power = [9.229, 5.101, 8.037, 3.993, 5.095, 2.491, 2.298, 4.654, 3.787, 2.685, 5.676, 8.033, 3.911, 4.235, 3.278,\n",
    "                 5.809, 3.586, 4.257, 4.377, 5.015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "\n",
    "# number_samples = [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 8001, 1000))\n",
    "\n",
    "\n",
    "# cnn_type = \"classification\"  # {\"classification\", \"regression\"}\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 200, 200, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# else:\n",
    "#     su_param = None\n",
    "# sensors = False\n",
    "# if sensors:\n",
    "#     sensors_num = 50\n",
    "#     sensors_file_path = \"rsc/\" + str(sensors_num) + \"/sensors\"\n",
    "    \n",
    "average_diff_power = [6.779, 5.645, 5.473, 4.982, 4.481, 4.071, 4.05, 3.639, 2.813, 2.343, 2.21, 2.372, 2.005, 1.997,\n",
    "                      1.937, 1.901]\n",
    "\n",
    "fp_mean_power = [4.073, 2.409, 3.424, 3.163, 2.833, 2.663, 2.857, 2.744, 1.744, 1.33, 1.184, 1.55, 0.579, 1.216, 1.492, 1.266]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "\n",
    "number_samples = [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 6001, 1000)) + [8000]\n",
    "# dataframe = pd.read_csv('ML/data/dynamic_pus_using_pus50000_15PUs_201912_3000_40_200.txt', delimiter=',', header=None)\n",
    "# dataframe_max = pd.read_csv('ML/data/dynamic_pus_max_power50000_15PUs_201912_3000_40_200.txt', delimiter=',', header=None)\n",
    "\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 200, 200, 4, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 5\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# else:\n",
    "#     su_param = None\n",
    "# sensors = False\n",
    "    \n",
    "average_diff_power = [12.742, 12.906, 12.731, 12.595, 12.859, 13.272, 12.632, 12.647, 11.309, 7.455, 7.131, 5.677,\n",
    "                      5.645, 5.292, 4.445]\n",
    "\n",
    "fp_mean_power = [5.963, 5.861, 8.957, 8.821, 8.215, 9.518, 8.633, 6.644, 6.605, 3.919, 2.539, 3.866, 1.96, 2.717, 1.671]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_diff_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_width = 5\n",
    "marker_size = 12\n",
    "reg_style = 'solid'\n",
    "class_reg = 'dashed'\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, average_diff_power, color='r', linewidth=line_width, markersize=marker_size, linestyle=class_reg)\n",
    "plt.plot(number_samples, fp_mean_power, color='midnightblue', linewidth=line_width, markersize=marker_size, linestyle=class_reg)\n",
    "plt.xlabel('# of Training Samples', fontsize=47)\n",
    "plt.ylabel('Avg. Diff. wrt Opt. (dB)', fontsize=45)\n",
    "plt.title('Dynamic PUs(200m*200m)')\n",
    "plt.grid(True)\n",
    "\n",
    "ax.set_yticks(np.arange(0,14, 2))\n",
    "# ax.set_xticks(np.arange(100,7000, 1500))\n",
    "plt.rcParams.update({'font.size': 42})\n",
    "ax.tick_params(axis='x', labelsize=46)\n",
    "ax.tick_params(axis='y', labelsize=45)\n",
    "\n",
    "# matplotlib.rcParams.update({'font.size': 22})\n",
    "\n",
    "ax.set_ylim([0, 14])\n",
    "ax.set_xlim([0, 8000])\n",
    "plt.legend(['Total', 'False-Positive'], ncol=2, loc='best', handletextpad=0.1,borderpad=0, columnspacing=0.2, borderaxespad=0.2)\n",
    "# plt.legend(handletextpad=0.1)\n",
    "plt.savefig('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + dtime + \".png\", \n",
    "            bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(image_dir + '/image10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/'.join(image_dir.split('/')[:-1]) + '/log_5__202006_2714_19.dat', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/home/shahrokh/projects/research/MLSpectrumAllocation/ML/data/pictures_1000_1000/log/noisy_std_1/' +\n",
    "            'pu_circle_su_circle_30/raw_power_min_max_norm/color/log_4/pus/log_4__202005_0512_10.dat', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[average_diff_power, fp_mean_power, number_samples, best_lambda, \n",
    " dataset_name, max_dataset_name, average_power_conserve, \n",
    " fp_mean_power_conserve] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(number_samples)\n",
    "print(average_diff_power)\n",
    "print(fp_mean_power)\n",
    "print(best_lambda)\n",
    "print(average_power_conserve)\n",
    "print(fp_mean_power_conserve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fp1, fp2, fp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples1, samples2, samples3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
