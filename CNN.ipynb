{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datetime, time\n",
    "import os, sys\n",
    "import tqdm\n",
    "import gc\n",
    "from multiprocessing import Process\n",
    "Point = namedtuple('Point', ('x', 'y'))\n",
    "Circle = namedtuple('Circle', ('r'))\n",
    "Square = namedtuple('Square', ('side'))\n",
    "Rectangle = namedtuple('Rectangle', ('length', 'width'))\n",
    "PointWithDistance = namedtuple('PointWithDistance', ('p', 'dist'))\n",
    "float_memory_used = 'float16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "# PART 1\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 10001, 1000))\n",
    "number_samples = [128, 256, 512, 1024, 2048, 4096, 8192] \n",
    "# number_samples = [4096, 4915, 5734, 6554, 7373, 8192]\n",
    "\n",
    "# cnn_type = \"classification\"  # {\"classification\", \"regression\"}\n",
    "validation_size, noise_floor = 0.33, -110.0\n",
    "su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "max_x, max_y, number_image_channels, su_szie = 100, 100, 8, 50  # su_size:30 for 1000, 10 for 100\n",
    "cell_size = 10\n",
    "pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "intensity_degradation, slope = 'log', 5  # 'log', 'linear', slope 3 for 1000, 5 for 100\n",
    "max_pus_num, max_sus_num = 20, 4\n",
    "propagation_model = 'splat' # 'splat', 'log', 'testbed'\n",
    "noise, std = False, 1 # False for splat\n",
    "if su_shape == 'circle':\n",
    "    su_param = Circle(su_szie)\n",
    "elif su_shape == 'square':\n",
    "    su_param = Square(su_szie)\n",
    "else:\n",
    "    su_param = None\n",
    "    \n",
    "sensors = False\n",
    "if sensors:\n",
    "    sensors_num = 49\n",
    "    sensors_file_path = \"../../java_workspace/research/commons/resources/sensors/square\" \\\n",
    "    + str(max(max_x, max_y)) + \"/placement/terrain-based/himanshu/\" + str(sensors_num) + \"/sensors.txt\"\n",
    "# num_pus = (data_reg.shape[1] - 3)//3\n",
    "\n",
    "# PART 2\n",
    "number_of_proccessors = 10\n",
    "memory_size_allowed = 4 # in Gigabyte\n",
    "float_size = 0\n",
    "if float_memory_used == \"float16\":\n",
    "    float_size = 16\n",
    "elif float_memory_used == \"float\" or \"float32\":\n",
    "    float_size = 32\n",
    "elif float_memory_used == \"float8\":\n",
    "    float_size = 8\n",
    "\n",
    "\n",
    "batch_size = int(memory_size_allowed / (max_x * max_y * number_image_channels * float_size/(8 * 1024 ** 3)))\n",
    "\n",
    "\n",
    "dtime = datetime.datetime.now().strftime('_%Y%m_%d%H_%M')\n",
    "color = \"color\" if number_image_channels > 1 else \"gray\"\n",
    "image_dir = 'ML/data/pictures_' + str(max_x) + '_' + str(max_y) + '/' + propagation_model + (\n",
    "    \"/noisy_std_\" + str(std) if noise else \"\") + '/pu_' + pu_shape + '_su_' + su_shape + '_' + (\n",
    "    \"\" if su_shape == 'point' else str(su_szie)) + \"/\" + style + \"/\" + color +'/' + (\n",
    "    \"\" if pu_shape == 'point' and su_shape == 'point' else (intensity_degradation + '_' + str(slope))) + (\n",
    "    \"/\" + str(sensors_num) + \"sensors\" if sensors else \"/pus_1_4_sus_7_channels\") + \"/images\"\n",
    "\n",
    "if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML/data/pictures_100_100/splat/pu_circle_su_circle_50/raw_power_min_max_norm/color/log_5/pus_1_4_sus_7_channels/images'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "num_columns = (sensors_num if sensors else max_pus_num * 3 + 1) + max_sus_num * 3 + 2\n",
    "cols = [i for i in range(num_columns)]\n",
    "dataset_name = \"dynamic_pus_using_pus_50000_min10_max20PUs_min1_max4SUs_square100grid_splat_2020_06_12_19_01.txt\"\n",
    "max_dataset_name = \"dynamic_pus_max_power_50000_min10_max20PUs_min1_max4SUs_square100grid_splat_2020_06_12_19_01.txt\"\n",
    "with open('/'.join(image_dir.split('/')[:-1]) + '/datasets' + dtime + '.txt', 'w') as set_file:\n",
    "    set_file.write(dataset_name + \"\\n\")\n",
    "    set_file.write(max_dataset_name)\n",
    "\n",
    "dataframe = pd.read_csv('../../java_workspace/research/spectrum_allocation/resources/data/' \n",
    "                        + dataset_name, delimiter=',', header=None, names=cols)\n",
    "dataframe_max = pd.read_csv('../../java_workspace/research/spectrum_allocation/resources/data/' \n",
    "                            + max_dataset_name, delimiter=',', header=None)\n",
    "\n",
    "dataframe.reset_index(drop=True, inplace=True)\n",
    "dataframe_max.reset_index(drop=True, inplace=True)\n",
    "dataframe_max[dataframe_max.shape[1] - 1] = dataframe_max[dataframe_max.shape[1] - 1].astype(float)\n",
    "\n",
    "dataframe_tot = pd.concat([dataframe, dataframe_max.iloc[:, dataframe_max.columns.values[-1:]]], axis=1,\n",
    "                        ignore_index=True)\n",
    "\n",
    "idx = dataframe_tot[dataframe_tot[dataframe_tot.columns[-1]] == -float('inf')].index\n",
    "dataframe_tot.drop(idx, inplace=True)\n",
    "\n",
    "data_reg = dataframe_tot.values\n",
    "data_reg[data_reg < noise_floor] = noise_floor\n",
    "# data_reg = np.concatenate((dataframe_tot.values[:, 0:dataframe_tot.shape[1]-3], \n",
    "#                            dataframe_tot.values[:, dataframe_tot.shape[1]-1:dataframe_tot.shape[1]]), axis=1)\n",
    "# data_class = dataframe_tot.values[:, 0:dataframe_tot.shape[1]-1]\n",
    "# y_class_power = dataframe_tot.values[:, -1]\n",
    "\n",
    "if sensors:\n",
    "    sensors_location = []\n",
    "    with open(sensors_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.split(',')\n",
    "            sensors_location.append(Point(int(float(line[0])), int(float(line[1]))))\n",
    "del dataframe, dataframe_tot, dataframe_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13000, 76)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = np.concatenate((data_reg[:,:2500], np.ones((4000, 1)), data_reg[:, 2500:2504],\n",
    "               data_reg[:, 2505:]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.   ,  75.   ,  31.   , -25.276,   1.   ,   5.966])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg[0, sensors_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = data_reg[:][:13000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg[512:1024, :] = data_reg[:512, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sensors_num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2d7ac49ee5f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_reg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensors_num\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_reg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensors_num\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sensors_num' is not defined"
     ]
    }
   ],
   "source": [
    "data_reg[4096:8192, sensors_num:] = data_reg[:4096, sensors_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17.     32.     56.     -5.715  16.     12.     -3.88   34.      2.\n",
      "  -3.098  11.     10.    -26.609  61.     41.    -13.344  12.     70.\n",
      " -25.913  81.      6.     -8.532   8.     48.    -26.373   3.     37.\n",
      " -23.107  49.     71.     -2.075  44.     70.     -0.41   52.     11.\n",
      " -11.571  23.     70.     -5.047  20.      2.     -9.039  72.     44.\n",
      " -15.071  22.     29.     -1.901  19.     34.    -16.977   3.     37.\n",
      "   3.      5.461  67.     41.      9.816  88.     33.     52.658   0.\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan   9.31 ]\n",
      "[ 20.      8.     16.    -28.161  38.     56.     -0.383  34.     99.\n",
      "  -3.339  95.     16.    -25.893  23.      5.    -29.936  11.     31.\n",
      " -25.639  77.     64.    -21.992  45.     95.     -2.317  34.     45.\n",
      "  -1.879  61.     39.    -26.608  68.     42.    -22.033  62.     89.\n",
      " -19.191  18.     39.    -28.891  18.     59.    -21.976  93.     78.\n",
      " -13.193   5.     80.    -24.397  93.     34.    -22.49   58.     18.\n",
      " -25.054  95.     17.    -11.308  95.     52.    -10.586   1.     97.\n",
      "  11.     38.734   0.        nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan  -7.67 ]\n"
     ]
    }
   ],
   "source": [
    "print(data_reg[10, :])\n",
    "print(data_reg[266, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(p1: Point, p2: Point):\n",
    "    return ((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2) ** 0.5 * cell_size\n",
    "\n",
    "def calculate_mu_sigma(data, num_pus):\n",
    "    sum_non_noise = 0\n",
    "    for pu_n in range(num_pus): # calculate mu\n",
    "        sum_non_noise += data[pu_n*3+2]\n",
    "    mu = ((max_x * max_y - num_pus) * noise_floor + sum_non_noise)/(max_x * max_y)\n",
    "    sum_square = 0\n",
    "    for pu_n in range(num_pus): # calculate sigma\n",
    "        sum_square += (data[pu_n*3+2]-mu)**2\n",
    "    sum_square += (max_x * max_y - num_pus) * (noise_floor - mu)**2\n",
    "    sigma = math.sqrt(sum_square/(max_x * max_y))\n",
    "    return mu, sigma\n",
    "\n",
    "def get_pu_param(pu_shape: str, intensity_degradation: str, pu_p: float, noise_floor: float, slope: float):\n",
    "    pu_param = None\n",
    "    if pu_shape == 'circle':\n",
    "        if intensity_degradation == \"linear\":\n",
    "            pu_param = Circle(int((pu_p - noise_floor) / slope)) # linear\n",
    "        elif intensity_degradation == \"log\":\n",
    "            pu_param = Circle(int(10 ** ((pu_p - noise_floor) / (10 *slope)))) # log_based\n",
    "    elif pu_shape == 'square':\n",
    "        if intensity_degradation == \"linear\":\n",
    "            pu_param = Square(int(2 ** 0.5 * (pu_p - noise_floor) / slope)) # linear\n",
    "        elif intensity_degradation == \"log\":\n",
    "            pu_param = Square(int(2 ** 0.5 * 10 ** ((pu_p - noise_floor) / (10 *slope)))) # log_based\n",
    "    elif pu_shape == 'point':\n",
    "        pu_param = None\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported PU shape(create_image)! \", pu_shape)\n",
    "    return pu_param\n",
    "\n",
    "def create_image(data, slope, sensors_num, style=\"raw_power_z_score\", noise_floor=-90, pu_shape= 'circle', pu_param=None, \n",
    "                 su_shape='circle', su_param=None, intensity_degradation=\"log\", max_pu_power: float=0):  \n",
    "    # style = {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "    # intensity_degradation= {\"log\", \"linear\"}\n",
    "    # if param is None, it's automatically calculated. Highest brightness(or power value) (255 or 1.) would\n",
    "    # assigned to the center(PU location) and radius(side) would be calculated based on its power, slope, and noise floor.\n",
    "    # If it is given, intensity(power) of pixel beside center would be calculated in the same fashin with an exception that \n",
    "    # intensity below zero(noise_floor) would be replaced by zero(noise_floor)\n",
    "    if style == \"raw_power_min_max_norm\":\n",
    "        # In this way, PUs' location are replaced with their power(dBm) and the power would fade with \n",
    "        # slope till gets noise_floor(in circle shape)\n",
    "        \n",
    "        # creating pu matrix\n",
    "        image = np.zeros((1,number_image_channels,max_x, max_y), dtype=float_memory_used)\n",
    "        if not sensors:\n",
    "            pus_num = int(data[0])\n",
    "#             print(pus_num)\n",
    "            for pu_i in range(pus_num):\n",
    "                pu_x = max(0, min(max_x-1, int(data[pu_i * 3 + 1]))) \n",
    "                pu_y = max(0, min(max_x-1, int(data[pu_i * 3 + 2])))\n",
    "                pu_p = data[pu_i * 3 + 3]\n",
    "#                 print(pu_x, pu_y, pu_p)\n",
    "                if pu_param is None:\n",
    "                    pu_param_p = get_pu_param(pu_shape, intensity_degradation, pu_p, noise_floor, slope)\n",
    "                else:\n",
    "                    pu_param_p = pu_param\n",
    "                points = points_inside_shape(center=Point(pu_x, pu_y), shape=pu_shape, param=pu_param_p)\n",
    "                for point in points:\n",
    "                    if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                        if intensity_degradation == \"linear\":\n",
    "                            image[0][int(abs(pu_p))//10][point.p.x][point.p.y] += (pu_p - slope * point.dist - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                        elif intensity_degradation == \"log\":\n",
    "                            if point.dist < 1:\n",
    "                                image[0][int(abs(pu_p))//5][point.p.x][point.p.y] += (pu_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                            else:\n",
    "                                image[0][int(abs(pu_p))//5][point.p.x][point.p.y] += (pu_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                    max_pu_power - noise_floor)\n",
    "        else:\n",
    "            ss_param, ss_shape = pu_param, pu_shape\n",
    "            for ss_i in range(sensors_num):\n",
    "                ss_x, ss_y, ss_p = max(0, min(max_x-1, int(sensors_location[ss_i].x))), max(0, min(max_x-1, int(\n",
    "                    sensors_location[ss_i].y))), max(noise_floor, data[ss_i])\n",
    "                ss_channel = 0 \n",
    "                if -62.5 <= ss_p < -50.0:\n",
    "                    ss_channel = 1\n",
    "                elif -75.0 <= ss_p < -62.6:\n",
    "                    ss_channel = 2\n",
    "                elif -87.5 <= ss_p < -75.0:\n",
    "                    ss_channel = 3\n",
    "                elif -100.0 <= ss_p < -87.5:\n",
    "                    ss_channel = 4\n",
    "#                 elif -70.0 <= ss_p < -65.0:\n",
    "#                     ss_channel = 5\n",
    "                elif ss_p < -100.0:\n",
    "                    ss_channel = 5\n",
    "                if ss_param is None:\n",
    "                    ss_param_p = get_pu_param(ss_shape, intensity_degradation, ss_p, noise_floor, slope)\n",
    "                else:\n",
    "                    ss_param_p = ss_param\n",
    "                points = points_inside_shape(center=Point(ss_x, ss_y), shape=ss_shape, param=ss_param_p)\n",
    "                for point in points:\n",
    "                    if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                        if intensity_degradation == \"linear\":\n",
    "                            image[0][ss_channel][point.p.x][point.p.y] += (ss_p - slope * point.dist - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                        elif intensity_degradation == \"log\":\n",
    "                            if point.dist < 1:\n",
    "                                image[0][ss_channel][point.p.x][point.p.y] += (ss_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                            else:\n",
    "                                image[0][ss_channel][point.p.x][point.p.y] += (ss_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                    max_pu_power - noise_floor)\n",
    "        del points\n",
    "        # creating su matrix\n",
    "        su_num_idx = sensors_num if sensors else (pus_num * 3 + 1)\n",
    "        su_num = int(data[su_num_idx])\n",
    "#         print(su_num)\n",
    "#         su_num = (len(data) - pus_num * (3 if not sensors else 1)) // 2\n",
    "#         if not (len(data) - pus_num * (3 if not sensors else 1)) % 2:\n",
    "#             raise ValueError(\"Data provided is not correct; can't get SUs' information(create_image)\")\n",
    "        if su_param is None:\n",
    "            # if su_param is unavailable, a circle(square) with radius(side) 1 is created\n",
    "            if su_shape == 'circle':\n",
    "                su_param = Circle(1)\n",
    "            elif su_shape == 'square':\n",
    "                su_param = Square(1)\n",
    "            elif su_shape == 'point':\n",
    "                su_param = None\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported SU shape(create_image)! \", su_shape)\n",
    "        \n",
    "        for su_i in range(su_num - 1):\n",
    "            su_x = max(0, min(max_x-1, int(data[su_num_idx + su_i * 3 + 1])))\n",
    "            su_y = max(0, min(max_x-1, int(data[su_num_idx + su_i * 3 + 2])))\n",
    "            su_p = data[su_num_idx + su_i * 3 + 3]\n",
    "#             su_p = su_intensity\n",
    "            su_param_p = get_pu_param(su_shape, intensity_degradation, su_p, noise_floor, slope)\n",
    "            points = points_inside_shape(center=Point(su_x, su_y), param=su_param_p, shape=su_shape)\n",
    "            su_channel = 0 if number_image_channels == 1 else -2\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if intensity_degradation == \"linear\":\n",
    "                            su_val = (su_p - slope * point.dist - noise_floor)/(max_pu_power - noise_floor)\n",
    "                    elif intensity_degradation == \"log\":\n",
    "                        if point.dist < 1:\n",
    "                            su_val = (su_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                        else:\n",
    "                            su_val = (su_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                    image[0][su_channel][point.p.x][point.p.y] += su_val\n",
    "            del points\n",
    "        # the last and  target SU\n",
    "        su_intensity = 1.\n",
    "        su_x = max(0, min(max_x-1, int(data[su_num_idx + (su_num - 1) * 3 + 1])))\n",
    "        su_y = max(0, min(max_x-1, int(data[su_num_idx + (su_num - 1) * 3 + 2])))\n",
    "#         print(su_x, su_y)\n",
    "        points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "        su_channel = 0 if number_image_channels == 1 else -1\n",
    "        for point in points:\n",
    "            if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                image[0][su_channel][point.p.x][point.p.y] += su_intensity\n",
    "        del points\n",
    "        return image\n",
    "        \n",
    "#         pu_image = [[(noise_floor - mu)/sigma] * max_y for _ in range(max_x)]\n",
    "    elif style == \"image_intensity\":\n",
    "        # creating PU image\n",
    "        image = np.zeros((1,number_image_channels,max_x, max_y), dtype=float_memory_used)\n",
    "        pus_num = int(data[0])\n",
    "#             print(pus_num)\n",
    "        \n",
    "#         for pu_i in range(pus_num):\n",
    "#             pu_x, pu_y, pu_p = max(0, min(max_x-1, int(data[pu_i*3]))), max(0, min(max_x-1, int(data[pu_i*3+1]))), data[pu_i*3+2]\n",
    "#             if pu_param is None:\n",
    "#                 pu_param_p = get_pu_param(pu_shape, intensity_degradation, pu_p, noise_floor, slope)\n",
    "#             else:\n",
    "#                 pu_param_p = pu_param\n",
    "#             points = points_inside_shape(center=Point(pu_x, pu_y), shape=pu_shape, param=pu_param_p)\n",
    "#             for point in points:\n",
    "#                 if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "#                     if intensity_degradation == \"linear\":\n",
    "#                         image[0][0][point.p.x][point.p.y] += max((pu_p - slope * point.dist + abs(noise_floor))\n",
    "#                                                               /(pu_p + abs(noise_floor)), 0)\n",
    "#                     elif intensity_degradation == \"log\":\n",
    "#                         if point.dist < 1:\n",
    "#                             image[0][0][point.p.x][point.p.y] = 1\n",
    "#                         else:\n",
    "#                             image[0][0][point.p.x][point.p.y] += max((pu_p - slope * 10*math.log10(point.dist) + abs(noise_floor))\n",
    "#                                                                  /(pu_p + abs(noise_floor)), 0)\n",
    "#                     image[0][0][point.p.x][point.p.y] = min(image[0][0][point.p.x][point.p.y], 1.0)\n",
    "        for pu_i in range(pus_num):\n",
    "            pu_x = max(0, min(max_x-1, int(data[pu_i * 3 + 1]))) \n",
    "            pu_y = max(0, min(max_x-1, int(data[pu_i * 3 + 2])))\n",
    "            pu_p = data[pu_i * 3 + 3]\n",
    "            \n",
    "            if pu_param is None:\n",
    "                pu_param_p = get_pu_param(pu_shape, intensity_degradation, pu_p, noise_floor, slope)\n",
    "            else:\n",
    "                pu_param_p = pu_param\n",
    "            \n",
    "            points = points_inside_shape(center=Point(pu_x, pu_y), shape=pu_shape, param=pu_param_p)\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if intensity_degradation == \"linear\":\n",
    "                        image[0][0][point.p.x][point.p.y] += (pu_p - slope * point.dist - noise_floor)/(\n",
    "                            max_pu_power - noise_floor)\n",
    "                    elif intensity_degradation == \"log\":\n",
    "                        if point.dist < 1:\n",
    "#                             image[0][0][point.p.x][point.p.y] += (pu_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                            image[0][0][point.p.x][point.p.y] += 0.1\n",
    "                        else:\n",
    "#                             image[0][0][point.p.x][point.p.y] += (pu_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "#                                 max_pu_power - noise_floor)\n",
    "                            image[0][0][point.p.x][point.p.y] += 0.1\n",
    "                        \n",
    "        # creating SU image\n",
    "        del points\n",
    "        # creating su matrix\n",
    "        su_num_idx = sensors_num if sensors else (pus_num * 3 + 1)\n",
    "        su_num = int(data[su_num_idx])\n",
    "#         print(su_num)\n",
    "#         su_num = (len(data) - pus_num * (3 if not sensors else 1)) // 2\n",
    "#         if not (len(data) - pus_num * (3 if not sensors else 1)) % 2:\n",
    "#             raise ValueError(\"Data provided is not correct; can't get SUs' information(create_image)\")\n",
    "        if su_param is None:\n",
    "            # if su_param is unavailable, a circle(square) with radius(side) 1 is created\n",
    "            if su_shape == 'circle':\n",
    "                su_param = Circle(1)\n",
    "            elif su_shape == 'square':\n",
    "                su_param = Square(1)\n",
    "            elif su_shape == 'point':\n",
    "                su_param = None\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported SU shape(create_image)! \", su_shape)\n",
    "        \n",
    "        for su_i in range(su_num - 1):\n",
    "            su_x = max(0, min(max_x-1, int(data[su_num_idx + su_i * 3 + 1])))\n",
    "            su_y = max(0, min(max_x-1, int(data[su_num_idx + su_i * 3 + 2])))\n",
    "            su_p = data[su_num_idx + su_i * 3 + 3]\n",
    "            \n",
    "#             su_p = su_intensity\n",
    "            points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "            su_channel = 0 if number_image_channels == 1 else -1\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if intensity_degradation == \"linear\":\n",
    "                            su_val = (su_p - slope * point.dist - noise_floor)/(max_pu_power - noise_floor)\n",
    "                    elif intensity_degradation == \"log\":\n",
    "                        if point.dist < 1:\n",
    "                            su_val = (su_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                        else:\n",
    "                            su_val = (su_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                    image[0][su_channel][point.p.x][point.p.y] += su_val\n",
    "            del points\n",
    "        # the last and  target SU\n",
    "        su_intensity = 1.\n",
    "        su_x = max(0, min(max_x-1, int(data[su_num_idx + (su_num - 1) * 3 + 1])))\n",
    "        su_y = max(0, min(max_x-1, int(data[su_num_idx + (su_num - 1) * 3 + 2])))\n",
    "#         print(su_x, su_y)\n",
    "        points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "        su_channel = 0 if number_image_channels == 1 else -1\n",
    "        for point in points:\n",
    "            if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                image[0][su_channel][point.p.x][point.p.y] += su_intensity\n",
    "        del points\n",
    "        return image\n",
    "#         su_num = (len(data) - pus_num * 3) // 2\n",
    "#         if not (len(data) - pus_num * 3) % 2:\n",
    "#             raise ValueError(\"Data provided is not correct; can't get SUs' information(create_image)\")\n",
    "# #         su_image = np.zeros((max_x, max_y), dtype=float_memory_used)\n",
    "#         if su_param is None:\n",
    "#             # if su_param is unavailable, a circle(square) with radius(side) 1 is created\n",
    "#             if su_shape == 'circle':\n",
    "#                 su_param = Circle(1)\n",
    "#             elif su_shape == 'square':\n",
    "#                 su_param = Square(1)\n",
    "#             elif su_shape == 'point':\n",
    "#                 su_param = None\n",
    "#             else:\n",
    "#                 raise ValueError(\"Unsupported SU shape(create_image)! \", su_shape)\n",
    "#         su_intensity = 1.\n",
    "#         for su_i in range(su_num):\n",
    "#             su_x, su_y, su_p = max(0, min(max_x-1, int(data[pus_num * (3 if not sensors else 1) +su_i*2]))\n",
    "#                                   ), max(0, min(max_x-1, int(data[pus_num * (3 if not sensors else 1) + su_i*2+1]))), su_intensity\n",
    "#             points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "#             for point in points:\n",
    "#                 if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "#                     if number_image_channels > 1:\n",
    "#                         image[0][1][point.p.x][point.p.y] = su_intensity\n",
    "#                     elif number_image_channels == 1:\n",
    "#                         image[0][0][point.p.x][point.p.y] = su_intensity\n",
    "# #         return np.array([pu_image, su_image, [[0.] * max_y for _ in range(max_x)]], dtype='float32') # return like this to be able to display as an RGB image with pyplot.imshow(imsave)\n",
    "# #         return np.append(pu_image, su_image, axis=0)\n",
    "#         return image\n",
    "        \n",
    "            \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported style(create_image)! \", style)\n",
    "        \n",
    "def points_inside_shape(center: Point, shape: str, param)-> list:\n",
    "    # This function returns points+distance around center with defined shape\n",
    "    if shape == 'circle':\n",
    "        # First creates points inside a square(around orgigin) with 2*r side and then remove those with distance > r.\n",
    "        # Shift all remaining around center. O(4r^2)\n",
    "        r, origin = param.r, Point(0, 0)\n",
    "        square_points = set((Point(x, y) for x in range(max(-int(r/cell_size), -max_x), \n",
    "                             min(int(r/cell_size), max_x) + 1) \n",
    "                             for y in range(max(-r, -max_y), min(r, max_y) + 1)))\n",
    "        points = []\n",
    "        while square_points:\n",
    "            p = square_points.pop()\n",
    "            dist = euclidian_distance(p, origin)\n",
    "            if dist <= r:\n",
    "                points.append(PointWithDistance(Point(p.x + center.x, p.y + center.y), dist))\n",
    "                if p.x != 0:\n",
    "                    points.append(PointWithDistance(Point(-p.x + center.x, p.y + center.y), dist))\n",
    "                    square_points.remove(Point(-p.x, p.y))\n",
    "                if p.y != 0:\n",
    "                    points.append(PointWithDistance(Point(p.x + center.x, -p.y + center.y), dist))\n",
    "                    square_points.remove(Point(p.x, -p.y))\n",
    "                if p.x != 0 and p.y != 0:\n",
    "                    points.append(PointWithDistance(Point(-p.x + center.x, -p.y + center.y), dist))\n",
    "                    square_points.remove(Point(-p.x, -p.y))\n",
    "        del square_points\n",
    "        return points\n",
    "    elif shape == 'square':\n",
    "        half_side = param.side // 2\n",
    "        return [PointWithDistance(Point(x, y), euclidian_distance(Point(x, y), center)) for x in range(-half_side + center.x,\n",
    "                                                                                               half_side + center.x+1) \n",
    "                         for y in range(-half_side + center.y, half_side + center.y + 1)]\n",
    "    elif shape == 'point':\n",
    "        return [PointWithDistance(center, 0)]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported shape(points_inside_shape)! \", shape)\n",
    "        \n",
    "def read_image(image_num):\n",
    "    if False and style == \"image_intensity\":\n",
    "        image = plt.imread(image_dir + '/image' + str(image_num)+'.png')\n",
    "        image = np.swapaxes(image, 0, 2)\n",
    "        image = np.array(image[:number_image_channels], dtype=float_memory_used).reshape(1, number_image_channels, max_x, max_y)\n",
    "    elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\" or style == \"image_intensity\":\n",
    "        suffix = 'npz'  # npy, npz\n",
    "        image = np.load(image_dir + '/image' + str(image_num) + '.' + suffix)  \n",
    "        if type(image) == np.lib.npyio.NpzFile:\n",
    "            image = image['a']\n",
    "    \n",
    "    return image\n",
    "    \n",
    "# TODO: Consider using min_max normalization becasue difference between values using\n",
    "# z-score is huge since most of the pixels have the same value, noise floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 0.000e+00, 2.000e+00, 2.000e+00, 2.000e+00, 2.000e+00,\n",
       "        4.000e+00, 2.000e+00, 4.000e+00, 1.100e+01, 1.200e+01, 1.000e+01,\n",
       "        1.100e+01, 2.100e+01, 2.900e+01, 2.600e+01, 3.500e+01, 5.000e+01,\n",
       "        5.600e+01, 6.100e+01, 5.900e+01, 8.000e+01, 8.900e+01, 8.700e+01,\n",
       "        1.100e+02, 1.040e+02, 1.230e+02, 1.310e+02, 1.300e+02, 1.520e+02,\n",
       "        1.640e+02, 1.520e+02, 1.530e+02, 1.450e+02, 1.480e+02, 1.580e+02,\n",
       "        1.710e+02, 1.910e+02, 1.820e+02, 1.960e+02, 2.220e+02, 2.590e+02,\n",
       "        3.030e+02, 3.360e+02, 3.790e+02, 3.740e+02, 4.740e+02, 5.290e+02,\n",
       "        5.290e+02, 5.360e+02, 6.420e+02, 5.880e+02, 7.400e+02, 7.520e+02,\n",
       "        8.070e+02, 9.160e+02, 9.610e+02, 1.071e+03, 1.111e+03, 1.251e+03,\n",
       "        1.273e+03, 1.338e+03, 1.360e+03, 1.382e+03, 1.398e+03, 1.435e+03,\n",
       "        1.459e+03, 1.497e+03, 1.504e+03, 1.532e+03, 1.491e+03, 1.478e+03,\n",
       "        1.392e+03, 1.283e+03, 1.194e+03, 1.172e+03, 1.048e+03, 9.430e+02,\n",
       "        8.290e+02, 8.210e+02, 7.300e+02, 6.580e+02, 5.710e+02, 4.880e+02,\n",
       "        4.860e+02, 3.710e+02, 4.140e+02, 3.900e+02, 3.280e+02, 2.680e+02,\n",
       "        2.510e+02, 2.350e+02, 2.010e+02, 2.080e+02, 2.240e+02, 2.500e+02,\n",
       "        1.930e+02, 1.700e+02, 1.160e+02, 8.900e+01, 5.500e+01, 4.300e+01,\n",
       "        2.400e+01, 3.600e+01, 9.000e+01, 8.900e+01, 7.200e+01, 4.600e+01,\n",
       "        1.600e+01, 1.400e+01, 6.000e+00, 2.300e+01, 2.500e+01, 1.200e+01,\n",
       "        9.000e+00, 5.000e+00, 2.000e+00, 1.000e+00, 5.400e+01, 5.600e+01,\n",
       "        6.400e+01, 1.430e+02, 1.870e+02, 4.700e+01, 1.900e+01, 1.100e+01,\n",
       "        6.000e+00, 9.600e+01, 4.400e+01, 5.600e+01, 3.000e+01, 5.100e+01,\n",
       "        5.000e+00, 3.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "        0.000e+00, 1.000e+00, 0.000e+00, 2.000e+00, 1.000e+00, 0.000e+00,\n",
       "        2.000e+00, 7.400e+01, 3.000e+00, 0.000e+00, 0.000e+00, 7.800e+01,\n",
       "        1.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        3.500e+01, 4.100e+01, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([-80.082     , -79.83995783, -79.59791566, -79.35587349,\n",
       "        -79.11383133, -78.87178916, -78.62974699, -78.38770482,\n",
       "        -78.14566265, -77.90362048, -77.66157831, -77.41953614,\n",
       "        -77.17749398, -76.93545181, -76.69340964, -76.45136747,\n",
       "        -76.2093253 , -75.96728313, -75.72524096, -75.4831988 ,\n",
       "        -75.24115663, -74.99911446, -74.75707229, -74.51503012,\n",
       "        -74.27298795, -74.03094578, -73.78890361, -73.54686145,\n",
       "        -73.30481928, -73.06277711, -72.82073494, -72.57869277,\n",
       "        -72.3366506 , -72.09460843, -71.85256627, -71.6105241 ,\n",
       "        -71.36848193, -71.12643976, -70.88439759, -70.64235542,\n",
       "        -70.40031325, -70.15827108, -69.91622892, -69.67418675,\n",
       "        -69.43214458, -69.19010241, -68.94806024, -68.70601807,\n",
       "        -68.4639759 , -68.22193373, -67.97989157, -67.7378494 ,\n",
       "        -67.49580723, -67.25376506, -67.01172289, -66.76968072,\n",
       "        -66.52763855, -66.28559639, -66.04355422, -65.80151205,\n",
       "        -65.55946988, -65.31742771, -65.07538554, -64.83334337,\n",
       "        -64.5913012 , -64.34925904, -64.10721687, -63.8651747 ,\n",
       "        -63.62313253, -63.38109036, -63.13904819, -62.89700602,\n",
       "        -62.65496386, -62.41292169, -62.17087952, -61.92883735,\n",
       "        -61.68679518, -61.44475301, -61.20271084, -60.96066867,\n",
       "        -60.71862651, -60.47658434, -60.23454217, -59.9925    ,\n",
       "        -59.75045783, -59.50841566, -59.26637349, -59.02433133,\n",
       "        -58.78228916, -58.54024699, -58.29820482, -58.05616265,\n",
       "        -57.81412048, -57.57207831, -57.33003614, -57.08799398,\n",
       "        -56.84595181, -56.60390964, -56.36186747, -56.1198253 ,\n",
       "        -55.87778313, -55.63574096, -55.3936988 , -55.15165663,\n",
       "        -54.90961446, -54.66757229, -54.42553012, -54.18348795,\n",
       "        -53.94144578, -53.69940361, -53.45736145, -53.21531928,\n",
       "        -52.97327711, -52.73123494, -52.48919277, -52.2471506 ,\n",
       "        -52.00510843, -51.76306627, -51.5210241 , -51.27898193,\n",
       "        -51.03693976, -50.79489759, -50.55285542, -50.31081325,\n",
       "        -50.06877108, -49.82672892, -49.58468675, -49.34264458,\n",
       "        -49.10060241, -48.85856024, -48.61651807, -48.3744759 ,\n",
       "        -48.13243373, -47.89039157, -47.6483494 , -47.40630723,\n",
       "        -47.16426506, -46.92222289, -46.68018072, -46.43813855,\n",
       "        -46.19609639, -45.95405422, -45.71201205, -45.46996988,\n",
       "        -45.22792771, -44.98588554, -44.74384337, -44.5018012 ,\n",
       "        -44.25975904, -44.01771687, -43.7756747 , -43.53363253,\n",
       "        -43.29159036, -43.04954819, -42.80750602, -42.56546386,\n",
       "        -42.32342169, -42.08137952, -41.83933735, -41.59729518,\n",
       "        -41.35525301, -41.11321084, -40.87116867, -40.62912651,\n",
       "        -40.38708434, -40.14504217, -39.903     ]),\n",
       " <a list of 166 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data_reg[:,0:1:sensors_num], bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving images once to save time\n",
    "# run this cell just for creating images\n",
    "def creating_image(start, end):\n",
    "    # for image_num in range(115, data_reg.shape[0]):\n",
    "    # for image_num in range(1625, 5000):\n",
    "    for image_num in tqdm.tqdm(range(start, end+1)):  #4463, data_reg.shape[0]\n",
    "        image = create_image(data=data_reg[image_num], slope=slope, style=style, \n",
    "                             noise_floor=noise_floor,\n",
    "                             pu_shape=pu_shape, su_shape=su_shape, su_param=su_param, \n",
    "                             sensors_num=(sensors_num if sensors else 0), \n",
    "                             intensity_degradation=intensity_degradation, \n",
    "                             max_pu_power=0.0)\n",
    "        if False and style == \"image_intensity\":\n",
    "            if number_image_channels != 3:\n",
    "                image = np.append(np.array(image[0]), np.zeros((3-number_image_channels,max_x, max_y), \n",
    "                                                               dtype=float_memory_used), axis=0)\n",
    "            image_save = np.swapaxes(image, 0, 2)\n",
    "            plt.imsave(image_dir + '/image' + str(image_num)+'.png', image_save)\n",
    "        elif style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\" or style == \"image_intensity\":\n",
    "    #         np.save(image_dir + '/image' + str(image_num), image)\n",
    "            np.savez_compressed(image_dir + '/image' + str(image_num), a=image)\n",
    "        del image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5000/5000 [30:45<00:00,  2.71it/s]\n",
      "100%|| 5000/5000 [30:56<00:00,  2.69it/s]\n",
      " 99%|| 4926/5000 [30:56<00:27,  2.66it/s]\n",
      "100%|| 5000/5000 [31:00<00:00,  2.69it/s]\n",
      "100%|| 5000/5000 [31:01<00:00,  2.69it/s]\n",
      " 99%|| 4974/5000 [31:01<00:05,  4.37it/s]\n",
      "100%|| 5000/5000 [31:04<00:00,  2.68it/s]\n",
      "100%|| 5000/5000 [31:05<00:00,  2.68it/s]\n",
      "100%|| 5000/5000 [31:06<00:00,  2.68it/s]\n",
      "100%|| 5000/5000 [31:10<00:00,  2.67it/s]\n"
     ]
    }
   ],
   "source": [
    "jobs = []\n",
    "proc_sizes = [data_reg.shape[0]//number_of_proccessors] * (number_of_proccessors)\n",
    "proc_sizes[-1] += data_reg.shape[0]%number_of_proccessors\n",
    "proc_idx = [(sum(proc_sizes[:i]), sum(proc_sizes[:i+1])-1) for i in range(number_of_proccessors)]\n",
    "\n",
    "for i in range(number_of_proccessors):\n",
    "    p = Process(target=creating_image, args=(proc_idx[i][0], proc_idx[i][1]))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "for i in range(number_of_proccessors):\n",
    "    jobs[i].join()\n",
    "\n",
    "for i in range(number_of_proccessors):\n",
    "    jobs[i].terminate()\n",
    "    jobs[i].close()\n",
    "del jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, point in enumerate(sensors_location):\n",
    "    print(idx+1, point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, point in enumerate(sensors_location):\n",
    "    print(idx+1, point,\"close\") if math.sqrt((point.x-917)**2+(point.y-415)**2)<=1.5 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [0, 0, 0, 0]\n",
    "idxx = [[],[],[],[]]\n",
    "for i in range(data_reg.shape[0]):\n",
    "    pus_c = int(data_reg[i][0]) * 3 + 1\n",
    "    idx = int(data_reg[i][pus_c]) - 1\n",
    "    count[idx] += 1\n",
    "    idxx[idx].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(count)\n",
    "print(idxx[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm = read_image(1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 300 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8868f8f41dfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 300 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "imm[300].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg[:,-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 19.   ,  85.   ,  40.   ,  -4.085,   1.   ,  72.   , -11.234,\n",
       "        45.   ,   7.   , -18.935,  12.   ,  77.   ,  -2.813,  81.   ,\n",
       "        89.   , -12.192,  50.   ,  27.   , -21.762,  89.   ,  86.   ,\n",
       "       -22.287,  10.   ,  40.   , -24.876,   0.   ,  82.   , -19.398,\n",
       "        13.   ,  98.   , -11.024,   1.   ,   0.   , -27.865,  90.   ,\n",
       "        57.   , -28.798,  42.   ,  99.   , -10.63 ,  44.   ,  26.   ,\n",
       "        -7.316,  87.   ,   0.   ,  -1.174,  75.   ,  52.   ,  -0.134,\n",
       "        90.   ,  32.   , -13.672,  59.   ,  78.   , -10.447,  58.   ,\n",
       "        45.   , -15.252,   4.   ,  65.   ,  51.   ,   4.977,   8.   ,\n",
       "        33.   ,  -2.422,  38.   ,  65.   ,   5.579,  99.   ,  59.   ,\n",
       "        33.884,   0.   ,     nan,     nan,     nan, -13.664])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg[1300][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd50245da10>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 4320x4320 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(60,60))         # Sample figsize in inches\n",
    "sns.heatmap(imm[0][-2], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(num_filters, kernel_lam, bias_lam):\n",
    "#     num_filters, lam = 5, 5\n",
    "    data_format = 'channels_first'\n",
    "    convolution_init, dense_init = \"lecun_normal\", \"RandomNormal\"  # lecun_normal\n",
    "    convolution_filter, dense_filter = 'selu', 'linear' #softsign, sigmoid; relu, linear\n",
    "    filter_shape, pool_size = (3, 3), (2,2)\n",
    "    cnn = models.Sequential()\n",
    "    cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size=pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "    cnn.add(layers.Dropout(0.15))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(1*num_filters, filter_shape,padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size=pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "    cnn.add(layers.Dropout(0.15))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(2*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(2*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "    cnn.add(layers.Dropout(0.15))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "#                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                          kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "    cnn.add(layers.Dropout(0.15))\n",
    "# from here for 1000\n",
    "    if max(max_x, max_y) == 1000:\n",
    "        cnn.add(layers.Conv2D(1*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                             kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                             kernel_initializer=convolution_init))\n",
    "    #     cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "    #                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "    #                          kernel_initializer='lecun_normal'))\n",
    "        cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "        cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Dropout(0.25))\n",
    "\n",
    "        cnn.add(layers.Conv2D(2*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                             kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam), \n",
    "                             kernel_initializer=convolution_init))\n",
    "    #     cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Conv2D(2*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "    #                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "    #                          kernel_initializer='lecun_normal'))\n",
    "        cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "        cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Dropout(0.25))\n",
    "\n",
    "        cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                             kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam), \n",
    "                             kernel_initializer=convolution_init))\n",
    "    #     cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "    #                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "    #                          kernel_initializer='lecun_normal'))\n",
    "        cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "        cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Flatten())\n",
    "    cnn.add(layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=convolution_init))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=convolution_init))\n",
    "    cnn.add(BatchNormalization())\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    cnn.add(layers.Dense(1, activation=dense_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=dense_init))\n",
    "    return cnn\n",
    "\n",
    "\n",
    "class DataBatchGenerator(Sequence):\n",
    "    def __init__(self, dataset:np.ndarray, batch_size:int, start_idx:int,\n",
    "                 number_image_channels:int,\n",
    "                 max_x, max_y, float_memory_used, conserve=0):\n",
    "#         print(dataset.shape[0])\n",
    "        self.dataset, self.batch_size, self.start_idx = dataset, batch_size, start_idx\n",
    "        self.number_image_channels, self.max_x, self.max_y = number_image_channels, max_x, max_y\n",
    "        self.float_memory_used = float_memory_used\n",
    "        self.conserve = conserve\n",
    "    \n",
    "    def __len__(self):\n",
    "        return np.ceil(self.dataset.shape[0] / self.batch_size).astype(np.int)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        size = min(self.dataset.shape[0] - idx * self.batch_size, self.batch_size)\n",
    "        batch_x = np.empty((size, self.number_image_channels, self.max_x, self.max_y), dtype=self.float_memory_used)\n",
    "        batch_y = np.empty((size), dtype=self.float_memory_used)\n",
    "        for i in range(size):\n",
    "            batch_x[i] = read_image(self.start_idx + idx * self.batch_size + i)\n",
    "            batch_y[i] = self.dataset[idx * self.batch_size + i][- 1 - self.conserve]\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "def custom_loss(fp_penalty_coef, fn_penalty_coef):\n",
    "    # custom loss function that penalize false positive and negative differently\n",
    "    def loss(y_true, y_pred):\n",
    "        res = y_pred - y_true\n",
    "        res = tf.where(res > 0, res * fp_penalty_coef, res * fn_penalty_coef)\n",
    "        return K.mean(K.square(res))\n",
    "    return loss\n",
    "\n",
    "def fp_mae(y_true, y_pred):\n",
    "    # custom metric that replace false negative with zero and return the mean of new vector\n",
    "    res = y_pred - y_true\n",
    "    res = tf.nn.relu(res)\n",
    "#     res = tf.where(res <= 0, 0, res)\n",
    "    return K.mean(res)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(10, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_96 (Conv2D)           (None, 10, 100, 100)      730       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_96 (MaxPooling (None, 10, 50, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_120 (Bat (None, 10, 50, 50)        40        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 50, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 10, 50, 50)        910       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_97 (MaxPooling (None, 10, 25, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_121 (Bat (None, 10, 25, 25)        40        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 25, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 20, 25, 25)        1820      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_98 (MaxPooling (None, 20, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_122 (Bat (None, 20, 12, 12)        80        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 30, 12, 12)        5430      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_99 (MaxPooling (None, 30, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_123 (Bat (None, 30, 6, 6)          120       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 1080)              0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 20)                21620     \n",
      "_________________________________________________________________\n",
      "batch_normalization_124 (Bat (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "batch_normalization_125 (Bat (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 31,391\n",
      "Trainable params: 31,171\n",
      "Non-trainable params: 220\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-088f92c63dbd>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_samples = [4096]  # [128, 256, 512, 1024, 2048, 4096, 8192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_samples: 4096 , New samples: 4096\n",
      "Validation size: 1352 , starts: 4096 , ends: 5447\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 20.74760, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_50/raw_power_min_max_norm/color/log_5/pus_1_4_sus_7_channels/models/4096/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00002: val_mae improved from 20.74760 to 20.70426, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_50/raw_power_min_max_norm/color/log_5/pus_1_4_sus_7_channels/models/4096/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00003: val_mae improved from 20.70426 to 20.65207, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_50/raw_power_min_max_norm/color/log_5/pus_1_4_sus_7_channels/models/4096/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00004: val_mae improved from 20.65207 to 20.55447, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_50/raw_power_min_max_norm/color/log_5/pus_1_4_sus_7_channels/models/4096/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00005: val_mae improved from 20.55447 to 20.43659, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_50/raw_power_min_max_norm/color/log_5/pus_1_4_sus_7_channels/models/4096/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00006: val_mae improved from 20.43659 to 20.35075, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_50/raw_power_min_max_norm/color/log_5/pus_1_4_sus_7_channels/models/4096/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00007: val_mae improved from 20.35075 to 20.12534, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_50/raw_power_min_max_norm/color/log_5/pus_1_4_sus_7_channels/models/4096/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 20.12534 to 20.01781, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_50/raw_power_min_max_norm/color/log_5/pus_1_4_sus_7_channels/models/4096/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 20.01781 to 20.00494, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_50/raw_power_min_max_norm/color/log_5/pus_1_4_sus_7_channels/models/4096/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 20.00494\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 20.00494\n",
      "\n",
      "Lambda: 1 , Time: 0:03:06\n",
      "Train Error(all epochs): 17.15140151977539 \n",
      " [20.205, 20.196, 20.192, 20.179, 20.159, 20.155, 20.167, 20.096, 20.129, 20.085, 20.053, 20.056, 20.081, 20.106, 19.968, 20.046, 19.961, 19.821, 19.681, 19.592, 19.481, 18.988, 19.1, 18.777, 18.67, 18.407, 18.1, 17.581, 17.455, 17.151]\n",
      "Train FP Error(all epochs): 8.792966842651367 \n",
      " [13.597, 13.58, 13.565, 13.54, 13.505, 13.467, 13.427, 13.337, 13.285, 13.18, 13.071, 12.966, 12.86, 12.745, 12.538, 12.434, 12.243, 12.02, 11.787, 11.573, 11.349, 10.931, 10.812, 10.478, 10.264, 9.97, 9.663, 9.265, 9.068, 8.793]\n",
      "Val Error(all epochs): 20.004940032958984 \n",
      " [20.748, 20.704, 20.652, 20.554, 20.437, 20.351, 20.125, 20.018, 20.005, 20.053, 20.014, 20.209, 20.345, 20.703, 20.489, 21.255, 21.428, 22.578, 22.983, 23.187, 23.068, 23.462, 24.029, 23.312, 24.72, 24.337, 24.485, 24.15, 24.578, 24.756]\n",
      "Val FP Error(all epochs): 14.175475120544434 \n",
      " [14.175, 14.223, 14.283, 14.404, 14.566, 14.702, 15.204, 15.715, 16.189, 16.626, 16.415, 17.282, 17.679, 18.516, 18.068, 19.538, 19.802, 21.459, 22.008, 22.261, 22.081, 22.581, 23.222, 22.26, 23.975, 23.261, 23.512, 23.054, 23.458, 23.581]\n",
      "\n",
      "Trainig set size: 4096 , Time: 0:03:06 , best_lambda: 1 , min_  error: 20.005\n"
     ]
    }
   ],
   "source": [
    "# CNN: support batching\n",
    "TEST, CONSERVE = False, False\n",
    "mini_batch = 16 if max(max_x, max_y) == 1000 else 256\n",
    "epochs = 35 if max(max_x, max_y) == 1000 else 30\n",
    "MAX_QUEUE_SIZE, WORKERS = 6, 1\n",
    "fp_penalty_coef, fn_penalty_coef = 1, 1\n",
    "hyper_metric, mode = \"val_mae\", 'min'  # the metric that hyper parameters are tuned with\n",
    "prev_sample = 0\n",
    "lambda_vec = [1]  #0.001, 0.01, 0.1, \n",
    "# lambda_vec = [0.01, 0.1, 1]\n",
    "# lambda_vec = [10]\n",
    "# MODEL_PATH = 'models/'\n",
    "average_diff_power, fp_mean_power = [],[] #[7.177, 8.088, 8.183], [3.438, 3.506, 2.662]\n",
    "best_lambda = []\n",
    "average_diff_power_conserve, fp_mean_power_conserve = [], []\n",
    "all_cnns = []\n",
    "if CONSERVE: # for conservative\n",
    "    prev_number_samples = [0] + number_samples[:-1]\n",
    "\n",
    "for num_sample_idx, number_sample in enumerate(number_samples):\n",
    "#     if num_sample_idx < 3:\n",
    "#         continue\n",
    "#     if num_sample_idx == 0:\n",
    "    if CONSERVE:\n",
    "        data_reg[prev_number_samples[num_sample_idx]:number_sample, -1] = data_reg[\n",
    "            prev_number_samples[num_sample_idx]:number_sample, -1] - 1 # conserv value\n",
    "    MODEL_PATH = '/'.join(image_dir.split('/')[:-1]) + '/models/' + str(number_sample)\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.makedirs(MODEL_PATH)\n",
    "    MODEL_PATH += \"/best_model_lambda_\"\n",
    "    if True:\n",
    "        cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "        for cnn in cnns:\n",
    "#             cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae', fp_mean])\n",
    "            cnn.compile(loss=custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                        optimizer='adam', \n",
    "                        metrics=['mse', 'mae', fp_mae])\n",
    "        checkpointers = [ModelCheckpoint(filepath=MODEL_PATH + str(lamb_idx)+ '.h5',\n",
    "                                         verbose=1, save_best_only=True, \n",
    "                                         monitor=hyper_metric,\n",
    "                                         mode=mode)\n",
    "                         for lamb_idx in range(len(lambda_vec))]\n",
    "    else:\n",
    "        cnns = []\n",
    "        cnns = [models.load_model(MODEL_PATH + str(lamb_idx) + '.h5', \n",
    "                                  custom_objects={ 'loss': custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                                                  'fp_mae': fp_mae }) \n",
    "                for lamb_idx in range(len(lambda_vec))]\n",
    "    number_start = time.time()\n",
    "    train_generator = DataBatchGenerator(dataset=data_reg[prev_sample:number_sample], batch_size=mini_batch,\n",
    "                                         start_idx=prev_sample, number_image_channels=number_image_channels,\n",
    "                                         max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "    \n",
    "\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "    val_generator = DataBatchGenerator(dataset=data_reg[number_sample:number_sample+val_size], \n",
    "                                       batch_size=mini_batch,\n",
    "                                       start_idx=number_sample,\n",
    "                                       number_image_channels=number_image_channels,\n",
    "                                       max_x=max_x, max_y=max_y, \n",
    "                                       float_memory_used=float_memory_used)\n",
    "  \n",
    "    print('number_samples:', number_sample, \", New samples:\", number_sample - prev_sample)\n",
    "    print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", number_sample + val_size - 1)\n",
    "    \n",
    "    for lamb_idx, lamb in enumerate(lambda_vec):\n",
    "#     for lamb_idx, lamb in enumerate(lambda_vec[:len(lambda_vec) - num_sample_idx//2]):\n",
    "#         if num_sample_idx == 3 and lamb_idx < 4:\n",
    "#             continue\n",
    "        lambda_start = time.time()\n",
    "        cnns[lamb_idx].fit(train_generator, epochs=epochs, verbose=0,\n",
    "                           validation_data=val_generator, \n",
    "                           shuffle=True, callbacks=[checkpointers[lamb_idx]], \n",
    "                           workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, \n",
    "                           use_multiprocessing=False)\n",
    "        \n",
    "        print(\"\\nLambda:\", lamb, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - lambda_start))))\n",
    "        print(\"Train Error(all epochs):\", min(cnns[lamb_idx].history.history['mae']), '\\n', \n",
    "              [round(val, 3) for val in cnns[lamb_idx].history.history['mae']])\n",
    "        print(\"Train FP Error(all epochs):\", min(cnns[lamb_idx].history.history['fp_mae']), '\\n',\n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['fp_mae']])\n",
    "        print(\"Val Error(all epochs):\", min(cnns[lamb_idx].history.history['val_mae']), '\\n', \n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['val_mae']])\n",
    "        print(\"Val FP Error(all epochs):\", min(cnns[lamb_idx].history.history['val_fp_mae']), '\\n',\n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['val_fp_mae']])\n",
    "#     if num_sample_idx == 3:    \n",
    "#         models_min_mae = [8.27781, 8.23545, 8.20838, 7.74743]\n",
    "#         models_min_mae += [min(cnns[lamb_idx].history.history[hyper_metric]) for lamb_idx in range(4,lamb_idx+1)]\n",
    "#     else:\n",
    "    models_min_mae = [min(cnns[lam_idx].history.history[hyper_metric]) for\n",
    "                      lam_idx,_ in enumerate(lambda_vec)]\n",
    "    best_lamb_idx = models_min_mae.index(min(models_min_mae))\n",
    "    best_lambda.append(lambda_vec[best_lamb_idx])\n",
    "    print(\"\\nTrainig set size:\", number_sample, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - \n",
    "                                                                                              number_start))),\n",
    "          \", best_lambda:\", lambda_vec[best_lamb_idx], \", min_\" , (\"fp_\" if hyper_metric == \"val_fp_mae\" else \"\"),\n",
    "          \"error:\", round(min(models_min_mae), 3))\n",
    "    all_cnns.append(cnns)\n",
    "    del cnns, train_generator, val_generator, checkpointers\n",
    "    \n",
    "    if TEST:\n",
    "        # evaluating test images\n",
    "        best_model = None\n",
    "        best_model = models.load_model(MODEL_PATH + str(best_lamb_idx) + '.h5', \n",
    "                                       custom_objects={ 'loss': custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                                                       'fp_mae': fp_mae,\n",
    "                                                      'mae':'mae', 'mse':'mse'})\n",
    "        test_generator = DataBatchGenerator(dataset=data_reg[number_sample + val_size:], \n",
    "                                            batch_size=mini_batch,\n",
    "                                            start_idx=number_sample + val_size, \n",
    "                                            number_image_channels=number_image_channels,\n",
    "                                            max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "\n",
    "        print(\"Test starts: \", number_sample + val_size, \", ends: \", data_reg.shape[0] - 1)\n",
    "        time.sleep(1)\n",
    "        test_res = best_model.evaluate(test_generator, verbose=1, \n",
    "                                       workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, use_multiprocessing=False)\n",
    "        \n",
    "        test_mae_idx, test_fp_mae_idx = [best_model.metrics_names.index(mtrc) \n",
    "                                         for mtrc in ['mae','fp_mae']]\n",
    "        test_mae, test_fp_mae = test_res[test_mae_idx], test_res[test_fp_mae_idx]\n",
    "        average_diff_power.append(round(test_mae, 3))\n",
    "        fp_mean_power.append(round(test_fp_mae, 3))\n",
    "        print('average_error: ', average_diff_power[-1], ', fp_average_error: ', \n",
    "              fp_mean_power[-1])\n",
    "        \n",
    "        if False:\n",
    "            test_generator_conserve = DataBatchGenerator(dataset=data_reg[number_sample + val_size:], \n",
    "                                                         batch_size=mini_batch,\n",
    "                                                         start_idx=number_sample + val_size, \n",
    "                                                         number_image_channels=number_image_channels,\n",
    "                                                         max_x=max_x, max_y=max_y, \n",
    "                                                         float_memory_used=float_memory_used, \n",
    "                                                         conserve=1)\n",
    "            test_res_conserve = best_model.evaluate(test_generator_conserve, verbose=1, \n",
    "                                                    workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, \n",
    "                                                    use_multiprocessing=False)\n",
    "            test_mae_cons, test_fp_mae_cons = test_res_conserve[test_mae_idx], test_res_conserve[test_fp_mae_idx]\n",
    "            average_diff_power_conserve.append(round(test_mae_cons, 3))\n",
    "            fp_mean_power_conserve.append(round(test_fp_mae_cons, 3))\n",
    "            print('Conserve, average_error: ', average_diff_power_conserve[-1], ', fp_average_error: ',\n",
    "                 fp_mean_power_conserve[-1])\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        \n",
    "        var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                     dtime + \".dat\", \"wb\") # file for saving results\n",
    "        pickle.dump([average_diff_power, fp_mean_power, number_samples, best_lambda, \n",
    "                     dataset_name, max_dataset_name, average_diff_power_conserve, fp_mean_power_conserve],\n",
    "                    file=var_f)\n",
    "        var_f.close()\n",
    "        del best_model, test_generator\n",
    "#     prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 256, 512, 1024, 2048, 4096, 8192]\n",
      "[8.158, 7.664, 7.332, 7.159, 7.066, 7.113, 6.794]\n",
      "[1.558, 1.948, 2.42, 2.822, 3.632, 3.832, 3.645]\n",
      "[]\n",
      "[]\n",
      "[0.001, 0.01, 0.1, 0.01, 1, 0.001, 1]\n"
     ]
    }
   ],
   "source": [
    "print(number_samples)\n",
    "print(average_diff_power)\n",
    "print(fp_mean_power)\n",
    "# print(best_lambda)\n",
    "print(average_diff_power_conserve)\n",
    "print(fp_mean_power_conserve)\n",
    "print(best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1466.68115234375,\n",
       "  1459.4544677734375,\n",
       "  1448.2159423828125,\n",
       "  1427.2926025390625,\n",
       "  1388.8023681640625,\n",
       "  1323.450439453125,\n",
       "  1222.5673828125,\n",
       "  1075.687744140625,\n",
       "  891.4771118164062,\n",
       "  703.18701171875,\n",
       "  495.680908203125,\n",
       "  330.5108642578125,\n",
       "  218.5363311767578,\n",
       "  157.66212463378906,\n",
       "  125.11569213867188,\n",
       "  95.85566711425781,\n",
       "  85.90016174316406,\n",
       "  66.99349975585938,\n",
       "  59.24590301513672,\n",
       "  50.673858642578125,\n",
       "  45.19337463378906,\n",
       "  44.061744689941406,\n",
       "  42.625240325927734,\n",
       "  39.62968826293945,\n",
       "  37.51704406738281,\n",
       "  36.51383972167969,\n",
       "  35.33610916137695,\n",
       "  33.22075271606445,\n",
       "  33.19552230834961,\n",
       "  32.014808654785156,\n",
       "  32.66262435913086,\n",
       "  33.656410217285156,\n",
       "  33.250587463378906,\n",
       "  31.449359893798828,\n",
       "  31.671939849853516,\n",
       "  30.960254669189453,\n",
       "  30.79509735107422,\n",
       "  32.09065628051758,\n",
       "  36.07826614379883,\n",
       "  35.02832794189453,\n",
       "  35.388641357421875,\n",
       "  31.01849937438965,\n",
       "  30.39098358154297,\n",
       "  29.20606231689453,\n",
       "  26.2185115814209,\n",
       "  21.933250427246094,\n",
       "  19.50713348388672,\n",
       "  17.70354652404785,\n",
       "  15.730507850646973,\n",
       "  15.011495590209961,\n",
       "  14.616086959838867,\n",
       "  14.664350509643555,\n",
       "  14.801301956176758,\n",
       "  13.730393409729004,\n",
       "  12.622812271118164,\n",
       "  11.908035278320312,\n",
       "  12.237488746643066,\n",
       "  11.547143936157227,\n",
       "  12.703455924987793,\n",
       "  15.908567428588867,\n",
       "  17.670663833618164,\n",
       "  19.0484619140625,\n",
       "  19.0216007232666,\n",
       "  18.42194366455078,\n",
       "  19.716712951660156,\n",
       "  19.713729858398438,\n",
       "  19.26943588256836,\n",
       "  18.659955978393555,\n",
       "  18.390918731689453,\n",
       "  19.38798713684082,\n",
       "  17.391788482666016,\n",
       "  15.803594589233398,\n",
       "  14.259018898010254,\n",
       "  12.645502090454102,\n",
       "  11.144073486328125,\n",
       "  9.880877494812012,\n",
       "  10.015406608581543,\n",
       "  9.10551929473877,\n",
       "  9.468545913696289,\n",
       "  9.684150695800781],\n",
       " 'mse': [1466.40234375,\n",
       "  1459.1744384765625,\n",
       "  1447.9342041015625,\n",
       "  1427.008544921875,\n",
       "  1388.5146484375,\n",
       "  1323.1578369140625,\n",
       "  1222.26904296875,\n",
       "  1075.382568359375,\n",
       "  891.1646118164062,\n",
       "  702.8670654296875,\n",
       "  495.3540954589844,\n",
       "  330.177734375,\n",
       "  218.1976776123047,\n",
       "  157.31893920898438,\n",
       "  124.76896667480469,\n",
       "  95.5062255859375,\n",
       "  85.54891967773438,\n",
       "  66.64082336425781,\n",
       "  58.89213180541992,\n",
       "  50.319190979003906,\n",
       "  44.8378791809082,\n",
       "  43.70537185668945,\n",
       "  42.26808166503906,\n",
       "  39.271785736083984,\n",
       "  37.15831756591797,\n",
       "  36.15440368652344,\n",
       "  34.9759407043457,\n",
       "  32.85995101928711,\n",
       "  32.83397674560547,\n",
       "  31.65245819091797,\n",
       "  32.29953384399414,\n",
       "  33.292686462402344,\n",
       "  32.886146545410156,\n",
       "  31.0841121673584,\n",
       "  31.306007385253906,\n",
       "  30.59371566772461,\n",
       "  30.427852630615234,\n",
       "  31.722614288330078,\n",
       "  35.709442138671875,\n",
       "  34.65871810913086,\n",
       "  35.018280029296875,\n",
       "  30.647275924682617,\n",
       "  30.018945693969727,\n",
       "  28.833263397216797,\n",
       "  25.84497833251953,\n",
       "  21.559043884277344,\n",
       "  19.13226890563965,\n",
       "  17.328067779541016,\n",
       "  15.354450225830078,\n",
       "  14.634973526000977,\n",
       "  14.239108085632324,\n",
       "  14.286808967590332,\n",
       "  14.423301696777344,\n",
       "  13.351968765258789,\n",
       "  12.243975639343262,\n",
       "  11.528801918029785,\n",
       "  11.857804298400879,\n",
       "  11.16706371307373,\n",
       "  12.322933197021484,\n",
       "  15.527551651000977,\n",
       "  17.28929901123047,\n",
       "  18.66668128967285,\n",
       "  18.639238357543945,\n",
       "  18.039045333862305,\n",
       "  19.333303451538086,\n",
       "  19.32965087890625,\n",
       "  18.884702682495117,\n",
       "  18.274642944335938,\n",
       "  18.005123138427734,\n",
       "  19.001617431640625,\n",
       "  17.004762649536133,\n",
       "  15.416025161743164,\n",
       "  13.870877265930176,\n",
       "  12.256819725036621,\n",
       "  10.754988670349121,\n",
       "  9.491397857666016,\n",
       "  9.62549114227295,\n",
       "  8.715226173400879,\n",
       "  9.077939987182617,\n",
       "  9.293224334716797],\n",
       " 'mae': [20.21358299255371,\n",
       "  20.1849365234375,\n",
       "  20.136472702026367,\n",
       "  20.037809371948242,\n",
       "  19.83868408203125,\n",
       "  19.489219665527344,\n",
       "  18.984161376953125,\n",
       "  18.15083122253418,\n",
       "  17.031635284423828,\n",
       "  15.801918983459473,\n",
       "  14.000191688537598,\n",
       "  12.077589988708496,\n",
       "  10.46805477142334,\n",
       "  9.181326866149902,\n",
       "  8.365257263183594,\n",
       "  7.422854423522949,\n",
       "  7.099658489227295,\n",
       "  6.3662638664245605,\n",
       "  6.042021751403809,\n",
       "  5.55050802230835,\n",
       "  5.200977802276611,\n",
       "  5.14588737487793,\n",
       "  5.024637699127197,\n",
       "  4.868701457977295,\n",
       "  4.718777656555176,\n",
       "  4.669982433319092,\n",
       "  4.590871810913086,\n",
       "  4.460169315338135,\n",
       "  4.415349960327148,\n",
       "  4.357052326202393,\n",
       "  4.387048721313477,\n",
       "  4.460641860961914,\n",
       "  4.414130210876465,\n",
       "  4.300333023071289,\n",
       "  4.249821186065674,\n",
       "  4.265463352203369,\n",
       "  4.226836681365967,\n",
       "  4.290592670440674,\n",
       "  4.50022554397583,\n",
       "  4.428068161010742,\n",
       "  4.420734405517578,\n",
       "  4.223166465759277,\n",
       "  4.171818256378174,\n",
       "  4.073684215545654,\n",
       "  3.8836255073547363,\n",
       "  3.5307157039642334,\n",
       "  3.344693899154663,\n",
       "  3.1800122261047363,\n",
       "  3.0031309127807617,\n",
       "  2.9335103034973145,\n",
       "  2.9017577171325684,\n",
       "  2.9096829891204834,\n",
       "  2.9001312255859375,\n",
       "  2.7682738304138184,\n",
       "  2.683194875717163,\n",
       "  2.6023342609405518,\n",
       "  2.615593671798706,\n",
       "  2.5545554161071777,\n",
       "  2.6716434955596924,\n",
       "  2.941032648086548,\n",
       "  3.029702663421631,\n",
       "  3.190977096557617,\n",
       "  3.189059257507324,\n",
       "  3.08711314201355,\n",
       "  3.139106273651123,\n",
       "  3.168802499771118,\n",
       "  3.155181646347046,\n",
       "  3.1510560512542725,\n",
       "  3.0659103393554688,\n",
       "  3.127964496612549,\n",
       "  2.97749924659729,\n",
       "  2.8329215049743652,\n",
       "  2.7379753589630127,\n",
       "  2.5701651573181152,\n",
       "  2.420846939086914,\n",
       "  2.269974708557129,\n",
       "  2.2471694946289062,\n",
       "  2.1738996505737305,\n",
       "  2.2200984954833984,\n",
       "  2.2475500106811523],\n",
       " 'fp_mae': [13.595062255859375,\n",
       "  13.543148040771484,\n",
       "  13.469622611999512,\n",
       "  13.359582901000977,\n",
       "  13.178335189819336,\n",
       "  12.890595436096191,\n",
       "  12.488739013671875,\n",
       "  11.811768531799316,\n",
       "  10.85794448852539,\n",
       "  9.722040176391602,\n",
       "  8.224762916564941,\n",
       "  6.64666223526001,\n",
       "  5.352294445037842,\n",
       "  4.4095587730407715,\n",
       "  3.823214054107666,\n",
       "  3.3838589191436768,\n",
       "  3.2506933212280273,\n",
       "  2.9903361797332764,\n",
       "  2.896470785140991,\n",
       "  2.6655707359313965,\n",
       "  2.518122673034668,\n",
       "  2.4676716327667236,\n",
       "  2.3930845260620117,\n",
       "  2.3910892009735107,\n",
       "  2.306485652923584,\n",
       "  2.25899338722229,\n",
       "  2.1810953617095947,\n",
       "  2.170879364013672,\n",
       "  2.1907317638397217,\n",
       "  2.1841588020324707,\n",
       "  2.1581597328186035,\n",
       "  2.1455554962158203,\n",
       "  2.1701340675354004,\n",
       "  2.164693832397461,\n",
       "  2.085535764694214,\n",
       "  2.0791773796081543,\n",
       "  2.0613090991973877,\n",
       "  2.130544662475586,\n",
       "  2.2528929710388184,\n",
       "  2.187265396118164,\n",
       "  2.1507508754730225,\n",
       "  2.1086602210998535,\n",
       "  2.1030983924865723,\n",
       "  2.0200417041778564,\n",
       "  1.9499661922454834,\n",
       "  1.748576045036316,\n",
       "  1.6437604427337646,\n",
       "  1.578392505645752,\n",
       "  1.5081000328063965,\n",
       "  1.415501594543457,\n",
       "  1.4062086343765259,\n",
       "  1.4682185649871826,\n",
       "  1.4402393102645874,\n",
       "  1.359897494316101,\n",
       "  1.329635500907898,\n",
       "  1.2789870500564575,\n",
       "  1.305834174156189,\n",
       "  1.2267875671386719,\n",
       "  1.3345905542373657,\n",
       "  1.4658681154251099,\n",
       "  1.5269436836242676,\n",
       "  1.563489317893982,\n",
       "  1.5990937948226929,\n",
       "  1.552750825881958,\n",
       "  1.5352344512939453,\n",
       "  1.5911648273468018,\n",
       "  1.590926170349121,\n",
       "  1.6045494079589844,\n",
       "  1.532492756843567,\n",
       "  1.5396836996078491,\n",
       "  1.4899057149887085,\n",
       "  1.4230585098266602,\n",
       "  1.40553879737854,\n",
       "  1.315374732017517,\n",
       "  1.2095550298690796,\n",
       "  1.1343059539794922,\n",
       "  1.118564248085022,\n",
       "  1.0855193138122559,\n",
       "  1.1108542680740356,\n",
       "  1.1311599016189575],\n",
       " 'val_loss': [1521.7515869140625,\n",
       "  1532.923095703125,\n",
       "  1556.802490234375,\n",
       "  1594.5771484375,\n",
       "  1635.0277099609375,\n",
       "  1694.86669921875,\n",
       "  1789.4713134765625,\n",
       "  1864.079833984375,\n",
       "  1922.3721923828125,\n",
       "  1991.9151611328125,\n",
       "  2036.646484375,\n",
       "  2008.399169921875,\n",
       "  2052.4501953125,\n",
       "  2006.42431640625,\n",
       "  2005.289794921875,\n",
       "  1975.189697265625,\n",
       "  1969.43115234375,\n",
       "  1953.6044921875,\n",
       "  1949.12939453125,\n",
       "  1926.154541015625,\n",
       "  1939.8363037109375,\n",
       "  1915.6719970703125,\n",
       "  1904.639404296875,\n",
       "  1901.17138671875,\n",
       "  1863.6278076171875,\n",
       "  1851.999755859375,\n",
       "  1815.4888916015625,\n",
       "  1836.1610107421875,\n",
       "  1798.991455078125,\n",
       "  1807.8416748046875,\n",
       "  1763.2252197265625,\n",
       "  1780.75146484375,\n",
       "  1769.3602294921875,\n",
       "  1792.02294921875,\n",
       "  1766.2442626953125,\n",
       "  1775.3760986328125,\n",
       "  1806.8321533203125,\n",
       "  1804.613525390625,\n",
       "  1792.3900146484375,\n",
       "  1811.5452880859375,\n",
       "  1798.55712890625,\n",
       "  1842.90478515625,\n",
       "  1866.946044921875,\n",
       "  1891.5635986328125,\n",
       "  1910.50537109375,\n",
       "  1927.16845703125,\n",
       "  1956.9439697265625,\n",
       "  1939.69384765625,\n",
       "  1916.9334716796875,\n",
       "  1946.6556396484375,\n",
       "  1915.8038330078125,\n",
       "  1898.233154296875,\n",
       "  1943.2762451171875,\n",
       "  1927.6865234375,\n",
       "  1927.7200927734375,\n",
       "  1947.385009765625,\n",
       "  1925.543212890625,\n",
       "  1916.6641845703125,\n",
       "  1947.6468505859375,\n",
       "  1917.9669189453125,\n",
       "  1950.4005126953125,\n",
       "  1903.205810546875,\n",
       "  1929.5728759765625,\n",
       "  1923.922119140625,\n",
       "  1952.3092041015625,\n",
       "  1897.9144287109375,\n",
       "  1941.355712890625,\n",
       "  1908.57177734375,\n",
       "  1945.901611328125,\n",
       "  1922.416748046875,\n",
       "  1925.1044921875,\n",
       "  1916.720458984375,\n",
       "  1894.3914794921875,\n",
       "  1903.385498046875,\n",
       "  1909.1865234375,\n",
       "  1950.94873046875,\n",
       "  1880.273681640625,\n",
       "  1926.22802734375,\n",
       "  1906.4072265625,\n",
       "  1894.33984375],\n",
       " 'val_mse': [1521.4720458984375,\n",
       "  1532.642333984375,\n",
       "  1556.519775390625,\n",
       "  1594.291015625,\n",
       "  1634.7376708984375,\n",
       "  1694.571044921875,\n",
       "  1789.1695556640625,\n",
       "  1863.7708740234375,\n",
       "  1922.0557861328125,\n",
       "  1991.591552734375,\n",
       "  2036.316162109375,\n",
       "  2008.0628662109375,\n",
       "  2052.109130859375,\n",
       "  2006.0791015625,\n",
       "  2004.94140625,\n",
       "  1974.839111328125,\n",
       "  1969.079345703125,\n",
       "  1953.2510986328125,\n",
       "  1948.775146484375,\n",
       "  1925.799560546875,\n",
       "  1939.4803466796875,\n",
       "  1915.3150634765625,\n",
       "  1904.2818603515625,\n",
       "  1900.8131103515625,\n",
       "  1863.2686767578125,\n",
       "  1851.6397705078125,\n",
       "  1815.1282958984375,\n",
       "  1835.7996826171875,\n",
       "  1798.629638671875,\n",
       "  1807.4788818359375,\n",
       "  1762.86181640625,\n",
       "  1780.3873291015625,\n",
       "  1768.995361328125,\n",
       "  1791.6572265625,\n",
       "  1765.8779296875,\n",
       "  1775.00927734375,\n",
       "  1806.4644775390625,\n",
       "  1804.2452392578125,\n",
       "  1792.0208740234375,\n",
       "  1811.175537109375,\n",
       "  1798.1861572265625,\n",
       "  1842.5330810546875,\n",
       "  1866.5736083984375,\n",
       "  1891.1904296875,\n",
       "  1910.13134765625,\n",
       "  1926.7938232421875,\n",
       "  1956.56884765625,\n",
       "  1939.3179931640625,\n",
       "  1916.557373046875,\n",
       "  1946.27880859375,\n",
       "  1915.42626953125,\n",
       "  1897.8553466796875,\n",
       "  1942.8980712890625,\n",
       "  1927.30810546875,\n",
       "  1927.3408203125,\n",
       "  1947.0054931640625,\n",
       "  1925.1634521484375,\n",
       "  1916.2840576171875,\n",
       "  1947.265869140625,\n",
       "  1917.5855712890625,\n",
       "  1950.0189208984375,\n",
       "  1902.8236083984375,\n",
       "  1929.1900634765625,\n",
       "  1923.5390625,\n",
       "  1951.925537109375,\n",
       "  1897.5299072265625,\n",
       "  1940.9708251953125,\n",
       "  1908.1861572265625,\n",
       "  1945.515380859375,\n",
       "  1922.0301513671875,\n",
       "  1924.7169189453125,\n",
       "  1916.33251953125,\n",
       "  1894.0029296875,\n",
       "  1902.9967041015625,\n",
       "  1908.79736328125,\n",
       "  1950.5592041015625,\n",
       "  1879.88330078125,\n",
       "  1925.837646484375,\n",
       "  1906.0164794921875,\n",
       "  1893.94873046875],\n",
       " 'val_mae': [20.77126121520996,\n",
       "  20.555347442626953,\n",
       "  20.24199676513672,\n",
       "  20.01934242248535,\n",
       "  20.039867401123047,\n",
       "  20.349895477294922,\n",
       "  21.28178596496582,\n",
       "  22.258989334106445,\n",
       "  23.06730079650879,\n",
       "  24.13576316833496,\n",
       "  24.834983825683594,\n",
       "  24.390399932861328,\n",
       "  25.058610916137695,\n",
       "  24.334877014160156,\n",
       "  24.324703216552734,\n",
       "  23.85080909729004,\n",
       "  23.755891799926758,\n",
       "  23.51381492614746,\n",
       "  23.44403839111328,\n",
       "  23.119199752807617,\n",
       "  23.325002670288086,\n",
       "  22.987489700317383,\n",
       "  22.881248474121094,\n",
       "  22.89732551574707,\n",
       "  22.510520935058594,\n",
       "  22.500503540039062,\n",
       "  22.32981300354004,\n",
       "  22.471527099609375,\n",
       "  22.514616012573242,\n",
       "  22.636877059936523,\n",
       "  22.77957534790039,\n",
       "  22.971853256225586,\n",
       "  23.38076400756836,\n",
       "  23.934572219848633,\n",
       "  24.2716064453125,\n",
       "  23.796133041381836,\n",
       "  25.247793197631836,\n",
       "  24.688745498657227,\n",
       "  24.786216735839844,\n",
       "  25.206701278686523,\n",
       "  24.687103271484375,\n",
       "  26.366689682006836,\n",
       "  26.85441780090332,\n",
       "  27.228723526000977,\n",
       "  27.994714736938477,\n",
       "  28.34222984313965,\n",
       "  28.786998748779297,\n",
       "  28.537689208984375,\n",
       "  28.074281692504883,\n",
       "  28.51970100402832,\n",
       "  28.03085708618164,\n",
       "  27.77047348022461,\n",
       "  28.377824783325195,\n",
       "  28.29046058654785,\n",
       "  28.346691131591797,\n",
       "  28.51049041748047,\n",
       "  28.09364891052246,\n",
       "  28.05271339416504,\n",
       "  28.664779663085938,\n",
       "  27.663732528686523,\n",
       "  28.396570205688477,\n",
       "  27.516220092773438,\n",
       "  28.04950714111328,\n",
       "  28.132577896118164,\n",
       "  28.273475646972656,\n",
       "  27.402231216430664,\n",
       "  28.108585357666016,\n",
       "  27.843036651611328,\n",
       "  28.350719451904297,\n",
       "  27.905481338500977,\n",
       "  28.188919067382812,\n",
       "  27.687978744506836,\n",
       "  27.4220027923584,\n",
       "  27.566556930541992,\n",
       "  27.530553817749023,\n",
       "  28.414623260498047,\n",
       "  27.074600219726562,\n",
       "  28.01995849609375,\n",
       "  27.59801483154297,\n",
       "  27.64790916442871],\n",
       " 'val_fp_mae': [14.144505500793457,\n",
       "  14.38996410369873,\n",
       "  14.900761604309082,\n",
       "  15.6837797164917,\n",
       "  16.51079750061035,\n",
       "  17.715654373168945,\n",
       "  19.60841178894043,\n",
       "  21.080968856811523,\n",
       "  22.189809799194336,\n",
       "  23.508445739746094,\n",
       "  24.336225509643555,\n",
       "  23.819692611694336,\n",
       "  24.58894157409668,\n",
       "  23.756750106811523,\n",
       "  23.747995376586914,\n",
       "  23.18834686279297,\n",
       "  23.078773498535156,\n",
       "  22.78289794921875,\n",
       "  22.70488166809082,\n",
       "  22.294448852539062,\n",
       "  22.562255859375,\n",
       "  22.125028610229492,\n",
       "  21.922584533691406,\n",
       "  21.8862361907959,\n",
       "  21.170644760131836,\n",
       "  20.851097106933594,\n",
       "  20.14429473876953,\n",
       "  20.384763717651367,\n",
       "  19.61842918395996,\n",
       "  19.71453285217285,\n",
       "  18.48278045654297,\n",
       "  18.741580963134766,\n",
       "  17.885936737060547,\n",
       "  17.841487884521484,\n",
       "  16.954788208007812,\n",
       "  17.806243896484375,\n",
       "  16.307310104370117,\n",
       "  17.428150177001953,\n",
       "  16.880746841430664,\n",
       "  16.797286987304688,\n",
       "  16.94407081604004,\n",
       "  15.816645622253418,\n",
       "  15.14832592010498,\n",
       "  15.313921928405762,\n",
       "  14.420161247253418,\n",
       "  14.408038139343262,\n",
       "  14.349613189697266,\n",
       "  14.446688652038574,\n",
       "  14.78036880493164,\n",
       "  14.646350860595703,\n",
       "  14.787993431091309,\n",
       "  15.067893981933594,\n",
       "  14.961750030517578,\n",
       "  14.759398460388184,\n",
       "  14.74152660369873,\n",
       "  14.821660041809082,\n",
       "  15.163060188293457,\n",
       "  14.95313549041748,\n",
       "  14.807354927062988,\n",
       "  15.530181884765625,\n",
       "  15.252765655517578,\n",
       "  15.573821067810059,\n",
       "  15.098304748535156,\n",
       "  14.873003959655762,\n",
       "  15.149307250976562,\n",
       "  15.3128080368042,\n",
       "  15.27997875213623,\n",
       "  14.828217506408691,\n",
       "  15.00853443145752,\n",
       "  15.11567211151123,\n",
       "  14.893990516662598,\n",
       "  15.324492454528809,\n",
       "  15.312371253967285,\n",
       "  15.272270202636719,\n",
       "  15.427834510803223,\n",
       "  14.983558654785156,\n",
       "  15.70792293548584,\n",
       "  14.973941802978516,\n",
       "  15.42009449005127,\n",
       "  15.071684837341309]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnns[0].history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = all_cnns[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_samples: 8192 , New samples: 8192\n",
      "Validation size: 2704 , starts: 8192 , ends: 10895\n",
      "\n",
      "Epoch 00061: val_mae improved from inf to 4.03655, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/8192/best_model_lambda_0new.h5\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 4.03655\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 4.03655\n",
      "Train Error(all epochs): 2.7838029861450195 \n",
      " [3.146, 3.051, 3.077, 3.16, 3.025, 3.048, 3.075, 3.047, 2.933, 2.916, 2.954, 2.952, 2.843, 2.839, 2.855, 2.931, 2.881, 2.853, 2.784, 2.87]\n",
      "Train FP Error(all epochs): 1.395856499671936 \n",
      " [1.565, 1.509, 1.525, 1.594, 1.505, 1.514, 1.543, 1.499, 1.472, 1.458, 1.471, 1.466, 1.421, 1.429, 1.414, 1.447, 1.427, 1.423, 1.396, 1.423]\n",
      "Val Error(all epochs): 4.036548614501953 \n",
      " [4.037, 5.122, 4.407, 4.095, 5.374, 4.484, 4.181, 4.058, 5.237, 6.0, 4.326, 4.051, 4.319, 4.129, 4.174, 4.58, 4.328, 4.15, 4.372, 4.068]\n",
      "Val FP Error(all epochs): 0.6289845108985901 \n",
      " [1.809, 0.989, 1.929, 2.832, 0.842, 1.47, 1.915, 2.469, 0.917, 0.629, 1.431, 2.745, 1.351, 1.903, 1.793, 1.255, 1.595, 1.794, 1.674, 2.165]\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    checkpointers = ModelCheckpoint(filepath=MODEL_PATH + str(0)+ 'new.h5',\n",
    "                                         verbose=1, save_best_only=True, \n",
    "                                         monitor=hyper_metric,\n",
    "                                         mode=mode)\n",
    "    number_start = time.time()\n",
    "    train_generator = DataBatchGenerator(dataset=data_reg[prev_sample:number_sample], batch_size=mini_batch,\n",
    "                                         start_idx=prev_sample, number_image_channels=number_image_channels,\n",
    "                                         max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "    \n",
    "\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "    val_generator = DataBatchGenerator(dataset=data_reg[number_sample:number_sample+val_size], \n",
    "                                       batch_size=mini_batch,\n",
    "                                       start_idx=number_sample,\n",
    "                                       number_image_channels=number_image_channels,\n",
    "                                       max_x=max_x, max_y=max_y, \n",
    "                                       float_memory_used=float_memory_used)\n",
    "  \n",
    "    print('number_samples:', number_sample, \", New samples:\", number_sample - prev_sample)\n",
    "    print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", number_sample + val_size - 1)\n",
    "    best_model.fit(train_generator, epochs=80, verbose=0,\n",
    "                   validation_data=val_generator, shuffle=True, callbacks=[checkpointers], \n",
    "                   workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, \n",
    "                   use_multiprocessing=False, initial_epoch=60)\n",
    "    print(\"Train Error(all epochs):\", min(best_model.history.history['mae']), '\\n',\n",
    "          [round(val, 3) for val in best_model.history.history['mae']])\n",
    "    print(\"Train FP Error(all epochs):\", min(best_model.history.history['fp_mae']), '\\n',\n",
    "          [round(val,3) for val in best_model.history.history['fp_mae']])\n",
    "    print(\"Val Error(all epochs):\", min(best_model.history.history['val_mae']), '\\n', \n",
    "          [round(val,3) for val in best_model.history.history['val_mae']])\n",
    "    print(\"Val FP Error(all epochs):\", min(best_model.history.history['val_fp_mae']), '\\n',\n",
    "          [round(val,3) for val in best_model.history.history['val_fp_mae']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test starts:  10896 , ends:  34263\n",
      "92/92 [==============================] - 22s 234ms/step - loss: 38.6681 - mse: 27.7563 - mae: 4.0863 - fp_mae: 1.7810\n"
     ]
    }
   ],
   "source": [
    "best_best_model = models.load_model(MODEL_PATH + str(0) + 'new.h5', \n",
    "                               custom_objects={ 'loss': custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                                               'fp_mae': fp_mae,\n",
    "                                               'mae':'mae', 'mse':'mse'})\n",
    "test_generator = DataBatchGenerator(dataset=data_reg[number_sample + val_size:], \n",
    "                                            batch_size=mini_batch,\n",
    "                                            start_idx=number_sample + val_size, \n",
    "                                            number_image_channels=number_image_channels,\n",
    "                                            max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "\n",
    "print(\"Test starts: \", number_sample + val_size, \", ends: \", data_reg.shape[0] - 1)\n",
    "time.sleep(1)\n",
    "test_res = best_best_model.evaluate(test_generator, verbose=1, \n",
    "                                    workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE,\n",
    "                                    use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[496.0564270019531, 56.21223449707031, 5.682240009307861, 1.5113146305084229]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [105.50102233886719,\n",
       "  100.78263854980469,\n",
       "  99.25178527832031,\n",
       "  104.09859466552734,\n",
       "  104.50546264648438],\n",
       " 'mse': [44.08177185058594,\n",
       "  41.80543518066406,\n",
       "  41.379180908203125,\n",
       "  44.375244140625,\n",
       "  44.21040725708008],\n",
       " 'mae': [5.269191265106201,\n",
       "  5.1021318435668945,\n",
       "  5.071562767028809,\n",
       "  5.278663635253906,\n",
       "  5.268550872802734],\n",
       " 'fp_mae': [0.19422784447669983,\n",
       "  0.1903233528137207,\n",
       "  0.19018331170082092,\n",
       "  0.2034783661365509,\n",
       "  0.19720497727394104],\n",
       " 'val_loss': [396.6565246582031,\n",
       "  401.5822448730469,\n",
       "  435.2545166015625,\n",
       "  567.9744262695312,\n",
       "  345.01153564453125],\n",
       " 'val_mse': [120.43984985351562,\n",
       "  76.076171875,\n",
       "  161.7263946533203,\n",
       "  71.23866271972656,\n",
       "  77.79705047607422],\n",
       " 'val_mae': [9.087770462036133,\n",
       "  6.748907089233398,\n",
       "  10.751054763793945,\n",
       "  6.494345188140869,\n",
       "  6.804019927978516],\n",
       " 'val_fp_mae': [0.6868877410888672,\n",
       "  0.9997519850730896,\n",
       "  0.640586793422699,\n",
       "  1.5676021575927734,\n",
       "  0.9557649493217468]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fac19dcf810>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(train_generator, epochs=15, verbose=0,\n",
    "               validation_data=val_generator, shuffle=True, callbacks=[checkpointers], \n",
    "               workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, \n",
    "               use_multiprocessing=False, initial_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_min_mae = [8.27781, 8.23545, 8.20838]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power = [8.166, 7.844, 7.592]\n",
    "fp_mean_power = [4.56, 4.42, 4.37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CNN: support batching\n",
    "TEST = True\n",
    "mini_batch, epochs = 16, 30\n",
    "batch_size = (batch_size // mini_batch) * mini_batch\n",
    "prev_sample = 0\n",
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]  #, 0.3, 1, 3, 10\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "for cnn in cnns:\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "for number_sample in number_samples:\n",
    "    number_start = time.time()\n",
    "    current_sample = number_sample - prev_sample\n",
    "    train_samples = [batch_size] * (current_sample//batch_size) + ([current_sample%batch_size] if \n",
    "                                                                    current_sample%batch_size else [])\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "#     val_samples = [batch_size] * (val_size//batch_size) + ([val_size%batch_size] if \n",
    "#                                                                val_size%batch_size else [])\n",
    "    \n",
    "    print('number_samples:', number_sample)\n",
    "    print(\"Train batches:\", train_samples)\n",
    "    for i, train_sample in enumerate(train_samples):\n",
    "        print(\"Train batch#:\", i, \", batch size:\", train_sample, \", starts:\", prev_sample + i * batch_size,\n",
    "                      \", ends:\", prev_sample + i * batch_size + train_sample - 1)\n",
    "    print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", number_sample + val_size - 1)\n",
    "#     print(\"Validation Batches:\", val_samples)\n",
    "#     for i, val_sample in enumerate(val_samples):\n",
    "#         print(\"Validation batch#:\", i, \", batch size:\", val_sample, \", starts:\", number_sample + i * batch_size,\n",
    "#                       \", ends:\", number_sample + i * batch_size + val_sample - 1)\n",
    "        \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb_idx, lamb in enumerate(lambda_vec):\n",
    "        lambda_start = time.time()\n",
    "        \n",
    "#         cnn = cnn_model(10, lamb, 0)\n",
    "#         cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "        # training on all batches\n",
    "        for i, train_sample in enumerate(train_samples):\n",
    "#             if lamb_idx == 0:\n",
    "#                 print(\"Train batch#:\", i, \", batch size:\", train_sample, \", starts:\", prev_sample + i * batch_size,\n",
    "#                       \", ends:\", prev_sample + i * batch_size + train_sample - 1)\n",
    "            x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "            y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "            for image_num in range(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample):\n",
    "                x_train[(image_num - prev_sample) % batch_size] = read_image(image_num)\n",
    "                y_train[(image_num - prev_sample) % batch_size] = np.asarray(data_reg[image_num][-1], \n",
    "                                                                             dtype=float_memory_used)\n",
    "            cnns[lamb_idx].fit(x_train, y_train, epochs=epochs, verbose=2, batch_size=mini_batch,\n",
    "                               validation_split=0.2, \n",
    "                               shuffle=True)\n",
    "            del x_train, y_train\n",
    "#         if lamb_idx == 0:\n",
    "#             print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", \n",
    "#                   number_sample + val_size - 1)\n",
    "        print(\"\\nLambda:\", lamb)\n",
    "        print(\"Train Error(all epochs): \", cnns[lamb_idx].history.history['mae'])\n",
    "        \n",
    "        # validating\n",
    "        val_mae, val_fp_mae = 0.0, 0.0\n",
    "#         for i, val_sample in enumerate(val_samples):\n",
    "#             x_val = np.empty((val_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "#             for image_num in range(val_sample):\n",
    "#                 x_val[image_num] = read_image(image_num + number_sample + i * batch_size)\n",
    "#             yp_val = cnns[lamb_idx].predict(x_val)\n",
    "        for image_num in range(val_size):\n",
    "            val_y = data_reg[image_num + number_sample][-1]\n",
    "            image = read_image(image_num + number_sample)\n",
    "            val_yp = cnns[lamb_idx].predict(image)[0][0]\n",
    "#             for image_num in range(val_sample):\n",
    "#                 val_yp = yp_val[image_num][0]\n",
    "#                 val_y = data_reg[image_num + number_sample + i * batch_size][-1]\n",
    "            val_mae += abs(val_y - val_yp)\n",
    "            if val_yp > val_y:\n",
    "                val_fp_mae += abs(val_yp - val_y)\n",
    "        val_mae /= val_size\n",
    "        val_fp_mae /= val_size\n",
    "        print(\"Val Error:\", round(val_mae, 3), \", Time:\", str(datetime.timedelta(seconds=int(time.time() - lambda_start))))\n",
    "        if val_mae < min_error:\n",
    "            min_error = val_mae\n",
    "            best_model = cnns[lamb_idx]\n",
    "            best_lam = lamb\n",
    "            best_lam_idx = lamb_idx\n",
    "    print(\"\\nTrainig set size:\", number_sample, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - number_start)))\n",
    "          ,\", best_lambda:\", best_lam, \", min_error:\", round(min_error, 3))\n",
    "    \n",
    "    \n",
    "    if TEST:\n",
    "        # evaluating test images\n",
    "        sum_mae, sum_fp_mae = 0, 0\n",
    "        test_size = 0\n",
    "\n",
    "        y_test_p = np.empty((data_reg.shape[0] - (number_sample + val_size)), dtype=float_memory_used)\n",
    "    #     test_size = data_reg.shape[0] - (number_sample + val_size)\n",
    "    #     test_samples = [batch_size] * (test_size//batch_size) + ([test_size%batch_size] if \n",
    "    #                                                              test_size%batch_size else [])\n",
    "        print(\"Test starts: \", number_sample + val_size, \", ends: \", data_reg.shape[0] - 1)\n",
    "        time.sleep(1)\n",
    "    #     for i, test_sample in tqdm.tqdm(enumerate(test_samples)):\n",
    "    #         x_test = np.empty((test_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "    #         for image_num in range(test_sample):\n",
    "    #             x_test[image_num] = read_image(number_sample + val_size + i * batch_size)\n",
    "    #         yp_test = cnns[best_lam_idx].predict(x_test)\n",
    "    #         for image_num in range(test_sample):\n",
    "    #             test_y = data_reg[number_sample + val_size + i * batch_size][-1]\n",
    "    #             test_yp = yp_test[image_num][0]\n",
    "    #             sum_mae += abs(test_yp - test_y)\n",
    "    #             if test_yp > test_y:\n",
    "    #                 sum_fp_mae += abs(test_yp - test_y)\n",
    "\n",
    "        for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "            test_size += 1\n",
    "            test_image = read_image(test_num)\n",
    "            test_y = data_reg[test_num][-1]\n",
    "            test_yp = best_model.predict(test_image)[0][0]\n",
    "            y_test_p[test_num - (number_sample + val_size)] = test_yp\n",
    "            sum_mae += abs(test_yp - test_y)\n",
    "            if test_yp > test_y:\n",
    "                sum_fp_mae += abs(test_yp - test_y)\n",
    "        fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "        average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "        print('average_error: ', average_diff_power[-1], ', fp_average_error: ', \n",
    "              fp_mean_power[-1])\n",
    "        print(\"\\n\\n\")\n",
    "        var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                     dtime + \".dat\", \"wb\") # file for saving results\n",
    "        pickle.dump([average_diff_power, fp_mean_power, number_samples], file=var_f)\n",
    "        var_f.close()\n",
    "    prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnns[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CNN: support batching\n",
    "prev_sample = 0\n",
    "# number_samples = [120, 200, 700]\n",
    "lambda_vec = [0, 0.001]  #0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "for cnn in cnns:\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "for number_sample in number_samples:\n",
    "    current_sample = number_sample - prev_sample\n",
    "    print(\"prev: \", prev_sample, \", now: \", number_sample, \", size\", current_sample) \n",
    "    train_samples = [batch_size] * (current_sample//batch_size) + ([current_sample%batch_size] if \n",
    "                                                                    current_sample%batch_size else [])\n",
    "    print(train_samples)\n",
    "    \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb_idx, lamb in enumerate(lambda_vec):\n",
    "        print(\"Lambda:\", lamb)\n",
    "#         cnn = cnn_model(10, lamb, 0)\n",
    "#         cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "        # training on all batches\n",
    "                                    \n",
    "        for i, train_sample in enumerate(train_samples):\n",
    "            for image_num in range(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample):\n",
    "                print(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample)\n",
    "                print((prev_sample + i * batch_size - prev_sample) % batch_size, \n",
    "                      (prev_sample + i * batch_size + train_sample - prev_sample)% batch_size)\n",
    "                break\n",
    "\n",
    "        \n",
    "        # validating\n",
    "        print(\"validating\")\n",
    "        val_size = math.ceil(number_sample * validation_size)\n",
    "        for image_num in range(val_size):\n",
    "            print(number_sample, val_size + number_sample)\n",
    "            break\n",
    "     \n",
    "    print(\"Test\") \n",
    "    \n",
    "    # evaluating test images\n",
    "\n",
    "    \n",
    "    for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "        print(number_sample + val_size, data_reg.shape[0])\n",
    "        break\n",
    "    prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + 'best_cnn_4000samples' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                 dtime + \".dat\", \"wb\") # file for saving results\n",
    "pickle.dump(best_model, file=var_f)\n",
    "var_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use self-training\n",
    "unlabeled_train_samples = [batch_size] * (len(y_test_p)//batch_size) + ([len(y_test_p)%batch_size] if len(y_test_p)%batch_size else [])\n",
    "labeled_train_samples = [batch_size] * (number_sample//batch_size) + ([number_sample%batch_size] if number_sample%batch_size else [])   \n",
    "min_min_error = float('inf')\n",
    "best_best_model, best_best_lam = None, None\n",
    "for lamb in tqdm.tqdm(lambda_vec):\n",
    "    print(\"Lambda:\", lamb)\n",
    "    cnn = cnn_model(10, lamb, 0)\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#     cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "    # training on all batches\n",
    "    # training on all batches\n",
    "    for i, train_sample in tqdm.tqdm(enumerate(labeled_train_samples)):\n",
    "        x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "        y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "        for image_num in range(i * batch_size, i * batch_size + train_sample):\n",
    "            x_train[image_num % batch_size] = read_image(image_num)\n",
    "            y_train[image_num % batch_size] = np.asarray(data_reg[image_num][-1], dtype=float_memory_used)\n",
    "        cnn.fit(x_train, y_train, epochs=6, verbose=0, batch_size=1, validation_split=0.0)\n",
    "        del x_train, y_train\n",
    "            \n",
    "    for i, train_sample in tqdm.tqdm(enumerate(unlabeled_train_samples)):\n",
    "        x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "        y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "        for image_num in range(i * batch_size + number_sample + val_size, i * batch_size + number_sample + val_size + train_sample):\n",
    "            x_train[(image_num-number_sample - val_size) % batch_size] = read_image(image_num)\n",
    "            y_train[(image_num-number_sample - val_size) % batch_size] = np.asarray(y_test_p[image_num-(number_sample + val_size)], dtype=float_memory_used)\n",
    "        cnn.fit(x_train, y_train, epochs=3, verbose=0, batch_size=1, validation_split=0.0)\n",
    "        del x_train, y_train\n",
    "        \n",
    "    # validating\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "    val_mae, val_fp_mae = 0.0, 0.0\n",
    "    for image_num in range(val_size):\n",
    "        val_y = data_reg[image_num + number_sample][-1]\n",
    "        image = read_image(image_num + number_sample)\n",
    "        val_yp = cnn.predict(image)[0][0]\n",
    "        val_mae += abs(val_y - val_yp)\n",
    "        if val_yp > val_y:\n",
    "            val_fp_mae += abs(val_yp - val_y)\n",
    "    val_mae /= val_size\n",
    "    val_fp_mae /= val_size\n",
    "    print(val_mae)\n",
    "    if val_mae < min_min_error:\n",
    "        min_min_error = val_mae\n",
    "        best_best_model = cnn\n",
    "        best_best_lam = lamb\n",
    "    sum_mae, sum_fp_mae = 0, 0\n",
    "    test_size = 0\n",
    "    \n",
    "for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "    test_size += 1\n",
    "    test_image = read_image(test_num)\n",
    "    test_y = data_reg[test_num][-1]\n",
    "    test_yp = best_best_model.predict(test_image)[0][0]\n",
    "#     y_test_p[test_num - (number_sample + val_size)] = test_yp\n",
    "    sum_mae += abs(test_yp - test_y)\n",
    "    if test_yp > test_y:\n",
    "        sum_fp_mae += abs(test_yp - test_y)\n",
    "fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "print('number_samples: ', number_sample, ', average_error: ', average_diff_power[-1], ' fp_average_error: ', \n",
    "      fp_mean_power[-1])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6.285, 6.366, 6.45, 6.454, 6.382, 6.26, 6.49, 6.224, 6.052, 5.87, 4.915, 4.836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "prev_sample = 0\n",
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1]\n",
    "max_train_samples = math.ceil(number_samples[-1] * (1 + validation_size))\n",
    "x_train = np.empty((max_train_samples, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "# x_train1 = np.empty((max_train_samples, 1, max_x, max_y), dtype=float_memory_used)\n",
    "# x_train2 = np.empty((max_train_samples, 1, max_x, max_y), dtype=float_memory_used)\n",
    "y_train = np.empty((max_train_samples), dtype=float_memory_used)\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "for number_sample in number_samples:\n",
    "    sample = math.ceil(number_sample * (1 + validation_size))\n",
    "    for image_num in range(prev_sample, sample):\n",
    "        prev_sample = sample\n",
    "        if style == \"image_intensity\":\n",
    "            image = plt.imread(image_dir + '/image' + str(image_num)+'.png')\n",
    "            image = np.swapaxes(image, 0, 2)\n",
    "            x_train[image_num] = np.array(image[:number_image_channels], dtype=float_memory_used).reshape(1, number_image_channels, max_x, max_y)\n",
    "            del image\n",
    "        elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "            x_train[image_num] = np.load(image_dir + '/image' + str(image_num)+'.npy')\n",
    "#             image = np.load(image_dir + '/image' + str(image_num)+'.npy')\n",
    "#             x_train1[image_num][0] = image[0][0]\n",
    "#             x_train2[image_num][0] = image[0][1]\n",
    "        y_train[image_num] = np.asarray(data_reg[image_num][-1], dtype=float_memory_used)\n",
    "        if image_num + 1 % 100 == 0:\n",
    "            print(image_num)\n",
    "#     cnn = cnn_model(7, 0, 0)\n",
    "#     cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#     cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "#             (validation_size + 1))\n",
    "    \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb in lambda_vec:\n",
    "        print(\"Lambda:\", lamb)\n",
    "        cnn = cnn_model(10, lamb, 0)\n",
    "        cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#         cnn.fit([x_train1[:sample], x_train2[:sample]], y_train[:sample], epochs=6, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "#                 (validation_size + 1))\n",
    "        cnn.fit(x_train[:sample], y_train[:sample], epochs=6, verbose=0, batch_size=1, validation_split=validation_size/\n",
    "                (validation_size + 1))\n",
    "        if cnn.history.history['val_mean_absolute_error'][-1] < min_error:\n",
    "            min_error = cnn.history.history['val_mean_absolute_error'][-1]\n",
    "            best_model = cnn\n",
    "            best_lam = lamb\n",
    "    print(\"best_lambda, \", best_lam, \"min_error\", min_error)    \n",
    "    # evaluating test images\n",
    "    sum_mae, sum_fp_mae = 0, 0\n",
    "    test_size = 0\n",
    "#     for test_num in range(max_train_samples, data_reg.shape[0]):\n",
    "    for test_num in range(sample, data_reg.shape[0]):\n",
    "        test_size += 1\n",
    "        if style == \"image_intensity\":\n",
    "            test_image = plt.imread(image_dir + '/image' + str(test_num) + '.png')\n",
    "            test_image = np.swapaxes(test_image, 0, 2)\n",
    "            test_image = np.array(test_image[:number_image_channels]).reshape(1, number_image_channels, max_x, max_y)\n",
    "        elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "            test_image = np.load(image_dir + '/image' + str(test_num)+'.npy')\n",
    "        test_y = data_reg[test_num][-1]\n",
    "        test_yp = best_model.predict(test_image)[0][0]\n",
    "        sum_mae += abs(test_yp - test_y)\n",
    "        if test_yp > test_y:\n",
    "            sum_fp_mae += abs(test_yp - test_y)\n",
    "        if test_num % 500 == 0:\n",
    "            print('test: ', test_num)\n",
    "    fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "    average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "    print('number_samples: ', number_sample, ', average_error: ', average_diff_power[-1], ' fp_average_error: ', fp_mean_power[-1])\n",
    "    print(\"\\n\")\n",
    "    var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + dtime + \".dat\", \"wb\") # file for saving results\n",
    "    pickle.dump([average_diff_power, fp_mean_power, number_samples], file=var_f)\n",
    "    var_f.close()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power[8], average_diff_power[9] = average_diff_power[9], average_diff_power[8]\n",
    "# fp_mean_power = fp_mean_power[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapee = Input(shape=(number_image_channels, max_x, max_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapee[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(1, 0)\n",
    "cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnn.history.history['val_mean_absolute_error'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(10, 0, 0)\n",
    "cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "            (validation_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3]\n",
    "min_error = float('inf')\n",
    "best_model, best_lam = None, None\n",
    "for lamb in lambda_vec:\n",
    "    print(\"Lambda:\", lamb)\n",
    "    cnn = cnn_model(15, lamb, 0)\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "    cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "            (validation_size + 1))\n",
    "    if cnn.history.history['val_mean_absolute_error'][-1] < min_error:\n",
    "        min_error = cnn.history.history['val_mean_absolute_error'][-1]\n",
    "        best_model = cnn\n",
    "        best_lam = lamb\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_lam)\n",
    "print(best_model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just run to dispaly the image. First change return line from create_image\n",
    "aa = np.swapaxes(np.append(np.array(x_train[50]), np.zeros((2,max_x, max_y), dtype=float_memory_used), axis=0), 0, 2)\n",
    "plt.imshow(aa)\n",
    "# plt.imsave('image.png', aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to read saved variables\n",
    "var_ff = open('ML/data/pictures_1000_1000/log_201912_0705_37.txt', 'rb')\n",
    "[average_diff_power_1, fp_mean_power_1, number_samples_1] = pickle.load(var_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_mean_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power[-1]*(data_reg.shape[0] - max_train_samples)/(300-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_fp_mae/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_mean_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pydotplus\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "keras.utils.vis_utils.pydot = pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARALLEL CNN\n",
    "def cnn_model(num_filters, kernel_lam, bias_lam):\n",
    "#     num_filters, lam = 5, 5\n",
    "    data_format = 'channels_first'\n",
    "    convolution_filter, dense_filter = 'selu', 'linear' #softsign, sigmoid; relu, linear\n",
    "    filter_shape, pool_size = (3, 3), (2,2)\n",
    "    # CNN for PU image\n",
    "    input1  = layers.Input(shape=(number_image_channels - 1, max_x, max_y), name='pus_input')\n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(input1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    \n",
    "    # CNN for SU\n",
    "    input2  = layers.Input(shape=(1, max_x, max_y), name='su_input')\n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(input2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    \n",
    "    # concatanate two CNN outputs\n",
    "    x = layers.concatenate([x1, x2])\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    x = layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    out = layers.Dense(1, activation=dense_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    \n",
    "    model = models.Model(inputs=[input1, input2], outputs=out)\n",
    "#     plot_model(model, to_file='model.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'square'\n",
    "# style = \"image_intensity\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# average_diff_power = [9.110476626067186, 21.070721128267266, 9.389938883165568, 10.886098907990405,\n",
    "#                                        7.697396928362106, 7.522477509027216, 9.493729427772132, 8.198866980620753,\n",
    "#                                        7.781910785203122, 9.41743984825801, 8.499455442627129, 9.86776958065812,\n",
    "#                                        9.033719411254367, 8.150143941293027, 8.963829050517273, 8.708150642874065,\n",
    "#                                        7.468060397898071, 8.233182799553932,8.206, 7.768]\n",
    "# fp_mean_power =  [8.174990557021465, 0.18043087058937837, 1.5141939559853392, 10.273307557711494,\n",
    "#                                    3.2306742061521443, 4.423113329284006, 8.674172526579392, 2.38235061342411,\n",
    "#                                    5.014172646429496, 6.884079514994618, 3.4544130456368367, 7.81721202679044,\n",
    "#                                    6.438635364829745, 4.069245107144559, 5.202978504937615, 3.405858414831347,\n",
    "#                                    4.117573271657338, 2.8100743146184377, 3.951, 3.502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAX_POWER ANAlysis\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# pu_shape, su_shape = 'circle', 'circle'\n",
    "# style = \"image_intensity\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# test_size = 3670\n",
    "# average_diff_power = [7.811849328268183, 9.178415418536536, 8.11891504382307, 7.881934146750136, 7.918868224324312,\n",
    "#                       7.709452054502398, 7.471729821563216, 8.63783455122861, 7.7635068514166345, 8.557134470036884,\n",
    "#                       8.103793715416188, 9.189284948409279, 11.977416480154307, 8.291134394492891, 8.960065032512803,\n",
    "#                       9.992745143323642, 8.475335283779392, 8.051642160173987, 7.322538645284376, 7.768582958795206]\n",
    "# fp_mean_power = [6.1844398077234635, 1.6157812496465958, 6.5620574110067595, 2.898169187355567, 6.262096880097353,\n",
    "#                  2.5478307871639267, 3.5784209073932067, 7.416731632966506, 5.5822838290638135, 5.800529848947965,\n",
    "#                  4.6984887763519785, 2.337296353076653, 9.85739104089764, 3.710259461284922, 5.323224159423669, \n",
    "#                  6.198328912769283, 2.302462751745074, 4.023802978234984, 3.781413967880959, 3.2793608103510508]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle'\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# num_pus = 15\n",
    "average_diff_power = [9.711, 7.867, 8.958, 7.571, 7.509, 7.891, 8.272, 7.118, 7.696, 7.689, 8.026, 9.674, 7.51, 7.771, 8.17,\n",
    "                      7.938, 7.869, 7.833, 9.434, 8.501]\n",
    "fp_mean_power = [9.229, 5.101, 8.037, 3.993, 5.095, 2.491, 2.298, 4.654, 3.787, 2.685, 5.676, 8.033, 3.911, 4.235, 3.278,\n",
    "                 5.809, 3.586, 4.257, 4.377, 5.015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "\n",
    "# number_samples = [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 8001, 1000))\n",
    "\n",
    "\n",
    "# cnn_type = \"classification\"  # {\"classification\", \"regression\"}\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 200, 200, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# else:\n",
    "#     su_param = None\n",
    "# sensors = False\n",
    "# if sensors:\n",
    "#     sensors_num = 50\n",
    "#     sensors_file_path = \"rsc/\" + str(sensors_num) + \"/sensors\"\n",
    "    \n",
    "average_diff_power = [6.779, 5.645, 5.473, 4.982, 4.481, 4.071, 4.05, 3.639, 2.813, 2.343, 2.21, 2.372, 2.005, 1.997,\n",
    "                      1.937, 1.901]\n",
    "\n",
    "fp_mean_power = [4.073, 2.409, 3.424, 3.163, 2.833, 2.663, 2.857, 2.744, 1.744, 1.33, 1.184, 1.55, 0.579, 1.216, 1.492, 1.266]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "\n",
    "number_samples = [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 6001, 1000)) + [8000]\n",
    "# dataframe = pd.read_csv('ML/data/dynamic_pus_using_pus50000_15PUs_201912_3000_40_200.txt', delimiter=',', header=None)\n",
    "# dataframe_max = pd.read_csv('ML/data/dynamic_pus_max_power50000_15PUs_201912_3000_40_200.txt', delimiter=',', header=None)\n",
    "\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 200, 200, 4, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 5\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# else:\n",
    "#     su_param = None\n",
    "# sensors = False\n",
    "    \n",
    "average_diff_power = [12.742, 12.906, 12.731, 12.595, 12.859, 13.272, 12.632, 12.647, 11.309, 7.455, 7.131, 5.677,\n",
    "                      5.645, 5.292, 4.445]\n",
    "\n",
    "fp_mean_power = [5.963, 5.861, 8.957, 8.821, 8.215, 9.518, 8.633, 6.644, 6.605, 3.919, 2.539, 3.866, 1.96, 2.717, 1.671]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_diff_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_width = 5\n",
    "marker_size = 12\n",
    "reg_style = 'solid'\n",
    "class_reg = 'dashed'\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, average_diff_power, color='r', linewidth=line_width, markersize=marker_size, linestyle=class_reg)\n",
    "plt.plot(number_samples, fp_mean_power, color='midnightblue', linewidth=line_width, markersize=marker_size, linestyle=class_reg)\n",
    "plt.xlabel('# of Training Samples', fontsize=47)\n",
    "plt.ylabel('Avg. Diff. wrt Opt. (dB)', fontsize=45)\n",
    "plt.title('Dynamic PUs(200m*200m)')\n",
    "plt.grid(True)\n",
    "\n",
    "ax.set_yticks(np.arange(0,14, 2))\n",
    "# ax.set_xticks(np.arange(100,7000, 1500))\n",
    "plt.rcParams.update({'font.size': 42})\n",
    "ax.tick_params(axis='x', labelsize=46)\n",
    "ax.tick_params(axis='y', labelsize=45)\n",
    "\n",
    "# matplotlib.rcParams.update({'font.size': 22})\n",
    "\n",
    "ax.set_ylim([0, 14])\n",
    "ax.set_xlim([0, 8000])\n",
    "plt.legend(['Total', 'False-Positive'], ncol=2, loc='best', handletextpad=0.1,borderpad=0, columnspacing=0.2, borderaxespad=0.2)\n",
    "# plt.legend(handletextpad=0.1)\n",
    "plt.savefig('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + dtime + \".png\", \n",
    "            bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(image_dir + '/image10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/'.join(image_dir.split('/')[:-1]) + '/log_5__202006_2714_19.dat', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/home/shahrokh/projects/research/MLSpectrumAllocation/ML/data/pictures_100_100/splat/' +\n",
    "            'pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus_1_4_sus_7_channels/log_5__202006_1302_40.dat', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "[average_diff_power, fp_mean_power, number_samples, best_lambda, \n",
    " dataset_name, max_dataset_name, average_power_conserve, \n",
    " fp_mean_power_conserve] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 512, 1024, 2048, 4096, 8192]\n",
      "[21.947, 21.696, 21.466, 21.369, 21.251, 21.07]\n",
      "[15.964, 16.258, 17.124, 17.177, 17.29, 15.634]\n",
      "[0.01, 0.01, 0.1, 0, 0.001, 0.001]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(number_samples)\n",
    "print(average_diff_power)\n",
    "print(fp_mean_power)\n",
    "print(best_lambda)\n",
    "print(average_power_conserve)\n",
    "print(fp_mean_power_conserve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fp1, fp2, fp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples1, samples2, samples3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
