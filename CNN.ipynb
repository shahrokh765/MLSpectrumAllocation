{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers, models, Input\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.utils import Sequence\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datetime, time\n",
    "import os, sys\n",
    "import tqdm\n",
    "import gc\n",
    "from multiprocessing import Process\n",
    "Point = namedtuple('Point', ('x', 'y'))\n",
    "Circle = namedtuple('Circle', ('r'))\n",
    "Square = namedtuple('Square', ('side'))\n",
    "Rectangle = namedtuple('Rectangle', ('length', 'width'))\n",
    "PointWithDistance = namedtuple('PointWithDistance', ('p', 'dist'))\n",
    "float_memory_used = 'float16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "# PART 1\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 10001, 1000))\n",
    "number_samples = [256, 512, 1024, 2048, 4096, 8192] \n",
    "number_samples = [8192]\n",
    "\n",
    "# cnn_type = \"classification\"  # {\"classification\", \"regression\"}\n",
    "validation_size, noise_floor = 0.33, -90.0\n",
    "su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "max_x, max_y, number_image_channels, su_szie = 1000, 1000, 7, 30\n",
    "pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "intensity_degradation, slope = 'log', 3  # 'log', 'linear'\n",
    "max_pus_num, max_sus_num = 20, 1\n",
    "propagation_model = 'log' # 'splat', 'log', 'testbed'\n",
    "noise, std = True, 1\n",
    "if su_shape == 'circle':\n",
    "    su_param = Circle(su_szie)\n",
    "elif su_shape == 'square':\n",
    "    su_param = Square(su_szie)\n",
    "else:\n",
    "    su_param = None\n",
    "    \n",
    "sensors = True\n",
    "if sensors:\n",
    "    sensors_num = 3600\n",
    "    sensors_file_path = \"rsc/sensors/\" + str(max(max_x, max_y)) + \"/\" + str(sensors_num) + \"/sensors\"\n",
    "# num_pus = (data_reg.shape[1] - 3)//3\n",
    "\n",
    "# PART 2\n",
    "number_of_proccessors = 6\n",
    "memory_size_allowed = 4 # in Gigabyte\n",
    "float_size = 0\n",
    "if float_memory_used == \"float16\":\n",
    "    float_size = 16\n",
    "elif float_memory_used == \"float\" or \"float32\":\n",
    "    float_size = 32\n",
    "elif float_memory_used == \"float8\":\n",
    "    float_size = 8\n",
    "\n",
    "\n",
    "batch_size = int(memory_size_allowed / (max_x * max_y * number_image_channels * float_size/(8 * 1024 ** 3)))\n",
    "\n",
    "\n",
    "dtime = datetime.datetime.now().strftime('_%Y%m_%d%H_%M')\n",
    "color = \"color\" if number_image_channels > 1 else \"gray\"\n",
    "image_dir = 'ML/data/pictures_' + str(max_x) + '_' + str(max_y) + '/' + propagation_model + (\n",
    "    \"/noisy_std_\" + str(std) if noise else \"\") + '/pu_' + pu_shape + '_su_' + su_shape + '_' + (\n",
    "    \"\" if su_shape == 'point' else str(su_szie)) + \"/\" + style + \"/\" + color +'/' + (\n",
    "    \"\" if pu_shape == 'point' and su_shape == 'point' else (intensity_degradation + '_' + str(slope))) + (\n",
    "    \"/\" + str(sensors_num) + \"sensors\" if sensors else \"/pus\") + \"/images\"\n",
    "\n",
    "if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/images'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "num_columns = (sensors_num if sensors else max_pus_num * 3 + 1) + max_sus_num * 3 + 2\n",
    "cols = [i for i in range(num_columns)]\n",
    "dataset_name = \"dynamic_pus_sensors_50000_min10_max20PUs_1SUs_3600sensors_1000grid_1cell_log_noisy_std1_202004_1304_36.txt\"\n",
    "max_dataset_name = \"dynamic_pus_max_power_50000_min10_max20PUs_1SUs_1000grid_1cell_log_noisy_std1_202004_1304_36.txt\"\n",
    "with open('/'.join(image_dir.split('/')[:-1]) + '/datasets' + dtime + '.txt', 'w') as set_file:\n",
    "    set_file.write(dataset_name)\n",
    "    set_file.write(max_dataset_name)\n",
    "\n",
    "dataframe = pd.read_csv('ML/data/' + dataset_name, delimiter=',', header=None, names=cols)\n",
    "dataframe_max = pd.read_csv('ML/data/' + max_dataset_name, delimiter=',', header=None)\n",
    "\n",
    "dataframe.reset_index(drop=True, inplace=True)\n",
    "dataframe_max.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dataframe_tot = pd.concat([dataframe, dataframe_max.iloc[:, dataframe_max.columns.values[-1]]], axis=1,\n",
    "                        ignore_index=True)\n",
    "\n",
    "idx = dataframe_tot[dataframe_tot[dataframe_tot.columns[-1]] == -float('inf')].index\n",
    "dataframe_tot.drop(idx, inplace=True)\n",
    "\n",
    "data_reg = dataframe_tot.values\n",
    "# data_reg = np.concatenate((dataframe_tot.values[:, 0:dataframe_tot.shape[1]-3], \n",
    "#                            dataframe_tot.values[:, dataframe_tot.shape[1]-1:dataframe_tot.shape[1]]), axis=1)\n",
    "# data_class = dataframe_tot.values[:, 0:dataframe_tot.shape[1]-1]\n",
    "# y_class_power = dataframe_tot.values[:, -1]\n",
    "\n",
    "if sensors:\n",
    "    sensors_location = []\n",
    "    with open(sensors_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.split(' ')\n",
    "            sensors_location.append(Point(int(float(line[0])), int(float(line[1]))))\n",
    "del dataframe, dataframe_max, dataframe_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48295, 3606)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = data_reg[0:35000][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(p1: Point, p2: Point):\n",
    "    return ((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2) ** 0.5\n",
    "\n",
    "def calculate_mu_sigma(data, num_pus):\n",
    "    sum_non_noise = 0\n",
    "    for pu_n in range(num_pus): # calculate mu\n",
    "        sum_non_noise += data[pu_n*3+2]\n",
    "    mu = ((max_x * max_y - num_pus) * noise_floor + sum_non_noise)/(max_x * max_y)\n",
    "    sum_square = 0\n",
    "    for pu_n in range(num_pus): # calculate sigma\n",
    "        sum_square += (data[pu_n*3+2]-mu)**2\n",
    "    sum_square += (max_x * max_y - num_pus) * (noise_floor - mu)**2\n",
    "    sigma = math.sqrt(sum_square/(max_x * max_y))\n",
    "    return mu, sigma\n",
    "\n",
    "def get_pu_param(pu_shape: str, intensity_degradation: str, pu_p: float, noise_floor: float, slope: float):\n",
    "    pu_param = None\n",
    "    if pu_shape == 'circle':\n",
    "        if intensity_degradation == \"linear\":\n",
    "            pu_param = Circle(int((pu_p - noise_floor) / slope)) # linear\n",
    "        elif intensity_degradation == \"log\":\n",
    "            pu_param = Circle(int(10 ** ((pu_p - noise_floor) / (10 *slope)))) # log_based\n",
    "    elif pu_shape == 'square':\n",
    "        if intensity_degradation == \"linear\":\n",
    "            pu_param = Square(int(2 ** 0.5 * (pu_p - noise_floor) / slope)) # linear\n",
    "        elif intensity_degradation == \"log\":\n",
    "            pu_param = Square(int(2 ** 0.5 * 10 ** ((pu_p - noise_floor) / (10 *slope)))) # log_based\n",
    "    elif pu_shape == 'point':\n",
    "        pu_param = None\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported PU shape(create_image)! \", pu_shape)\n",
    "    return pu_param\n",
    "\n",
    "def create_image(data, slope, sensors_num, style=\"raw_power_z_score\", noise_floor=-90, pu_shape= 'circle', pu_param=None, \n",
    "                 su_shape='circle', su_param=None, intensity_degradation=\"log\", max_pu_power: float=0):  \n",
    "    # style = {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "    # intensity_degradation= {\"log\", \"linear\"}\n",
    "    # if param is None, it's automatically calculated. Highest brightness(or power value) (255 or 1.) would\n",
    "    # assigned to the center(PU location) and radius(side) would be calculated based on its power, slope, and noise floor.\n",
    "    # If it is given, intensity(power) of pixel beside center would be calculated in the same fashin with an exception that \n",
    "    # intensity below zero(noise_floor) would be replaced by zero(noise_floor)\n",
    "    if style == \"raw_power_min_max_norm\":\n",
    "        # In this way, PUs' location are replaced with their power(dBm) and the power would fade with \n",
    "        # slope till gets noise_floor(in circle shape)\n",
    "        \n",
    "        # creating pu matrix\n",
    "        image = np.zeros((1,number_image_channels,max_x, max_y), dtype=float_memory_used)\n",
    "        if not sensors:\n",
    "            pus_num = int(data[0])\n",
    "#             print(pus_num)\n",
    "            for pu_i in range(pus_num):\n",
    "                pu_x = max(0, min(max_x-1, int(data[pu_i * 3 + 1]))) \n",
    "                pu_y = max(0, min(max_x-1, int(data[pu_i * 3 + 2])))\n",
    "                pu_p = data[pu_i * 3 + 3]\n",
    "#                 print(pu_x, pu_y, pu_p)\n",
    "                if pu_param is None:\n",
    "                    pu_param_p = get_pu_param(pu_shape, intensity_degradation, pu_p, noise_floor, slope)\n",
    "                else:\n",
    "                    pu_param_p = pu_param\n",
    "                points = points_inside_shape(center=Point(pu_x, pu_y), shape=pu_shape, param=pu_param_p)\n",
    "                for point in points:\n",
    "                    if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                        if intensity_degradation == \"linear\":\n",
    "                            image[0][int(abs(pu_p))//5][point.p.x][point.p.y] += (pu_p - slope * point.dist - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                        elif intensity_degradation == \"log\":\n",
    "                            if point.dist < 1:\n",
    "                                image[0][int(abs(pu_p))//5][point.p.x][point.p.y] += (pu_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                            else:\n",
    "                                image[0][int(abs(pu_p))//5][point.p.x][point.p.y] += (pu_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                    max_pu_power - noise_floor)\n",
    "        else:\n",
    "            ss_param, ss_shape = pu_param, pu_shape\n",
    "            for ss_i in range(sensors_num):\n",
    "                ss_x, ss_y, ss_p = max(0, min(max_x-1, int(sensors_location[ss_i].x))), max(0, min(max_x-1, int(\n",
    "                    sensors_location[ss_i].y))), max(noise_floor, data[ss_i])\n",
    "                ss_channel = 0 \n",
    "                if -50.0 <= ss_p < -40.0:\n",
    "                    ss_channel = 1\n",
    "                elif -60.0 <= ss_p < -50.0:\n",
    "                    ss_channel = 2\n",
    "                elif -70.0 <= ss_p < -60.0:\n",
    "                    ss_channel = 3\n",
    "                elif -80.0 <= ss_p < -70.0:\n",
    "                    ss_channel = 4\n",
    "#                 elif -70.0 <= ss_p < -65.0:\n",
    "#                     ss_channel = 5\n",
    "                elif ss_p < -80.0:\n",
    "                    ss_channel = 5\n",
    "                if ss_param is None:\n",
    "                    ss_param_p = get_pu_param(ss_shape, intensity_degradation, ss_p, noise_floor, slope)\n",
    "                else:\n",
    "                    ss_param_p = ss_param\n",
    "                points = points_inside_shape(center=Point(ss_x, ss_y), shape=ss_shape, param=ss_param_p)\n",
    "                for point in points:\n",
    "                    if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                        if intensity_degradation == \"linear\":\n",
    "                            image[0][ss_channel][point.p.x][point.p.y] += (ss_p - slope * point.dist - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                        elif intensity_degradation == \"log\":\n",
    "                            if point.dist < 1:\n",
    "                                image[0][ss_channel][point.p.x][point.p.y] += (ss_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                            else:\n",
    "                                image[0][ss_channel][point.p.x][point.p.y] += (ss_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                    max_pu_power - noise_floor)\n",
    "        del points\n",
    "        # creating su matrix\n",
    "        su_num_idx = sensors_num if sensors else (pus_num * 3 + 1)\n",
    "        su_num = int(data[su_num_idx])\n",
    "#         print(su_num)\n",
    "#         su_num = (len(data) - pus_num * (3 if not sensors else 1)) // 2\n",
    "#         if not (len(data) - pus_num * (3 if not sensors else 1)) % 2:\n",
    "#             raise ValueError(\"Data provided is not correct; can't get SUs' information(create_image)\")\n",
    "        if su_param is None:\n",
    "            # if su_param is unavailable, a circle(square) with radius(side) 1 is created\n",
    "            if su_shape == 'circle':\n",
    "                su_param = Circle(1)\n",
    "            elif su_shape == 'square':\n",
    "                su_param = Square(1)\n",
    "            elif su_shape == 'point':\n",
    "                su_param = None\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported SU shape(create_image)! \", su_shape)\n",
    "        \n",
    "        for su_i in range(su_num - 1):\n",
    "            su_x = max(0, min(max_x-1, int(data[su_num_idx + su_i * 3 + 1])))\n",
    "            su_y = max(0, min(max_x-1, int(data[su_num_idx + su_i * 3 + 2])))\n",
    "            su_p = data[su_num_idx + su_i * 3 + 3]\n",
    "#             su_p = su_intensity\n",
    "            points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "            su_channel = 0 if number_image_channels == 1 else -1\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if intensity_degradation == \"linear\":\n",
    "                            su_val = (su_p - slope * point.dist - noise_floor)/(max_pu_power - noise_floor)\n",
    "                    elif intensity_degradation == \"log\":\n",
    "                        if point.dist < 1:\n",
    "                            su_val = (su_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                        else:\n",
    "                            su_val = (su_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                    image[0][su_channel][point.p.x][point.p.y] += su_val\n",
    "            del points\n",
    "        # the last and  target SU\n",
    "        su_intensity = 1.\n",
    "        su_x = max(0, min(max_x-1, int(data[su_num_idx + (su_num - 1) * 3 + 1])))\n",
    "        su_y = max(0, min(max_x-1, int(data[su_num_idx + (su_num - 1) * 3 + 2])))\n",
    "#         print(su_x, su_y)\n",
    "        points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "        su_channel = 0 if number_image_channels == 1 else -1\n",
    "        for point in points:\n",
    "            if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                image[0][su_channel][point.p.x][point.p.y] += su_intensity\n",
    "        del points\n",
    "        return image\n",
    "        \n",
    "#         pu_image = [[(noise_floor - mu)/sigma] * max_y for _ in range(max_x)]\n",
    "    elif style == \"image_intensity\":\n",
    "        # creating PU image\n",
    "        image = np.zeros((1,number_image_channels,max_x, max_y), dtype=float_memory_used)\n",
    "        for pu_i in range(pus_num):\n",
    "            pu_x, pu_y, pu_p = max(0, min(max_x-1, int(data[pu_i*3]))), max(0, min(max_x-1, int(data[pu_i*3+1]))), data[pu_i*3+2]\n",
    "            if pu_param is None:\n",
    "                pu_param_p = get_pu_param(pu_shape, intensity_degradation, pu_p, noise_floor, slope)\n",
    "            else:\n",
    "                pu_param_p = pu_param\n",
    "            points = points_inside_shape(center=Point(pu_x, pu_y), shape=pu_shape, param=pu_param_p)\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if intensity_degradation == \"linear\":\n",
    "                        image[0][0][point.p.x][point.p.y] += max((pu_p - slope * point.dist + abs(noise_floor))\n",
    "                                                              /(pu_p + abs(noise_floor)), 0)\n",
    "                    elif intensity_degradation == \"log\":\n",
    "                        if point.dist < 1:\n",
    "                            image[0][0][point.p.x][point.p.y] = 1\n",
    "                        else:\n",
    "                            image[0][0][point.p.x][point.p.y] += max((pu_p - slope * 10*math.log10(point.dist) + abs(noise_floor))\n",
    "                                                                 /(pu_p + abs(noise_floor)), 0)\n",
    "                    image[0][0][point.p.x][point.p.y] = min(image[0][0][point.p.x][point.p.y], 1.0)\n",
    "                        \n",
    "        # creating SU image\n",
    "        su_num = (len(data) - pus_num * 3) // 2\n",
    "        if not (len(data) - pus_num * 3) % 2:\n",
    "            raise ValueError(\"Data provided is not correct; can't get SUs' information(create_image)\")\n",
    "#         su_image = np.zeros((max_x, max_y), dtype=float_memory_used)\n",
    "        if su_param is None:\n",
    "            # if su_param is unavailable, a circle(square) with radius(side) 1 is created\n",
    "            if su_shape == 'circle':\n",
    "                su_param = Circle(1)\n",
    "            elif su_shape == 'square':\n",
    "                su_param = Square(1)\n",
    "            elif su_shape == 'point':\n",
    "                su_param = None\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported SU shape(create_image)! \", su_shape)\n",
    "        su_intensity = 1.\n",
    "        for su_i in range(su_num):\n",
    "            su_x, su_y, su_p = max(0, min(max_x-1, int(data[pus_num * (3 if not sensors else 1) +su_i*2]))\n",
    "                                  ), max(0, min(max_x-1, int(data[pus_num * (3 if not sensors else 1) + su_i*2+1]))), su_intensity\n",
    "            points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if number_image_channels > 1:\n",
    "                        image[0][1][point.p.x][point.p.y] = su_intensity\n",
    "                    elif number_image_channels == 1:\n",
    "                        image[0][0][point.p.x][point.p.y] = su_intensity\n",
    "#         return np.array([pu_image, su_image, [[0.] * max_y for _ in range(max_x)]], dtype='float32') # return like this to be able to display as an RGB image with pyplot.imshow(imsave)\n",
    "#         return np.append(pu_image, su_image, axis=0)\n",
    "        return image\n",
    "        \n",
    "            \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported style(create_image)! \", style)\n",
    "        \n",
    "def points_inside_shape(center: Point, shape: str, param)-> list:\n",
    "    # This function returns points+distance around center with defined shape\n",
    "    if shape == 'circle':\n",
    "        # First creates points inside a square(around orgigin) with 2*r side and then remove those with distance > r.\n",
    "        # Shift all remaining around center. O(4r^2)\n",
    "        r, origin = param.r, Point(0, 0)\n",
    "        square_points = set((Point(x, y) for x in range(max(-r, -max_x), min(r, max_x) + 1) \n",
    "                             for y in range(max(-r, -max_y), min(r, max_y) + 1)))\n",
    "        points = []\n",
    "        while square_points:\n",
    "            p = square_points.pop()\n",
    "            dist = euclidian_distance(p, origin)\n",
    "            if dist <= r:\n",
    "                points.append(PointWithDistance(Point(p.x + center.x, p.y + center.y), dist))\n",
    "                if p.x != 0:\n",
    "                    points.append(PointWithDistance(Point(-p.x + center.x, p.y + center.y), dist))\n",
    "                    square_points.remove(Point(-p.x, p.y))\n",
    "                if p.y != 0:\n",
    "                    points.append(PointWithDistance(Point(p.x + center.x, -p.y + center.y), dist))\n",
    "                    square_points.remove(Point(p.x, -p.y))\n",
    "                if p.x != 0 and p.y != 0:\n",
    "                    points.append(PointWithDistance(Point(-p.x + center.x, -p.y + center.y), dist))\n",
    "                    square_points.remove(Point(-p.x, -p.y))\n",
    "        del square_points\n",
    "        return points\n",
    "    elif shape == 'square':\n",
    "        half_side = param.side // 2\n",
    "        return [PointWithDistance(Point(x, y), euclidian_distance(Point(x, y), center)) for x in range(-half_side + center.x,\n",
    "                                                                                               half_side + center.x+1) \n",
    "                         for y in range(-half_side + center.y, half_side + center.y + 1)]\n",
    "    elif shape == 'point':\n",
    "        return [PointWithDistance(center, 0)]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported shape(points_inside_shape)! \", shape)\n",
    "        \n",
    "def read_image(image_num):\n",
    "    if style == \"image_intensity\":\n",
    "        image = plt.imread(image_dir + '/image' + str(image_num)+'.png')\n",
    "        image = np.swapaxes(image, 0, 2)\n",
    "        image = np.array(image[:number_image_channels], dtype=float_memory_used).reshape(1, number_image_channels, max_x, max_y)\n",
    "    elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "        suffix = 'npz'  # npy, npz\n",
    "        image = np.load(image_dir + '/image' + str(image_num) + '.' + suffix)  \n",
    "        if type(image) == np.lib.npyio.NpzFile:\n",
    "            image = image['a']\n",
    "    \n",
    "    return image\n",
    "    \n",
    "# TODO: Consider using min_max normalization becasue difference between values using\n",
    "# z-score is huge since most of the pixels have the same value, noise floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 2.000e+00, 0.000e+00, 5.000e+00, 8.000e+00, 4.000e+00,\n",
       "        9.000e+00, 1.700e+01, 2.100e+01, 2.100e+01, 3.500e+01, 5.800e+01,\n",
       "        7.200e+01, 7.500e+01, 1.170e+02, 1.550e+02, 1.750e+02, 2.350e+02,\n",
       "        3.160e+02, 3.530e+02, 4.300e+02, 5.360e+02, 6.140e+02, 6.880e+02,\n",
       "        8.040e+02, 9.830e+02, 1.007e+03, 1.103e+03, 1.134e+03, 1.159e+03,\n",
       "        1.244e+03, 1.281e+03, 1.280e+03, 1.246e+03, 1.284e+03, 1.175e+03,\n",
       "        1.182e+03, 1.096e+03, 1.043e+03, 1.050e+03, 9.270e+02, 8.670e+02,\n",
       "        8.340e+02, 7.980e+02, 6.590e+02, 6.180e+02, 6.130e+02, 5.460e+02,\n",
       "        5.250e+02, 4.770e+02, 4.660e+02, 4.200e+02, 3.810e+02, 3.640e+02,\n",
       "        3.190e+02, 2.980e+02, 2.680e+02, 2.570e+02, 2.450e+02, 2.180e+02,\n",
       "        1.830e+02, 2.050e+02, 1.770e+02, 1.760e+02, 1.480e+02, 1.480e+02,\n",
       "        1.120e+02, 1.220e+02, 1.080e+02, 8.100e+01, 9.400e+01, 7.800e+01,\n",
       "        8.500e+01, 7.900e+01, 6.900e+01, 7.000e+01, 6.700e+01, 5.900e+01,\n",
       "        5.500e+01, 5.400e+01, 4.900e+01, 4.400e+01, 3.700e+01, 3.700e+01,\n",
       "        4.200e+01, 3.400e+01, 2.300e+01, 3.700e+01, 2.300e+01, 1.900e+01,\n",
       "        2.100e+01, 3.100e+01, 1.700e+01, 1.800e+01, 2.400e+01, 2.000e+01,\n",
       "        9.000e+00, 9.000e+00, 1.500e+01, 9.000e+00, 7.000e+00, 9.000e+00,\n",
       "        6.000e+00, 1.000e+01, 7.000e+00, 1.000e+01, 6.000e+00, 6.000e+00,\n",
       "        1.000e+01, 1.000e+01, 6.000e+00, 9.000e+00, 5.000e+00, 5.000e+00,\n",
       "        6.000e+00, 4.000e+00, 4.000e+00, 8.000e+00, 3.000e+00, 2.000e+00,\n",
       "        4.000e+00, 3.000e+00, 4.000e+00, 4.000e+00, 2.000e+00, 4.000e+00,\n",
       "        2.000e+00, 1.000e+00, 1.000e+00, 2.000e+00, 2.000e+00, 2.000e+00,\n",
       "        6.000e+00, 1.000e+00, 2.000e+00, 0.000e+00, 3.000e+00, 2.000e+00,\n",
       "        1.000e+00, 0.000e+00, 2.000e+00, 2.000e+00, 0.000e+00, 2.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 1.000e+00,\n",
       "        0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 2.000e+00]),\n",
       " array([-96.67      , -96.15522346, -95.64044693, -95.12567039,\n",
       "        -94.61089385, -94.09611732, -93.58134078, -93.06656425,\n",
       "        -92.55178771, -92.03701117, -91.52223464, -91.0074581 ,\n",
       "        -90.49268156, -89.97790503, -89.46312849, -88.94835196,\n",
       "        -88.43357542, -87.91879888, -87.40402235, -86.88924581,\n",
       "        -86.37446927, -85.85969274, -85.3449162 , -84.83013966,\n",
       "        -84.31536313, -83.80058659, -83.28581006, -82.77103352,\n",
       "        -82.25625698, -81.74148045, -81.22670391, -80.71192737,\n",
       "        -80.19715084, -79.6823743 , -79.16759777, -78.65282123,\n",
       "        -78.13804469, -77.62326816, -77.10849162, -76.59371508,\n",
       "        -76.07893855, -75.56416201, -75.04938547, -74.53460894,\n",
       "        -74.0198324 , -73.50505587, -72.99027933, -72.47550279,\n",
       "        -71.96072626, -71.44594972, -70.93117318, -70.41639665,\n",
       "        -69.90162011, -69.38684358, -68.87206704, -68.3572905 ,\n",
       "        -67.84251397, -67.32773743, -66.81296089, -66.29818436,\n",
       "        -65.78340782, -65.26863128, -64.75385475, -64.23907821,\n",
       "        -63.72430168, -63.20952514, -62.6947486 , -62.17997207,\n",
       "        -61.66519553, -61.15041899, -60.63564246, -60.12086592,\n",
       "        -59.60608939, -59.09131285, -58.57653631, -58.06175978,\n",
       "        -57.54698324, -57.0322067 , -56.51743017, -56.00265363,\n",
       "        -55.48787709, -54.97310056, -54.45832402, -53.94354749,\n",
       "        -53.42877095, -52.91399441, -52.39921788, -51.88444134,\n",
       "        -51.3696648 , -50.85488827, -50.34011173, -49.8253352 ,\n",
       "        -49.31055866, -48.79578212, -48.28100559, -47.76622905,\n",
       "        -47.25145251, -46.73667598, -46.22189944, -45.70712291,\n",
       "        -45.19234637, -44.67756983, -44.1627933 , -43.64801676,\n",
       "        -43.13324022, -42.61846369, -42.10368715, -41.58891061,\n",
       "        -41.07413408, -40.55935754, -40.04458101, -39.52980447,\n",
       "        -39.01502793, -38.5002514 , -37.98547486, -37.47069832,\n",
       "        -36.95592179, -36.44114525, -35.92636872, -35.41159218,\n",
       "        -34.89681564, -34.38203911, -33.86726257, -33.35248603,\n",
       "        -32.8377095 , -32.32293296, -31.80815642, -31.29337989,\n",
       "        -30.77860335, -30.26382682, -29.74905028, -29.23427374,\n",
       "        -28.71949721, -28.20472067, -27.68994413, -27.1751676 ,\n",
       "        -26.66039106, -26.14561453, -25.63083799, -25.11606145,\n",
       "        -24.60128492, -24.08650838, -23.57173184, -23.05695531,\n",
       "        -22.54217877, -22.02740223, -21.5126257 , -20.99784916,\n",
       "        -20.48307263, -19.96829609, -19.45351955, -18.93874302,\n",
       "        -18.42396648, -17.90918994, -17.39441341, -16.87963687,\n",
       "        -16.36486034, -15.8500838 , -15.33530726, -14.82053073,\n",
       "        -14.30575419, -13.79097765, -13.27620112, -12.76142458,\n",
       "        -12.24664804, -11.73187151, -11.21709497, -10.70231844,\n",
       "        -10.1875419 ,  -9.67276536,  -9.15798883,  -8.64321229,\n",
       "         -8.12843575,  -7.61365922,  -7.09888268,  -6.58410615,\n",
       "         -6.06932961,  -5.55455307,  -5.03977654,  -4.525     ]),\n",
       " <a list of 179 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data_reg[:,0:1:3600], bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving images once to save time\n",
    "# run this cell just for creating images\n",
    "def creating_image(start, end):\n",
    "    # for image_num in range(115, data_reg.shape[0]):\n",
    "    # for image_num in range(1625, 5000):\n",
    "    for image_num in tqdm.tqdm(range(start, end+1)):  #4463, data_reg.shape[0]\n",
    "        image = create_image(data=data_reg[image_num], slope=slope, style=style, noise_floor=noise_floor,\n",
    "                             pu_shape=pu_shape, su_shape=su_shape, su_param=su_param, \n",
    "                             sensors_num=(sensors_num if sensors else 0), \n",
    "                             intensity_degradation=intensity_degradation, \n",
    "                             max_pu_power=-40.0)\n",
    "        if style == \"image_intensity\":\n",
    "            if number_image_channels != 3:\n",
    "                image = np.append(np.array(image[0]), np.zeros((3-number_image_channels,max_x, max_y), \n",
    "                                                               dtype=float_memory_used), axis=0)\n",
    "            image_save = np.swapaxes(image, 0, 2)\n",
    "            plt.imsave(image_dir + '/image' + str(image_num)+'.png', image_save)\n",
    "        elif style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "    #         np.save(image_dir + '/image' + str(image_num), image)\n",
    "            np.savez_compressed(image_dir + '/image' + str(image_num), a=image)\n",
    "        del image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5833/5833 [21:30:13<00:00, 13.27s/it]   \n",
      "100%|██████████| 5833/5833 [21:32:24<00:00, 13.29s/it]\n",
      "100%|██████████| 5833/5833 [21:36:02<00:00, 13.33s/it]\n",
      "100%|██████████| 5833/5833 [21:36:13<00:00, 13.33s/it]\n",
      "100%|██████████| 5833/5833 [21:42:13<00:00, 13.40s/it]\n",
      "100%|██████████| 5835/5835 [21:47:54<00:00, 13.45s/it]\n"
     ]
    }
   ],
   "source": [
    "jobs = []\n",
    "proc_sizes = [data_reg.shape[0]//number_of_proccessors] * (number_of_proccessors)\n",
    "proc_sizes[-1] += data_reg.shape[0]%number_of_proccessors\n",
    "proc_idx = [(sum(proc_sizes[:i]), sum(proc_sizes[:i+1])-1) for i in range(number_of_proccessors)]\n",
    "\n",
    "for i in range(number_of_proccessors):\n",
    "    p = Process(target=creating_image, args=(proc_idx[i][0], proc_idx[i][1]))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "for i in range(number_of_proccessors):\n",
    "    jobs[i].join()\n",
    "\n",
    "for i in range(number_of_proccessors):\n",
    "    jobs[i].terminate()\n",
    "    jobs[i].close()\n",
    "del jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Point(x=25, y=25)\n",
      "2 Point(x=25, y=75)\n",
      "3 Point(x=25, y=125)\n",
      "4 Point(x=25, y=175)\n",
      "5 Point(x=25, y=225)\n",
      "6 Point(x=25, y=275)\n",
      "7 Point(x=25, y=325)\n",
      "8 Point(x=25, y=375)\n",
      "9 Point(x=25, y=425)\n",
      "10 Point(x=25, y=475)\n",
      "11 Point(x=25, y=525)\n",
      "12 Point(x=25, y=575)\n",
      "13 Point(x=25, y=625)\n",
      "14 Point(x=25, y=675)\n",
      "15 Point(x=25, y=725)\n",
      "16 Point(x=25, y=775)\n",
      "17 Point(x=25, y=825)\n",
      "18 Point(x=25, y=875)\n",
      "19 Point(x=25, y=925)\n",
      "20 Point(x=25, y=975)\n",
      "21 Point(x=75, y=25)\n",
      "22 Point(x=75, y=75)\n",
      "23 Point(x=75, y=125)\n",
      "24 Point(x=75, y=175)\n",
      "25 Point(x=75, y=225)\n",
      "26 Point(x=75, y=275)\n",
      "27 Point(x=75, y=325)\n",
      "28 Point(x=75, y=375)\n",
      "29 Point(x=75, y=425)\n",
      "30 Point(x=75, y=475)\n",
      "31 Point(x=75, y=525)\n",
      "32 Point(x=75, y=575)\n",
      "33 Point(x=75, y=625)\n",
      "34 Point(x=75, y=675)\n",
      "35 Point(x=75, y=725)\n",
      "36 Point(x=75, y=775)\n",
      "37 Point(x=75, y=825)\n",
      "38 Point(x=75, y=875)\n",
      "39 Point(x=75, y=925)\n",
      "40 Point(x=75, y=975)\n",
      "41 Point(x=125, y=25)\n",
      "42 Point(x=125, y=75)\n",
      "43 Point(x=125, y=125)\n",
      "44 Point(x=125, y=175)\n",
      "45 Point(x=125, y=225)\n",
      "46 Point(x=125, y=275)\n",
      "47 Point(x=125, y=325)\n",
      "48 Point(x=125, y=375)\n",
      "49 Point(x=125, y=425)\n",
      "50 Point(x=125, y=475)\n",
      "51 Point(x=125, y=525)\n",
      "52 Point(x=125, y=575)\n",
      "53 Point(x=125, y=625)\n",
      "54 Point(x=125, y=675)\n",
      "55 Point(x=125, y=725)\n",
      "56 Point(x=125, y=775)\n",
      "57 Point(x=125, y=825)\n",
      "58 Point(x=125, y=875)\n",
      "59 Point(x=125, y=925)\n",
      "60 Point(x=125, y=975)\n",
      "61 Point(x=175, y=25)\n",
      "62 Point(x=175, y=75)\n",
      "63 Point(x=175, y=125)\n",
      "64 Point(x=175, y=175)\n",
      "65 Point(x=175, y=225)\n",
      "66 Point(x=175, y=275)\n",
      "67 Point(x=175, y=325)\n",
      "68 Point(x=175, y=375)\n",
      "69 Point(x=175, y=425)\n",
      "70 Point(x=175, y=475)\n",
      "71 Point(x=175, y=525)\n",
      "72 Point(x=175, y=575)\n",
      "73 Point(x=175, y=625)\n",
      "74 Point(x=175, y=675)\n",
      "75 Point(x=175, y=725)\n",
      "76 Point(x=175, y=775)\n",
      "77 Point(x=175, y=825)\n",
      "78 Point(x=175, y=875)\n",
      "79 Point(x=175, y=925)\n",
      "80 Point(x=175, y=975)\n",
      "81 Point(x=225, y=25)\n",
      "82 Point(x=225, y=75)\n",
      "83 Point(x=225, y=125)\n",
      "84 Point(x=225, y=175)\n",
      "85 Point(x=225, y=225)\n",
      "86 Point(x=225, y=275)\n",
      "87 Point(x=225, y=325)\n",
      "88 Point(x=225, y=375)\n",
      "89 Point(x=225, y=425)\n",
      "90 Point(x=225, y=475)\n",
      "91 Point(x=225, y=525)\n",
      "92 Point(x=225, y=575)\n",
      "93 Point(x=225, y=625)\n",
      "94 Point(x=225, y=675)\n",
      "95 Point(x=225, y=725)\n",
      "96 Point(x=225, y=775)\n",
      "97 Point(x=225, y=825)\n",
      "98 Point(x=225, y=875)\n",
      "99 Point(x=225, y=925)\n",
      "100 Point(x=225, y=975)\n",
      "101 Point(x=275, y=25)\n",
      "102 Point(x=275, y=75)\n",
      "103 Point(x=275, y=125)\n",
      "104 Point(x=275, y=175)\n",
      "105 Point(x=275, y=225)\n",
      "106 Point(x=275, y=275)\n",
      "107 Point(x=275, y=325)\n",
      "108 Point(x=275, y=375)\n",
      "109 Point(x=275, y=425)\n",
      "110 Point(x=275, y=475)\n",
      "111 Point(x=275, y=525)\n",
      "112 Point(x=275, y=575)\n",
      "113 Point(x=275, y=625)\n",
      "114 Point(x=275, y=675)\n",
      "115 Point(x=275, y=725)\n",
      "116 Point(x=275, y=775)\n",
      "117 Point(x=275, y=825)\n",
      "118 Point(x=275, y=875)\n",
      "119 Point(x=275, y=925)\n",
      "120 Point(x=275, y=975)\n",
      "121 Point(x=325, y=25)\n",
      "122 Point(x=325, y=75)\n",
      "123 Point(x=325, y=125)\n",
      "124 Point(x=325, y=175)\n",
      "125 Point(x=325, y=225)\n",
      "126 Point(x=325, y=275)\n",
      "127 Point(x=325, y=325)\n",
      "128 Point(x=325, y=375)\n",
      "129 Point(x=325, y=425)\n",
      "130 Point(x=325, y=475)\n",
      "131 Point(x=325, y=525)\n",
      "132 Point(x=325, y=575)\n",
      "133 Point(x=325, y=625)\n",
      "134 Point(x=325, y=675)\n",
      "135 Point(x=325, y=725)\n",
      "136 Point(x=325, y=775)\n",
      "137 Point(x=325, y=825)\n",
      "138 Point(x=325, y=875)\n",
      "139 Point(x=325, y=925)\n",
      "140 Point(x=325, y=975)\n",
      "141 Point(x=375, y=25)\n",
      "142 Point(x=375, y=75)\n",
      "143 Point(x=375, y=125)\n",
      "144 Point(x=375, y=175)\n",
      "145 Point(x=375, y=225)\n",
      "146 Point(x=375, y=275)\n",
      "147 Point(x=375, y=325)\n",
      "148 Point(x=375, y=375)\n",
      "149 Point(x=375, y=425)\n",
      "150 Point(x=375, y=475)\n",
      "151 Point(x=375, y=525)\n",
      "152 Point(x=375, y=575)\n",
      "153 Point(x=375, y=625)\n",
      "154 Point(x=375, y=675)\n",
      "155 Point(x=375, y=725)\n",
      "156 Point(x=375, y=775)\n",
      "157 Point(x=375, y=825)\n",
      "158 Point(x=375, y=875)\n",
      "159 Point(x=375, y=925)\n",
      "160 Point(x=375, y=975)\n",
      "161 Point(x=425, y=25)\n",
      "162 Point(x=425, y=75)\n",
      "163 Point(x=425, y=125)\n",
      "164 Point(x=425, y=175)\n",
      "165 Point(x=425, y=225)\n",
      "166 Point(x=425, y=275)\n",
      "167 Point(x=425, y=325)\n",
      "168 Point(x=425, y=375)\n",
      "169 Point(x=425, y=425)\n",
      "170 Point(x=425, y=475)\n",
      "171 Point(x=425, y=525)\n",
      "172 Point(x=425, y=575)\n",
      "173 Point(x=425, y=625)\n",
      "174 Point(x=425, y=675)\n",
      "175 Point(x=425, y=725)\n",
      "176 Point(x=425, y=775)\n",
      "177 Point(x=425, y=825)\n",
      "178 Point(x=425, y=875)\n",
      "179 Point(x=425, y=925)\n",
      "180 Point(x=425, y=975)\n",
      "181 Point(x=475, y=25)\n",
      "182 Point(x=475, y=75)\n",
      "183 Point(x=475, y=125)\n",
      "184 Point(x=475, y=175)\n",
      "185 Point(x=475, y=225)\n",
      "186 Point(x=475, y=275)\n",
      "187 Point(x=475, y=325)\n",
      "188 Point(x=475, y=375)\n",
      "189 Point(x=475, y=425)\n",
      "190 Point(x=475, y=475)\n",
      "191 Point(x=475, y=525)\n",
      "192 Point(x=475, y=575)\n",
      "193 Point(x=475, y=625)\n",
      "194 Point(x=475, y=675)\n",
      "195 Point(x=475, y=725)\n",
      "196 Point(x=475, y=775)\n",
      "197 Point(x=475, y=825)\n",
      "198 Point(x=475, y=875)\n",
      "199 Point(x=475, y=925)\n",
      "200 Point(x=475, y=975)\n",
      "201 Point(x=525, y=25)\n",
      "202 Point(x=525, y=75)\n",
      "203 Point(x=525, y=125)\n",
      "204 Point(x=525, y=175)\n",
      "205 Point(x=525, y=225)\n",
      "206 Point(x=525, y=275)\n",
      "207 Point(x=525, y=325)\n",
      "208 Point(x=525, y=375)\n",
      "209 Point(x=525, y=425)\n",
      "210 Point(x=525, y=475)\n",
      "211 Point(x=525, y=525)\n",
      "212 Point(x=525, y=575)\n",
      "213 Point(x=525, y=625)\n",
      "214 Point(x=525, y=675)\n",
      "215 Point(x=525, y=725)\n",
      "216 Point(x=525, y=775)\n",
      "217 Point(x=525, y=825)\n",
      "218 Point(x=525, y=875)\n",
      "219 Point(x=525, y=925)\n",
      "220 Point(x=525, y=975)\n",
      "221 Point(x=575, y=25)\n",
      "222 Point(x=575, y=75)\n",
      "223 Point(x=575, y=125)\n",
      "224 Point(x=575, y=175)\n",
      "225 Point(x=575, y=225)\n",
      "226 Point(x=575, y=275)\n",
      "227 Point(x=575, y=325)\n",
      "228 Point(x=575, y=375)\n",
      "229 Point(x=575, y=425)\n",
      "230 Point(x=575, y=475)\n",
      "231 Point(x=575, y=525)\n",
      "232 Point(x=575, y=575)\n",
      "233 Point(x=575, y=625)\n",
      "234 Point(x=575, y=675)\n",
      "235 Point(x=575, y=725)\n",
      "236 Point(x=575, y=775)\n",
      "237 Point(x=575, y=825)\n",
      "238 Point(x=575, y=875)\n",
      "239 Point(x=575, y=925)\n",
      "240 Point(x=575, y=975)\n",
      "241 Point(x=625, y=25)\n",
      "242 Point(x=625, y=75)\n",
      "243 Point(x=625, y=125)\n",
      "244 Point(x=625, y=175)\n",
      "245 Point(x=625, y=225)\n",
      "246 Point(x=625, y=275)\n",
      "247 Point(x=625, y=325)\n",
      "248 Point(x=625, y=375)\n",
      "249 Point(x=625, y=425)\n",
      "250 Point(x=625, y=475)\n",
      "251 Point(x=625, y=525)\n",
      "252 Point(x=625, y=575)\n",
      "253 Point(x=625, y=625)\n",
      "254 Point(x=625, y=675)\n",
      "255 Point(x=625, y=725)\n",
      "256 Point(x=625, y=775)\n",
      "257 Point(x=625, y=825)\n",
      "258 Point(x=625, y=875)\n",
      "259 Point(x=625, y=925)\n",
      "260 Point(x=625, y=975)\n",
      "261 Point(x=675, y=25)\n",
      "262 Point(x=675, y=75)\n",
      "263 Point(x=675, y=125)\n",
      "264 Point(x=675, y=175)\n",
      "265 Point(x=675, y=225)\n",
      "266 Point(x=675, y=275)\n",
      "267 Point(x=675, y=325)\n",
      "268 Point(x=675, y=375)\n",
      "269 Point(x=675, y=425)\n",
      "270 Point(x=675, y=475)\n",
      "271 Point(x=675, y=525)\n",
      "272 Point(x=675, y=575)\n",
      "273 Point(x=675, y=625)\n",
      "274 Point(x=675, y=675)\n",
      "275 Point(x=675, y=725)\n",
      "276 Point(x=675, y=775)\n",
      "277 Point(x=675, y=825)\n",
      "278 Point(x=675, y=875)\n",
      "279 Point(x=675, y=925)\n",
      "280 Point(x=675, y=975)\n",
      "281 Point(x=725, y=25)\n",
      "282 Point(x=725, y=75)\n",
      "283 Point(x=725, y=125)\n",
      "284 Point(x=725, y=175)\n",
      "285 Point(x=725, y=225)\n",
      "286 Point(x=725, y=275)\n",
      "287 Point(x=725, y=325)\n",
      "288 Point(x=725, y=375)\n",
      "289 Point(x=725, y=425)\n",
      "290 Point(x=725, y=475)\n",
      "291 Point(x=725, y=525)\n",
      "292 Point(x=725, y=575)\n",
      "293 Point(x=725, y=625)\n",
      "294 Point(x=725, y=675)\n",
      "295 Point(x=725, y=725)\n",
      "296 Point(x=725, y=775)\n",
      "297 Point(x=725, y=825)\n",
      "298 Point(x=725, y=875)\n",
      "299 Point(x=725, y=925)\n",
      "300 Point(x=725, y=975)\n",
      "301 Point(x=775, y=25)\n",
      "302 Point(x=775, y=75)\n",
      "303 Point(x=775, y=125)\n",
      "304 Point(x=775, y=175)\n",
      "305 Point(x=775, y=225)\n",
      "306 Point(x=775, y=275)\n",
      "307 Point(x=775, y=325)\n",
      "308 Point(x=775, y=375)\n",
      "309 Point(x=775, y=425)\n",
      "310 Point(x=775, y=475)\n",
      "311 Point(x=775, y=525)\n",
      "312 Point(x=775, y=575)\n",
      "313 Point(x=775, y=625)\n",
      "314 Point(x=775, y=675)\n",
      "315 Point(x=775, y=725)\n",
      "316 Point(x=775, y=775)\n",
      "317 Point(x=775, y=825)\n",
      "318 Point(x=775, y=875)\n",
      "319 Point(x=775, y=925)\n",
      "320 Point(x=775, y=975)\n",
      "321 Point(x=825, y=25)\n",
      "322 Point(x=825, y=75)\n",
      "323 Point(x=825, y=125)\n",
      "324 Point(x=825, y=175)\n",
      "325 Point(x=825, y=225)\n",
      "326 Point(x=825, y=275)\n",
      "327 Point(x=825, y=325)\n",
      "328 Point(x=825, y=375)\n",
      "329 Point(x=825, y=425)\n",
      "330 Point(x=825, y=475)\n",
      "331 Point(x=825, y=525)\n",
      "332 Point(x=825, y=575)\n",
      "333 Point(x=825, y=625)\n",
      "334 Point(x=825, y=675)\n",
      "335 Point(x=825, y=725)\n",
      "336 Point(x=825, y=775)\n",
      "337 Point(x=825, y=825)\n",
      "338 Point(x=825, y=875)\n",
      "339 Point(x=825, y=925)\n",
      "340 Point(x=825, y=975)\n",
      "341 Point(x=875, y=25)\n",
      "342 Point(x=875, y=75)\n",
      "343 Point(x=875, y=125)\n",
      "344 Point(x=875, y=175)\n",
      "345 Point(x=875, y=225)\n",
      "346 Point(x=875, y=275)\n",
      "347 Point(x=875, y=325)\n",
      "348 Point(x=875, y=375)\n",
      "349 Point(x=875, y=425)\n",
      "350 Point(x=875, y=475)\n",
      "351 Point(x=875, y=525)\n",
      "352 Point(x=875, y=575)\n",
      "353 Point(x=875, y=625)\n",
      "354 Point(x=875, y=675)\n",
      "355 Point(x=875, y=725)\n",
      "356 Point(x=875, y=775)\n",
      "357 Point(x=875, y=825)\n",
      "358 Point(x=875, y=875)\n",
      "359 Point(x=875, y=925)\n",
      "360 Point(x=875, y=975)\n",
      "361 Point(x=925, y=25)\n",
      "362 Point(x=925, y=75)\n",
      "363 Point(x=925, y=125)\n",
      "364 Point(x=925, y=175)\n",
      "365 Point(x=925, y=225)\n",
      "366 Point(x=925, y=275)\n",
      "367 Point(x=925, y=325)\n",
      "368 Point(x=925, y=375)\n",
      "369 Point(x=925, y=425)\n",
      "370 Point(x=925, y=475)\n",
      "371 Point(x=925, y=525)\n",
      "372 Point(x=925, y=575)\n",
      "373 Point(x=925, y=625)\n",
      "374 Point(x=925, y=675)\n",
      "375 Point(x=925, y=725)\n",
      "376 Point(x=925, y=775)\n",
      "377 Point(x=925, y=825)\n",
      "378 Point(x=925, y=875)\n",
      "379 Point(x=925, y=925)\n",
      "380 Point(x=925, y=975)\n",
      "381 Point(x=975, y=25)\n",
      "382 Point(x=975, y=75)\n",
      "383 Point(x=975, y=125)\n",
      "384 Point(x=975, y=175)\n",
      "385 Point(x=975, y=225)\n",
      "386 Point(x=975, y=275)\n",
      "387 Point(x=975, y=325)\n",
      "388 Point(x=975, y=375)\n",
      "389 Point(x=975, y=425)\n",
      "390 Point(x=975, y=475)\n",
      "391 Point(x=975, y=525)\n",
      "392 Point(x=975, y=575)\n",
      "393 Point(x=975, y=625)\n",
      "394 Point(x=975, y=675)\n",
      "395 Point(x=975, y=725)\n",
      "396 Point(x=975, y=775)\n",
      "397 Point(x=975, y=825)\n",
      "398 Point(x=975, y=875)\n",
      "399 Point(x=975, y=925)\n",
      "400 Point(x=975, y=975)\n"
     ]
    }
   ],
   "source": [
    "for idx, point in enumerate(sensors_location):\n",
    "    print(idx+1, point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823 Point(x=916, y=416) close\n"
     ]
    }
   ],
   "source": [
    "for idx, point in enumerate(sensors_location):\n",
    "    print(idx+1, point,\"close\") if math.sqrt((point.x-917)**2+(point.y-415)**2)<=1.5 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [0, 0, 0, 0]\n",
    "idxx = [[],[],[],[]]\n",
    "for i in range(data_reg.shape[0]):\n",
    "    pus_c = int(data_reg[i][0]) * 3 + 1\n",
    "    idx = int(data_reg[i][pus_c]) - 1\n",
    "    count[idx] += 1\n",
    "    idxx[idx].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24178, 12235, 5997, 3024]\n",
      "[18, 37, 42, 58, 79, 82, 89, 90, 103, 124, 142, 149, 171, 173, 189, 207, 233, 238, 269, 277, 293, 319, 331, 341, 387, 396, 404, 410, 418, 420, 432, 440, 444, 497, 525, 539, 544, 614, 616, 619, 627, 632, 633, 645, 648, 651, 663, 732, 775, 778, 843, 902, 923, 949, 965, 967, 968, 988, 996, 1018, 1020, 1024, 1030, 1036, 1075, 1084, 1105, 1116, 1129, 1133, 1140, 1142, 1152, 1168, 1171, 1188, 1250, 1251, 1264, 1279, 1288, 1306, 1329, 1367, 1369, 1389, 1390, 1421, 1430, 1435, 1440, 1447, 1450, 1456, 1463, 1534, 1539, 1550, 1562, 1594, 1606, 1621, 1632, 1654, 1658, 1664, 1683, 1714, 1754, 1773, 1796, 1820, 1821, 1843, 1848, 1865, 1871, 1897, 1905, 1938, 1943, 1948, 1997, 2017, 2023, 2040, 2053, 2062, 2087, 2103, 2110, 2116, 2119, 2148, 2157, 2169, 2182, 2220, 2227, 2288, 2326, 2364, 2372, 2387, 2402, 2426, 2431, 2434, 2436, 2441, 2447, 2472, 2478, 2491, 2497, 2532, 2543, 2557, 2582, 2588, 2619, 2628, 2706, 2741, 2742, 2743, 2747, 2751, 2762, 2788, 2807, 2870, 2874, 2894, 2915, 2922, 2931, 2957, 2966, 2974, 2989, 3026, 3030, 3046, 3049, 3063, 3082, 3083, 3105, 3119, 3154, 3159, 3178, 3181, 3182, 3196, 3212, 3229, 3232, 3249, 3258, 3260, 3284, 3285, 3290, 3292, 3304, 3307, 3309, 3333, 3340, 3346, 3364, 3365, 3380, 3397, 3437, 3443, 3472, 3499, 3503, 3517, 3518, 3520, 3524, 3572, 3588, 3600, 3608, 3616, 3626, 3641, 3649, 3665, 3666, 3667, 3669, 3676, 3682, 3684, 3729, 3738, 3744, 3749, 3764, 3765, 3784, 3788, 3809, 3812, 3822, 3845, 3852, 3862, 3881, 3891, 3899, 3910, 3942, 3953, 3974, 3978, 4045, 4047, 4052, 4087, 4135, 4140, 4144, 4159, 4160, 4168, 4177, 4183, 4193, 4195, 4207, 4208, 4251, 4264, 4281, 4282, 4287, 4295, 4314, 4320, 4335, 4395, 4406, 4416, 4450, 4467, 4513, 4514, 4521, 4547, 4568, 4578, 4587, 4607, 4622, 4646, 4648, 4672, 4681, 4702, 4708, 4723, 4727, 4728, 4742, 4743, 4748, 4774, 4780, 4799, 4813, 4817, 4822, 4870, 4905, 4913, 4925, 4930, 4952, 4975, 4976, 4982, 4992, 5003, 5028, 5033, 5039, 5051, 5056, 5058, 5063, 5081, 5084, 5095, 5098, 5146, 5174, 5190, 5197, 5240, 5245, 5263, 5278, 5305, 5324, 5339, 5347, 5352, 5365, 5374, 5384, 5385, 5390, 5395, 5427, 5436, 5439, 5447, 5464, 5490, 5502, 5510, 5512, 5514, 5531, 5532, 5533, 5536, 5539, 5557, 5593, 5606, 5626, 5681, 5694, 5713, 5769, 5821, 5842, 5846, 5859, 5863, 5889, 5903, 5942, 5960, 5964, 5989, 5997, 6001, 6016, 6022, 6024, 6037, 6048, 6058, 6077, 6081, 6082, 6099, 6106, 6125, 6146, 6165, 6194, 6208, 6213, 6219, 6225, 6232, 6242, 6245, 6252, 6294, 6308, 6318, 6325, 6327, 6342, 6366, 6370, 6372, 6373, 6386, 6400, 6419, 6423, 6432, 6436, 6443, 6501, 6511, 6520, 6541, 6573, 6601, 6605, 6612, 6616, 6617, 6619, 6631, 6656, 6680, 6718, 6726, 6754, 6762, 6764, 6768, 6783, 6796, 6823, 6828, 6840, 6846, 6847, 6853, 6859, 6881, 6925, 6926, 6929, 6930, 6939, 6955, 6956, 6958, 6967, 7021, 7037, 7050, 7057, 7071, 7078, 7082, 7115, 7118, 7143, 7172, 7198, 7202, 7214, 7227, 7235, 7254, 7268, 7308, 7331, 7382, 7410, 7426, 7427, 7434, 7447, 7458, 7487, 7509, 7512, 7521, 7547, 7557, 7571, 7579, 7583, 7588, 7589, 7591, 7618, 7625, 7632, 7691, 7700, 7705, 7717, 7731, 7733, 7738, 7744, 7757, 7767, 7771, 7777, 7812, 7828, 7889, 7910, 7921, 7922, 7963, 7999, 8016, 8024, 8050, 8051, 8066, 8076, 8108, 8116, 8146, 8173, 8180, 8181, 8183, 8214, 8220, 8228, 8232, 8235, 8263, 8297, 8310, 8311, 8331, 8371, 8372, 8388, 8389, 8393, 8407, 8468, 8472, 8494, 8500, 8509, 8531, 8556, 8571, 8579, 8584, 8622, 8623, 8629, 8655, 8675, 8677, 8687, 8727, 8736, 8738, 8746, 8753, 8786, 8789, 8792, 8816, 8829, 8835, 8839, 8847, 8866, 8899, 8906, 8909, 8930, 8940, 8944, 8952, 8967, 8970, 8987, 8997, 9034, 9061, 9080, 9087, 9095, 9102, 9110, 9127, 9131, 9148, 9158, 9161, 9175, 9178, 9208, 9217, 9242, 9248, 9258, 9266, 9273, 9283, 9288, 9305, 9335, 9342, 9347, 9357, 9371, 9399, 9428, 9441, 9458, 9464, 9473, 9490, 9539, 9541, 9552, 9603, 9608, 9625, 9629, 9635, 9662, 9670, 9671, 9672, 9688, 9699, 9710, 9763, 9774, 9790, 9793, 9865, 9876, 9889, 9896, 9903, 9907, 9952, 10010, 10020, 10021, 10034, 10043, 10046, 10050, 10056, 10074, 10084, 10090, 10105, 10115, 10159, 10170, 10181, 10192, 10213, 10218, 10256, 10259, 10295, 10296, 10303, 10320, 10331, 10336, 10351, 10372, 10421, 10430, 10438, 10458, 10471, 10529, 10531, 10557, 10571, 10591, 10593, 10623, 10629, 10637, 10642, 10662, 10667, 10723, 10769, 10794, 10800, 10812, 10829, 10837, 10838, 10844, 10855, 10865, 10880, 10885, 10887, 10895, 10909, 10914, 10941, 10978, 10980, 10981, 10986, 11010, 11017, 11048, 11056, 11068, 11069, 11116, 11117, 11118, 11135, 11148, 11156, 11166, 11174, 11203, 11204, 11256, 11284, 11287, 11297, 11322, 11341, 11355, 11375, 11403, 11406, 11430, 11442, 11443, 11470, 11484, 11487, 11491, 11508, 11520, 11559, 11578, 11582, 11583, 11590, 11616, 11626, 11627, 11636, 11650, 11672, 11673, 11681, 11693, 11700, 11711, 11733, 11737, 11748, 11751, 11757, 11765, 11781, 11791, 11796, 11802, 11805, 11810, 11832, 11838, 11842, 11852, 11874, 11895, 11935, 11939, 11940, 11943, 11980, 11989, 12002, 12017, 12020, 12021, 12033, 12034, 12037, 12077, 12080, 12089, 12091, 12125, 12136, 12166, 12184, 12193, 12194, 12195, 12212, 12244, 12276, 12312, 12324, 12330, 12361, 12362, 12371, 12374, 12386, 12404, 12417, 12455, 12475, 12515, 12518, 12525, 12529, 12541, 12545, 12546, 12560, 12567, 12569, 12592, 12611, 12651, 12656, 12673, 12676, 12678, 12722, 12725, 12736, 12742, 12757, 12758, 12772, 12782, 12785, 12806, 12833, 12835, 12837, 12849, 12851, 12858, 12888, 12892, 12895, 12922, 12956, 12987, 13013, 13030, 13033, 13063, 13066, 13069, 13078, 13091, 13111, 13112, 13150, 13180, 13196, 13199, 13220, 13235, 13239, 13242, 13244, 13286, 13288, 13296, 13298, 13308, 13313, 13338, 13347, 13360, 13384, 13386, 13412, 13444, 13478, 13489, 13490, 13526, 13529, 13560, 13561, 13570, 13571, 13572, 13576, 13592, 13613, 13635, 13641, 13702, 13746, 13750, 13757, 13773, 13814, 13835, 13869, 13878, 13881, 13904, 13906, 13918, 13923, 13928, 13931, 13937, 13979, 13998, 14039, 14052, 14069, 14075, 14090, 14095, 14098, 14121, 14129, 14145, 14179, 14180, 14194, 14200, 14226, 14247, 14249, 14254, 14261, 14271, 14280, 14309, 14313, 14319, 14326, 14345, 14357, 14409, 14457, 14467, 14485, 14491, 14495, 14499, 14504, 14520, 14526, 14530, 14540, 14541, 14552, 14576, 14581, 14584, 14591, 14594, 14614, 14641, 14665, 14679, 14686, 14757, 14782, 14786, 14793, 14796, 14804, 14813, 14842, 14846, 14874, 14901, 14917, 14930, 15024, 15038, 15040, 15051, 15054, 15072, 15078, 15084, 15091, 15096, 15111, 15122, 15133, 15137, 15149, 15180, 15218, 15259, 15263, 15264, 15273, 15275, 15279, 15299, 15304, 15305, 15318, 15320, 15346, 15361, 15365, 15395, 15442, 15457, 15459, 15480, 15516, 15528, 15539, 15571, 15578, 15585, 15630, 15632, 15635, 15660, 15670, 15679, 15714, 15740, 15764, 15794, 15894, 15926, 15930, 15946, 15956, 15981, 15987, 15989, 15998, 16028, 16034, 16037, 16060, 16067, 16087, 16092, 16096, 16145, 16159, 16173, 16183, 16186, 16189, 16191, 16201, 16206, 16208, 16219, 16231, 16237, 16241, 16272, 16313, 16323, 16349, 16361, 16366, 16367, 16373, 16390, 16410, 16417, 16479, 16489, 16505, 16506, 16507, 16523, 16536, 16581, 16583, 16588, 16607, 16612, 16617, 16637, 16644, 16650, 16651, 16658, 16667, 16673, 16675, 16687, 16724, 16748, 16783, 16795, 16882, 16927, 16941, 16954, 16963, 16989, 17018, 17040, 17075, 17120, 17128, 17134, 17135, 17147, 17149, 17155, 17162, 17246, 17251, 17258, 17261, 17269, 17299, 17305, 17320, 17336, 17347, 17361, 17370, 17371, 17380, 17395, 17396, 17404, 17428, 17467, 17497, 17527, 17539, 17563, 17573, 17576, 17578, 17599, 17621, 17622, 17647, 17661, 17665, 17692, 17726, 17735, 17737, 17738, 17748, 17762, 17791, 17797, 17824, 17841, 17842, 17864, 17881, 17894, 17897, 17898, 17904, 17921, 17938, 17939, 17943, 17956, 17982, 17992, 17998, 18011, 18028, 18071, 18076, 18086, 18095, 18135, 18136, 18143, 18154, 18168, 18205, 18216, 18226, 18229, 18231, 18238, 18241, 18296, 18301, 18337, 18360, 18366, 18369, 18381, 18392, 18430, 18474, 18483, 18486, 18492, 18506, 18508, 18511, 18524, 18535, 18536, 18564, 18576, 18632, 18643, 18653, 18673, 18679, 18686, 18727, 18750, 18754, 18765, 18769, 18774, 18780, 18790, 18842, 18853, 18875, 18906, 18918, 18928, 19041, 19043, 19062, 19068, 19097, 19100, 19110, 19131, 19144, 19162, 19170, 19192, 19207, 19211, 19213, 19221, 19223, 19246, 19266, 19282, 19283, 19311, 19312, 19316, 19319, 19336, 19371, 19379, 19383, 19390, 19428, 19438, 19466, 19482, 19498, 19511, 19520, 19525, 19601, 19610, 19611, 19632, 19640, 19645, 19657, 19660, 19662, 19674, 19675, 19696, 19705, 19768, 19772, 19774, 19785, 19787, 19790, 19805, 19818, 19846, 19860, 19866, 19895, 19898, 19911, 19948, 19951, 19958, 19983, 20043, 20050, 20071, 20094, 20097, 20101, 20114, 20205, 20207, 20209, 20217, 20229, 20236, 20239, 20258, 20262, 20304, 20318, 20358, 20372, 20392, 20407, 20420, 20424, 20429, 20559, 20563, 20580, 20590, 20595, 20624, 20637, 20643, 20647, 20655, 20659, 20663, 20708, 20712, 20728, 20734, 20739, 20752, 20763, 20768, 20779, 20795, 20817, 20823, 20831, 20852, 20858, 20905, 20938, 20946, 20962, 20989, 20991, 20992, 21008, 21014, 21058, 21075, 21084, 21100, 21109, 21150, 21175, 21207, 21208, 21210, 21229, 21237, 21245, 21250, 21264, 21265, 21273, 21284, 21294, 21322, 21341, 21348, 21350, 21379, 21393, 21400, 21478, 21484, 21491, 21494, 21505, 21506, 21514, 21555, 21607, 21613, 21616, 21619, 21654, 21661, 21665, 21708, 21716, 21721, 21734, 21756, 21783, 21784, 21786, 21792, 21800, 21811, 21840, 21884, 21926, 21955, 21983, 22004, 22012, 22016, 22030, 22039, 22042, 22051, 22054, 22057, 22078, 22087, 22090, 22094, 22125, 22131, 22153, 22172, 22193, 22205, 22206, 22208, 22225, 22231, 22236, 22244, 22257, 22258, 22264, 22289, 22296, 22307, 22325, 22333, 22370, 22432, 22433, 22441, 22442, 22453, 22473, 22482, 22484, 22487, 22513, 22516, 22586, 22623, 22626, 22638, 22679, 22683, 22694, 22696, 22697, 22736, 22737, 22759, 22760, 22765, 22778, 22779, 22782, 22809, 22879, 22893, 22914, 22916, 22972, 22978, 22979, 22985, 22989, 22993, 23009, 23013, 23019, 23028, 23045, 23056, 23071, 23092, 23096, 23122, 23127, 23154, 23182, 23199, 23205, 23223, 23232, 23235, 23239, 23256, 23261, 23263, 23274, 23293, 23299, 23330, 23336, 23337, 23354, 23384, 23430, 23462, 23469, 23489, 23492, 23501, 23504, 23543, 23593, 23600, 23631, 23644, 23654, 23663, 23680, 23695, 23699, 23719, 23731, 23733, 23759, 23762, 23778, 23783, 23803, 23805, 23809, 23826, 23865, 23868, 23909, 23926, 23928, 23943, 23945, 23991, 24004, 24008, 24034, 24037, 24051, 24060, 24074, 24085, 24092, 24094, 24140, 24149, 24150, 24166, 24169, 24182, 24184, 24203, 24213, 24219, 24222, 24229, 24247, 24249, 24255, 24267, 24280, 24300, 24306, 24314, 24325, 24352, 24362, 24376, 24397, 24405, 24415, 24417, 24429, 24441, 24446, 24464, 24493, 24509, 24512, 24515, 24533, 24551, 24560, 24562, 24570, 24572, 24580, 24612, 24623, 24647, 24657, 24668, 24669, 24675, 24723, 24732, 24742, 24771, 24784, 24789, 24811, 24818, 24821, 24829, 24832, 24842, 24860, 24919, 24936, 24939, 24978, 24984, 25005, 25046, 25053, 25057, 25060, 25068, 25089, 25106, 25132, 25146, 25182, 25197, 25200, 25213, 25231, 25233, 25251, 25256, 25258, 25268, 25297, 25319, 25356, 25378, 25381, 25385, 25386, 25425, 25436, 25453, 25465, 25484, 25495, 25517, 25520, 25526, 25540, 25560, 25568, 25589, 25623, 25626, 25639, 25686, 25687, 25745, 25753, 25767, 25779, 25786, 25787, 25802, 25831, 25833, 25850, 25861, 25894, 25903, 25905, 25906, 25908, 25926, 25935, 25942, 25951, 25994, 26002, 26011, 26021, 26023, 26037, 26075, 26087, 26089, 26097, 26101, 26107, 26121, 26141, 26147, 26185, 26186, 26204, 26271, 26272, 26277, 26289, 26297, 26310, 26319, 26324, 26332, 26341, 26378, 26396, 26418, 26425, 26426, 26456, 26499, 26514, 26519, 26523, 26527, 26535, 26545, 26555, 26577, 26584, 26600, 26627, 26632, 26651, 26653, 26657, 26662, 26664, 26677, 26678, 26681, 26690, 26697, 26698, 26708, 26714, 26736, 26753, 26765, 26795, 26812, 26828, 26835, 26847, 26862, 26866, 26873, 26899, 26917, 26939, 26974, 26988, 26994, 27008, 27097, 27102, 27105, 27107, 27123, 27139, 27181, 27196, 27197, 27224, 27235, 27238, 27249, 27263, 27297, 27300, 27371, 27378, 27405, 27442, 27477, 27535, 27537, 27548, 27566, 27577, 27595, 27601, 27606, 27618, 27619, 27630, 27636, 27654, 27657, 27702, 27713, 27739, 27752, 27754, 27786, 27804, 27818, 27821, 27825, 27832, 27858, 27863, 27877, 27894, 27907, 27920, 27936, 27940, 27943, 27960, 27966, 27979, 27997, 28010, 28024, 28078, 28103, 28107, 28121, 28129, 28132, 28166, 28171, 28175, 28176, 28183, 28196, 28200, 28213, 28232, 28246, 28247, 28268, 28304, 28360, 28361, 28386, 28401, 28410, 28413, 28435, 28440, 28455, 28478, 28479, 28480, 28481, 28482, 28496, 28528, 28543, 28560, 28573, 28580, 28589, 28597, 28639, 28672, 28675, 28693, 28785, 28789, 28797, 28800, 28807, 28816, 28846, 28858, 28882, 28892, 28897, 28899, 28904, 28916, 28942, 28943, 28948, 28963, 29031, 29120, 29143, 29145, 29147, 29155, 29181, 29226, 29254, 29284, 29325, 29331, 29340, 29342, 29356, 29358, 29380, 29414, 29432, 29445, 29449, 29459, 29466, 29472, 29489, 29572, 29636, 29659, 29666, 29677, 29678, 29680, 29699, 29722, 29726, 29744, 29763, 29782, 29784, 29790, 29809, 29823, 29856, 29885, 29902, 29912, 29954, 29963, 29973, 30011, 30122, 30131, 30154, 30168, 30173, 30192, 30206, 30228, 30239, 30260, 30265, 30266, 30281, 30282, 30300, 30326, 30332, 30335, 30336, 30340, 30346, 30376, 30393, 30397, 30436, 30439, 30478, 30523, 30528, 30540, 30552, 30564, 30567, 30572, 30591, 30592, 30596, 30599, 30617, 30621, 30625, 30645, 30671, 30715, 30731, 30739, 30758, 30764, 30779, 30780, 30783, 30792, 30800, 30819, 30829, 30833, 30840, 30871, 30882, 30887, 30895, 30905, 30915, 30917, 30919, 30925, 30941, 30946, 30947, 30956, 30971, 30973, 30974, 30978, 31025, 31041, 31044, 31072, 31083, 31093, 31118, 31143, 31170, 31187, 31219, 31226, 31248, 31253, 31261, 31316, 31323, 31330, 31344, 31375, 31402, 31403, 31404, 31415, 31426, 31445, 31454, 31455, 31473, 31503, 31509, 31512, 31529, 31549, 31555, 31561, 31569, 31574, 31582, 31587, 31631, 31656, 31700, 31713, 31716, 31740, 31769, 31781, 31787, 31790, 31833, 31865, 31876, 31880, 31894, 31916, 31923, 31947, 31950, 31980, 32008, 32012, 32028, 32030, 32032, 32042, 32051, 32064, 32122, 32131, 32146, 32154, 32180, 32197, 32200, 32201, 32264, 32295, 32301, 32318, 32330, 32372, 32379, 32398, 32433, 32436, 32437, 32439, 32441, 32446, 32448, 32461, 32474, 32479, 32480, 32511, 32515, 32517, 32519, 32548, 32558, 32559, 32579, 32581, 32584, 32612, 32623, 32639, 32644, 32648, 32652, 32653, 32687, 32703, 32708, 32720, 32723, 32765, 32780, 32784, 32787, 32817, 32859, 32867, 32872, 32895, 32908, 32917, 32919, 32936, 32957, 32968, 32971, 33000, 33011, 33020, 33030, 33053, 33059, 33069, 33081, 33102, 33109, 33128, 33146, 33160, 33188, 33298, 33306, 33310, 33319, 33325, 33362, 33371, 33381, 33453, 33470, 33488, 33495, 33507, 33517, 33526, 33529, 33536, 33553, 33599, 33616, 33631, 33652, 33661, 33666, 33674, 33693, 33701, 33702, 33713, 33717, 33719, 33748, 33750, 33755, 33768, 33779, 33785, 33791, 33872, 33889, 33920, 33936, 33937, 33963, 33970, 33972, 33998, 34000, 34002, 34037, 34043, 34065, 34081, 34096, 34118, 34136, 34152, 34202, 34213, 34237, 34239, 34256, 34274, 34279, 34281, 34292, 34315, 34318, 34354, 34362, 34374, 34375, 34387, 34405, 34406, 34428, 34438, 34463, 34477, 34483, 34515, 34548, 34558, 34571, 34602, 34614, 34615, 34627, 34657, 34670, 34701, 34725, 34747, 34751, 34765, 34777, 34790, 34799, 34818, 34859, 34863, 34890, 34926, 34937, 34958, 34976, 34986, 34998, 35002, 35005, 35009, 35031, 35053, 35063, 35066, 35084, 35086, 35106, 35110, 35119, 35128, 35158, 35191, 35218, 35265, 35270, 35295, 35305, 35330, 35344, 35365, 35366, 35369, 35384, 35397, 35424, 35434, 35438, 35477, 35493, 35529, 35540, 35574, 35595, 35609, 35610, 35613, 35614, 35617, 35630, 35633, 35641, 35660, 35661, 35671, 35672, 35675, 35678, 35724, 35727, 35732, 35761, 35770, 35785, 35788, 35789, 35800, 35807, 35810, 35812, 35814, 35855, 35865, 35867, 35868, 35872, 35904, 35923, 35937, 35997, 36014, 36017, 36030, 36041, 36058, 36060, 36082, 36086, 36090, 36106, 36136, 36176, 36197, 36223, 36241, 36259, 36268, 36271, 36283, 36300, 36302, 36318, 36325, 36328, 36339, 36341, 36354, 36369, 36373, 36375, 36400, 36410, 36415, 36418, 36423, 36436, 36498, 36509, 36527, 36553, 36555, 36574, 36579, 36607, 36635, 36662, 36663, 36684, 36697, 36707, 36713, 36719, 36722, 36730, 36733, 36744, 36748, 36765, 36769, 36793, 36794, 36801, 36809, 36811, 36828, 36836, 36850, 36887, 36893, 36901, 36913, 36963, 36964, 36971, 36986, 36993, 36997, 37002, 37003, 37064, 37089, 37090, 37098, 37106, 37109, 37114, 37116, 37131, 37132, 37193, 37199, 37215, 37218, 37235, 37285, 37293, 37304, 37320, 37329, 37348, 37351, 37360, 37378, 37388, 37437, 37440, 37450, 37456, 37495, 37502, 37521, 37532, 37549, 37572, 37593, 37610, 37620, 37653, 37655, 37660, 37692, 37698, 37705, 37728, 37750, 37757, 37765, 37791, 37805, 37807, 37823, 37825, 37867, 37887, 37925, 37933, 37947, 37951, 37991, 38002, 38022, 38088, 38094, 38111, 38136, 38193, 38213, 38240, 38266, 38275, 38283, 38308, 38331, 38346, 38348, 38355, 38380, 38386, 38413, 38449, 38450, 38454, 38462, 38474, 38495, 38500, 38534, 38565, 38568, 38596, 38618, 38620, 38628, 38653, 38659, 38661, 38684, 38688, 38699, 38702, 38711, 38712, 38736, 38740, 38749, 38774, 38782, 38827, 38841, 38848, 38853, 38866, 38882, 38898, 38907, 38914, 38922, 38928, 38931, 38958, 38986, 38989, 38999, 39004, 39008, 39009, 39030, 39067, 39077, 39102, 39119, 39121, 39140, 39161, 39176, 39199, 39212, 39215, 39275, 39291, 39309, 39318, 39349, 39354, 39372, 39374, 39375, 39387, 39412, 39418, 39426, 39430, 39457, 39466, 39474, 39491, 39513, 39516, 39520, 39529, 39537, 39558, 39562, 39585, 39587, 39592, 39602, 39604, 39613, 39620, 39649, 39676, 39677, 39703, 39717, 39720, 39768, 39769, 39775, 39794, 39810, 39820, 39833, 39853, 39855, 39872, 39877, 39881, 39892, 39895, 39907, 39912, 39914, 39924, 39925, 39946, 39960, 39961, 39982, 39993, 40019, 40022, 40039, 40056, 40070, 40118, 40137, 40138, 40145, 40146, 40149, 40151, 40178, 40185, 40190, 40222, 40239, 40245, 40260, 40261, 40268, 40287, 40312, 40321, 40331, 40343, 40344, 40363, 40369, 40373, 40450, 40451, 40462, 40492, 40499, 40501, 40521, 40530, 40574, 40586, 40598, 40601, 40615, 40618, 40627, 40709, 40749, 40752, 40774, 40799, 40825, 40853, 40886, 40887, 40889, 40894, 40906, 40915, 40946, 40952, 40964, 40966, 40998, 41018, 41028, 41031, 41033, 41037, 41055, 41056, 41086, 41088, 41109, 41145, 41162, 41164, 41184, 41199, 41205, 41229, 41279, 41286, 41288, 41300, 41310, 41311, 41313, 41326, 41337, 41355, 41358, 41359, 41364, 41397, 41414, 41418, 41449, 41470, 41477, 41494, 41501, 41517, 41525, 41534, 41542, 41552, 41562, 41573, 41590, 41618, 41628, 41629, 41668, 41678, 41680, 41685, 41694, 41701, 41713, 41732, 41780, 41781, 41799, 41805, 41808, 41819, 41850, 41857, 41885, 41915, 41919, 41945, 41947, 41952, 41979, 41983, 41988, 41999, 42013, 42015, 42032, 42046, 42055, 42082, 42109, 42135, 42141, 42162, 42169, 42187, 42210, 42213, 42239, 42244, 42259, 42279, 42314, 42341, 42345, 42353, 42357, 42382, 42384, 42405, 42433, 42464, 42465, 42468, 42491, 42504, 42509, 42514, 42518, 42547, 42573, 42593, 42621, 42629, 42632, 42634, 42652, 42704, 42715, 42725, 42760, 42767, 42796, 42816, 42823, 42832, 42838, 42853, 42856, 42882, 42888, 42958, 42960, 42974, 42991, 43004, 43011, 43023, 43028, 43034, 43051, 43076, 43078, 43079, 43116, 43121, 43169, 43174, 43200, 43204, 43213, 43220, 43252, 43262, 43293, 43304, 43324, 43337, 43339, 43375, 43399, 43403, 43416, 43417, 43465, 43508, 43509, 43513, 43517, 43562, 43582, 43584, 43595, 43601, 43649, 43655, 43657, 43668, 43676, 43677, 43681, 43702, 43721, 43736, 43763, 43766, 43796, 43800, 43814, 43843, 43848, 43862, 43894, 43896, 43920, 43926, 43947, 43962, 43984, 43996, 44002, 44022, 44056, 44069, 44085, 44103, 44111, 44124, 44139, 44148, 44153, 44249, 44265, 44282, 44292, 44328, 44332, 44340, 44376, 44395, 44401, 44439, 44489, 44500, 44516, 44527, 44541, 44555, 44570, 44587, 44646, 44653, 44658, 44668, 44669, 44674, 44682, 44691, 44785, 44792, 44796, 44828, 44832, 44838, 44843, 44851, 44860, 44873, 44889, 44909, 44917, 44925, 44947, 44949, 44966, 44973, 44982, 44995, 45026, 45043, 45047, 45049, 45055, 45060, 45091, 45111, 45122, 45135, 45152, 45155, 45173, 45179, 45182, 45189, 45230, 45277, 45279, 45293, 45298, 45305, 45311, 45342, 45354, 45377, 45380, 45388, 45396, 45422, 45426]\n"
     ]
    }
   ],
   "source": [
    "print(count)\n",
    "print(idxx[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm = read_image(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-78.997   1.    581.    975.     39.628   0.     31.139]\n"
     ]
    }
   ],
   "source": [
    "print(data_reg[1][-7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7effb9f58d10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 4320x4320 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(60,60))         # Sample figsize in inches\n",
    "sns.heatmap(imm[0][6], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(num_filters, kernel_lam, bias_lam):\n",
    "#     num_filters, lam = 5, 5\n",
    "    data_format = 'channels_first'\n",
    "    convolution_init, dense_init = \"lecun_normal\", \"RandomNormal\"\n",
    "    convolution_filter, dense_filter = 'selu', 'linear' #softsign, sigmoid; relu, linear\n",
    "    filter_shape, pool_size = (3, 3), (2,2)\n",
    "    cnn = models.Sequential()\n",
    "    cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size=pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(2*num_filters, filter_shape,padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size=pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(2*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "#                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                          kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "#                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                          kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam), \n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(2*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "#                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                          kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam), \n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "#                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                          kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Flatten())\n",
    "    cnn.add(layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=convolution_init))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization())\n",
    "    cnn.add(layers.Dense(1, activation=dense_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=dense_init))\n",
    "    return cnn\n",
    "\n",
    "\n",
    "class DataBatchGenerator(Sequence):\n",
    "    def __init__(self, dataset:np.ndarray, batch_size:int, start_idx:int, number_image_channels:int,\n",
    "                 max_x, max_y, float_memory_used):\n",
    "#         print(dataset.shape[0])\n",
    "        self.dataset, self.batch_size, self.start_idx = dataset, batch_size, start_idx\n",
    "        self.number_image_channels, self.max_x, self.max_y = number_image_channels, max_x, max_y\n",
    "        self.float_memory_used = float_memory_used\n",
    "    \n",
    "    def __len__(self):\n",
    "        return np.ceil(self.dataset.shape[0] / self.batch_size).astype(np.int)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        size = min(self.dataset.shape[0] - idx * self.batch_size, self.batch_size)\n",
    "        batch_x = np.empty((size, self.number_image_channels, self.max_x, self.max_y), dtype=self.float_memory_used)\n",
    "        batch_y = np.empty((size), dtype=self.float_memory_used)\n",
    "        for i in range(size):\n",
    "            batch_x[i] = read_image(self.start_idx + idx * self.batch_size + i)\n",
    "            batch_y[i] = self.dataset[idx * self.batch_size + i][-1]\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "def custom_loss(fp_penalty_coef, fn_penalty_coef):\n",
    "    # custom loss function that penalize false positive and negative differently\n",
    "    def loss(y_true, y_pred):\n",
    "        res = y_pred - y_true\n",
    "        res = tf.where(res > 0, res * fp_penalty_coef, res * fn_penalty_coef)\n",
    "        return K.mean(K.square(res))\n",
    "    return loss\n",
    "\n",
    "def fp_mae(y_true, y_pred):\n",
    "    # custom metric that replace false negative with zero and return the mean of new vector\n",
    "    res = y_pred - y_true\n",
    "    res = tf.nn.relu(res)\n",
    "#     res = tf.where(res <= 0, 0, res)\n",
    "    return K.mean(res)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(10, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 10, 1000, 1000)    640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 500, 500)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10, 500, 500)      40        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 500, 500)      1820      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 20, 250, 250)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 20, 250, 250)      80        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 250, 250)      5430      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 125, 125)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 125, 125)      120       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 40, 125, 125)      10840     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 40, 62, 62)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 40, 62, 62)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 40, 62, 62)        14440     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 40, 31, 31)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 40, 31, 31)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 40, 31, 31)        14440     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 40, 15, 15)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 40, 15, 15)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 40, 15, 15)        14440     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 40, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 40, 7, 7)          160       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1960)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                39220     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 102,671\n",
      "Trainable params: 102,191\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_samples: 8192 , New samples: 8192\n",
      "Validation size: 2704 , starts: 8192 , ends: 10895\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 8.30981, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00002: val_mae improved from 8.30981 to 7.40473, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 7.40473\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 7.40473\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 7.40473\n",
      "\n",
      "Epoch 00006: val_mae improved from 7.40473 to 7.34970, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 7.34970\n",
      "\n",
      "Epoch 00008: val_mae improved from 7.34970 to 7.11146, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 7.11146 to 6.95831, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 6.95831 to 6.62158, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 6.62158 to 6.52957, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 6.52957 to 6.42451, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 6.42451\n",
      "\n",
      "Epoch 00014: val_mae improved from 6.42451 to 5.64710, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 5.64710\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 5.64710\n",
      "\n",
      "Epoch 00017: val_mae improved from 5.64710 to 5.20050, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 5.20050\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 5.20050\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 5.20050\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 5.20050\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 5.20050\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 5.20050\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 5.20050\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 5.20050\n",
      "\n",
      "Lambda: 0 , Time: 3:49:41\n",
      "Train Error(all epochs): 2.5214934 \n",
      " [15.799, 7.796, 7.343, 7.203, 7.175, 7.118, 6.986, 6.798, 6.527, 6.284, 5.912, 5.385, 4.919, 4.556, 4.266, 4.093, 3.896, 3.634, 3.476, 3.256, 3.046, 2.887, 2.698, 2.74, 2.521]\n",
      "Train FP Error(all epochs): 1.2582748 \n",
      " [1.739, 3.473, 3.517, 3.559, 3.492, 3.502, 3.471, 3.369, 3.249, 3.097, 2.972, 2.664, 2.447, 2.269, 2.132, 2.038, 1.937, 1.823, 1.737, 1.631, 1.505, 1.462, 1.346, 1.37, 1.258]\n",
      "Val Error(all epochs): 5.200500965118408 \n",
      " [8.31, 7.405, 7.565, 7.725, 7.498, 7.35, 10.072, 7.111, 6.958, 6.622, 6.53, 6.425, 6.658, 5.647, 5.794, 5.704, 5.201, 5.435, 5.816, 5.209, 5.254, 5.215, 5.831, 5.331, 5.689]\n",
      "Val FP Error(all epochs): 1.7314566373825073 \n",
      " [5.365, 3.661, 3.188, 2.975, 3.407, 3.918, 9.56, 5.02, 4.282, 3.699, 4.621, 3.74, 3.442, 1.731, 2.641, 1.868, 2.724, 2.015, 4.336, 2.507, 2.385, 3.028, 4.388, 2.66, 2.19]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 8.24661, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00002: val_mae improved from 8.24661 to 7.52907, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00003: val_mae improved from 7.52907 to 7.25330, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00004: val_mae improved from 7.25330 to 7.23969, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 7.23969\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 7.23969\n",
      "\n",
      "Epoch 00007: val_mae improved from 7.23969 to 6.74962, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 6.74962 to 6.37019, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 6.37019 to 5.87275, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 5.87275\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 5.87275\n",
      "\n",
      "Epoch 00012: val_mae improved from 5.87275 to 5.61677, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 5.61677\n",
      "\n",
      "Epoch 00014: val_mae improved from 5.61677 to 5.50607, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 5.50607\n",
      "\n",
      "Epoch 00016: val_mae improved from 5.50607 to 5.37190, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 5.37190\n",
      "\n",
      "Epoch 00018: val_mae improved from 5.37190 to 5.30532, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 5.30532\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 5.30532\n",
      "\n",
      "Epoch 00021: val_mae improved from 5.30532 to 5.23990, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 5.23990\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 5.23990\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 5.23990\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 5.23990\n",
      "\n",
      "Lambda: 0.001 , Time: 3:53:30\n",
      "Train Error(all epochs): 2.4135706 \n",
      " [15.841, 7.39, 7.178, 7.106, 6.978, 6.662, 6.42, 6.099, 5.662, 5.159, 4.801, 4.511, 4.226, 3.98, 3.786, 3.574, 3.366, 3.243, 3.111, 2.905, 2.746, 2.662, 2.494, 2.525, 2.414]\n",
      "Train FP Error(all epochs): 1.196891 \n",
      " [1.511, 3.562, 3.529, 3.516, 3.441, 3.305, 3.203, 3.01, 2.815, 2.561, 2.394, 2.246, 2.104, 1.973, 1.904, 1.781, 1.682, 1.618, 1.553, 1.455, 1.378, 1.326, 1.238, 1.274, 1.197]\n",
      "Val Error(all epochs): 5.2399001121521 \n",
      " [8.247, 7.529, 7.253, 7.24, 7.316, 7.291, 6.75, 6.37, 5.873, 7.311, 5.922, 5.617, 6.054, 5.506, 5.802, 5.372, 5.393, 5.305, 5.41, 5.521, 5.24, 5.556, 5.392, 5.376, 5.559]\n",
      "Val FP Error(all epochs): 1.3283659219741821 \n",
      " [5.757, 3.488, 3.905, 3.542, 4.862, 3.073, 2.769, 3.383, 2.742, 1.692, 1.573, 3.161, 1.328, 3.732, 4.305, 3.24, 2.01, 2.161, 2.66, 4.2, 2.562, 2.548, 3.352, 2.773, 3.924]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 7.76887, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_mae improved from 7.76887 to 7.46088, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 7.46088\n",
      "\n",
      "Epoch 00004: val_mae improved from 7.46088 to 7.32908, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 7.32908\n",
      "\n",
      "Epoch 00006: val_mae improved from 7.32908 to 7.27257, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00007: val_mae improved from 7.27257 to 7.20523, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 7.20523 to 6.93075, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 6.93075\n",
      "\n",
      "Epoch 00010: val_mae improved from 6.93075 to 6.75989, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 6.75989\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 6.75989\n",
      "\n",
      "Epoch 00013: val_mae improved from 6.75989 to 6.67462, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 6.67462 to 5.17884, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 5.17884\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 5.17884\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 5.17884\n",
      "\n",
      "Epoch 00018: val_mae improved from 5.17884 to 5.08617, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 5.08617\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 5.08617\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 5.08617\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 5.08617\n",
      "\n",
      "Epoch 00023: val_mae improved from 5.08617 to 5.01693, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 5.01693\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 5.01693\n",
      "\n",
      "Lambda: 0.01 , Time: 3:52:13\n",
      "Train Error(all epochs): 2.7071304 \n",
      " [15.597, 7.427, 7.275, 7.196, 7.14, 7.109, 7.026, 6.84, 6.668, 6.456, 5.968, 5.362, 4.93, 4.52, 4.283, 4.025, 3.856, 3.636, 3.529, 3.338, 3.17, 3.018, 2.86, 2.777, 2.707]\n",
      "Train FP Error(all epochs): 1.3486924 \n",
      " [1.621, 3.507, 3.557, 3.535, 3.497, 3.499, 3.479, 3.371, 3.312, 3.192, 2.974, 2.659, 2.439, 2.254, 2.121, 2.013, 1.903, 1.812, 1.749, 1.675, 1.581, 1.497, 1.429, 1.379, 1.349]\n",
      "Val Error(all epochs): 5.016932010650635 \n",
      " [7.769, 7.461, 7.641, 7.329, 7.446, 7.273, 7.205, 6.931, 7.223, 6.76, 9.969, 6.879, 6.675, 5.179, 5.404, 5.825, 5.311, 5.086, 5.534, 5.214, 5.14, 5.391, 5.017, 5.284, 5.451]\n",
      "Val FP Error(all epochs): 1.1675214767456055 \n",
      " [4.93, 3.722, 2.842, 3.258, 3.799, 4.051, 4.402, 3.554, 5.293, 4.06, 1.168, 1.657, 5.662, 2.727, 3.793, 1.452, 2.519, 2.785, 2.359, 3.745, 3.107, 2.602, 2.939, 2.651, 4.118]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 7.67595, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00002: val_mae improved from 7.67595 to 7.33501, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00003: val_mae improved from 7.33501 to 7.13779, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 7.13779\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 7.13779\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 7.13779\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 7.13779\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 7.13779\n",
      "\n",
      "Epoch 00009: val_mae improved from 7.13779 to 6.65482, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 6.65482 to 5.46289, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 5.46289\n",
      "\n",
      "Epoch 00012: val_mae improved from 5.46289 to 5.44120, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 5.44120\n",
      "\n",
      "Epoch 00014: val_mae improved from 5.44120 to 4.94236, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 4.94236 to 4.71045, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 4.71045\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 4.71045\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 4.71045\n",
      "\n",
      "Epoch 00019: val_mae improved from 4.71045 to 4.62934, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 4.62934\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 4.62934\n",
      "\n",
      "Epoch 00022: val_mae improved from 4.62934 to 4.34264, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 4.34264\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 4.34264\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 4.34264\n",
      "\n",
      "Lambda: 0.1 , Time: 3:53:26\n",
      "Train Error(all epochs): 3.4897532 \n",
      " [15.877, 7.615, 7.279, 7.184, 7.045, 6.972, 6.833, 6.603, 6.059, 5.554, 5.217, 4.874, 4.645, 4.419, 4.33, 4.175, 4.079, 3.991, 3.933, 3.869, 3.844, 3.711, 3.603, 3.565, 3.49]\n",
      "Train FP Error(all epochs): 1.6441216 \n",
      " [1.644, 3.47, 3.511, 3.491, 3.423, 3.413, 3.356, 3.232, 2.985, 2.729, 2.575, 2.383, 2.285, 2.179, 2.133, 2.061, 1.994, 1.964, 1.941, 1.91, 1.901, 1.807, 1.78, 1.764, 1.716]\n",
      "Val Error(all epochs): 4.3426384925842285 \n",
      " [7.676, 7.335, 7.138, 8.29, 7.151, 8.667, 7.406, 7.51, 6.655, 5.463, 5.603, 5.441, 6.062, 4.942, 4.71, 5.082, 4.742, 4.924, 4.629, 4.832, 5.513, 4.343, 4.583, 4.71, 5.164]\n",
      "Val FP Error(all epochs): 1.2786154747009277 \n",
      " [4.969, 3.392, 3.863, 2.207, 4.872, 2.286, 2.654, 6.078, 4.916, 3.26, 3.504, 3.769, 5.196, 2.525, 2.71, 3.826, 3.295, 2.33, 2.311, 2.245, 1.279, 1.909, 2.632, 2.666, 1.461]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 7.38975, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_4.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 7.38975\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 7.38975\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 7.38975\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 7.38975\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 7.38975\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 7.38975\n",
      "\n",
      "Epoch 00008: val_mae improved from 7.38975 to 7.33278, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_4.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00009: val_mae improved from 7.33278 to 7.28701, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_4.h5\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 7.28701\n",
      "\n",
      "Epoch 00011: val_mae improved from 7.28701 to 7.21970, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_4.h5\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 7.21970\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 7.21970\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 7.21970\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 7.21970\n",
      "\n",
      "Epoch 00016: val_mae improved from 7.21970 to 7.20932, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_4.h5\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 7.20932\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 7.20932\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 7.20932\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 7.20932\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 7.20932\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 7.20932\n",
      "\n",
      "Epoch 00023: val_mae improved from 7.20932 to 7.12881, saving model to ML/data/pictures_1000_1000/log/noisy_std_1/pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/3600sensors/models/8192/best_model_lambda_4.h5\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 7.12881\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 7.12881\n",
      "\n",
      "Lambda: 1 , Time: 3:52:25\n",
      "Train Error(all epochs): 7.152094 \n",
      " [16.095, 7.524, 7.426, 7.457, 7.4, 7.339, 7.329, 7.254, 7.261, 7.225, 7.225, 7.215, 7.203, 7.209, 7.188, 7.184, 7.176, 7.186, 7.178, 7.178, 7.175, 7.159, 7.164, 7.159, 7.152]\n",
      "Train FP Error(all epochs): 1.4048579 \n",
      " [1.405, 3.307, 3.408, 3.397, 3.43, 3.435, 3.442, 3.443, 3.453, 3.474, 3.429, 3.49, 3.485, 3.483, 3.474, 3.486, 3.503, 3.491, 3.505, 3.486, 3.5, 3.496, 3.487, 3.516, 3.496]\n",
      "Val Error(all epochs): 7.12880802154541 \n",
      " [7.39, 7.4, 8.087, 7.59, 7.509, 8.323, 7.407, 7.333, 7.287, 7.346, 7.22, 7.38, 7.382, 7.292, 7.341, 7.209, 7.376, 7.267, 7.491, 7.23, 7.291, 7.262, 7.129, 15.591, 7.26]\n",
      "Val FP Error(all epochs): 1.0962858200073242 \n",
      " [3.583, 3.17, 2.716, 3.157, 4.575, 3.581, 3.331, 3.456, 4.672, 3.57, 4.14, 3.245, 3.437, 3.494, 3.306, 3.652, 3.402, 3.362, 3.117, 3.673, 3.387, 3.383, 4.221, 1.096, 3.621]\n",
      "\n",
      "Trainig set size: 8192 , Time: 19:21:17 , best_lambda: 0.1 , min_  error: 4.343\n",
      "Test starts:  10896 , ends:  34999\n",
      "1507/1507 [==============================] - 1138s 755ms/step\n",
      "average_error:  4.351 , fp_average_error:  1.843\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CNN: support batching\n",
    "TEST = True\n",
    "mini_batch, epochs = 16, 25\n",
    "MAX_QUEUE_SIZE, WORKERS = 6, 1\n",
    "fp_penalty_coef, fn_penalty_coef = 1, 1\n",
    "hyper_metric, mode = 'val_mae', 'min'  # the metric that hyper parameters are tuned with\n",
    "prev_sample = 0\n",
    "lambda_vec = [0, 0.001, 0.01, 0.1, 1]  #0.003, 0.01, 0.03, 0.1, 0.3, 1, 3\n",
    "# MODEL_PATH = 'models/'\n",
    "average_diff_power, fp_mean_power = [],[] #[7.177, 8.088, 8.183], [3.438, 3.506, 2.662]\n",
    "best_lambda = []\n",
    "# average_diff_power, fp_mean_power = [7.568, 7.916],[3.357, 2.705] \n",
    "# checkpointers = [ModelCheckpoint(filepath=MODEL_PATH + str(lamb_idx)+ '.h5',\n",
    "#                                  verbose=1, save_best_only=True, monitor=hyper_metric, mode=mode, period=1)\n",
    "#                  for lamb_idx in range(len(lambda_vec))]\n",
    "\n",
    "for num_sample_idx, number_sample in enumerate(number_samples):\n",
    "#     if num_sample_idx < 3:\n",
    "#         continue\n",
    "#     if num_sample_idx == 0:\n",
    "    MODEL_PATH = '/'.join(image_dir.split('/')[:-1]) + '/models/' + str(number_sample)\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.makedirs(MODEL_PATH)\n",
    "    MODEL_PATH += \"/best_model_lambda_\"\n",
    "    if True:\n",
    "        cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "        for cnn in cnns:\n",
    "#             cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae', fp_mean])\n",
    "            cnn.compile(loss=custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                        optimizer='adam', \n",
    "                        metrics=['mse', 'mae', fp_mae])\n",
    "        checkpointers = [ModelCheckpoint(filepath=MODEL_PATH + str(lamb_idx)+ '.h5',\n",
    "                                         verbose=1, save_best_only=True, monitor=hyper_metric, mode=mode, period=1)\n",
    "                         for lamb_idx in range(len(lambda_vec))]\n",
    "    else:\n",
    "        cnns = []\n",
    "        cnns = [models.load_model(MODEL_PATH + str(lamb_idx) + '.h5', \n",
    "                                  custom_objects={ 'loss': custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                                                  'fp_mae': fp_mae }) \n",
    "                for lamb_idx in range(len(lambda_vec))]\n",
    "    number_start = time.time()\n",
    "    train_generator = DataBatchGenerator(dataset=data_reg[prev_sample:number_sample], batch_size=mini_batch,\n",
    "                                         start_idx=prev_sample, number_image_channels=number_image_channels,\n",
    "                                         max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "    \n",
    "\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "    val_generator = DataBatchGenerator(dataset=data_reg[number_sample:number_sample+val_size], \n",
    "                                       batch_size=mini_batch,\n",
    "                                       start_idx=number_sample, number_image_channels=number_image_channels,\n",
    "                                       max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "  \n",
    "    print('number_samples:', number_sample, \", New samples:\", number_sample - prev_sample)\n",
    "    print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", number_sample + val_size - 1)\n",
    "\n",
    "    for lamb_idx, lamb in enumerate(lambda_vec[:len(lambda_vec) - num_sample_idx//2]):\n",
    "#         if num_sample_idx == 3 and lamb_idx < 4:\n",
    "#             continue\n",
    "        lambda_start = time.time()\n",
    "        cnns[lamb_idx].fit(train_generator, epochs=epochs, verbose=0, validation_data=val_generator, \n",
    "                           shuffle=True, callbacks=[checkpointers[lamb_idx]], \n",
    "                           workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, use_multiprocessing=False)\n",
    "        \n",
    "        print(\"\\nLambda:\", lamb, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - lambda_start))))\n",
    "        print(\"Train Error(all epochs):\", min(cnns[lamb_idx].history.history['mae']), '\\n', \n",
    "              [round(val, 3) for val in cnns[lamb_idx].history.history['mae']])\n",
    "        print(\"Train FP Error(all epochs):\", min(cnns[lamb_idx].history.history['fp_mae']), '\\n',\n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['fp_mae']])\n",
    "        print(\"Val Error(all epochs):\", min(cnns[lamb_idx].history.history['val_mae']), '\\n', \n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['val_mae']])\n",
    "        print(\"Val FP Error(all epochs):\", min(cnns[lamb_idx].history.history['val_fp_mae']), '\\n',\n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['val_fp_mae']])\n",
    "#     if num_sample_idx == 3:    \n",
    "#         models_min_mae = [8.27781, 8.23545, 8.20838, 7.74743]\n",
    "#         models_min_mae += [min(cnns[lamb_idx].history.history[hyper_metric]) for lamb_idx in range(4,lamb_idx+1)]\n",
    "#     else:\n",
    "    models_min_mae = [min(cnns[lamb_idx].history.history[hyper_metric]) for lamb_idx in range(lamb_idx+1)]\n",
    "    best_lamb_idx = models_min_mae.index(min(models_min_mae))\n",
    "    best_lambda.append(lambda_vec[best_lamb_idx])\n",
    "    print(\"\\nTrainig set size:\", number_sample, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - \n",
    "                                                                                              number_start)))\n",
    "          ,\", best_lambda:\", lambda_vec[best_lamb_idx], \", min_\" , (\"fp_\" if hyper_metric == \"val_fp_mae\" else \"\"),\n",
    "          \"error:\", round(min(models_min_mae), 3))\n",
    "    del cnns, train_generator, val_generator, checkpointers\n",
    "    \n",
    "    if TEST:\n",
    "        # evaluating test images\n",
    "        best_model = None\n",
    "        best_model = models.load_model(MODEL_PATH + str(best_lamb_idx) + '.h5', \n",
    "                                       custom_objects={ 'loss': custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                                                       'fp_mae': fp_mae })\n",
    "        test_generator = DataBatchGenerator(dataset=data_reg[number_sample + val_size:], \n",
    "                                            batch_size=mini_batch,\n",
    "                                            start_idx=number_sample + val_size, \n",
    "                                            number_image_channels=number_image_channels,\n",
    "                                            max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "\n",
    "        print(\"Test starts: \", number_sample + val_size, \", ends: \", data_reg.shape[0] - 1)\n",
    "        time.sleep(1)\n",
    "        test_res = best_model.evaluate(test_generator, verbose=1, \n",
    "                                       workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, use_multiprocessing=False)\n",
    "        \n",
    "        test_mae_idx, test_fp_mae_idx = [best_model.metrics_names.index(mtrc) for mtrc in ['mae','fp_mae']]\n",
    "        test_mae, test_fp_mae = test_res[test_mae_idx], test_res[test_fp_mae_idx]\n",
    "        average_diff_power.append(round(test_mae, 3))\n",
    "        fp_mean_power.append(round(test_fp_mae, 3))\n",
    "\n",
    "        print('average_error: ', average_diff_power[-1], ', fp_average_error: ', \n",
    "              fp_mean_power[-1])\n",
    "        print(\"\\n\\n\")\n",
    "        var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                     dtime + \".dat\", \"wb\") # file for saving results\n",
    "        pickle.dump([average_diff_power, fp_mean_power, number_samples, best_lambda, \n",
    "                     dataset_name, max_dataset_name], file=var_f)\n",
    "        var_f.close()\n",
    "        del best_model, test_generator\n",
    "#     prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_min_mae = [8.27781, 8.23545, 8.20838]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power = [8.166, 7.844, 7.592]\n",
    "fp_mean_power = [4.56, 4.42, 4.37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.351]\n",
      "[1.843]\n",
      "[8192]\n",
      "[0.1]\n"
     ]
    }
   ],
   "source": [
    "print(average_diff_power)\n",
    "print(fp_mean_power)\n",
    "print(number_samples)\n",
    "print(best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<built-in function GetOperationInputs> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1443\u001b[0m     \u001b[0m__swig_setmethods__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m     \u001b[0m__setattr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_swig_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTF_Output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m     \u001b[0m__swig_getmethods__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m_swig_setattr\u001b[0;34m(self, class_type, name, value)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_swig_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_swig_setattr_nondynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m_swig_setattr_nondynamic\u001b[0;34m(self, class_type, name, value, static)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SwigPyObject'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2bfc622779b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlambda_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#, 0.3, 1, 3, 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0maverage_diff_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_mean_power\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlamb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlambda_vec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcnns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-2bfc622779b0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlambda_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#, 0.3, 1, 3, 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0maverage_diff_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_mean_power\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlamb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlambda_vec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcnns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-21260a02aa4c>\u001b[0m in \u001b[0;36mcnn_model\u001b[0;34m(num_filters, kernel_lam, bias_lam)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m#                          kernel_initializer='lecun_normal'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;31m#     cnn.add(layers.Dropout(0.25))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'cntk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             sample_size = K.prod([K.shape(inputs)[axis]\n\u001b[0;32m--> 189\u001b[0;31m                                   for axis in reduction_axes])\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0msample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/keras/layers/normalization.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'cntk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             sample_size = K.prod([K.shape(inputs)[axis]\n\u001b[0;32m--> 189\u001b[0;31m                                   for axis in reduction_axes])\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0msample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m    977\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10392\u001b[0m                         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10393\u001b[0m                         \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10394\u001b[0;31m                         shrink_axis_mask=shrink_axis_mask, name=name)\n\u001b[0m\u001b[1;32m  10395\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10396\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    791\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    792\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    794\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    546\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    547\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3427\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3428\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3429\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3430\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3431\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_control_flow_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_control_flow_post_processing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m     \u001b[0mavailable\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m     \"\"\"\n\u001b[0;32m-> 1800\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m       \u001b[0mcontrol_flow_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckInputFromValidContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2161\u001b[0m     \u001b[0;34m\"\"\"The list of `Tensor` objects representing the data inputs of this op.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs_val\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2163\u001b[0;31m       \u001b[0mtf_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetOperationInputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2164\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2165\u001b[0m       retval = [\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function GetOperationInputs> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "# CNN: support batching\n",
    "TEST = True\n",
    "mini_batch, epochs = 16, 30\n",
    "batch_size = (batch_size // mini_batch) * mini_batch\n",
    "prev_sample = 0\n",
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]  #, 0.3, 1, 3, 10\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "for cnn in cnns:\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "for number_sample in number_samples:\n",
    "    number_start = time.time()\n",
    "    current_sample = number_sample - prev_sample\n",
    "    train_samples = [batch_size] * (current_sample//batch_size) + ([current_sample%batch_size] if \n",
    "                                                                    current_sample%batch_size else [])\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "#     val_samples = [batch_size] * (val_size//batch_size) + ([val_size%batch_size] if \n",
    "#                                                                val_size%batch_size else [])\n",
    "    \n",
    "    print('number_samples:', number_sample)\n",
    "    print(\"Train batches:\", train_samples)\n",
    "    for i, train_sample in enumerate(train_samples):\n",
    "        print(\"Train batch#:\", i, \", batch size:\", train_sample, \", starts:\", prev_sample + i * batch_size,\n",
    "                      \", ends:\", prev_sample + i * batch_size + train_sample - 1)\n",
    "    print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", number_sample + val_size - 1)\n",
    "#     print(\"Validation Batches:\", val_samples)\n",
    "#     for i, val_sample in enumerate(val_samples):\n",
    "#         print(\"Validation batch#:\", i, \", batch size:\", val_sample, \", starts:\", number_sample + i * batch_size,\n",
    "#                       \", ends:\", number_sample + i * batch_size + val_sample - 1)\n",
    "        \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb_idx, lamb in enumerate(lambda_vec):\n",
    "        lambda_start = time.time()\n",
    "        \n",
    "#         cnn = cnn_model(10, lamb, 0)\n",
    "#         cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "        # training on all batches\n",
    "        for i, train_sample in enumerate(train_samples):\n",
    "#             if lamb_idx == 0:\n",
    "#                 print(\"Train batch#:\", i, \", batch size:\", train_sample, \", starts:\", prev_sample + i * batch_size,\n",
    "#                       \", ends:\", prev_sample + i * batch_size + train_sample - 1)\n",
    "            x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "            y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "            for image_num in range(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample):\n",
    "                x_train[(image_num - prev_sample) % batch_size] = read_image(image_num)\n",
    "                y_train[(image_num - prev_sample) % batch_size] = np.asarray(data_reg[image_num][-1], \n",
    "                                                                             dtype=float_memory_used)\n",
    "            cnns[lamb_idx].fit(x_train, y_train, epochs=epochs, verbose=2, batch_size=mini_batch,\n",
    "                               validation_split=0.2, \n",
    "                               shuffle=True)\n",
    "            del x_train, y_train\n",
    "#         if lamb_idx == 0:\n",
    "#             print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", \n",
    "#                   number_sample + val_size - 1)\n",
    "        print(\"\\nLambda:\", lamb)\n",
    "        print(\"Train Error(all epochs): \", cnns[lamb_idx].history.history['mae'])\n",
    "        \n",
    "        # validating\n",
    "        val_mae, val_fp_mae = 0.0, 0.0\n",
    "#         for i, val_sample in enumerate(val_samples):\n",
    "#             x_val = np.empty((val_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "#             for image_num in range(val_sample):\n",
    "#                 x_val[image_num] = read_image(image_num + number_sample + i * batch_size)\n",
    "#             yp_val = cnns[lamb_idx].predict(x_val)\n",
    "        for image_num in range(val_size):\n",
    "            val_y = data_reg[image_num + number_sample][-1]\n",
    "            image = read_image(image_num + number_sample)\n",
    "            val_yp = cnns[lamb_idx].predict(image)[0][0]\n",
    "#             for image_num in range(val_sample):\n",
    "#                 val_yp = yp_val[image_num][0]\n",
    "#                 val_y = data_reg[image_num + number_sample + i * batch_size][-1]\n",
    "            val_mae += abs(val_y - val_yp)\n",
    "            if val_yp > val_y:\n",
    "                val_fp_mae += abs(val_yp - val_y)\n",
    "        val_mae /= val_size\n",
    "        val_fp_mae /= val_size\n",
    "        print(\"Val Error:\", round(val_mae, 3), \", Time:\", str(datetime.timedelta(seconds=int(time.time() - lambda_start))))\n",
    "        if val_mae < min_error:\n",
    "            min_error = val_mae\n",
    "            best_model = cnns[lamb_idx]\n",
    "            best_lam = lamb\n",
    "            best_lam_idx = lamb_idx\n",
    "    print(\"\\nTrainig set size:\", number_sample, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - number_start)))\n",
    "          ,\", best_lambda:\", best_lam, \", min_error:\", round(min_error, 3))\n",
    "    \n",
    "    \n",
    "    if TEST:\n",
    "        # evaluating test images\n",
    "        sum_mae, sum_fp_mae = 0, 0\n",
    "        test_size = 0\n",
    "\n",
    "        y_test_p = np.empty((data_reg.shape[0] - (number_sample + val_size)), dtype=float_memory_used)\n",
    "    #     test_size = data_reg.shape[0] - (number_sample + val_size)\n",
    "    #     test_samples = [batch_size] * (test_size//batch_size) + ([test_size%batch_size] if \n",
    "    #                                                              test_size%batch_size else [])\n",
    "        print(\"Test starts: \", number_sample + val_size, \", ends: \", data_reg.shape[0] - 1)\n",
    "        time.sleep(1)\n",
    "    #     for i, test_sample in tqdm.tqdm(enumerate(test_samples)):\n",
    "    #         x_test = np.empty((test_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "    #         for image_num in range(test_sample):\n",
    "    #             x_test[image_num] = read_image(number_sample + val_size + i * batch_size)\n",
    "    #         yp_test = cnns[best_lam_idx].predict(x_test)\n",
    "    #         for image_num in range(test_sample):\n",
    "    #             test_y = data_reg[number_sample + val_size + i * batch_size][-1]\n",
    "    #             test_yp = yp_test[image_num][0]\n",
    "    #             sum_mae += abs(test_yp - test_y)\n",
    "    #             if test_yp > test_y:\n",
    "    #                 sum_fp_mae += abs(test_yp - test_y)\n",
    "\n",
    "        for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "            test_size += 1\n",
    "            test_image = read_image(test_num)\n",
    "            test_y = data_reg[test_num][-1]\n",
    "            test_yp = best_model.predict(test_image)[0][0]\n",
    "            y_test_p[test_num - (number_sample + val_size)] = test_yp\n",
    "            sum_mae += abs(test_yp - test_y)\n",
    "            if test_yp > test_y:\n",
    "                sum_fp_mae += abs(test_yp - test_y)\n",
    "        fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "        average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "        print('average_error: ', average_diff_power[-1], ', fp_average_error: ', \n",
    "              fp_mean_power[-1])\n",
    "        print(\"\\n\\n\")\n",
    "        var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                     dtime + \".dat\", \"wb\") # file for saving results\n",
    "        pickle.dump([average_diff_power, fp_mean_power, number_samples], file=var_f)\n",
    "        var_f.close()\n",
    "    prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d_216_1/kernel:0' shape=(3, 3, 7, 10) dtype=float32, numpy=\n",
       " array([[[[ 0.13334414, -0.0261361 , -0.07441936,  0.16142276,\n",
       "            0.10993325,  0.04581179,  0.24121895,  0.23147854,\n",
       "            0.17021964, -0.0591266 ],\n",
       "          [ 0.09241038,  0.10264444,  0.00484879, -0.02517582,\n",
       "            0.06216534, -0.06764037,  0.02806018,  0.08384448,\n",
       "            0.13874047,  0.15180951],\n",
       "          [ 0.1893204 , -0.05741746,  0.00313846,  0.03854534,\n",
       "           -0.20698836,  0.00660574, -0.1372445 , -0.11774021,\n",
       "            0.10552079, -0.1360089 ],\n",
       "          [-0.1331031 ,  0.02123114,  0.00091115, -0.03792882,\n",
       "            0.22543769, -0.07044397, -0.09563252, -0.04734167,\n",
       "           -0.09483308,  0.04207201],\n",
       "          [ 0.06165536,  0.04747773,  0.00436929,  0.0485286 ,\n",
       "           -0.16992377,  0.06714778,  0.20848735,  0.16978653,\n",
       "           -0.07686065, -0.09264071],\n",
       "          [ 0.08572359, -0.19217153, -0.08705788,  0.12219634,\n",
       "           -0.27800012,  0.1237585 , -0.21454357,  0.04010623,\n",
       "           -0.13206151, -0.07199094],\n",
       "          [-0.13942277,  0.12991397,  0.05158436,  0.20681241,\n",
       "            0.0927059 , -0.06157902,  0.09529742, -0.06181924,\n",
       "           -0.20937485,  0.08383203]],\n",
       " \n",
       "         [[ 0.14524975, -0.05317885,  0.07710187, -0.06027135,\n",
       "           -0.03889057, -0.13648398, -0.11979997,  0.1689479 ,\n",
       "           -0.1522798 , -0.05902102],\n",
       "          [ 0.06488625,  0.12912498,  0.09674022,  0.20966475,\n",
       "           -0.04465631,  0.12140161,  0.14916958, -0.02789529,\n",
       "            0.03566265, -0.07232169],\n",
       "          [-0.07508589,  0.11446775, -0.13920276,  0.22177145,\n",
       "            0.08524486,  0.0902052 , -0.10775251,  0.08795813,\n",
       "           -0.0761055 , -0.09227429],\n",
       "          [ 0.02373275, -0.11338315,  0.1032308 , -0.07559496,\n",
       "            0.04385605, -0.1355971 ,  0.10978308,  0.10370436,\n",
       "            0.03486014,  0.04627065],\n",
       "          [-0.21984474,  0.05307737,  0.04838712,  0.16839921,\n",
       "            0.11966983,  0.14054751, -0.10383917, -0.17774169,\n",
       "           -0.08481254,  0.01736768],\n",
       "          [ 0.04152398, -0.06096472, -0.00492838,  0.1368062 ,\n",
       "            0.1721607 ,  0.07199505, -0.14697716, -0.23859444,\n",
       "           -0.1461731 , -0.03527378],\n",
       "          [-0.27617452,  0.15010485,  0.11511505, -0.12417073,\n",
       "           -0.08122088,  0.14036025,  0.1422506 ,  0.17473486,\n",
       "            0.08986371,  0.01991365]],\n",
       " \n",
       "         [[ 0.04023483,  0.01661961, -0.08479083, -0.28282636,\n",
       "            0.12767118,  0.0509973 , -0.05391447,  0.19763674,\n",
       "            0.16401489,  0.02086166],\n",
       "          [ 0.02320998,  0.21452   ,  0.02131915, -0.22229502,\n",
       "            0.07397044,  0.08494943,  0.04313029, -0.19079794,\n",
       "           -0.15622707, -0.12654568],\n",
       "          [-0.16471341,  0.07649319,  0.01780317,  0.17973316,\n",
       "            0.00282395,  0.01653246,  0.14217037, -0.07009459,\n",
       "            0.2320501 , -0.25558722],\n",
       "          [-0.13088815, -0.03935688, -0.01927   ,  0.06664042,\n",
       "            0.05449986, -0.27412698,  0.04830834,  0.05888246,\n",
       "           -0.11925068, -0.29004106],\n",
       "          [ 0.09491049, -0.02301907,  0.0727259 , -0.1380526 ,\n",
       "            0.06161747,  0.08663608,  0.00969613, -0.02390122,\n",
       "           -0.07748399, -0.11728296],\n",
       "          [-0.28847724, -0.17691025,  0.10943054,  0.17433746,\n",
       "           -0.01487851, -0.18751724, -0.12222388,  0.05808705,\n",
       "           -0.11082985, -0.17230581],\n",
       "          [-0.04870008, -0.2375922 ,  0.0976412 ,  0.22535303,\n",
       "            0.01409588, -0.02963496,  0.2672263 ,  0.00094256,\n",
       "            0.05225825,  0.03488791]]],\n",
       " \n",
       " \n",
       "        [[[-0.19926119, -0.03603117, -0.05551852, -0.10433564,\n",
       "           -0.14335166,  0.06645513, -0.2795412 , -0.17509606,\n",
       "            0.15266582, -0.05958281],\n",
       "          [ 0.00352683, -0.05189499,  0.14581002, -0.09802195,\n",
       "           -0.0185049 , -0.19627838, -0.17125873, -0.11177973,\n",
       "           -0.15869416,  0.23808493],\n",
       "          [ 0.07290543, -0.04298121,  0.01518185,  0.24427563,\n",
       "           -0.04966308,  0.13753985,  0.09585362,  0.13073985,\n",
       "            0.14580618, -0.05254631],\n",
       "          [ 0.04517658, -0.0560442 , -0.04483185, -0.19104496,\n",
       "           -0.02319299, -0.01029402, -0.15246606,  0.26141602,\n",
       "           -0.09231006,  0.27955005],\n",
       "          [-0.1809828 ,  0.06103823,  0.14722025,  0.08918977,\n",
       "            0.05734708, -0.11969002,  0.06482836, -0.1559477 ,\n",
       "            0.0741372 ,  0.04197035],\n",
       "          [-0.06164405,  0.10421135,  0.11966567, -0.11889777,\n",
       "            0.02610188, -0.02379085,  0.25728026,  0.22226161,\n",
       "            0.05567339, -0.09093149],\n",
       "          [-0.0941878 , -0.13269533,  0.14010622, -0.15810324,\n",
       "            0.09464984,  0.04383229,  0.11680618, -0.05575173,\n",
       "            0.05689744,  0.12688859]],\n",
       " \n",
       "         [[ 0.09463172,  0.07173032, -0.17775638,  0.12823975,\n",
       "            0.22743171, -0.03096067, -0.07845164,  0.10056094,\n",
       "            0.1375068 , -0.00266118],\n",
       "          [-0.13137127, -0.05241982,  0.1078676 , -0.1591938 ,\n",
       "            0.14385167,  0.17707717,  0.15017428, -0.05183896,\n",
       "            0.08562967,  0.07045954],\n",
       "          [ 0.00724656,  0.04945549, -0.00321115, -0.10365249,\n",
       "           -0.11740654, -0.03923345,  0.05962155,  0.10888351,\n",
       "           -0.09101029,  0.13877763],\n",
       "          [ 0.07962049,  0.05093174, -0.0761327 ,  0.12048989,\n",
       "            0.03043546, -0.10803499,  0.03744312,  0.02285842,\n",
       "            0.03543871, -0.05152218],\n",
       "          [-0.07119177, -0.07241955,  0.02490062,  0.00423546,\n",
       "           -0.04316133,  0.19139971, -0.01283269, -0.07494903,\n",
       "           -0.02201682, -0.06245283],\n",
       "          [ 0.00799846,  0.18765801, -0.09534817, -0.077469  ,\n",
       "           -0.11586822, -0.0051675 , -0.0102727 , -0.11339141,\n",
       "            0.03436622,  0.09942368],\n",
       "          [ 0.07523795,  0.03675905,  0.02437227, -0.01435202,\n",
       "           -0.02034545, -0.09359565, -0.02359232,  0.04803864,\n",
       "            0.20680504, -0.00644547]],\n",
       " \n",
       "         [[-0.1005403 ,  0.11378611,  0.21102735,  0.06846891,\n",
       "            0.09442588,  0.09777017, -0.11909521,  0.12265773,\n",
       "           -0.06148191, -0.07069711],\n",
       "          [ 0.01405865, -0.10141152, -0.11822031, -0.13485955,\n",
       "           -0.16953868, -0.21654141, -0.05722266, -0.01606212,\n",
       "           -0.07794228, -0.1521405 ],\n",
       "          [-0.08736753,  0.02725688, -0.01609255, -0.1761448 ,\n",
       "           -0.02491948, -0.07835825, -0.02474505, -0.2482235 ,\n",
       "            0.19618578, -0.08405739],\n",
       "          [-0.13201593,  0.07316361,  0.14873287,  0.03337387,\n",
       "            0.04706023, -0.03948716, -0.15505248,  0.06093074,\n",
       "            0.05425106,  0.18854883],\n",
       "          [ 0.12107033, -0.19670665,  0.03158212,  0.08311516,\n",
       "            0.01700125, -0.04055984, -0.08617479,  0.03713043,\n",
       "           -0.04209922, -0.01615153],\n",
       "          [ 0.0248774 , -0.02845379, -0.07260788, -0.1052746 ,\n",
       "            0.15719673, -0.07497114,  0.0163184 ,  0.15407056,\n",
       "           -0.19900005, -0.0528684 ],\n",
       "          [-0.09391885, -0.03256474,  0.02134794, -0.06547134,\n",
       "            0.02687071,  0.0165927 , -0.21028309,  0.18223254,\n",
       "            0.1601678 ,  0.06802534]]],\n",
       " \n",
       " \n",
       "        [[[-0.11673861, -0.02761208, -0.05152625,  0.26689234,\n",
       "            0.05464312, -0.0165887 , -0.15953052, -0.20351106,\n",
       "           -0.00750204, -0.04550588],\n",
       "          [-0.18615605,  0.19847395, -0.22109997, -0.04208753,\n",
       "            0.0015387 , -0.08712109, -0.12053566,  0.04012857,\n",
       "            0.12612605,  0.0755921 ],\n",
       "          [-0.19893515,  0.09130076, -0.02334492,  0.10549977,\n",
       "            0.10952222, -0.20525998,  0.13201837,  0.09622242,\n",
       "           -0.27899146, -0.1937835 ],\n",
       "          [ 0.02993972,  0.06206925, -0.02340401,  0.1940042 ,\n",
       "           -0.27053413, -0.02356468,  0.0402792 ,  0.00274105,\n",
       "            0.10014538,  0.1180291 ],\n",
       "          [ 0.09827848, -0.05272344, -0.24212418,  0.18239398,\n",
       "            0.28893584,  0.03425925,  0.18894415, -0.16935891,\n",
       "           -0.19899593, -0.17445645],\n",
       "          [-0.16428833,  0.15912978, -0.03123697,  0.19525754,\n",
       "            0.1313913 , -0.1464028 ,  0.19579571, -0.03027558,\n",
       "            0.02622594,  0.05283794],\n",
       "          [ 0.00537856, -0.02129651,  0.01653795, -0.03506261,\n",
       "            0.06030509,  0.0077933 , -0.26723355,  0.08907922,\n",
       "           -0.23224692,  0.15809113]],\n",
       " \n",
       "         [[-0.04699924,  0.21412279, -0.13859469,  0.15074492,\n",
       "           -0.05260769,  0.02953377,  0.21503067,  0.09594385,\n",
       "            0.18201022,  0.18532227],\n",
       "          [ 0.0813347 ,  0.1836983 , -0.05178611,  0.14537628,\n",
       "            0.13789822,  0.1196593 , -0.13453369, -0.05221471,\n",
       "           -0.26833838,  0.20581754],\n",
       "          [ 0.26625836, -0.22261377,  0.03792743,  0.14181626,\n",
       "           -0.13818225, -0.03733314, -0.2065161 , -0.11526174,\n",
       "            0.0504146 , -0.08647973],\n",
       "          [ 0.09377266,  0.2062351 ,  0.05943884,  0.03329353,\n",
       "           -0.10891343, -0.11080927,  0.23227565,  0.23207027,\n",
       "            0.15182719, -0.16632546],\n",
       "          [-0.01662905,  0.14488567,  0.1271512 ,  0.02320437,\n",
       "            0.01788143,  0.05921528, -0.0353229 , -0.188283  ,\n",
       "            0.1494947 , -0.18092439],\n",
       "          [-0.13061637,  0.1592543 ,  0.00978735, -0.05683037,\n",
       "            0.17805217,  0.02800326,  0.26188764, -0.11778035,\n",
       "            0.06277441, -0.12744053],\n",
       "          [ 0.00465929, -0.04557341, -0.15533756, -0.05069922,\n",
       "           -0.14725295, -0.0853371 , -0.20699254,  0.07564644,\n",
       "            0.02780418,  0.2634452 ]],\n",
       " \n",
       "         [[ 0.01776883, -0.03514121, -0.12700932,  0.12356611,\n",
       "           -0.10552283,  0.20057616,  0.04670141,  0.12937702,\n",
       "           -0.05964081,  0.2509442 ],\n",
       "          [-0.03483937,  0.04906264, -0.0862985 , -0.22901045,\n",
       "            0.00186068, -0.07967521, -0.02993756, -0.03580993,\n",
       "            0.23193611, -0.02563061],\n",
       "          [ 0.01709478,  0.07445383, -0.19091251, -0.0331335 ,\n",
       "            0.0253082 ,  0.02352164,  0.2859322 ,  0.10892042,\n",
       "            0.18633689, -0.0595445 ],\n",
       "          [-0.20758714,  0.07152744, -0.01677686, -0.01780074,\n",
       "           -0.12487143,  0.00212223, -0.01722952,  0.2022124 ,\n",
       "           -0.2645012 , -0.04340143],\n",
       "          [ 0.13472383,  0.00098047, -0.10209464,  0.14819503,\n",
       "           -0.08379597, -0.18391946, -0.01674595,  0.14736894,\n",
       "            0.11205667, -0.14535202],\n",
       "          [-0.07028721, -0.13803037, -0.09943354, -0.27029005,\n",
       "            0.04495002, -0.04398946,  0.05618115,  0.1637726 ,\n",
       "           -0.21474266, -0.09334109],\n",
       "          [-0.15808658, -0.23804595,  0.18949424,  0.04920245,\n",
       "           -0.20425159, -0.18336712, -0.08576456, -0.13084741,\n",
       "            0.00551501,  0.05699825]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_216_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.00394855,  0.01156156,  0.00672093, -0.00029083,  0.0033301 ,\n",
       "        -0.00794703, -0.01068521, -0.00623209, -0.00136579,  0.0004727 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_246_1/gamma:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.99889743, 1.0080869 , 0.9918417 , 0.99180245, 0.99210924,\n",
       "        1.0056474 , 1.0041177 , 1.0091603 , 0.999746  , 0.99256486],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_246_1/beta:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 1.2581445e-02,  7.9289870e-03, -7.9357335e-03, -1.1723038e-02,\n",
       "        -7.7971257e-03,  2.2734562e-03,  5.4945835e-05, -6.2508588e-03,\n",
       "         4.6733394e-04,  5.2858326e-03], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_217_1/kernel:0' shape=(3, 3, 10, 20) dtype=float32, numpy=\n",
       " array([[[[-0.00613516, -0.07706599,  0.006248  , ...,  0.01483129,\n",
       "           -0.13148054,  0.01379959],\n",
       "          [-0.06125846, -0.04463966,  0.15691034, ...,  0.06724139,\n",
       "           -0.08870574,  0.04128341],\n",
       "          [ 0.18929154, -0.07877082,  0.09513605, ..., -0.06041372,\n",
       "           -0.03992198, -0.18455972],\n",
       "          ...,\n",
       "          [ 0.02003453, -0.11194929, -0.11064813, ..., -0.08062167,\n",
       "            0.13399614, -0.022826  ],\n",
       "          [ 0.10247879, -0.09553227,  0.04918528, ...,  0.23149642,\n",
       "           -0.09936932, -0.01014787],\n",
       "          [-0.06446787,  0.0508823 ,  0.03458132, ...,  0.09098805,\n",
       "            0.05103992, -0.22692856]],\n",
       " \n",
       "         [[ 0.00899815, -0.01982983,  0.2108407 , ..., -0.11129528,\n",
       "            0.04713659,  0.02240109],\n",
       "          [ 0.0239722 ,  0.03624769, -0.13892104, ..., -0.1916124 ,\n",
       "            0.11251629,  0.05872869],\n",
       "          [-0.14052154, -0.02749509,  0.067243  , ..., -0.07384579,\n",
       "            0.1350736 ,  0.04331046],\n",
       "          ...,\n",
       "          [-0.1179302 , -0.04421049,  0.02058602, ..., -0.18133816,\n",
       "            0.14051902, -0.00200996],\n",
       "          [-0.13089395, -0.02914838,  0.02653082, ...,  0.09342858,\n",
       "           -0.08133891,  0.13094549],\n",
       "          [ 0.06657103, -0.18192683,  0.2327268 , ...,  0.06579488,\n",
       "            0.16109888, -0.0417343 ]],\n",
       " \n",
       "         [[ 0.14598422,  0.02474008, -0.2001503 , ..., -0.05117525,\n",
       "           -0.08759225,  0.09137008],\n",
       "          [ 0.11352185,  0.10408597,  0.05276801, ...,  0.02367296,\n",
       "            0.0709122 , -0.05202084],\n",
       "          [ 0.04591953,  0.00177405, -0.05923538, ..., -0.04373968,\n",
       "            0.09335176, -0.23466058],\n",
       "          ...,\n",
       "          [ 0.04117727,  0.09622082, -0.00483591, ..., -0.00573619,\n",
       "           -0.00544672, -0.07039722],\n",
       "          [-0.15966627,  0.13912055,  0.04043337, ...,  0.18531808,\n",
       "            0.12856238,  0.12779331],\n",
       "          [-0.11824572, -0.00606683, -0.02776809, ...,  0.03119941,\n",
       "           -0.06217549, -0.1021296 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.11843395, -0.11313166,  0.10206358, ...,  0.1424125 ,\n",
       "            0.02883888,  0.10749669],\n",
       "          [-0.0932157 ,  0.08986368,  0.08855385, ..., -0.04054831,\n",
       "            0.20761569,  0.17895086],\n",
       "          [ 0.21287711, -0.13902958, -0.05071876, ..., -0.10464473,\n",
       "            0.13464488,  0.00796567],\n",
       "          ...,\n",
       "          [-0.01583735, -0.10220268,  0.16242856, ..., -0.22936785,\n",
       "           -0.02587985,  0.05995097],\n",
       "          [-0.05231554, -0.07904537,  0.09455277, ...,  0.03787832,\n",
       "            0.05256969, -0.03759636],\n",
       "          [-0.09452608, -0.05021729, -0.00096467, ..., -0.1103365 ,\n",
       "            0.10697437, -0.14381793]],\n",
       " \n",
       "         [[-0.04669933,  0.01557779, -0.0037258 , ...,  0.12755205,\n",
       "            0.11051998,  0.04037065],\n",
       "          [ 0.07087644,  0.08811377,  0.0231888 , ..., -0.06829704,\n",
       "            0.07152358, -0.01255593],\n",
       "          [ 0.06456453,  0.1441479 ,  0.21550633, ...,  0.11959073,\n",
       "           -0.21130289, -0.01518227],\n",
       "          ...,\n",
       "          [ 0.06106412,  0.13728103, -0.02890644, ...,  0.07025255,\n",
       "           -0.0409243 , -0.0301967 ],\n",
       "          [-0.10983857,  0.08415116, -0.16161825, ..., -0.03688908,\n",
       "           -0.1048198 ,  0.06283347],\n",
       "          [-0.02078158,  0.07726054,  0.22857217, ..., -0.02705708,\n",
       "           -0.21459246,  0.20110175]],\n",
       " \n",
       "         [[ 0.10718577, -0.03096308, -0.03471959, ..., -0.15640563,\n",
       "           -0.17416269,  0.1678829 ],\n",
       "          [ 0.23790742, -0.12122889,  0.05106934, ..., -0.14332658,\n",
       "            0.13123561, -0.17268288],\n",
       "          [-0.07216983,  0.02125906,  0.04503383, ...,  0.02436657,\n",
       "            0.05501794,  0.01041913],\n",
       "          ...,\n",
       "          [-0.23144129, -0.04420161, -0.1883411 , ...,  0.06308959,\n",
       "            0.07754758, -0.0654578 ],\n",
       "          [ 0.0442895 ,  0.0457861 ,  0.08194239, ..., -0.15825216,\n",
       "            0.04440489, -0.0206511 ],\n",
       "          [-0.028714  ,  0.13239929, -0.03383066, ...,  0.09529423,\n",
       "           -0.22242351, -0.07872296]]],\n",
       " \n",
       " \n",
       "        [[[-0.09778915,  0.05839903,  0.02432927, ..., -0.04064826,\n",
       "           -0.10225639,  0.10601223],\n",
       "          [ 0.10263681, -0.01321077, -0.14533637, ..., -0.07213327,\n",
       "           -0.20481627, -0.02181217],\n",
       "          [-0.05705408, -0.16224189,  0.06692079, ..., -0.13675866,\n",
       "            0.03165859,  0.08559091],\n",
       "          ...,\n",
       "          [ 0.1333062 , -0.01051405,  0.10658982, ..., -0.13980907,\n",
       "           -0.13984981, -0.13669503],\n",
       "          [ 0.14150469,  0.06306539, -0.049619  , ..., -0.08240972,\n",
       "           -0.17580837, -0.15314321],\n",
       "          [ 0.12678467,  0.00361737,  0.12182796, ...,  0.05166734,\n",
       "            0.01910091,  0.19070801]],\n",
       " \n",
       "         [[-0.07456422,  0.04228234, -0.04476889, ...,  0.01102671,\n",
       "            0.03837417,  0.00232783],\n",
       "          [-0.1743557 ,  0.03958088,  0.21821131, ..., -0.06465518,\n",
       "           -0.05084631,  0.07745536],\n",
       "          [ 0.07760292,  0.0065304 , -0.1256236 , ...,  0.01159124,\n",
       "            0.18457702, -0.15225986],\n",
       "          ...,\n",
       "          [ 0.0826866 , -0.04612084, -0.08189004, ..., -0.1406778 ,\n",
       "           -0.15322529,  0.01678441],\n",
       "          [-0.07755306, -0.01942021, -0.04269481, ...,  0.20054315,\n",
       "            0.04770061, -0.06134127],\n",
       "          [-0.06864616, -0.02571295, -0.01662292, ..., -0.1724913 ,\n",
       "            0.01081838,  0.00735117]],\n",
       " \n",
       "         [[ 0.04716585, -0.04663199, -0.22949034, ...,  0.06523322,\n",
       "           -0.03782558,  0.11918577],\n",
       "          [-0.04422992,  0.02638413, -0.03934672, ..., -0.00764357,\n",
       "           -0.06596323,  0.00637577],\n",
       "          [-0.13985588,  0.04368904, -0.13685353, ..., -0.07130355,\n",
       "            0.13632149,  0.02693932],\n",
       "          ...,\n",
       "          [ 0.16433991, -0.18598363,  0.0482639 , ...,  0.07945465,\n",
       "           -0.00088441, -0.07022502],\n",
       "          [-0.0102343 ,  0.03097694,  0.01139166, ...,  0.00272   ,\n",
       "            0.09357451, -0.04334646],\n",
       "          [-0.10491278, -0.01409396, -0.11717147, ...,  0.08654676,\n",
       "           -0.1032054 ,  0.03606071]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_217_1/bias:0' shape=(20,) dtype=float32, numpy=\n",
       " array([-0.0060811 , -0.0068215 ,  0.00610762,  0.00381076, -0.00332611,\n",
       "         0.01825029, -0.00569285,  0.0057989 , -0.00631325, -0.00456895,\n",
       "        -0.00355404, -0.00981498, -0.00726559,  0.01567949,  0.00570573,\n",
       "         0.00865319,  0.00934281, -0.00607597,  0.0064635 ,  0.0063222 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_247_1/gamma:0' shape=(20,) dtype=float32, numpy=\n",
       " array([1.0085537 , 0.9999157 , 1.0029037 , 1.0036793 , 0.9965737 ,\n",
       "        0.9955619 , 0.99597555, 0.9951744 , 0.99155873, 0.99123126,\n",
       "        1.0021704 , 1.0111369 , 1.0073707 , 0.9978239 , 0.9897377 ,\n",
       "        0.9979535 , 1.0064371 , 1.0076557 , 0.99272054, 0.9983158 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_247_1/beta:0' shape=(20,) dtype=float32, numpy=\n",
       " array([-0.00536959, -0.00913435,  0.00736503, -0.00202524, -0.00472902,\n",
       "         0.00195614, -0.00162657, -0.00393156, -0.00975933, -0.00361821,\n",
       "         0.0016747 , -0.01143507,  0.00245739,  0.00032578, -0.00409207,\n",
       "        -0.00324961,  0.00862126, -0.01241841,  0.00541203,  0.00482147],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_218_1/kernel:0' shape=(3, 3, 20, 10) dtype=float32, numpy=\n",
       " array([[[[ 0.02090567, -0.01063356,  0.01568592, ..., -0.00421554,\n",
       "           -0.04153974, -0.04014684],\n",
       "          [ 0.04146984, -0.06783944, -0.0200508 , ...,  0.09385803,\n",
       "            0.04323528,  0.01106868],\n",
       "          [ 0.03960693,  0.05715526,  0.05039765, ...,  0.13124132,\n",
       "           -0.01877139,  0.12398075],\n",
       "          ...,\n",
       "          [ 0.01227695, -0.00760612,  0.05333555, ..., -0.06424541,\n",
       "           -0.01374738,  0.04552693],\n",
       "          [ 0.0417938 , -0.02966972,  0.0077204 , ...,  0.10324682,\n",
       "           -0.0336564 ,  0.08304278],\n",
       "          [ 0.06021956, -0.07890533, -0.05801883, ...,  0.08471491,\n",
       "            0.14794236, -0.03558924]],\n",
       " \n",
       "         [[-0.06004382,  0.14762361, -0.14524157, ..., -0.05869973,\n",
       "            0.03716639,  0.10489431],\n",
       "          [-0.12088605,  0.00969887, -0.15406442, ..., -0.0068292 ,\n",
       "           -0.09708827, -0.15776071],\n",
       "          [ 0.00866788,  0.02003344, -0.00541908, ...,  0.0622683 ,\n",
       "            0.06663585,  0.05296098],\n",
       "          ...,\n",
       "          [-0.02643398,  0.07877985,  0.02854742, ..., -0.05691448,\n",
       "           -0.10097322, -0.0748076 ],\n",
       "          [ 0.0615546 ,  0.03269725,  0.14803933, ...,  0.14153697,\n",
       "            0.11893072,  0.05922618],\n",
       "          [ 0.12306278,  0.01435436,  0.0020571 , ..., -0.12050573,\n",
       "           -0.0762575 ,  0.16076486]],\n",
       " \n",
       "         [[-0.1540486 ,  0.11167903,  0.03835633, ...,  0.11817916,\n",
       "           -0.15860094, -0.05598804],\n",
       "          [-0.15525052, -0.14420928,  0.03094636, ..., -0.04865462,\n",
       "            0.0121097 ,  0.02022653],\n",
       "          [-0.06025796,  0.01669158, -0.02238417, ..., -0.04274051,\n",
       "            0.10321181, -0.09857506],\n",
       "          ...,\n",
       "          [-0.00701016,  0.1400375 , -0.13470443, ...,  0.10114507,\n",
       "           -0.12888566, -0.04554447],\n",
       "          [ 0.07841129,  0.00090785, -0.01532124, ..., -0.12396181,\n",
       "           -0.0439156 , -0.02015512],\n",
       "          [ 0.00565134, -0.02282265,  0.04575562, ...,  0.12269929,\n",
       "            0.11260708,  0.0627861 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.03517975, -0.09904189,  0.08187799, ...,  0.09351594,\n",
       "            0.05125515, -0.00984296],\n",
       "          [ 0.00697843,  0.08033408, -0.10224243, ..., -0.04909829,\n",
       "           -0.04039364,  0.16326733],\n",
       "          [-0.07986713, -0.11045446, -0.0182618 , ...,  0.03425604,\n",
       "            0.04857165, -0.01289561],\n",
       "          ...,\n",
       "          [-0.01944935,  0.16133569, -0.13886565, ..., -0.04946548,\n",
       "           -0.09193281,  0.07258816],\n",
       "          [ 0.03535461, -0.01553783, -0.12240314, ..., -0.03787487,\n",
       "           -0.03542279, -0.10071688],\n",
       "          [-0.02973528, -0.0235173 , -0.14208344, ...,  0.01603398,\n",
       "           -0.10384908, -0.03715665]],\n",
       " \n",
       "         [[-0.00868847,  0.09747783,  0.05609084, ..., -0.06709271,\n",
       "           -0.0365287 ,  0.02167607],\n",
       "          [ 0.00520192,  0.04545872, -0.00385959, ..., -0.10382078,\n",
       "            0.09922986,  0.04590368],\n",
       "          [-0.12633488, -0.09125228,  0.01445932, ..., -0.03902439,\n",
       "            0.0587509 ,  0.13841613],\n",
       "          ...,\n",
       "          [-0.16209798,  0.13320892, -0.07741296, ...,  0.07428703,\n",
       "           -0.10164525,  0.02643708],\n",
       "          [ 0.02213026,  0.01649134,  0.0436659 , ...,  0.0232906 ,\n",
       "            0.04629252, -0.00076802],\n",
       "          [ 0.03799146,  0.0559881 , -0.02978235, ...,  0.00977015,\n",
       "            0.11580397, -0.03857177]],\n",
       " \n",
       "         [[ 0.06608044, -0.0416215 ,  0.06630466, ...,  0.055699  ,\n",
       "            0.00784587,  0.09676087],\n",
       "          [-0.00490601,  0.12060454, -0.05847608, ...,  0.03492145,\n",
       "            0.00243892, -0.02397208],\n",
       "          [ 0.02921079, -0.00870965, -0.02787584, ...,  0.00931264,\n",
       "           -0.10823767,  0.05034735],\n",
       "          ...,\n",
       "          [ 0.03446243, -0.1045508 ,  0.06442372, ...,  0.07789522,\n",
       "            0.01189602,  0.08175033],\n",
       "          [ 0.00793133, -0.10998193, -0.02340578, ...,  0.06498767,\n",
       "           -0.15805757, -0.12531461],\n",
       "          [ 0.06383936,  0.04361217,  0.01095787, ...,  0.00465115,\n",
       "           -0.04824472,  0.00653344]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00245395,  0.03652324,  0.16486716, ...,  0.05380679,\n",
       "           -0.05727434, -0.11223233],\n",
       "          [ 0.05858332,  0.06456722,  0.00737718, ..., -0.05184856,\n",
       "            0.06343709, -0.00745704],\n",
       "          [-0.02949599, -0.04968589, -0.10517275, ..., -0.05019437,\n",
       "            0.05241147,  0.0156231 ],\n",
       "          ...,\n",
       "          [ 0.01725427,  0.15474428, -0.06188389, ...,  0.00435201,\n",
       "           -0.00123665,  0.10892878],\n",
       "          [ 0.01494043, -0.03885448,  0.01336966, ..., -0.0267803 ,\n",
       "            0.06688994, -0.14476316],\n",
       "          [ 0.14485203, -0.10829151, -0.07587951, ...,  0.06992213,\n",
       "           -0.10144979,  0.02104662]],\n",
       " \n",
       "         [[ 0.02576772,  0.01628014,  0.08864211, ..., -0.0828298 ,\n",
       "            0.03301449,  0.0850352 ],\n",
       "          [ 0.07903824,  0.04840345,  0.05991028, ...,  0.08987902,\n",
       "           -0.10944261,  0.03650283],\n",
       "          [ 0.03825856, -0.00832999, -0.04583719, ...,  0.06594151,\n",
       "           -0.07302982,  0.07432107],\n",
       "          ...,\n",
       "          [-0.04050666, -0.12797402,  0.07386046, ..., -0.10249872,\n",
       "            0.04911845,  0.06743121],\n",
       "          [ 0.07613551,  0.00332004, -0.07916892, ..., -0.00123999,\n",
       "            0.05332122, -0.13459298],\n",
       "          [-0.02192901,  0.04683131,  0.00082733, ..., -0.00446338,\n",
       "           -0.12011667,  0.03525013]],\n",
       " \n",
       "         [[-0.04359539, -0.06374618,  0.1202983 , ...,  0.00113101,\n",
       "            0.02773231,  0.0731922 ],\n",
       "          [ 0.02177648,  0.07440197, -0.06188597, ..., -0.09979589,\n",
       "           -0.00345127,  0.15094717],\n",
       "          [-0.00584744, -0.031125  ,  0.06415071, ...,  0.03767491,\n",
       "            0.05926217, -0.12075986],\n",
       "          ...,\n",
       "          [ 0.04383463, -0.05182926,  0.03458637, ..., -0.11864363,\n",
       "            0.01741709, -0.15909383],\n",
       "          [-0.12114664, -0.08047332,  0.09436321, ...,  0.02143348,\n",
       "            0.14162898, -0.03481112],\n",
       "          [ 0.01134355,  0.00687216,  0.02118197, ...,  0.0458432 ,\n",
       "            0.02889669, -0.01219227]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_218_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 4.9985615e-03, -6.2674466e-03,  2.9960005e-03, -5.8403853e-03,\n",
       "        -7.8184283e-05, -2.7212226e-03,  1.2709799e-03,  8.3391936e-03,\n",
       "         1.3473940e-02,  1.5454404e-03], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_248_1/gamma:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.99919415, 1.0033033 , 0.99802935, 1.000345  , 0.99773407,\n",
       "        1.0104444 , 1.0010378 , 0.9978654 , 1.0017155 , 0.9996311 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_248_1/beta:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.01331361, -0.00868953,  0.00726795,  0.00127022,  0.00731085,\n",
       "        -0.0044188 , -0.0090006 ,  0.0002409 , -0.00658916,  0.0044319 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_219_1/kernel:0' shape=(3, 3, 10, 10) dtype=float32, numpy=\n",
       " array([[[[ 2.83129606e-02, -1.62238032e-02,  1.03980504e-01,\n",
       "            1.16387211e-01, -1.06103413e-01,  5.61737977e-02,\n",
       "           -1.46659836e-01, -1.29340915e-02,  1.27901323e-02,\n",
       "            5.08181863e-02],\n",
       "          [ 9.80623253e-03, -9.37586352e-02, -1.98928304e-02,\n",
       "           -1.94695219e-01,  2.00361088e-01,  1.11831360e-01,\n",
       "            2.42758051e-01, -5.33776470e-02,  1.82724893e-01,\n",
       "           -2.01382041e-01],\n",
       "          [-8.73721913e-02,  4.33610752e-03,  4.48629409e-02,\n",
       "            5.48482053e-02,  8.65596533e-02,  2.04726696e-01,\n",
       "            2.42778962e-03,  7.55755603e-02,  1.12725645e-01,\n",
       "           -8.08122940e-03],\n",
       "          [ 1.87131241e-02,  2.89434455e-02, -9.44256485e-02,\n",
       "           -7.55071547e-03, -3.37521769e-02, -9.08817127e-02,\n",
       "           -1.92754716e-01, -3.49253858e-03, -7.13579729e-02,\n",
       "           -1.08991116e-01],\n",
       "          [ 1.05075799e-01, -2.05045298e-01, -1.68525428e-02,\n",
       "            2.29099188e-02, -1.71253443e-01, -1.90423220e-01,\n",
       "           -8.28932002e-02, -8.61670077e-02, -7.59391934e-02,\n",
       "            1.02766417e-01],\n",
       "          [ 1.50967371e-02, -1.48425549e-01, -1.78931765e-02,\n",
       "            1.73622563e-01,  7.03308210e-02, -1.47450194e-01,\n",
       "            3.78412120e-02, -1.73187628e-01,  1.86909065e-02,\n",
       "            1.24283642e-01],\n",
       "          [-8.66790563e-02,  2.08363533e-01, -2.15889933e-03,\n",
       "            1.31178916e-01,  5.47453202e-02, -1.24806426e-01,\n",
       "           -1.41787799e-02, -2.28378568e-02, -2.13128418e-01,\n",
       "            9.85392258e-02],\n",
       "          [ 2.00720485e-02, -5.98793551e-02, -1.57219812e-01,\n",
       "            1.22725964e-02, -1.11461073e-01, -1.41769096e-01,\n",
       "           -6.00360036e-02, -1.04730532e-01, -2.06204563e-01,\n",
       "           -9.85325128e-02],\n",
       "          [ 1.13914095e-01, -4.76640165e-02, -9.19190645e-02,\n",
       "            1.26577899e-01,  1.16801009e-01, -1.39470711e-01,\n",
       "            1.13734327e-01, -3.09173437e-03,  4.84448113e-02,\n",
       "           -2.80253701e-02],\n",
       "          [-7.73362964e-02,  4.04877998e-02,  8.21664631e-02,\n",
       "            1.34849161e-01, -5.47892861e-02, -1.04941633e-02,\n",
       "            1.29061297e-01,  1.57013908e-01,  1.52578220e-01,\n",
       "            7.48907030e-03]],\n",
       " \n",
       "         [[ 6.11932902e-03, -2.01341957e-01, -6.55429363e-02,\n",
       "            2.36354306e-01, -1.28261894e-01,  1.24785705e-02,\n",
       "           -6.12892136e-02,  1.89868510e-02, -1.59349188e-01,\n",
       "           -1.18715525e-01],\n",
       "          [ 4.51506525e-02, -4.20441888e-02, -7.08670635e-03,\n",
       "           -4.88252798e-03, -7.80906156e-02, -2.43846208e-01,\n",
       "           -2.31665194e-01, -1.65995300e-01,  2.43167460e-01,\n",
       "            2.33564109e-01],\n",
       "          [-1.00800224e-01,  8.09214711e-02,  9.82760489e-02,\n",
       "           -4.53637056e-02, -7.35944510e-02,  4.42068614e-02,\n",
       "            3.55523340e-02, -9.24341157e-02,  1.25541553e-01,\n",
       "            8.92291367e-02],\n",
       "          [ 1.51286796e-01, -3.83212566e-02,  4.72230464e-02,\n",
       "            3.73164192e-02,  1.42405853e-01,  6.37520179e-02,\n",
       "            8.13184679e-02, -3.31907496e-02, -2.84174234e-02,\n",
       "            6.62456304e-02],\n",
       "          [ 1.42802238e-01, -6.38124533e-03,  3.67526300e-02,\n",
       "            2.14254007e-01, -4.47148345e-02, -1.12954974e-01,\n",
       "           -2.18075924e-02, -7.93670267e-02, -3.08635482e-03,\n",
       "            8.13045874e-02],\n",
       "          [-1.21790268e-01,  2.42588706e-02,  1.54956177e-01,\n",
       "            2.93280147e-02, -9.38752573e-03,  8.03945288e-02,\n",
       "           -6.01228513e-02,  1.97463080e-01, -9.00273323e-02,\n",
       "           -2.03024633e-02],\n",
       "          [-5.71390167e-02,  1.48167282e-01, -2.24257652e-02,\n",
       "            1.80787429e-01, -1.91152856e-01,  7.82837421e-02,\n",
       "           -9.25571695e-02, -1.24554791e-01,  1.04387037e-01,\n",
       "            4.86497506e-02],\n",
       "          [ 1.21415062e-02, -1.17459297e-01,  1.29809305e-01,\n",
       "            4.45848657e-03,  2.13454694e-01, -2.84447726e-02,\n",
       "           -6.14425167e-02,  1.73679944e-02,  7.73714185e-02,\n",
       "           -1.43704489e-01],\n",
       "          [ 3.15138586e-02, -9.94348302e-02,  9.24090073e-02,\n",
       "            9.74579379e-02,  8.72250944e-02,  3.41705121e-02,\n",
       "            1.99354161e-02, -2.02842817e-01,  1.89016894e-01,\n",
       "           -1.42573178e-01],\n",
       "          [-1.25684381e-01, -1.00860551e-01,  1.66402146e-01,\n",
       "            1.84860025e-02,  5.38686551e-02, -7.63851032e-02,\n",
       "            2.20281482e-01, -7.81994238e-02, -2.29272675e-02,\n",
       "           -5.43190204e-02]],\n",
       " \n",
       "         [[-4.01767008e-02, -3.81764583e-02, -9.16618761e-03,\n",
       "            2.57409681e-02, -1.05128229e-01,  6.99722916e-02,\n",
       "           -2.14407697e-01,  1.73669323e-04,  1.60017461e-01,\n",
       "           -6.00143410e-02],\n",
       "          [ 1.34740472e-01, -9.66027975e-02, -2.19858973e-03,\n",
       "            1.11641444e-01,  1.19974781e-02,  1.43931573e-02,\n",
       "            8.19125250e-02,  2.36033320e-01,  7.85621479e-02,\n",
       "            3.52069363e-02],\n",
       "          [-1.61485925e-01,  2.34725237e-01,  2.11585134e-01,\n",
       "           -1.98489696e-01,  4.65236567e-02, -4.63504046e-02,\n",
       "           -7.07902387e-02, -6.04882911e-02,  8.41681063e-02,\n",
       "           -4.46977094e-02],\n",
       "          [ 1.33270755e-01, -1.77671947e-02,  3.69175598e-02,\n",
       "           -2.01188549e-01,  2.16184463e-02, -1.80943087e-01,\n",
       "           -4.58246395e-02,  8.48286897e-02, -1.54296026e-01,\n",
       "           -2.31164377e-02],\n",
       "          [ 1.79150149e-01, -6.76531792e-02, -1.56912953e-01,\n",
       "            4.04863358e-02,  4.27235328e-02, -6.50712028e-02,\n",
       "           -1.93436593e-01, -6.32430017e-02,  1.10042244e-01,\n",
       "           -1.39101848e-01],\n",
       "          [-3.99310365e-02,  2.42456421e-02,  4.05376889e-02,\n",
       "           -7.04867914e-02,  2.25961015e-01,  1.17363364e-01,\n",
       "           -5.90360612e-02, -6.30392730e-02, -6.30781129e-02,\n",
       "           -1.29879162e-01],\n",
       "          [ 8.54523629e-02, -2.15316445e-01,  6.61987662e-02,\n",
       "            1.52793795e-01, -1.21433884e-01,  7.31147528e-02,\n",
       "            3.67294401e-02,  2.71249209e-02, -8.48096684e-02,\n",
       "            9.98852998e-02],\n",
       "          [ 3.34720127e-02, -1.25386119e-02, -1.13391310e-01,\n",
       "           -4.81449850e-02, -1.01651937e-01, -5.83157837e-02,\n",
       "            6.98072910e-02, -2.51918249e-02,  1.01924531e-01,\n",
       "            1.03339896e-01],\n",
       "          [-1.21283501e-01, -1.44275418e-02, -1.04601830e-01,\n",
       "            1.18158452e-01, -1.30609661e-01, -8.51946846e-02,\n",
       "            1.06896400e-01,  7.87511989e-02, -1.38920724e-01,\n",
       "            5.03838398e-02],\n",
       "          [ 9.79290053e-06,  2.07273707e-01, -1.56843942e-02,\n",
       "            1.53424710e-01,  1.43007105e-02,  2.11922497e-01,\n",
       "           -8.35004970e-02, -3.15120220e-02, -8.58905464e-02,\n",
       "            9.53425840e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 2.00899113e-02,  1.06507167e-01,  1.12569794e-01,\n",
       "            5.49545279e-03,  7.51778856e-02, -4.37212503e-03,\n",
       "            1.04209311e-01, -7.66417310e-02,  6.01512287e-03,\n",
       "           -1.04138918e-01],\n",
       "          [ 3.18270549e-03,  8.21854025e-02,  5.57398312e-02,\n",
       "            1.91434324e-01,  3.84605117e-02,  4.93508503e-02,\n",
       "            1.62451621e-02,  1.71981305e-01, -1.04712464e-01,\n",
       "            6.04983866e-02],\n",
       "          [-1.49672627e-01,  1.13039106e-01, -1.94703713e-01,\n",
       "           -2.60298867e-02,  1.79217413e-01,  5.45258038e-02,\n",
       "           -2.98164245e-02,  2.23772824e-02,  7.14413151e-02,\n",
       "           -2.02146575e-01],\n",
       "          [-5.72881997e-02,  8.11996907e-02, -3.08678262e-02,\n",
       "            2.38460228e-01,  3.87122408e-02, -9.00933594e-02,\n",
       "           -2.40432024e-02, -6.07253201e-02,  4.65678126e-02,\n",
       "            2.07203515e-02],\n",
       "          [ 1.56572223e-01, -2.69654170e-02, -8.72026458e-02,\n",
       "           -2.38066599e-01, -2.35741660e-01, -1.40856817e-01,\n",
       "            5.61638176e-02,  6.03501461e-02, -3.35139968e-02,\n",
       "           -6.20052814e-02],\n",
       "          [ 3.56668308e-02, -2.23486260e-01,  9.45441350e-02,\n",
       "            1.73284292e-01,  1.98778555e-01, -6.15402311e-02,\n",
       "           -5.03478609e-02,  2.19090562e-02, -9.25640985e-02,\n",
       "           -3.44366953e-02],\n",
       "          [ 9.05511230e-02, -7.97437280e-02, -1.51533827e-01,\n",
       "           -2.45877672e-02,  7.41868913e-02,  5.57781160e-02,\n",
       "           -1.38228804e-01,  1.38877630e-01,  6.86035911e-03,\n",
       "           -1.35780334e-01],\n",
       "          [ 3.76973152e-02,  4.19895798e-02,  4.39788215e-02,\n",
       "           -2.73699574e-02, -1.23707771e-01, -5.33239543e-02,\n",
       "            9.20776799e-02, -1.05991952e-01,  2.45116472e-01,\n",
       "            1.70258984e-01],\n",
       "          [-3.85737978e-02,  3.77977937e-02, -1.34565502e-01,\n",
       "            1.67865772e-02,  1.79697387e-02,  6.42088726e-02,\n",
       "            3.02807149e-02, -1.91765353e-01,  2.07179412e-01,\n",
       "            7.59577900e-02],\n",
       "          [-2.60505918e-02, -5.73843345e-03, -1.47325858e-01,\n",
       "           -3.20808589e-02,  1.05278902e-01,  3.87905575e-02,\n",
       "           -1.10959955e-01, -9.13213938e-02,  2.18660124e-02,\n",
       "           -3.05902194e-02]],\n",
       " \n",
       "         [[-1.23221174e-01, -6.07353577e-04, -1.35187283e-01,\n",
       "           -6.13944381e-02, -1.17465109e-01,  1.52044594e-01,\n",
       "            1.19614944e-01,  9.87146720e-02, -2.00308576e-01,\n",
       "           -2.29040042e-01],\n",
       "          [ 7.88311511e-02, -1.09998554e-01,  2.38945156e-01,\n",
       "           -1.34254187e-01, -7.02443253e-03, -2.36085467e-02,\n",
       "           -1.93788297e-02,  6.25462681e-02, -1.07806124e-01,\n",
       "            2.26303991e-02],\n",
       "          [ 6.59231991e-02,  6.75223544e-02,  5.03149517e-02,\n",
       "            4.55942526e-02, -3.14266160e-02, -5.69219217e-02,\n",
       "           -5.68435080e-02,  9.75023434e-02, -2.26747200e-01,\n",
       "           -2.86582746e-02],\n",
       "          [ 1.80034190e-02, -1.98804736e-01, -8.07423797e-03,\n",
       "            2.42109708e-02,  7.15936301e-03,  8.01295117e-02,\n",
       "           -1.32244006e-01,  1.37002021e-01, -5.79625405e-02,\n",
       "           -1.88237011e-01],\n",
       "          [-5.71402311e-02, -4.22745757e-02,  7.14820847e-02,\n",
       "            1.14351451e-01, -5.98136932e-02,  5.01520969e-02,\n",
       "            3.45501900e-02, -6.32073283e-02, -1.18889302e-01,\n",
       "           -2.23582551e-01],\n",
       "          [-4.12171558e-02, -1.63696483e-01,  5.49158789e-02,\n",
       "            9.33221802e-02,  7.14174509e-02, -6.26139119e-02,\n",
       "            4.56676520e-02,  1.05864212e-01,  1.53272048e-01,\n",
       "            8.63303095e-02],\n",
       "          [ 7.59049505e-02,  3.00823450e-02, -3.52703817e-02,\n",
       "            1.51237443e-01,  9.42618772e-02, -5.78911714e-02,\n",
       "           -1.88533396e-01,  1.85683534e-01, -6.58352524e-02,\n",
       "            1.11291893e-02],\n",
       "          [-1.81884207e-02,  1.38931096e-01, -6.68178685e-03,\n",
       "           -9.54097435e-02, -1.86438905e-03, -1.56380624e-01,\n",
       "            6.25710264e-02,  8.60823989e-02,  1.05746709e-01,\n",
       "           -1.59648314e-01],\n",
       "          [ 4.11932468e-02, -3.02847736e-02,  4.39207405e-02,\n",
       "            2.05051631e-01,  1.54822562e-02, -1.42320961e-01,\n",
       "           -4.87674773e-02, -1.02113135e-01,  2.12309901e-02,\n",
       "           -1.37282208e-01],\n",
       "          [-4.61015292e-02,  4.73923571e-02, -1.28647164e-01,\n",
       "            3.61755155e-02,  1.92175701e-01, -1.08970247e-01,\n",
       "           -1.67172533e-02, -1.03741273e-01, -9.14234817e-02,\n",
       "           -4.69418876e-02]],\n",
       " \n",
       "         [[ 1.97339877e-01, -7.92988986e-02,  3.61178927e-02,\n",
       "            8.75269324e-02, -1.27176102e-02,  1.71080425e-01,\n",
       "            2.23619431e-01, -1.64433405e-01, -9.96130854e-02,\n",
       "            3.44512835e-02],\n",
       "          [ 6.31227195e-02,  1.86223760e-01,  6.69227913e-02,\n",
       "            8.71588066e-02,  1.62240833e-01,  9.18638241e-03,\n",
       "            3.68096232e-02,  1.32041704e-02,  6.75824413e-05,\n",
       "           -4.22172621e-02],\n",
       "          [-1.10416561e-01,  3.98903862e-02, -7.48601779e-02,\n",
       "           -1.74434975e-01, -1.80871427e-01, -1.01983920e-01,\n",
       "           -9.76700410e-02,  1.06864423e-01,  3.02613038e-03,\n",
       "           -2.24782843e-02],\n",
       "          [ 6.83157220e-02, -1.52197881e-02,  9.79706496e-02,\n",
       "            7.68000484e-02, -2.31230766e-01, -9.90973087e-04,\n",
       "           -2.65486985e-02,  1.15314730e-01,  3.98474634e-02,\n",
       "            8.69876966e-02],\n",
       "          [ 1.40313685e-01,  1.46533594e-01, -6.51161075e-02,\n",
       "           -1.79117575e-01, -2.81689912e-02,  2.70518716e-02,\n",
       "           -1.32394224e-01,  2.51960419e-02, -7.56366625e-02,\n",
       "           -1.09888412e-01],\n",
       "          [-4.34448533e-02, -1.00457175e-02,  3.21859419e-02,\n",
       "           -6.23803623e-02, -1.33000359e-01, -1.15383923e-01,\n",
       "           -2.52384469e-02, -1.09912001e-01, -8.42400715e-02,\n",
       "           -1.65273443e-01],\n",
       "          [-6.06370643e-02, -3.23680602e-02,  4.55051772e-02,\n",
       "           -3.92534509e-02,  1.06640838e-01, -1.74291939e-01,\n",
       "           -6.02066368e-02, -2.57290117e-02, -4.42988090e-02,\n",
       "            6.82166964e-02],\n",
       "          [-7.94913396e-02,  2.23139040e-02, -9.35547501e-02,\n",
       "            5.75350299e-02,  5.55182993e-02,  2.99230199e-02,\n",
       "            2.28930354e-01, -4.30358425e-02, -1.76778406e-01,\n",
       "           -3.75630744e-02],\n",
       "          [-1.52267501e-01, -6.42918870e-02,  2.45847646e-02,\n",
       "            1.20171353e-01, -1.07269645e-01,  1.77991539e-01,\n",
       "           -1.71826363e-01,  1.47688374e-01,  5.74155292e-03,\n",
       "            6.37402758e-02],\n",
       "          [-1.28713310e-01,  4.82489914e-02, -4.67829108e-02,\n",
       "            1.05251744e-01, -2.60181464e-02,  1.74795583e-01,\n",
       "           -2.31962115e-01, -4.60058488e-02, -5.17882071e-02,\n",
       "           -7.63179883e-02]]],\n",
       " \n",
       " \n",
       "        [[[-1.44817248e-01,  2.26501569e-01, -6.66333511e-02,\n",
       "            2.10161716e-01, -3.24297585e-02,  1.21231750e-01,\n",
       "            1.04640760e-02,  1.14110850e-01, -2.48254873e-02,\n",
       "           -8.51678401e-02],\n",
       "          [ 6.60309047e-02, -5.13744131e-02, -4.83217426e-02,\n",
       "            2.13335156e-01, -5.97906373e-02, -1.41597008e-02,\n",
       "            2.04290561e-02,  1.16385892e-01, -1.05206758e-01,\n",
       "            7.37921372e-02],\n",
       "          [-1.19293474e-01, -3.85328941e-03, -9.86413732e-02,\n",
       "           -1.63997129e-01, -3.44718359e-02,  9.56578255e-02,\n",
       "           -1.20063625e-01,  8.15209597e-02, -2.21521333e-01,\n",
       "            1.03575267e-01],\n",
       "          [ 1.95028171e-01, -1.26510382e-01, -7.74103701e-02,\n",
       "           -1.69102192e-01,  7.19323978e-02, -4.03051041e-02,\n",
       "            1.62848845e-01,  3.21326181e-02,  8.33434463e-02,\n",
       "           -1.62626430e-01],\n",
       "          [-8.75652730e-02, -1.49491966e-01,  4.28811368e-03,\n",
       "            3.23839635e-02,  1.37482926e-01,  1.60996914e-01,\n",
       "           -8.75477493e-02,  7.81943724e-02,  6.33267462e-02,\n",
       "           -1.30919129e-01],\n",
       "          [-1.89303473e-01, -1.87263578e-01, -2.62267813e-02,\n",
       "            1.76763430e-01, -1.15484316e-02,  8.36394876e-02,\n",
       "            5.89777790e-02, -1.11105904e-01,  5.87093942e-02,\n",
       "            5.47035299e-02],\n",
       "          [-2.08298549e-01,  2.30278913e-03,  1.16173305e-01,\n",
       "           -5.41599058e-02, -8.23790729e-02, -1.35533875e-02,\n",
       "            1.33200869e-01, -6.03954755e-02,  1.96013507e-02,\n",
       "            3.12862471e-02],\n",
       "          [-1.85225368e-01, -8.42582434e-02, -1.15580134e-01,\n",
       "           -9.96347889e-02, -3.65294293e-02,  1.04543768e-01,\n",
       "           -8.10248107e-02,  9.70584601e-02,  6.56780452e-02,\n",
       "            1.60754502e-01],\n",
       "          [ 3.11631411e-02,  2.21990682e-02,  7.80974329e-02,\n",
       "           -1.48668915e-01,  1.43399224e-01, -4.82461564e-02,\n",
       "            3.16404887e-02,  9.08872262e-02, -4.38953340e-02,\n",
       "            4.53006756e-03],\n",
       "          [-1.97347045e-01,  5.47768846e-02, -7.89908171e-02,\n",
       "           -1.58007741e-01,  1.25662357e-01,  1.09114312e-01,\n",
       "           -1.11749873e-01,  1.00479506e-01,  8.23318139e-02,\n",
       "           -1.01387180e-01]],\n",
       " \n",
       "         [[ 2.33938098e-02, -9.43448618e-02, -6.36696368e-02,\n",
       "            1.74629074e-02, -3.73220965e-02, -9.87456739e-02,\n",
       "            6.62156707e-03,  8.11567530e-02,  1.52127802e-01,\n",
       "            1.19627461e-01],\n",
       "          [-1.69830605e-01, -9.37439203e-02,  1.05857998e-01,\n",
       "           -4.16716896e-02,  6.91281334e-02, -1.68573167e-02,\n",
       "            1.69957429e-01,  7.32689165e-03,  5.44025302e-02,\n",
       "            5.06813191e-02],\n",
       "          [-2.28049960e-02, -7.82734454e-02,  3.35688926e-02,\n",
       "            3.65514010e-02, -3.18110362e-02,  1.49431005e-01,\n",
       "            8.57109651e-02,  2.67472747e-03,  1.60440847e-01,\n",
       "            7.99737051e-02],\n",
       "          [ 4.91654128e-02,  3.52480523e-02, -3.43381353e-02,\n",
       "            2.15078983e-03, -1.40986711e-01, -1.70772851e-01,\n",
       "           -2.80163810e-02,  7.13505433e-05,  5.86924492e-04,\n",
       "           -1.14723993e-02],\n",
       "          [ 8.04784521e-02,  3.89645323e-02, -3.97195108e-03,\n",
       "           -4.08654623e-02, -3.92556228e-02,  1.07515231e-01,\n",
       "           -4.24126647e-02, -1.86153591e-01, -7.11496472e-02,\n",
       "            2.82673053e-02],\n",
       "          [-4.15638052e-02,  1.19508067e-02,  1.61667794e-01,\n",
       "           -5.98270074e-02,  1.59446061e-01, -1.54596463e-01,\n",
       "           -7.53921568e-02,  9.29858722e-03, -1.06049754e-01,\n",
       "            8.28401148e-02],\n",
       "          [ 1.21008217e-01, -4.27485742e-02,  1.39313042e-01,\n",
       "           -1.36166960e-01, -3.57744209e-02, -2.24507570e-01,\n",
       "           -1.47161499e-01, -7.15941638e-02, -1.14483694e-02,\n",
       "           -7.64013873e-03],\n",
       "          [ 4.46193703e-02,  6.67277798e-02, -3.73464776e-03,\n",
       "           -8.73474255e-02,  1.32458001e-01,  1.00006141e-01,\n",
       "           -1.37554884e-01, -7.53911659e-02, -5.00236899e-02,\n",
       "            2.74028201e-02],\n",
       "          [-4.06835079e-02,  7.67779797e-02, -3.67930345e-03,\n",
       "            1.60293102e-01, -9.20196995e-02, -1.03736660e-02,\n",
       "            7.64677152e-02, -3.93676311e-02, -1.77490652e-01,\n",
       "           -4.54227999e-02],\n",
       "          [ 1.16835363e-01, -2.86053400e-02, -1.81422345e-02,\n",
       "            3.87039520e-02, -2.17868648e-02,  1.51334047e-01,\n",
       "           -1.48274109e-01,  1.91059664e-01, -2.39984598e-02,\n",
       "            5.10003045e-02]],\n",
       " \n",
       "         [[ 2.61268318e-02, -2.80166529e-02,  1.15276687e-01,\n",
       "           -2.17348672e-02, -1.20558091e-01, -9.46394801e-02,\n",
       "            1.15609176e-01, -2.09887475e-01,  1.63544729e-01,\n",
       "           -1.23697519e-01],\n",
       "          [ 6.32945597e-02,  9.43811436e-04, -9.15335044e-02,\n",
       "            1.71730921e-01, -3.68504822e-02, -1.29017040e-01,\n",
       "            1.35943172e-02, -5.16752079e-02,  1.34774551e-01,\n",
       "            2.17116047e-02],\n",
       "          [ 4.05768231e-02, -7.65066892e-02, -9.12971124e-02,\n",
       "           -8.82846713e-02, -2.78011169e-02,  4.94951792e-02,\n",
       "           -1.06464466e-02, -5.60789481e-02,  3.15501541e-02,\n",
       "           -1.46239996e-01],\n",
       "          [-7.02964887e-02, -2.11720690e-01,  5.88321835e-02,\n",
       "            6.51261583e-02, -1.23016223e-01,  6.94340691e-02,\n",
       "           -4.82710600e-02,  8.33265558e-02, -1.01150116e-02,\n",
       "           -1.12979785e-01],\n",
       "          [ 9.89388525e-02, -1.67651594e-01, -1.74290240e-01,\n",
       "           -3.42526436e-02,  7.54584670e-02, -9.62401628e-02,\n",
       "           -2.77377870e-02, -2.37906516e-01, -9.84840393e-02,\n",
       "            1.66777018e-02],\n",
       "          [-7.32936561e-02, -2.10263096e-02, -1.26178876e-01,\n",
       "            1.32635962e-02,  2.07519475e-02,  1.24720454e-01,\n",
       "            1.93842184e-02,  2.52824835e-02, -1.62117369e-02,\n",
       "            6.89930022e-02],\n",
       "          [-9.29243788e-02,  1.63770676e-01,  1.31339535e-01,\n",
       "           -6.65975874e-03,  1.06957085e-01, -6.68346807e-02,\n",
       "            7.12891072e-02, -1.65606692e-01,  1.10420033e-01,\n",
       "           -2.30020117e-02],\n",
       "          [-2.39494704e-02, -2.72205845e-02, -9.64355692e-02,\n",
       "           -7.17165768e-02, -1.00173734e-01, -5.15200421e-02,\n",
       "           -3.80541496e-02, -6.95788935e-02,  4.53404896e-02,\n",
       "            8.21581408e-02],\n",
       "          [-1.19920053e-01, -7.69955590e-02, -1.02899656e-01,\n",
       "            9.14903358e-02, -5.14953025e-02,  8.42553675e-02,\n",
       "           -3.65705676e-02, -2.82598846e-03,  1.30101413e-01,\n",
       "            4.11561430e-02],\n",
       "          [ 4.03209701e-02, -1.04061730e-01, -2.15942726e-01,\n",
       "            9.21981782e-03,  2.14306235e-01,  7.95683637e-02,\n",
       "            8.54182988e-03, -1.10809542e-02, -1.15611874e-01,\n",
       "            9.50715840e-02]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_219_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([-0.00359031,  0.00930855,  0.0001581 , -0.01199857,  0.01158896,\n",
       "         0.00556783, -0.00089094,  0.00080338, -0.00311097, -0.01332143],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_249_1/gamma:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.9998816 , 1.0022944 , 0.99472344, 1.0043478 , 0.9926456 ,\n",
       "        1.0033965 , 1.0001464 , 1.0021745 , 0.9974514 , 1.0024154 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_249_1/beta:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.00724354, -0.00172935, -0.00293744,  0.00704751, -0.00181972,\n",
       "         0.00639493, -0.01191419,  0.01088994,  0.00031498,  0.00212661],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_220_1/kernel:0' shape=(3, 3, 10, 10) dtype=float32, numpy=\n",
       " array([[[[-0.04071948, -0.10485952,  0.01714608, -0.00553399,\n",
       "           -0.04601976, -0.15614097,  0.01015718, -0.01447301,\n",
       "           -0.08060953, -0.01971467],\n",
       "          [ 0.10052959,  0.12239464, -0.04159877, -0.01063146,\n",
       "            0.01214133, -0.09487503,  0.1215203 ,  0.15190482,\n",
       "            0.02280762,  0.15189311],\n",
       "          [ 0.06481729,  0.02730891, -0.10479853, -0.22123197,\n",
       "            0.01312567,  0.02179761,  0.02754615,  0.07520343,\n",
       "           -0.15668066,  0.05704654],\n",
       "          [ 0.06913419,  0.16359174, -0.12802126,  0.06997892,\n",
       "           -0.15446733, -0.14898828,  0.02798152, -0.07788127,\n",
       "           -0.0007164 , -0.2034076 ],\n",
       "          [ 0.0710422 ,  0.01030962, -0.22790797,  0.06738345,\n",
       "            0.00239257, -0.17682263,  0.06270509, -0.11894358,\n",
       "           -0.11957943,  0.11605055],\n",
       "          [ 0.19660985,  0.03488865, -0.02263503, -0.18835084,\n",
       "            0.0132584 ,  0.11811081, -0.06893843, -0.10773569,\n",
       "            0.10691939, -0.00357162],\n",
       "          [-0.16067961,  0.09657294, -0.04251616,  0.09307007,\n",
       "            0.1380811 , -0.07799418,  0.13037837, -0.07571174,\n",
       "           -0.11876293,  0.15251985],\n",
       "          [-0.1596559 , -0.10186213, -0.05905106, -0.00574584,\n",
       "            0.04571532,  0.11937636, -0.16703257,  0.15985481,\n",
       "            0.09312058,  0.01634785],\n",
       "          [-0.1570705 , -0.05822331,  0.01686043, -0.15325579,\n",
       "            0.10246415, -0.15451688,  0.17035854, -0.12048357,\n",
       "            0.03490257,  0.0536119 ],\n",
       "          [-0.11687016, -0.07540125,  0.02444064, -0.17479359,\n",
       "           -0.14535907, -0.02633318,  0.22531435,  0.2060504 ,\n",
       "           -0.01372607, -0.19613992]],\n",
       " \n",
       "         [[ 0.03584301, -0.17299747, -0.04163562,  0.09959974,\n",
       "            0.00024959, -0.19808501, -0.01001026, -0.03504771,\n",
       "            0.09851305,  0.08893088],\n",
       "          [-0.04703859, -0.01428755, -0.12625444,  0.03017144,\n",
       "            0.03471938, -0.01430298,  0.13372639, -0.06289706,\n",
       "           -0.11124481,  0.14173086],\n",
       "          [-0.05502491, -0.00274278, -0.05702636,  0.21902218,\n",
       "           -0.19908437,  0.07024401, -0.07636495, -0.05490524,\n",
       "            0.12540717,  0.06467061],\n",
       "          [-0.15175089,  0.02079302,  0.09135033, -0.20282026,\n",
       "           -0.00815917,  0.02331526, -0.03340711, -0.2332676 ,\n",
       "           -0.17544949,  0.05481697],\n",
       "          [ 0.06899571,  0.02624624,  0.05847004, -0.0886029 ,\n",
       "            0.03417983, -0.20107238, -0.10540645, -0.08783702,\n",
       "            0.0434263 ,  0.13393244],\n",
       "          [ 0.1185165 , -0.05626282, -0.15149537,  0.09938962,\n",
       "           -0.0516636 , -0.02684043, -0.16565251, -0.03567411,\n",
       "            0.06572168, -0.01274624],\n",
       "          [ 0.06294444,  0.11881127,  0.08658954, -0.22784126,\n",
       "            0.05728424,  0.07628844,  0.06929845,  0.13603081,\n",
       "           -0.06107324, -0.04483739],\n",
       "          [ 0.08387396,  0.03528679, -0.03536478,  0.1490879 ,\n",
       "            0.05306144, -0.00647309, -0.16366966, -0.12046362,\n",
       "           -0.21901882, -0.09095283],\n",
       "          [-0.15251149, -0.15765509, -0.14195757,  0.06762421,\n",
       "           -0.15752289, -0.01296381, -0.02569367, -0.07656731,\n",
       "            0.16692142, -0.07053657],\n",
       "          [-0.03376301,  0.01094438,  0.19577473,  0.01565439,\n",
       "            0.10653786, -0.09451327, -0.03955395,  0.0212913 ,\n",
       "           -0.07982403,  0.1518836 ]],\n",
       " \n",
       "         [[ 0.06127471,  0.12454933, -0.09871164, -0.02527269,\n",
       "           -0.24028088, -0.05731723, -0.09198619,  0.19669445,\n",
       "            0.09193442,  0.04997336],\n",
       "          [-0.15162796,  0.07103198, -0.2218252 , -0.06372958,\n",
       "            0.06751615, -0.11743066, -0.02287547, -0.02629605,\n",
       "            0.09435048, -0.06150759],\n",
       "          [ 0.03620581,  0.00529569, -0.1737143 ,  0.18374074,\n",
       "            0.14244598,  0.04220079, -0.02583253,  0.12407978,\n",
       "           -0.06102292, -0.24223   ],\n",
       "          [ 0.1340856 ,  0.10628098,  0.10994002,  0.08776351,\n",
       "           -0.08998794,  0.03906384,  0.1969851 ,  0.07152422,\n",
       "            0.10800077,  0.01129551],\n",
       "          [-0.10427738, -0.14131749, -0.09314509,  0.15294255,\n",
       "            0.00875395, -0.19724834,  0.07097492, -0.19248793,\n",
       "            0.11776944, -0.18697022],\n",
       "          [-0.21740752,  0.17058925,  0.02181068, -0.00537843,\n",
       "           -0.11766393,  0.02217668, -0.00633296,  0.18343277,\n",
       "           -0.02777596, -0.14459547],\n",
       "          [ 0.03907492, -0.03859345, -0.02074963,  0.16998057,\n",
       "           -0.05929814, -0.12201289,  0.10748371, -0.04498356,\n",
       "            0.02333236,  0.21452245],\n",
       "          [-0.13871734,  0.0768059 , -0.08137463,  0.03905621,\n",
       "           -0.02389872, -0.08273219,  0.178774  ,  0.01808699,\n",
       "            0.09966321, -0.02609221],\n",
       "          [ 0.12111259,  0.17795041, -0.17967065, -0.08150757,\n",
       "            0.09129849,  0.02136693,  0.08330797, -0.12106644,\n",
       "           -0.01447172,  0.04401728],\n",
       "          [-0.05973915, -0.13731964,  0.00412354, -0.20115303,\n",
       "            0.11221953,  0.12197675,  0.11637232, -0.01218905,\n",
       "            0.10711353,  0.04065799]]],\n",
       " \n",
       " \n",
       "        [[[ 0.11289847, -0.15464102, -0.00503754, -0.20162842,\n",
       "            0.05786053,  0.00533249, -0.18682201,  0.07544801,\n",
       "            0.02992214,  0.1668975 ],\n",
       "          [-0.10690458, -0.10048852, -0.02218767,  0.11023614,\n",
       "            0.09695517, -0.14174752,  0.06219684, -0.1919142 ,\n",
       "           -0.11960484,  0.01888142],\n",
       "          [-0.09511629, -0.18400536, -0.01591347, -0.06207559,\n",
       "           -0.10421262, -0.00059714,  0.16427276, -0.04733974,\n",
       "            0.06939485,  0.06274066],\n",
       "          [ 0.17805433,  0.06046224, -0.19576204, -0.22586821,\n",
       "            0.02761406,  0.01868501,  0.01100948,  0.11048465,\n",
       "            0.03097244, -0.1579483 ],\n",
       "          [-0.01618839, -0.15260719, -0.0739207 ,  0.15400434,\n",
       "           -0.03664052, -0.04921087,  0.09785999, -0.06049857,\n",
       "            0.10606468, -0.02535314],\n",
       "          [ 0.00225398, -0.01712299, -0.09167674,  0.06150055,\n",
       "            0.04941973, -0.15490845,  0.0133996 , -0.20383632,\n",
       "           -0.06137588, -0.01955652],\n",
       "          [-0.10831454,  0.14457142,  0.08378258, -0.07117862,\n",
       "            0.08462255, -0.06013887,  0.01102784, -0.09678876,\n",
       "           -0.04734738, -0.11299018],\n",
       "          [ 0.12706931, -0.16220117,  0.01146989,  0.16133499,\n",
       "           -0.11934187, -0.09769115, -0.01804904, -0.0156853 ,\n",
       "           -0.02324687, -0.07757235],\n",
       "          [ 0.02574534, -0.14199553, -0.03150017, -0.03116885,\n",
       "            0.07719991,  0.07375062,  0.10555299, -0.05428745,\n",
       "            0.10313854,  0.07112016],\n",
       "          [-0.11598127, -0.0091943 , -0.08493185, -0.09912208,\n",
       "            0.13042375, -0.04010193, -0.00853848,  0.07666725,\n",
       "           -0.06170472, -0.04473584]],\n",
       " \n",
       "         [[ 0.18541652, -0.08166829,  0.05931174,  0.0687143 ,\n",
       "            0.0206749 , -0.00349296,  0.02489174, -0.2250181 ,\n",
       "            0.02561674,  0.01654119],\n",
       "          [ 0.02235785,  0.15290965,  0.16797732, -0.10170828,\n",
       "            0.06666873,  0.06588035, -0.02047775, -0.04356691,\n",
       "            0.09203377, -0.15294786],\n",
       "          [ 0.12796025,  0.00598191,  0.09989008, -0.0790161 ,\n",
       "            0.12956847, -0.04990802, -0.15634565, -0.13368894,\n",
       "            0.1074358 ,  0.00722903],\n",
       "          [-0.07765963,  0.09684461,  0.10540554, -0.17978643,\n",
       "            0.01679352,  0.02194397, -0.19048038,  0.05023158,\n",
       "           -0.10282219, -0.0738554 ],\n",
       "          [ 0.04523521,  0.12468612, -0.00278854, -0.06440792,\n",
       "            0.01214961,  0.03171487, -0.15661153,  0.10195048,\n",
       "           -0.05681071,  0.09453958],\n",
       "          [-0.24545331,  0.03853856, -0.15444192,  0.0375212 ,\n",
       "           -0.17065908,  0.02467153,  0.11351469,  0.05238007,\n",
       "            0.08989196,  0.05569572],\n",
       "          [ 0.02132878,  0.09569966, -0.01469224,  0.05609416,\n",
       "            0.09769177,  0.09231827,  0.07557043,  0.01838791,\n",
       "           -0.12677646,  0.01195089],\n",
       "          [ 0.06954648, -0.22083355, -0.01797156, -0.14597464,\n",
       "            0.06826974, -0.081863  ,  0.11297221, -0.0428413 ,\n",
       "            0.10324905,  0.1393388 ],\n",
       "          [ 0.06487879, -0.03823928,  0.11502053, -0.01297036,\n",
       "           -0.11708786,  0.05787999, -0.1587728 , -0.16029215,\n",
       "            0.17177664, -0.06030221],\n",
       "          [-0.08974628, -0.07788979, -0.04751116, -0.11183922,\n",
       "           -0.04852448,  0.2261977 ,  0.03013522,  0.16078137,\n",
       "           -0.03389005,  0.02587434]],\n",
       " \n",
       "         [[-0.22064258, -0.1908499 ,  0.1619993 ,  0.00171418,\n",
       "            0.00499647,  0.0356807 , -0.03211457,  0.0227444 ,\n",
       "            0.01557114,  0.07679296],\n",
       "          [ 0.16405907, -0.10235137,  0.19470684,  0.06001658,\n",
       "           -0.01353316, -0.05786043, -0.00766128,  0.0117112 ,\n",
       "            0.09051093, -0.01511177],\n",
       "          [ 0.08177408, -0.10976675, -0.00812047, -0.00562421,\n",
       "           -0.00303697, -0.15946068,  0.08626227, -0.00499012,\n",
       "           -0.1173096 , -0.03632371],\n",
       "          [-0.14015436, -0.06482852, -0.15247655, -0.07005783,\n",
       "            0.10436854, -0.14747691,  0.1761564 , -0.17428459,\n",
       "            0.05565731,  0.0011449 ],\n",
       "          [-0.0943415 ,  0.0610148 , -0.02266471, -0.06868771,\n",
       "           -0.00603163,  0.09057862, -0.18225738,  0.0421923 ,\n",
       "           -0.15266865,  0.01043644],\n",
       "          [ 0.14794429,  0.07333588,  0.03740503, -0.02257978,\n",
       "            0.06609224,  0.19682123, -0.1163616 , -0.08159977,\n",
       "            0.0072358 ,  0.06852735],\n",
       "          [-0.0651397 ,  0.01005876, -0.04705166, -0.12529229,\n",
       "           -0.09129009, -0.23530817,  0.04610407, -0.02511613,\n",
       "            0.23942219, -0.14881833],\n",
       "          [ 0.07650554, -0.03960873,  0.05548701, -0.06427865,\n",
       "           -0.01404515, -0.00616937, -0.13400944,  0.05420984,\n",
       "           -0.15849394,  0.01798212],\n",
       "          [-0.09546657, -0.00642325,  0.01698399,  0.01165512,\n",
       "           -0.1624189 , -0.06639475,  0.17512451, -0.13609318,\n",
       "           -0.10183471, -0.13549955],\n",
       "          [ 0.07150143, -0.04271057, -0.05001621, -0.15579191,\n",
       "           -0.02295755, -0.08440073,  0.16827273, -0.05433117,\n",
       "           -0.01002587, -0.19261776]]],\n",
       " \n",
       " \n",
       "        [[[-0.20251998,  0.06005263, -0.04277775, -0.17661318,\n",
       "            0.06117032,  0.04669086,  0.03107794,  0.1361526 ,\n",
       "            0.01230303, -0.01073117],\n",
       "          [-0.07932968,  0.03389952,  0.03450581,  0.11374214,\n",
       "           -0.05691527,  0.13838384,  0.04805163,  0.11313576,\n",
       "            0.00486441, -0.21703206],\n",
       "          [ 0.07742762,  0.10740251, -0.06258997,  0.01293524,\n",
       "           -0.10563585, -0.12704892,  0.12839483, -0.04431823,\n",
       "            0.08342117, -0.02499664],\n",
       "          [-0.09744524, -0.11671849, -0.081049  ,  0.0633539 ,\n",
       "           -0.11850443, -0.04462986,  0.07294473,  0.12783615,\n",
       "           -0.10020887,  0.08576722],\n",
       "          [-0.16309842, -0.04522684, -0.06323169, -0.02649159,\n",
       "            0.05199269, -0.01176355, -0.18834168, -0.04120415,\n",
       "           -0.0309468 , -0.02431837],\n",
       "          [-0.17008474,  0.03527879,  0.2277572 ,  0.0088373 ,\n",
       "            0.0708084 ,  0.05941654, -0.10174911, -0.06945047,\n",
       "           -0.068343  ,  0.06255998],\n",
       "          [ 0.0323961 ,  0.10770498,  0.05446687,  0.01792963,\n",
       "            0.10994683,  0.08290577, -0.03532308, -0.06596331,\n",
       "            0.17329252,  0.03543949],\n",
       "          [-0.17184028,  0.15156507, -0.21384974,  0.15247706,\n",
       "            0.0694531 ,  0.04920005, -0.17181833,  0.18541402,\n",
       "            0.05097588, -0.17945701],\n",
       "          [ 0.20021752, -0.1243031 ,  0.02150231,  0.05106107,\n",
       "            0.08970558,  0.06849953, -0.18999201,  0.12235851,\n",
       "            0.12034073, -0.19433671],\n",
       "          [-0.04437713,  0.03170646,  0.07078171, -0.03053322,\n",
       "            0.10315339, -0.22447115, -0.13915972,  0.15811579,\n",
       "           -0.00648672, -0.01367181]],\n",
       " \n",
       "         [[ 0.16140978,  0.11316536, -0.20823586,  0.01832259,\n",
       "           -0.05768735,  0.09112018, -0.03280644,  0.05539392,\n",
       "           -0.17670569, -0.13981041],\n",
       "          [ 0.03498236,  0.11269991,  0.06907249,  0.00681815,\n",
       "           -0.03897691, -0.14707784,  0.01052724, -0.1433602 ,\n",
       "           -0.10020322, -0.0380563 ],\n",
       "          [ 0.02061832, -0.07458472,  0.03065838,  0.03084412,\n",
       "           -0.06744804,  0.1126416 , -0.08785947,  0.08583914,\n",
       "            0.04491587,  0.02384045],\n",
       "          [-0.07670262, -0.10945703, -0.03515705, -0.0132307 ,\n",
       "           -0.10082775,  0.19376473, -0.08196668,  0.11700287,\n",
       "           -0.15478927,  0.06883012],\n",
       "          [ 0.19329807, -0.07721043, -0.05044011, -0.07425848,\n",
       "            0.01303517,  0.00928462,  0.16434738,  0.02432305,\n",
       "            0.19915117, -0.1370751 ],\n",
       "          [ 0.11291897,  0.03270883, -0.0741464 , -0.22647488,\n",
       "            0.10608979,  0.18271068,  0.07438621, -0.01800349,\n",
       "           -0.16483486,  0.06453727],\n",
       "          [-0.06176921, -0.08688622,  0.20038864,  0.12067015,\n",
       "            0.10269438, -0.2071071 ,  0.0278663 ,  0.20764521,\n",
       "            0.07976376,  0.06854606],\n",
       "          [ 0.0587667 ,  0.05752633, -0.06581632, -0.23164083,\n",
       "           -0.07636323, -0.06333343, -0.10733242, -0.11426241,\n",
       "           -0.16433886, -0.04515222],\n",
       "          [ 0.01505341,  0.06945779,  0.06915069, -0.00130332,\n",
       "            0.17749286,  0.02595201, -0.16322969,  0.07412928,\n",
       "           -0.0337011 ,  0.19729573],\n",
       "          [-0.05369836, -0.10434227, -0.00446344, -0.05092714,\n",
       "           -0.11501723, -0.09971204, -0.1293128 ,  0.0031383 ,\n",
       "           -0.11612388,  0.13635582]],\n",
       " \n",
       "         [[ 0.02212952,  0.14714009, -0.23290543,  0.14697589,\n",
       "           -0.15616232, -0.13103327, -0.03035648,  0.05661544,\n",
       "           -0.16774169, -0.05829484],\n",
       "          [-0.08871987,  0.05801985, -0.19764267, -0.18147   ,\n",
       "           -0.0206146 ,  0.01274008, -0.09907413,  0.01654987,\n",
       "           -0.11404741, -0.10752384],\n",
       "          [-0.06638953,  0.04510949, -0.00762828,  0.06289761,\n",
       "            0.07442535, -0.161487  ,  0.13958897,  0.06849246,\n",
       "            0.08515238,  0.000786  ],\n",
       "          [-0.12195646, -0.01146095,  0.03910394,  0.0471328 ,\n",
       "            0.02098483,  0.03838791,  0.00285232, -0.13144788,\n",
       "           -0.05738182,  0.03315028],\n",
       "          [-0.07006919, -0.10729159, -0.0334678 ,  0.10826814,\n",
       "            0.13783583,  0.19463652,  0.09013799, -0.05372679,\n",
       "            0.05105552,  0.06432493],\n",
       "          [-0.00549034, -0.13485856,  0.03763136,  0.01879119,\n",
       "           -0.03949698,  0.0134861 , -0.04179855, -0.21516779,\n",
       "            0.07669239,  0.03330083],\n",
       "          [ 0.05061371,  0.14030577,  0.03123054, -0.15735008,\n",
       "           -0.16376708,  0.0801961 , -0.05549176, -0.031226  ,\n",
       "            0.04177024, -0.13219434],\n",
       "          [-0.0754587 , -0.03180633,  0.02867719, -0.13401198,\n",
       "            0.11331809, -0.07974488,  0.13790596,  0.1288196 ,\n",
       "           -0.04573924,  0.00581217],\n",
       "          [-0.11379898, -0.10041856, -0.12411294, -0.20843421,\n",
       "            0.02338842,  0.08861326,  0.04386873, -0.09510503,\n",
       "            0.05781312, -0.00976666],\n",
       "          [-0.12648784,  0.16420619,  0.04192559, -0.10347714,\n",
       "           -0.1059532 ,  0.01498076,  0.08983373,  0.00621853,\n",
       "            0.09020483, -0.05104116]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_220_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.00197952,  0.000255  , -0.00790314,  0.00083751,  0.00138084,\n",
       "         0.00356111, -0.01154541,  0.00106886, -0.00576153, -0.00365566],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_250_1/gamma:0' shape=(10,) dtype=float32, numpy=\n",
       " array([1.0093904, 0.9823292, 1.0047513, 0.9891817, 0.9999991, 1.0094211,\n",
       "        1.013434 , 0.9825863, 1.0096635, 1.0008535], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_250_1/beta:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 3.70635977e-03,  3.70083237e-03, -7.12216645e-03,  1.43356575e-02,\n",
       "        -5.76976733e-03, -5.98404149e-04, -1.57424845e-02,  3.97230469e-05,\n",
       "         2.08421401e-03,  1.47233149e-02], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_221_1/kernel:0' shape=(3, 3, 10, 10) dtype=float32, numpy=\n",
       " array([[[[-1.49680197e-01, -2.81311218e-02, -1.06407747e-01,\n",
       "            1.96579665e-01,  5.35590202e-02,  1.30665660e-01,\n",
       "            1.75376132e-01,  3.73159833e-02,  1.11317396e-01,\n",
       "           -9.37561225e-03],\n",
       "          [-1.34816870e-01,  6.31669834e-02, -7.94403628e-02,\n",
       "            1.39063090e-01,  9.76344347e-02, -9.13428068e-02,\n",
       "            8.73562545e-02,  8.75391345e-03,  6.88722283e-02,\n",
       "           -7.06084296e-02],\n",
       "          [-1.18113984e-03, -1.40973374e-01,  2.03572884e-01,\n",
       "           -1.18924133e-01, -1.08975284e-01,  1.03204131e-01,\n",
       "           -6.72276970e-03, -1.48482472e-01,  8.27709287e-02,\n",
       "           -2.12832680e-03],\n",
       "          [ 1.38651505e-01,  1.08192943e-01, -1.23593986e-01,\n",
       "           -7.05923587e-02, -8.71801153e-02,  1.84071288e-01,\n",
       "            1.10211700e-01, -8.07639658e-02, -1.95592642e-01,\n",
       "           -8.26702192e-02],\n",
       "          [-9.94699299e-02, -1.07054763e-01, -5.23898639e-02,\n",
       "           -5.42491712e-02,  2.01344024e-02,  2.42214873e-02,\n",
       "            1.64175797e-02,  1.20985433e-01,  4.86409925e-02,\n",
       "            7.69801512e-02],\n",
       "          [-8.52369219e-02, -1.21187329e-01,  7.64299259e-02,\n",
       "           -1.98289320e-01,  1.54101193e-01,  1.18926547e-01,\n",
       "            1.53621465e-01, -5.86784258e-02,  2.36623764e-01,\n",
       "            1.29226185e-02],\n",
       "          [ 2.71709375e-02, -6.13340661e-02, -1.78482607e-02,\n",
       "            1.49160907e-01, -1.73055218e-04,  1.16560422e-01,\n",
       "            3.77960168e-02,  1.83996543e-01,  1.24050363e-03,\n",
       "           -1.00240223e-01],\n",
       "          [-4.57102209e-02, -3.39884944e-02, -1.86633304e-01,\n",
       "           -2.46123910e-01,  1.38793886e-01, -9.83169824e-02,\n",
       "            2.17247140e-02,  3.69331837e-02,  4.76752557e-02,\n",
       "           -5.47556542e-02],\n",
       "          [-2.06578359e-01, -1.85784340e-01, -3.48497927e-02,\n",
       "           -4.31498466e-03,  7.64293410e-03, -3.27919461e-02,\n",
       "           -1.00645043e-01,  4.84678745e-02, -2.19642967e-01,\n",
       "            2.07518041e-02],\n",
       "          [-1.15115782e-02, -1.77961327e-02,  2.01726794e-01,\n",
       "           -8.66440833e-02, -6.40381053e-02, -9.26993322e-03,\n",
       "           -1.11482456e-01, -1.94860343e-02,  6.11087568e-02,\n",
       "           -7.73886815e-02]],\n",
       " \n",
       "         [[-7.47056082e-02, -8.84091016e-03, -2.33575076e-01,\n",
       "            1.36886895e-01,  2.15550974e-01,  4.39960547e-02,\n",
       "            9.35931876e-02,  3.34682949e-02, -2.39152405e-02,\n",
       "            7.93463886e-02],\n",
       "          [-1.45578876e-01, -1.53541192e-01, -2.15596519e-03,\n",
       "            5.89195490e-02, -1.66202962e-01,  1.15048490e-01,\n",
       "            1.14936426e-01, -1.75685678e-02, -2.00182021e-01,\n",
       "            9.13383812e-03],\n",
       "          [-4.28714789e-02, -1.20123802e-02,  2.33108759e-01,\n",
       "           -8.22080225e-02,  6.41822144e-02, -4.79891375e-02,\n",
       "            5.40179424e-02, -4.09348309e-03,  1.22995190e-01,\n",
       "            5.70756458e-02],\n",
       "          [ 7.96533078e-02, -1.00307629e-01, -1.36671901e-01,\n",
       "            5.06461971e-02,  1.36794478e-01,  1.20585058e-02,\n",
       "            5.70732206e-02, -1.91772640e-01, -1.69597894e-01,\n",
       "           -2.57042013e-02],\n",
       "          [-1.87047701e-02,  7.57228732e-02, -9.47461128e-02,\n",
       "            1.00886479e-01, -1.62676588e-01,  2.46307980e-02,\n",
       "            1.11355193e-01,  2.35538393e-01, -1.18823163e-01,\n",
       "            6.09402219e-03],\n",
       "          [ 5.68431914e-02,  4.14320081e-03,  2.79352218e-02,\n",
       "           -5.27897850e-02, -8.07667524e-02,  1.41782582e-01,\n",
       "           -7.45272487e-02, -3.07364929e-02,  6.95183799e-02,\n",
       "            1.81575507e-01],\n",
       "          [-1.02249615e-01, -1.02215834e-01, -1.24335382e-02,\n",
       "           -1.18095484e-02, -1.14101274e-02, -3.90266106e-02,\n",
       "           -6.24566488e-02,  2.20102087e-01,  2.75235679e-02,\n",
       "            6.45985734e-03],\n",
       "          [ 1.38521582e-01, -7.55202174e-02, -1.61772326e-01,\n",
       "            4.52878959e-02, -2.49117147e-02, -7.83284893e-04,\n",
       "           -1.19661674e-01, -8.43393952e-02,  7.61132687e-02,\n",
       "           -1.61605820e-01],\n",
       "          [-3.29880267e-02,  1.00795135e-01, -7.58266747e-02,\n",
       "            7.65054002e-02, -1.62856057e-01, -9.46197659e-02,\n",
       "            9.10825431e-02, -1.36923650e-02, -1.24775171e-01,\n",
       "            2.34196529e-01],\n",
       "          [-2.21790057e-02, -2.88499668e-02,  1.06571302e-01,\n",
       "           -2.22299710e-01, -3.22095379e-02, -5.36386147e-02,\n",
       "           -1.00468509e-01,  2.91865859e-02, -3.53289843e-02,\n",
       "            1.30740225e-01]],\n",
       " \n",
       "         [[-4.94829454e-02,  9.59822685e-02,  1.34878367e-01,\n",
       "           -1.05875529e-01,  1.25939637e-01, -7.20457658e-02,\n",
       "           -6.71485439e-02, -1.47675037e-01,  3.79866958e-02,\n",
       "           -2.54017543e-02],\n",
       "          [ 1.22674249e-01, -5.52300476e-02,  2.04978153e-01,\n",
       "            1.23918727e-02, -9.47810560e-02, -1.37793375e-02,\n",
       "            7.80836791e-02, -1.02386028e-01,  1.29711311e-02,\n",
       "           -7.56295845e-02],\n",
       "          [ 6.70239031e-02, -8.30368418e-03, -1.09383456e-01,\n",
       "           -1.12906948e-01,  1.16848655e-01,  1.00945115e-01,\n",
       "           -1.09600723e-01,  2.17050701e-01, -5.94233200e-02,\n",
       "            2.28721678e-01],\n",
       "          [ 2.59420672e-03,  1.68077871e-01, -7.18516037e-02,\n",
       "           -4.95075509e-02, -7.00223222e-02, -1.16094835e-01,\n",
       "           -1.88895375e-01, -1.74512297e-01,  1.03838429e-01,\n",
       "           -1.63749263e-01],\n",
       "          [ 4.80861440e-02, -1.77174062e-02,  4.24010567e-02,\n",
       "           -3.42526771e-02, -1.68942541e-01,  8.75190794e-02,\n",
       "           -2.44816989e-01,  6.94306120e-02,  6.21153079e-02,\n",
       "            1.37290135e-01],\n",
       "          [-2.08797172e-01, -4.05532308e-02, -4.29239459e-02,\n",
       "            8.96525458e-02, -1.89520866e-02,  1.84562236e-01,\n",
       "            1.36201784e-01, -3.01860981e-02,  1.25725225e-01,\n",
       "            2.49877460e-02],\n",
       "          [ 1.39584485e-02, -9.47535262e-02, -2.21405141e-02,\n",
       "            9.24755782e-02,  8.36518928e-02, -6.96720649e-03,\n",
       "           -7.20776990e-02, -3.25784758e-02, -3.67111228e-02,\n",
       "            2.31812999e-01],\n",
       "          [-6.13574795e-02, -6.37081414e-02,  2.74964310e-02,\n",
       "            2.70515457e-02, -1.56575561e-01,  2.83582998e-03,\n",
       "            8.35375488e-03,  6.32457212e-02, -1.57961667e-01,\n",
       "            2.86451802e-02],\n",
       "          [ 3.34097818e-02,  1.91885214e-02,  9.11539048e-02,\n",
       "            1.37058824e-01,  8.44052881e-02, -3.01868096e-02,\n",
       "            1.27720889e-02, -2.01866459e-02,  9.49821472e-02,\n",
       "            1.30769491e-01],\n",
       "          [ 6.05794303e-02,  2.67430171e-02,  1.07398639e-02,\n",
       "           -1.08180352e-01, -8.17065686e-02, -4.98952456e-02,\n",
       "           -1.40352711e-01, -1.61531389e-01, -1.97286233e-02,\n",
       "           -2.57325303e-02]]],\n",
       " \n",
       " \n",
       "        [[[-5.39280064e-02,  1.67594641e-01, -9.17426944e-02,\n",
       "           -1.02081418e-01,  3.45276445e-02, -7.74610788e-02,\n",
       "           -1.24233454e-01,  1.17162026e-01,  3.20462473e-02,\n",
       "            1.68169081e-01],\n",
       "          [ 5.10880463e-02, -8.38677064e-02,  1.40391767e-01,\n",
       "           -7.46513531e-02,  1.10769182e-01,  9.88962576e-02,\n",
       "            1.25173047e-01, -7.63666332e-02, -9.18156505e-02,\n",
       "            9.08718109e-02],\n",
       "          [-6.14559278e-03,  6.58683851e-02, -3.04469932e-02,\n",
       "           -1.17772453e-01,  1.07677348e-01,  1.31930094e-02,\n",
       "            1.33603722e-01,  8.21027085e-02,  4.84314524e-02,\n",
       "            3.54344882e-02],\n",
       "          [ 3.58222798e-02,  1.16257384e-01,  6.22684211e-02,\n",
       "           -1.76238403e-01, -1.74277253e-03,  8.58085230e-02,\n",
       "            7.66934007e-02, -2.01055333e-01,  1.20316833e-01,\n",
       "            1.64935235e-02],\n",
       "          [ 1.76936816e-02, -1.55859562e-02, -6.96527287e-02,\n",
       "            6.57303333e-02,  5.83223104e-02, -2.25793980e-02,\n",
       "           -1.19101703e-02, -1.28977269e-01, -1.33931696e-01,\n",
       "           -1.92136049e-01],\n",
       "          [ 7.72732822e-03, -6.29518330e-02,  1.42663531e-03,\n",
       "           -2.27829423e-02,  1.13558425e-02, -1.86278984e-01,\n",
       "            3.35377385e-03,  7.06866756e-02,  7.20796222e-03,\n",
       "            1.63015053e-01],\n",
       "          [-7.32125267e-02,  6.63840249e-02, -1.14432603e-01,\n",
       "           -5.58559708e-02, -1.91648737e-01, -3.74244675e-02,\n",
       "            5.54271750e-02, -1.57391354e-01,  1.93031117e-01,\n",
       "           -4.39109094e-02],\n",
       "          [-6.34488687e-02,  4.90583405e-02, -7.45063052e-02,\n",
       "           -8.99688378e-02,  1.07905623e-02,  7.75345191e-02,\n",
       "            1.54253751e-01, -6.86039636e-03,  3.26282568e-02,\n",
       "           -3.87118477e-03],\n",
       "          [ 5.53019978e-02,  7.22846463e-02,  1.06936917e-01,\n",
       "            1.16029933e-01,  2.21494352e-03,  9.31462646e-03,\n",
       "            3.24176922e-02,  1.25462832e-02,  1.36775136e-01,\n",
       "           -6.49383618e-03],\n",
       "          [ 7.27056293e-03, -1.55529752e-01, -6.07924387e-02,\n",
       "           -1.01503558e-01, -1.65364444e-01, -1.15813792e-01,\n",
       "           -8.70182067e-02, -1.33265793e-01, -5.25717773e-02,\n",
       "           -5.58144674e-02]],\n",
       " \n",
       "         [[-2.60091363e-03, -3.93324606e-02,  9.52863842e-02,\n",
       "            1.97784916e-01,  1.95907857e-02,  1.26940668e-01,\n",
       "           -1.04159534e-01,  5.43266274e-02, -4.64087948e-02,\n",
       "            9.67282522e-03],\n",
       "          [ 1.54243529e-01,  1.98608935e-01,  1.91035364e-02,\n",
       "            1.10068418e-01, -3.28944027e-02,  6.63913414e-02,\n",
       "           -6.70764968e-03,  1.86666511e-02,  6.22768104e-02,\n",
       "           -1.19018868e-01],\n",
       "          [-1.39641896e-01,  1.05240000e-02,  9.22252014e-02,\n",
       "           -9.33112204e-02, -1.84091642e-01,  2.02633157e-01,\n",
       "           -1.04232915e-01, -7.39971409e-03, -1.02201596e-01,\n",
       "           -2.01537296e-01],\n",
       "          [ 5.91648370e-02, -6.77326927e-03, -6.46430627e-02,\n",
       "           -1.37257531e-01, -4.14509289e-02, -4.60041054e-02,\n",
       "           -2.31061522e-02,  4.07638066e-02, -1.75786361e-01,\n",
       "           -5.33430502e-02],\n",
       "          [ 3.54920588e-02,  1.42556027e-01,  8.63464251e-02,\n",
       "            1.40445353e-02,  1.47527328e-03,  1.50682479e-01,\n",
       "            2.22244784e-01, -2.16357484e-01, -1.07420444e-01,\n",
       "            4.31216024e-02],\n",
       "          [-6.11734651e-02,  9.21869949e-02, -5.65241426e-02,\n",
       "           -2.96385884e-02, -1.75565314e-02,  3.25573012e-02,\n",
       "            1.06514804e-01, -1.41993925e-01, -3.88675258e-02,\n",
       "            7.25356117e-02],\n",
       "          [-1.96413562e-01, -7.09757134e-02,  2.45310161e-02,\n",
       "           -2.36587916e-02,  5.90995178e-02,  9.04940590e-02,\n",
       "            1.41443327e-01,  2.56511550e-02,  5.03312424e-02,\n",
       "            7.23049268e-02],\n",
       "          [ 6.33128062e-02,  2.36100666e-02,  4.06751037e-02,\n",
       "           -8.12039077e-02,  8.23835954e-02,  6.55425861e-02,\n",
       "           -5.58932759e-02, -1.19248129e-01, -8.08746088e-03,\n",
       "            1.83601037e-01],\n",
       "          [ 2.02790454e-01,  1.83140442e-01, -1.68053228e-02,\n",
       "            3.10031809e-02, -7.07050636e-02, -3.20337601e-02,\n",
       "            1.71345830e-01, -4.90078591e-02,  1.77566901e-01,\n",
       "            6.13179021e-02],\n",
       "          [ 6.95571080e-02,  1.19671166e-01,  1.34246409e-01,\n",
       "            7.16535076e-02, -5.09294458e-02, -1.27774417e-01,\n",
       "           -1.99407250e-01,  2.29503989e-01, -1.83411129e-02,\n",
       "            4.22849059e-02]],\n",
       " \n",
       "         [[ 4.04368304e-02, -2.88768020e-02, -1.06188422e-02,\n",
       "           -3.12712900e-02,  1.61021411e-01, -2.22817250e-02,\n",
       "            8.57803151e-02, -5.86468168e-02, -1.67912379e-01,\n",
       "           -1.13414377e-01],\n",
       "          [ 2.36013848e-02,  7.50278309e-02, -2.62412038e-02,\n",
       "           -9.15828273e-02,  9.23719853e-02,  1.04178198e-01,\n",
       "            2.83821113e-02, -7.69179314e-02, -8.28887895e-02,\n",
       "            7.48398975e-02],\n",
       "          [-1.65404305e-02, -9.48879421e-02, -8.04012828e-03,\n",
       "           -8.05114396e-03,  4.29966785e-02,  4.92052920e-02,\n",
       "            1.01576276e-01, -5.66836223e-02,  1.73120216e-01,\n",
       "            1.40896976e-01],\n",
       "          [-1.98316067e-01, -9.32448059e-02, -5.05019724e-02,\n",
       "           -7.47036934e-02, -1.68954998e-01, -1.94620445e-01,\n",
       "            7.69003853e-02,  1.94854308e-02,  1.85638860e-01,\n",
       "           -1.22129671e-01],\n",
       "          [-1.10229202e-01, -4.19616513e-02, -2.87538581e-02,\n",
       "           -1.43047631e-01,  6.77324980e-02, -1.20855018e-03,\n",
       "           -4.61208075e-02,  9.39248279e-02,  7.57611096e-02,\n",
       "            7.49965012e-02],\n",
       "          [ 6.50469363e-02, -1.11282118e-01,  6.93727657e-02,\n",
       "           -5.99698052e-02, -1.60088297e-02, -2.38666162e-02,\n",
       "           -5.72486334e-02, -9.65825990e-02, -6.67491183e-03,\n",
       "            1.29542992e-01],\n",
       "          [ 1.04570135e-01, -7.75957629e-02, -2.40392778e-02,\n",
       "            1.97381988e-01,  3.20416540e-02,  1.84741259e-01,\n",
       "           -2.32209209e-02, -3.04796081e-03,  1.72492445e-01,\n",
       "           -1.25666201e-01],\n",
       "          [ 9.71554406e-03,  5.97857758e-02, -7.69614801e-02,\n",
       "            1.35467604e-01, -1.24438420e-01,  5.70588410e-02,\n",
       "            1.20569788e-01, -4.38539460e-02,  6.12866227e-03,\n",
       "            2.16522694e-01],\n",
       "          [-2.20400438e-01,  5.77064604e-02, -1.29826680e-01,\n",
       "            5.30939922e-02, -2.98254844e-03,  1.35260567e-01,\n",
       "           -4.64693122e-02, -1.35895371e-01, -8.52931663e-02,\n",
       "           -2.03872427e-01],\n",
       "          [ 5.97086586e-02,  9.83923599e-02,  7.80172125e-02,\n",
       "            1.26716301e-01,  1.15544632e-01,  1.03848159e-01,\n",
       "            4.37828666e-03,  1.00937456e-01, -2.42823195e-02,\n",
       "           -7.42272884e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 1.92128289e-02,  1.77934226e-02, -5.53577673e-03,\n",
       "           -6.63697571e-02, -1.40888870e-01, -7.45937154e-02,\n",
       "           -4.82417233e-02, -7.10275546e-02, -3.94047052e-02,\n",
       "            8.05705488e-02],\n",
       "          [ 8.62730071e-02,  9.94455535e-03,  3.47991996e-02,\n",
       "            7.12873489e-02, -9.57207233e-02, -6.55744150e-02,\n",
       "           -3.02342251e-02, -3.15203555e-02,  1.64673761e-01,\n",
       "            7.17963874e-02],\n",
       "          [ 2.60472409e-02, -7.02779740e-03, -2.30330274e-01,\n",
       "            7.49110505e-02,  1.10953651e-01, -1.33140087e-01,\n",
       "            1.55009940e-01, -3.11664622e-02, -4.24729697e-02,\n",
       "            1.03534475e-01],\n",
       "          [ 6.04713373e-02,  2.05682561e-01, -9.54778269e-02,\n",
       "           -1.62574306e-01,  7.96765089e-02,  2.90449639e-03,\n",
       "            1.55522078e-01, -6.13388717e-02, -1.09134197e-01,\n",
       "           -3.42827961e-02],\n",
       "          [-1.71907708e-01,  9.78100225e-02, -4.37815711e-02,\n",
       "           -1.76050887e-01,  9.80441868e-02, -8.18742588e-02,\n",
       "            1.43085644e-01,  2.07248360e-01,  5.44944704e-02,\n",
       "           -3.73346321e-02],\n",
       "          [-2.67435536e-02,  6.55322075e-02, -7.86309466e-02,\n",
       "            6.49956614e-02, -1.78760543e-01, -2.54943371e-02,\n",
       "           -1.55982301e-01,  1.38953626e-01,  9.11766738e-02,\n",
       "           -1.86520010e-01],\n",
       "          [-1.03331774e-01,  4.88946997e-02,  9.34663862e-02,\n",
       "           -6.95407018e-02,  1.66091416e-02, -9.96493772e-02,\n",
       "           -2.13903427e-01, -2.01650411e-01, -2.34020799e-01,\n",
       "           -5.94956391e-02],\n",
       "          [-6.07179254e-02,  1.23180442e-01, -1.21208891e-01,\n",
       "            1.52541086e-01,  1.18657365e-01, -1.48040010e-02,\n",
       "           -1.90515950e-01, -2.63537420e-03, -1.22922231e-02,\n",
       "           -7.93105811e-02],\n",
       "          [ 1.46470889e-01,  1.21206902e-01, -1.37490988e-01,\n",
       "            6.40377849e-02, -9.16145220e-02, -1.50441200e-01,\n",
       "           -7.55041763e-02,  5.98738752e-02, -2.31982842e-02,\n",
       "            2.20536336e-01],\n",
       "          [ 1.05487369e-01,  1.28338754e-01, -1.52771801e-01,\n",
       "           -1.88242853e-01, -1.10845469e-01, -1.40596122e-01,\n",
       "           -1.20144151e-01,  2.45242100e-02,  1.51708767e-01,\n",
       "           -1.01708561e-01]],\n",
       " \n",
       "         [[ 1.72845334e-01, -1.25604019e-01,  1.33641317e-01,\n",
       "            4.04579490e-02,  8.35966021e-02,  1.39085367e-01,\n",
       "           -2.91587343e-03,  5.89791313e-02, -1.10722467e-01,\n",
       "           -8.25300533e-03],\n",
       "          [-3.85943651e-02, -5.52834244e-03, -6.60579130e-02,\n",
       "           -4.00725901e-02, -7.33786449e-02, -5.57579473e-02,\n",
       "            5.49288765e-02, -7.71716461e-02,  9.67678949e-02,\n",
       "           -5.36358766e-02],\n",
       "          [ 6.31357506e-02, -7.95869902e-02,  2.30668597e-02,\n",
       "           -1.25354260e-01,  4.57943007e-02, -1.31031916e-01,\n",
       "           -2.23545469e-02, -1.45911336e-01, -2.58782338e-02,\n",
       "            1.26057863e-01],\n",
       "          [ 1.42065957e-01, -6.37072995e-02,  1.58923030e-01,\n",
       "            1.36071444e-01,  2.32386366e-01,  2.99505480e-02,\n",
       "            1.59596339e-01,  1.16529599e-01,  8.29188302e-02,\n",
       "            4.13727425e-02],\n",
       "          [-8.39753449e-02, -1.22638559e-03, -1.22768596e-01,\n",
       "            1.76768869e-01, -4.71950434e-02, -4.97799888e-02,\n",
       "           -9.00771767e-02,  4.85064164e-02,  6.78406358e-02,\n",
       "           -8.99808332e-02],\n",
       "          [-2.27302998e-01,  1.02155045e-01, -2.28036195e-01,\n",
       "            9.61558223e-02,  1.34382434e-02, -1.59893651e-02,\n",
       "           -4.69922610e-02,  3.54808718e-02,  1.02006935e-01,\n",
       "            7.01127350e-02],\n",
       "          [ 5.33290021e-02,  3.64869498e-02,  6.65657222e-02,\n",
       "            1.25354365e-01,  1.80090964e-02, -4.92076427e-02,\n",
       "           -9.24024284e-02, -3.73851992e-02, -1.61868349e-01,\n",
       "           -6.48851842e-02],\n",
       "          [-7.01166913e-02,  1.58480749e-01,  2.07382396e-01,\n",
       "           -6.58719540e-02,  4.88419533e-02, -2.45018918e-02,\n",
       "           -1.10430539e-01,  7.38897473e-02,  6.01079352e-02,\n",
       "            1.10069431e-01],\n",
       "          [ 9.77990776e-02,  2.81934198e-02, -1.06900953e-01,\n",
       "            6.20236620e-02, -1.51472734e-02, -5.14046215e-02,\n",
       "            2.27638502e-02,  2.13117838e-01, -1.41426787e-01,\n",
       "            1.06300861e-01],\n",
       "          [-1.81076095e-01, -5.51315770e-02, -3.71913537e-02,\n",
       "            8.13364461e-02,  9.51878130e-02,  2.31749862e-02,\n",
       "            5.63872904e-02, -1.39083579e-01, -1.43878609e-02,\n",
       "            9.25984606e-02]],\n",
       " \n",
       "         [[ 1.36738136e-01, -6.34746477e-02,  1.66212648e-01,\n",
       "            9.85228047e-02,  1.38977438e-01, -1.03970706e-01,\n",
       "            1.40005937e-02,  1.53721021e-02, -4.81428504e-02,\n",
       "            5.00008352e-02],\n",
       "          [ 1.15253128e-01,  8.35740566e-03, -1.12546887e-02,\n",
       "            4.10504714e-02,  2.47760210e-02,  1.58003084e-02,\n",
       "            2.12162256e-01,  4.83559333e-02,  3.87155600e-02,\n",
       "            1.36043280e-01],\n",
       "          [-1.48874342e-01, -4.93719354e-02, -8.75356123e-02,\n",
       "            9.88865942e-02, -6.89833462e-02,  1.58193648e-01,\n",
       "            5.75094819e-02, -1.07686117e-03, -5.68900518e-02,\n",
       "           -2.07435936e-02],\n",
       "          [ 5.35938516e-02,  1.06049046e-01, -5.05688675e-02,\n",
       "           -1.31206550e-02,  7.94260055e-02, -2.19230905e-01,\n",
       "           -2.94644907e-02, -1.60624027e-01, -1.47828788e-01,\n",
       "            1.84335597e-02],\n",
       "          [ 3.48137431e-02, -5.34157865e-02, -2.16885135e-02,\n",
       "           -6.33188710e-02, -9.05745625e-02, -7.91164264e-02,\n",
       "           -2.10458964e-01, -6.76964000e-02, -1.80010900e-01,\n",
       "           -9.71905049e-03],\n",
       "          [ 6.61928579e-02,  1.20223477e-01, -1.90484464e-01,\n",
       "           -7.68819973e-02, -1.28065795e-01,  5.69903776e-02,\n",
       "           -7.33211190e-02, -1.85040031e-02,  1.05476305e-01,\n",
       "           -7.10267350e-02],\n",
       "          [ 1.24808298e-02, -4.60802019e-02, -1.11355275e-01,\n",
       "            6.49864301e-02,  4.54837084e-02,  1.05324537e-01,\n",
       "            2.29376461e-02, -1.19073108e-01, -1.38661247e-02,\n",
       "           -1.79929640e-02],\n",
       "          [ 9.60325450e-02,  1.83594823e-01, -1.58979416e-01,\n",
       "            1.00522146e-01,  1.11762155e-02,  2.41647605e-02,\n",
       "           -2.18177699e-02,  1.85354859e-01, -1.09150745e-02,\n",
       "            1.15122646e-01],\n",
       "          [ 4.16480787e-02,  4.95696254e-02, -8.30421448e-02,\n",
       "            7.16779083e-02, -1.18645743e-01,  1.66722015e-01,\n",
       "            1.91439301e-01, -1.49367750e-02, -5.70707396e-03,\n",
       "           -1.21999301e-01],\n",
       "          [-1.46046758e-01,  1.34193942e-01, -1.04773799e-02,\n",
       "            1.38629824e-01, -6.06858805e-02, -2.07495406e-01,\n",
       "           -1.32488281e-01, -2.08368316e-01,  6.05427995e-02,\n",
       "            1.39334664e-01]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_221_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([-0.0062598 ,  0.01044028,  0.00826102,  0.00102786,  0.0070779 ,\n",
       "        -0.01753479,  0.00921691,  0.00088934, -0.0003165 ,  0.00144496],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_251_1/gamma:0' shape=(10,) dtype=float32, numpy=\n",
       " array([1.0206   , 1.012373 , 0.9850669, 1.0041416, 1.0102712, 0.9787165,\n",
       "        0.9942517, 1.0116374, 1.0117885, 0.9851484], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_251_1/beta:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.00484862,  0.01330577,  0.02101878,  0.00546109, -0.00357618,\n",
       "        -0.00865569,  0.01535316,  0.01735472, -0.00729665, -0.00832963],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_222_1/kernel:0' shape=(3, 3, 10, 10) dtype=float32, numpy=\n",
       " array([[[[ 6.09884225e-02, -1.55911520e-01,  9.18808728e-02,\n",
       "            1.53676269e-03,  5.16833141e-02, -1.08217997e-02,\n",
       "           -4.36521694e-02,  1.48633197e-01, -9.18598175e-02,\n",
       "            2.58852411e-02],\n",
       "          [ 5.19879609e-02, -4.10362408e-02,  6.83984607e-02,\n",
       "            2.52555124e-03, -2.04759493e-01,  1.38535276e-01,\n",
       "           -5.86690428e-03, -4.08499874e-02,  5.56018203e-02,\n",
       "            1.61608949e-01],\n",
       "          [ 2.09904820e-01, -5.13222218e-02,  8.10022503e-02,\n",
       "            7.11881071e-02,  1.56515595e-02, -1.68078229e-01,\n",
       "            3.81507240e-02, -6.74333831e-04, -1.31781250e-01,\n",
       "            6.29176944e-02],\n",
       "          [ 1.30435228e-02, -7.94094875e-02, -6.18874375e-03,\n",
       "           -4.98803221e-02, -1.24663994e-01, -1.15591541e-01,\n",
       "           -8.88058171e-02, -6.01012036e-02, -1.94526270e-01,\n",
       "            4.12803255e-02],\n",
       "          [ 1.29509240e-01,  6.09131344e-02,  2.03955546e-02,\n",
       "           -4.90079857e-02,  3.84364091e-02,  6.47365525e-02,\n",
       "           -1.61823064e-01,  2.28582054e-01, -3.57664153e-02,\n",
       "            1.01007037e-01],\n",
       "          [-1.62467107e-01,  1.56917498e-01, -8.92669521e-03,\n",
       "            6.24041520e-02,  1.74723551e-01,  9.41444114e-02,\n",
       "            6.63095266e-02,  9.04447660e-02,  8.76063183e-02,\n",
       "            4.88353074e-02],\n",
       "          [ 1.15862727e-01,  1.59298424e-02, -1.27125708e-02,\n",
       "           -1.20021395e-01, -1.42834798e-01, -3.79167460e-02,\n",
       "            3.38648930e-02, -1.79873988e-01,  5.13253771e-02,\n",
       "            1.32107303e-01],\n",
       "          [ 1.40298158e-01, -1.27087101e-01,  6.43701181e-02,\n",
       "           -1.84707731e-01,  1.49094462e-01, -4.23004180e-02,\n",
       "            1.75103962e-01, -1.12789813e-02, -1.08008876e-01,\n",
       "            2.07520336e-01],\n",
       "          [-1.02187358e-01, -6.60104975e-02,  2.85069495e-02,\n",
       "           -2.51403470e-02,  1.21435270e-01, -7.89074227e-02,\n",
       "           -3.65192927e-02, -1.22461677e-01, -6.09741546e-02,\n",
       "           -7.44605884e-02],\n",
       "          [-6.00945465e-02,  9.92450938e-02, -3.98885868e-02,\n",
       "            7.21316114e-02, -1.90605402e-01, -1.14099510e-01,\n",
       "            1.39880344e-01, -1.06888019e-01,  2.62934994e-02,\n",
       "           -1.49898633e-01]],\n",
       " \n",
       "         [[-2.13918164e-01, -6.71755224e-02,  1.44938603e-01,\n",
       "           -6.01470843e-02,  2.52604723e-01,  5.40407710e-02,\n",
       "            4.49910946e-02,  1.23251565e-01,  1.24979794e-01,\n",
       "           -1.10018790e-01],\n",
       "          [ 2.21881270e-01,  9.24755633e-02,  1.22763634e-01,\n",
       "           -1.91852927e-01, -3.44604664e-02,  3.72907557e-02,\n",
       "           -6.26171678e-02,  3.17012891e-03,  1.04743809e-01,\n",
       "           -1.60263237e-02],\n",
       "          [ 4.77342531e-02,  9.81134623e-02,  7.02554658e-02,\n",
       "            5.67419939e-02,  8.02766755e-02, -2.28695720e-02,\n",
       "           -5.28047187e-03, -1.27478866e-02,  6.05510399e-02,\n",
       "           -4.73402105e-02],\n",
       "          [-1.26675561e-01,  1.52781978e-01, -3.76594514e-02,\n",
       "           -3.94495241e-02, -1.91794947e-01, -1.12947136e-01,\n",
       "            5.87089024e-02, -1.02343678e-01,  1.70376480e-01,\n",
       "            8.24336428e-03],\n",
       "          [ 7.01066405e-02, -2.42821947e-02, -1.25176013e-01,\n",
       "           -1.58636257e-01, -1.77911818e-01, -7.83485472e-02,\n",
       "           -8.41975063e-02, -7.50746112e-03, -1.40094519e-01,\n",
       "            4.63505127e-02],\n",
       "          [-3.87127027e-02, -6.61593825e-02, -8.03589448e-02,\n",
       "            2.19131052e-03, -1.34593681e-01, -2.33924761e-01,\n",
       "           -2.90767523e-03,  5.28427996e-02, -3.24732363e-02,\n",
       "            8.84874240e-02],\n",
       "          [ 1.03716865e-01,  5.59312031e-02, -7.19450861e-02,\n",
       "           -2.10272506e-01,  1.02196261e-01, -7.70337582e-02,\n",
       "            9.20567289e-02,  8.42153504e-02,  1.13757484e-01,\n",
       "           -1.93421707e-01],\n",
       "          [-2.03814059e-02,  1.43949986e-01,  9.89322588e-02,\n",
       "            2.11724713e-01, -4.90998887e-02, -1.50525704e-01,\n",
       "            1.85306519e-01,  1.55779928e-01,  7.76550323e-02,\n",
       "            1.06205093e-02],\n",
       "          [ 3.06025520e-02,  4.15136032e-02, -1.44123763e-01,\n",
       "            2.44146436e-02,  6.59703612e-02,  9.15602073e-02,\n",
       "            1.16755143e-02,  1.49887167e-02, -1.94965333e-01,\n",
       "           -1.89973131e-01],\n",
       "          [-1.01540357e-01,  1.64853185e-01,  6.01237193e-02,\n",
       "           -1.04176784e-02,  1.61645994e-01, -1.07164793e-01,\n",
       "           -6.43010512e-02,  1.56997576e-01, -1.63661003e-01,\n",
       "            1.41821012e-01]],\n",
       " \n",
       "         [[-6.58762604e-02, -6.92506805e-02, -1.54798096e-02,\n",
       "            1.99335925e-02,  1.70848772e-01,  9.04776379e-02,\n",
       "            2.74351034e-02,  1.74217336e-02, -9.63249207e-02,\n",
       "           -5.43724895e-02],\n",
       "          [-3.66811752e-02, -1.39256582e-01,  8.70228000e-03,\n",
       "           -7.19759241e-02, -5.08343130e-02,  1.82408273e-01,\n",
       "           -5.78069799e-02,  5.10350056e-02,  6.81904852e-02,\n",
       "           -1.56853408e-01],\n",
       "          [ 4.68716724e-03, -4.16644625e-02,  1.09844301e-02,\n",
       "            1.24518527e-02,  8.31575245e-02,  1.90592647e-01,\n",
       "           -5.79037368e-02,  1.44653860e-02, -7.86593556e-02,\n",
       "           -1.17759164e-02],\n",
       "          [ 8.98692980e-02,  1.36323154e-01, -2.01560222e-02,\n",
       "            1.16608866e-01, -2.89750900e-02, -4.50599566e-02,\n",
       "           -3.94578837e-02,  2.47135460e-01,  2.57095005e-02,\n",
       "            5.06814942e-02],\n",
       "          [ 2.80491170e-02,  2.14132220e-02,  1.64653063e-01,\n",
       "            3.87462378e-02,  3.29150259e-02, -2.28710040e-01,\n",
       "            6.44334629e-02, -1.75837234e-01, -6.53662160e-02,\n",
       "           -2.34033223e-02],\n",
       "          [ 2.94972993e-02,  8.22214708e-02,  3.71754505e-02,\n",
       "           -1.21380508e-01,  1.43267006e-01,  4.30392437e-02,\n",
       "            2.07553372e-01, -1.13371797e-01, -7.29790255e-02,\n",
       "            8.57114196e-02],\n",
       "          [ 1.61846094e-02,  6.82179332e-02, -8.19583982e-03,\n",
       "           -5.14749996e-02, -3.29122171e-02, -1.31908860e-02,\n",
       "           -5.33885173e-02, -3.28062065e-02,  2.66196597e-02,\n",
       "            1.33457080e-01],\n",
       "          [ 8.15095231e-02, -1.73285097e-01,  1.04799554e-01,\n",
       "           -1.29630845e-02,  1.81698352e-02,  2.06590831e-01,\n",
       "           -9.35521051e-02, -1.79075032e-01, -3.47759924e-03,\n",
       "           -1.09985515e-01],\n",
       "          [-3.85013558e-02, -4.63656336e-02,  2.35404130e-02,\n",
       "            6.86504319e-02,  1.68991566e-01,  3.28610800e-02,\n",
       "            1.38017133e-01, -4.32992838e-02, -1.98117360e-01,\n",
       "           -1.67059571e-01],\n",
       "          [-1.26659870e-01, -6.14094362e-02, -3.14549319e-02,\n",
       "            4.73948866e-02, -5.30263782e-02,  2.63188640e-03,\n",
       "           -3.49291936e-02, -6.14689887e-02,  7.07498044e-02,\n",
       "           -1.28549233e-01]]],\n",
       " \n",
       " \n",
       "        [[[-1.82318920e-03,  1.58854146e-02, -1.94047481e-01,\n",
       "           -3.24399509e-02, -6.61604013e-03,  5.57613969e-02,\n",
       "           -1.81691106e-02,  4.67351116e-02,  1.15099840e-01,\n",
       "            5.16282879e-02],\n",
       "          [-1.85927272e-01,  1.75824184e-02, -1.73490137e-01,\n",
       "           -1.28140420e-01,  2.13512644e-01,  8.41040537e-02,\n",
       "            7.88671747e-02,  5.54748476e-02,  5.77501208e-02,\n",
       "           -2.88808113e-03],\n",
       "          [-4.81532030e-02,  5.08492403e-02, -1.45248502e-01,\n",
       "           -3.25083844e-02, -4.92570139e-02, -1.58101916e-02,\n",
       "            1.00662462e-01, -7.95356855e-02,  5.03704175e-02,\n",
       "            2.03764960e-02],\n",
       "          [-4.22944762e-02, -4.58547100e-02,  6.97943866e-02,\n",
       "           -7.30946362e-02, -1.45391181e-01,  7.38340802e-03,\n",
       "           -2.03544274e-03,  1.98411345e-01,  4.26901914e-02,\n",
       "           -1.31678283e-01],\n",
       "          [-7.15149343e-02, -1.12513982e-01,  1.02087006e-01,\n",
       "           -1.06376559e-01,  1.53624833e-01,  1.52645767e-01,\n",
       "           -3.31143057e-03,  1.18051559e-01, -8.44356567e-02,\n",
       "            2.98468154e-02],\n",
       "          [ 9.04143453e-02, -1.28598571e-01,  3.59382480e-02,\n",
       "           -1.61953479e-01, -9.37252268e-02, -1.16764553e-01,\n",
       "           -1.53854921e-01,  2.68188938e-02, -7.91809037e-02,\n",
       "            1.53061986e-01],\n",
       "          [ 4.44421284e-02,  6.51991963e-02, -1.85128093e-01,\n",
       "            1.44432679e-01, -1.36698723e-01, -9.50672552e-02,\n",
       "            1.74300186e-02,  1.00136586e-01,  3.29212137e-02,\n",
       "           -1.45648435e-01],\n",
       "          [-1.36186898e-01, -1.50406301e-01,  1.90345217e-02,\n",
       "            5.48743531e-02,  2.73896828e-02, -4.92608882e-02,\n",
       "            9.10690147e-03, -1.38297863e-02,  8.93360525e-02,\n",
       "            9.89797935e-02],\n",
       "          [-1.90612599e-02, -3.74721438e-02,  2.32740149e-01,\n",
       "           -1.59774810e-01,  1.01502709e-01,  2.25890294e-01,\n",
       "           -1.21507108e-01,  5.68931960e-02,  6.63412139e-02,\n",
       "            2.05370076e-02],\n",
       "          [ 8.72998834e-02,  3.61935496e-02,  1.79456430e-04,\n",
       "           -1.81920633e-01, -2.79958416e-02, -1.39296325e-02,\n",
       "           -1.79953769e-01,  7.07977265e-02,  2.19890438e-02,\n",
       "           -2.84942761e-02]],\n",
       " \n",
       "         [[ 1.01596676e-01,  3.93851986e-03, -1.43210009e-01,\n",
       "            6.30257353e-02, -2.44287178e-02, -1.38574108e-01,\n",
       "            6.91541210e-02,  4.49186899e-02, -1.91653818e-01,\n",
       "            8.36449191e-02],\n",
       "          [ 1.24641120e-01,  1.01457663e-01, -1.05865046e-01,\n",
       "            2.62778662e-02, -9.23217908e-02,  2.72993334e-02,\n",
       "           -6.63280440e-03,  1.09415159e-01,  6.44654930e-02,\n",
       "           -5.95266782e-02],\n",
       "          [-1.57383785e-01, -7.53770862e-03,  1.20534502e-01,\n",
       "            3.56074460e-02, -1.19481571e-01,  8.19243565e-02,\n",
       "            1.72155857e-01,  1.70612521e-02,  6.02865927e-02,\n",
       "           -2.84028184e-02],\n",
       "          [ 1.81452166e-02, -7.89756700e-02, -6.85189515e-02,\n",
       "            2.98589021e-02,  1.27622470e-01, -2.96098031e-02,\n",
       "            1.49903595e-01, -1.49620384e-01,  5.24331145e-02,\n",
       "            1.77456066e-01],\n",
       "          [-1.00342497e-01,  1.54135093e-01,  2.18511477e-01,\n",
       "            5.91389015e-02,  1.73015326e-01, -1.15863383e-01,\n",
       "           -2.15712711e-01, -8.87726620e-02, -2.15742573e-01,\n",
       "           -6.22709394e-02],\n",
       "          [-8.80780965e-02, -1.48520932e-01, -3.39175873e-02,\n",
       "           -1.47602439e-01, -5.26952147e-02, -1.72419082e-02,\n",
       "           -1.77932322e-01, -1.45525590e-01,  1.47714972e-01,\n",
       "            6.36498109e-02],\n",
       "          [-2.40673404e-02,  1.79054625e-02, -1.14512183e-01,\n",
       "            9.48490016e-03,  6.46733586e-03, -3.94448042e-02,\n",
       "            5.88647686e-02,  2.04063609e-01, -3.25348675e-02,\n",
       "            1.22611679e-01],\n",
       "          [ 7.30698556e-02,  6.16005957e-02,  1.43148992e-02,\n",
       "           -1.83108856e-03, -1.04686283e-01, -9.93366241e-02,\n",
       "           -1.70938119e-01, -1.18930995e-01,  8.71630386e-02,\n",
       "            1.45819291e-01],\n",
       "          [ 4.42778692e-02,  9.28258970e-02,  1.42958211e-02,\n",
       "           -4.03711852e-03,  1.97738279e-02,  2.22641453e-01,\n",
       "           -7.89072886e-02,  1.60942331e-01, -5.63588925e-03,\n",
       "            5.40717579e-02],\n",
       "          [-8.09699073e-02,  2.33436357e-02, -6.38746619e-02,\n",
       "           -1.26720175e-01, -1.62958235e-01,  1.23562165e-01,\n",
       "            9.83533114e-02, -5.56362309e-02, -3.47247906e-02,\n",
       "           -5.98955452e-02]],\n",
       " \n",
       "         [[-8.37513953e-02, -9.82432589e-02,  6.98158219e-02,\n",
       "           -2.25838348e-01,  1.59346953e-01,  3.08765983e-03,\n",
       "            3.75548303e-02, -3.88259068e-02, -1.00911453e-01,\n",
       "           -1.03307657e-01],\n",
       "          [ 1.97575584e-01,  1.60355896e-01,  6.95593730e-02,\n",
       "           -4.14747894e-02, -3.35847326e-02,  3.82494517e-02,\n",
       "            2.49884147e-02, -2.25087963e-02, -2.31039189e-02,\n",
       "           -6.34907633e-02],\n",
       "          [-6.77883029e-02,  1.40978489e-02,  8.33611339e-02,\n",
       "           -8.49131793e-02,  5.40235154e-02,  2.21297175e-01,\n",
       "           -2.03892179e-02,  3.55404876e-02,  6.72701597e-02,\n",
       "            3.10638621e-02],\n",
       "          [ 1.23960897e-01,  8.72278214e-03, -5.74046839e-03,\n",
       "           -7.40369558e-02, -8.00102670e-03, -6.55037165e-02,\n",
       "           -1.79585844e-01,  1.39023392e-02,  2.24092484e-01,\n",
       "           -2.15746667e-02],\n",
       "          [-5.40797412e-02,  5.57266101e-02, -1.52766556e-01,\n",
       "           -1.43109813e-01, -1.50904417e-01,  1.52364790e-01,\n",
       "           -3.03326491e-02,  1.63265839e-02, -9.15180147e-02,\n",
       "            4.28685732e-02],\n",
       "          [-3.24619114e-02, -5.75355161e-03,  5.33844680e-02,\n",
       "           -2.72240937e-02,  1.15254737e-01, -1.07539475e-01,\n",
       "            1.05242670e-01,  2.19424456e-01, -2.09927540e-02,\n",
       "           -1.11736253e-01],\n",
       "          [ 7.27966204e-02, -7.76667073e-02, -8.13511088e-02,\n",
       "            1.46623403e-01, -1.23419903e-01, -1.91197414e-02,\n",
       "            3.72774303e-02, -1.70879792e-02, -1.75712302e-01,\n",
       "           -1.28107116e-01],\n",
       "          [-5.81778549e-02,  7.52703426e-03, -5.36224395e-02,\n",
       "           -1.53226420e-01, -1.76591828e-01,  7.51886219e-02,\n",
       "            1.83194727e-02, -1.66053548e-02,  1.25225857e-01,\n",
       "            7.61967450e-02],\n",
       "          [-6.47076368e-02,  7.81276226e-02,  5.90285659e-02,\n",
       "           -1.03489295e-01,  1.26920745e-01,  3.21165174e-02,\n",
       "            6.91256151e-02,  1.33773923e-01,  1.62373170e-01,\n",
       "           -1.52625337e-01],\n",
       "          [-3.38198338e-03,  9.60136950e-02, -1.03340603e-01,\n",
       "            2.15928163e-02, -1.72715947e-01, -6.54332489e-02,\n",
       "            1.34748304e-02,  1.84389338e-01,  2.14733124e-01,\n",
       "           -1.27636895e-01]]],\n",
       " \n",
       " \n",
       "        [[[-5.72487153e-02, -8.48052278e-02,  3.22265662e-02,\n",
       "           -5.78179918e-02,  1.28101677e-01,  1.58473939e-01,\n",
       "           -7.54220560e-02,  1.32093668e-01,  2.33383805e-01,\n",
       "           -1.15722366e-01],\n",
       "          [-1.02224788e-02, -1.60959110e-01, -2.02564567e-01,\n",
       "            1.11231148e-01,  8.12135357e-03,  4.37409021e-02,\n",
       "           -1.63944885e-02,  3.87283005e-02, -1.03581138e-01,\n",
       "            9.66289192e-02],\n",
       "          [ 1.70913041e-01, -9.86335799e-02, -2.22286731e-01,\n",
       "           -1.93155110e-01,  7.00056106e-02,  9.87530276e-02,\n",
       "           -3.02797779e-02, -3.65099832e-02, -3.35889868e-02,\n",
       "           -1.37804057e-02],\n",
       "          [-1.14387140e-01, -6.47734329e-02, -4.94480133e-03,\n",
       "           -1.34902552e-01,  1.18751340e-01,  9.33219790e-02,\n",
       "           -1.67215541e-01,  2.52969265e-02, -1.24690764e-01,\n",
       "            1.08907409e-01],\n",
       "          [-6.02494143e-02,  4.37940424e-03, -1.16560765e-01,\n",
       "            7.19733490e-03,  2.02703089e-01, -7.45186508e-02,\n",
       "           -1.44066596e-02, -3.16836722e-02,  1.24907687e-01,\n",
       "           -7.63059333e-02],\n",
       "          [-3.83481383e-02, -2.13824064e-02, -2.75953449e-02,\n",
       "            6.84097409e-02, -1.69583216e-01,  5.95436199e-03,\n",
       "           -1.00538835e-01, -1.17597524e-02, -8.25946555e-02,\n",
       "           -1.04783960e-01],\n",
       "          [ 1.03725612e-01,  1.56569656e-03, -8.72428864e-02,\n",
       "           -1.35807589e-01,  3.58727798e-02,  5.36341369e-02,\n",
       "           -5.95963299e-02, -1.02669545e-01, -1.92129537e-02,\n",
       "           -5.29571250e-03],\n",
       "          [ 1.66431412e-01, -8.50443915e-02, -3.68361216e-04,\n",
       "           -1.22271016e-01, -6.22071549e-02,  1.84024990e-01,\n",
       "           -2.06981655e-02,  5.10773808e-02, -1.64195761e-01,\n",
       "           -7.47016212e-03],\n",
       "          [-1.33918226e-01,  8.10595378e-02,  1.91381991e-01,\n",
       "            5.97120337e-02, -1.25407830e-01, -3.39757986e-02,\n",
       "            1.42521173e-01, -2.16524497e-01, -1.72460034e-01,\n",
       "            3.27481590e-02],\n",
       "          [-9.17129964e-02, -1.33029699e-01,  1.40553817e-01,\n",
       "            2.17585359e-02, -2.09670052e-01, -1.32320493e-01,\n",
       "            5.36734015e-02, -6.50676936e-02, -1.29806519e-01,\n",
       "            1.33882836e-01]],\n",
       " \n",
       "         [[ 1.77583709e-01,  7.08102807e-02, -3.56910601e-02,\n",
       "            2.93368306e-02,  1.22254997e-01,  1.12285845e-01,\n",
       "            1.02203555e-01, -9.37266573e-02,  4.18816768e-02,\n",
       "            8.75405744e-02],\n",
       "          [-5.05812056e-02, -4.99347895e-02, -1.37910038e-01,\n",
       "           -1.20067693e-01, -2.29363680e-01,  2.72239074e-02,\n",
       "            1.82496414e-01, -1.11918829e-01,  1.24363698e-01,\n",
       "           -2.42734049e-02],\n",
       "          [-1.51678041e-01, -3.48596200e-02, -8.25854391e-02,\n",
       "            5.61607741e-02,  3.47820632e-02,  1.52223960e-01,\n",
       "            1.13834448e-01,  7.94520974e-03,  1.10888965e-02,\n",
       "           -1.45252571e-01],\n",
       "          [ 1.35262772e-01, -1.50139228e-01,  2.75228396e-02,\n",
       "           -9.38156992e-03, -1.38097093e-01, -3.54256555e-02,\n",
       "            2.03926843e-02,  1.46144882e-01,  3.45589779e-02,\n",
       "            1.09135181e-01],\n",
       "          [-1.84741840e-02,  8.79635215e-02,  2.00954959e-01,\n",
       "           -6.98660091e-02, -1.77546404e-02,  7.23016262e-02,\n",
       "            4.78423573e-02,  4.67819646e-02, -1.49977699e-01,\n",
       "           -1.52793974e-02],\n",
       "          [-1.18439220e-01, -3.81074138e-02, -1.26110688e-01,\n",
       "           -8.90176464e-03, -1.29179403e-01, -2.09559157e-01,\n",
       "           -6.02095723e-02, -6.51390254e-02,  1.00703910e-01,\n",
       "            5.50648421e-02],\n",
       "          [-4.35692780e-02,  1.21340938e-01, -1.78980842e-01,\n",
       "            5.71243614e-02,  1.54734597e-01, -5.60330376e-02,\n",
       "           -2.92591006e-02,  6.46137297e-02,  4.10101824e-02,\n",
       "            1.21786036e-01],\n",
       "          [ 3.55715714e-02, -4.23233472e-02,  7.59725496e-02,\n",
       "            5.39392084e-02, -1.43719777e-01,  1.69608351e-02,\n",
       "           -2.08356440e-01,  1.04784913e-01,  1.04015715e-01,\n",
       "            6.46675229e-02],\n",
       "          [-2.75656898e-02,  1.00417562e-01, -9.97113660e-02,\n",
       "           -9.30047408e-02, -8.76960009e-02,  9.78812352e-02,\n",
       "           -1.82487652e-01,  9.78306960e-03,  6.39280584e-03,\n",
       "           -1.72535109e-03],\n",
       "          [-1.92937572e-02,  7.16361851e-02, -5.94575889e-02,\n",
       "            3.82559486e-02, -1.42993182e-01, -1.46934018e-01,\n",
       "            1.94515109e-01, -1.71059519e-01,  2.74748113e-02,\n",
       "            1.81733117e-01]],\n",
       " \n",
       "         [[ 8.81209504e-04,  4.02738042e-02, -8.63057077e-02,\n",
       "            1.08388431e-01,  1.55251175e-01, -1.16841279e-01,\n",
       "           -1.67092800e-01, -2.98405020e-03, -7.43149966e-02,\n",
       "           -2.19333440e-01],\n",
       "          [-1.61251381e-01,  5.02078272e-02, -8.63676593e-02,\n",
       "           -9.01486054e-02, -6.28710538e-02, -1.87068488e-02,\n",
       "           -4.93947789e-02, -2.34395582e-02, -9.83483046e-02,\n",
       "            1.65921822e-02],\n",
       "          [-7.74485320e-02, -4.57736403e-02, -1.02327608e-01,\n",
       "           -2.31521819e-02, -1.10409766e-01, -1.46637470e-01,\n",
       "           -1.04474314e-02,  2.04918012e-02, -5.89139052e-02,\n",
       "           -3.72169986e-02],\n",
       "          [ 6.97484463e-02,  9.64208320e-02, -1.37324080e-01,\n",
       "           -6.01743609e-02, -1.52207851e-01,  6.03301264e-02,\n",
       "            1.16438670e-02,  1.07263736e-01,  1.98158398e-01,\n",
       "           -3.21472064e-02],\n",
       "          [ 8.53320137e-02, -4.13481966e-02,  2.71352306e-02,\n",
       "           -1.31538287e-01, -7.74883777e-02,  2.63664778e-03,\n",
       "            2.34595202e-02, -1.05661817e-01,  1.67327136e-01,\n",
       "           -1.93270594e-01],\n",
       "          [-4.43720780e-02, -7.14359456e-04, -1.13732196e-01,\n",
       "            8.67425874e-02,  3.29676233e-02,  1.02667540e-01,\n",
       "           -1.29162585e-02, -4.07149680e-02, -1.27355844e-01,\n",
       "           -1.44696552e-02],\n",
       "          [-2.18618557e-01,  1.37471005e-01,  1.70343012e-01,\n",
       "           -1.51689779e-02,  1.86409056e-01,  1.71448976e-01,\n",
       "           -1.54014798e-02, -7.06073865e-02,  1.34535804e-01,\n",
       "            1.65892318e-01],\n",
       "          [ 2.73819696e-02,  1.61369368e-01,  9.99595001e-02,\n",
       "            2.73034461e-02,  7.36600719e-03, -5.33396639e-02,\n",
       "           -3.27817611e-02,  1.06058352e-01, -3.62744331e-02,\n",
       "            6.09628074e-02],\n",
       "          [-8.53351429e-02,  3.21087800e-02,  1.34820491e-01,\n",
       "            4.01169509e-02,  1.72940999e-01, -1.55232772e-01,\n",
       "            2.08530471e-01, -4.83142287e-02,  1.01973787e-01,\n",
       "           -6.35484159e-02],\n",
       "          [ 5.69912456e-02,  2.40827650e-01,  2.71893349e-02,\n",
       "            6.79329410e-02,  6.79738820e-02,  1.00607254e-01,\n",
       "            1.88058652e-02, -1.38892308e-01, -1.58151060e-01,\n",
       "            8.87979269e-02]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_222_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.01038157,  0.01591234, -0.01501723, -0.00158185, -0.00270523,\n",
       "         0.00681001,  0.00779648,  0.01508327, -0.00130156,  0.01191309],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_252_1/gamma:0' shape=(10,) dtype=float32, numpy=\n",
       " array([1.0190768 , 1.0104896 , 0.9892408 , 0.9941015 , 0.9771624 ,\n",
       "        0.99164206, 1.0099045 , 0.9773337 , 1.0104694 , 1.0175258 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_252_1/beta:0' shape=(10,) dtype=float32, numpy=\n",
       " array([-0.01144655, -0.00905783,  0.02508394, -0.02210938, -0.01558204,\n",
       "        -0.0015242 ,  0.00679631,  0.00771992, -0.02037501,  0.01387537],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_91_1/kernel:0' shape=(490, 20) dtype=float32, numpy=\n",
       " array([[-0.01174289, -0.06218738, -0.00271733, ...,  0.01561758,\n",
       "         -0.02404902,  0.00484791],\n",
       "        [ 0.00962214,  0.05815508,  0.02876431, ..., -0.01578763,\n",
       "         -0.01768532, -0.01353296],\n",
       "        [ 0.04160998,  0.05566163, -0.06045888, ..., -0.04044367,\n",
       "          0.02588542,  0.05591514],\n",
       "        ...,\n",
       "        [ 0.09206723, -0.00655904, -0.00282526, ..., -0.06398024,\n",
       "         -0.05080422,  0.06562621],\n",
       "        [ 0.00476659, -0.01276326, -0.06191447, ...,  0.00530164,\n",
       "         -0.03213973, -0.02985386],\n",
       "        [ 0.0200663 ,  0.01595821, -0.06984008, ..., -0.03426492,\n",
       "          0.05033324,  0.0783935 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_91_1/bias:0' shape=(20,) dtype=float32, numpy=\n",
       " array([ 0.005835  , -0.00596507,  0.00147384, -0.00054252, -0.02727936,\n",
       "         0.00847889, -0.00048217, -0.01216589, -0.00139977, -0.00922385,\n",
       "         0.00526728,  0.02018436,  0.00739786,  0.00179655, -0.00392976,\n",
       "        -0.00871166,  0.01200207,  0.01996418, -0.01012331, -0.00982745],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_253_1/gamma:0' shape=(20,) dtype=float32, numpy=\n",
       " array([1.0260072 , 1.0223162 , 1.0300529 , 1.0317101 , 1.0334682 ,\n",
       "        1.020658  , 0.9955607 , 0.98868316, 0.99532115, 1.0237337 ,\n",
       "        1.0348066 , 1.0262543 , 1.0313947 , 1.0356615 , 0.99503124,\n",
       "        1.0198082 , 1.0200044 , 1.0432831 , 1.0317796 , 1.0112538 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_253_1/beta:0' shape=(20,) dtype=float32, numpy=\n",
       " array([-0.04179243, -0.04216946, -0.03859504, -0.04131984, -0.04142517,\n",
       "        -0.04254702, -0.04139746,  0.04165493, -0.040511  ,  0.0378389 ,\n",
       "         0.03711302, -0.04178489,  0.04159493,  0.04190646,  0.0401951 ,\n",
       "        -0.04103273, -0.04173254,  0.04161543, -0.04261713, -0.04052645],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_92_1/kernel:0' shape=(20, 20) dtype=float32, numpy=\n",
       " array([[ 2.99599916e-01, -2.73134381e-01, -4.06697780e-01,\n",
       "          4.72388417e-01, -1.46952599e-01, -1.91827238e-01,\n",
       "          1.74954385e-01, -4.26740080e-01,  6.10167794e-02,\n",
       "         -2.56492108e-01, -4.33208235e-02, -2.69241661e-01,\n",
       "          6.27774596e-02, -4.28875275e-02,  2.99391866e-01,\n",
       "         -2.05162778e-01, -9.27182008e-03, -2.49004960e-01,\n",
       "          4.66867805e-01,  2.16461703e-01],\n",
       "        [ 1.33018151e-01, -3.75863642e-01, -1.80779815e-01,\n",
       "         -3.08480769e-01,  3.36188257e-01,  4.84300591e-02,\n",
       "          2.21055061e-01, -1.21558970e-02,  1.35197369e-02,\n",
       "          2.89225936e-01, -4.06939924e-01,  2.36521006e-01,\n",
       "          4.27917421e-01,  1.02636382e-01,  2.14320898e-01,\n",
       "          3.64725408e-03,  2.90411681e-01,  2.90761665e-02,\n",
       "         -8.30228031e-02,  1.00582838e-03],\n",
       "        [ 3.02828610e-01, -1.06324337e-01,  3.40818077e-01,\n",
       "          2.12999940e-01, -4.16552238e-02,  5.70539124e-02,\n",
       "          6.14924058e-02,  1.05800681e-01, -4.92577255e-02,\n",
       "         -3.12945247e-01, -2.70478964e-01, -2.07692042e-01,\n",
       "          4.00464892e-01, -1.68190166e-01, -6.27418533e-02,\n",
       "         -1.68293640e-01, -4.20632899e-01, -4.07618999e-01,\n",
       "          1.01577364e-01, -8.14381894e-03],\n",
       "        [-3.30091894e-01, -4.51181620e-01, -3.49830091e-01,\n",
       "          1.96558580e-01, -3.66561383e-01, -9.77515951e-02,\n",
       "          3.35935384e-01, -1.63142920e-01,  7.07920864e-02,\n",
       "         -2.03003660e-01, -2.82687843e-01,  1.93242520e-01,\n",
       "          3.32783610e-01, -4.83936481e-02, -3.56034219e-01,\n",
       "          7.43166804e-02, -2.80525178e-01, -3.08047235e-02,\n",
       "          1.14341654e-01,  4.07730550e-01],\n",
       "        [-3.23909432e-01,  1.77694649e-01, -1.35667861e-01,\n",
       "          7.87703544e-02, -2.95743942e-01, -9.72761512e-02,\n",
       "          1.99221820e-01, -6.43795952e-02,  3.69074456e-02,\n",
       "         -3.15872192e-01, -8.80443901e-02, -1.54430106e-01,\n",
       "         -2.26384532e-02, -1.40667766e-01, -2.42293719e-02,\n",
       "         -2.70222217e-01, -2.10120469e-01,  1.45511791e-01,\n",
       "         -1.83593899e-01,  1.34862006e-01],\n",
       "        [ 1.58552695e-02, -1.34397164e-01,  1.86190963e-01,\n",
       "          7.46620819e-02,  4.12022591e-01, -3.22353870e-01,\n",
       "          1.10812582e-01, -3.41550112e-01,  2.06524059e-01,\n",
       "         -6.44949973e-02,  8.51373374e-02, -1.01333268e-01,\n",
       "          1.37194440e-01, -6.66373298e-02, -1.58831552e-01,\n",
       "          4.60253693e-02, -3.79694551e-01, -1.09755762e-01,\n",
       "         -1.83818804e-03,  3.24807823e-01],\n",
       "        [-1.14777729e-01, -1.02372281e-01, -2.57812440e-01,\n",
       "          2.67992914e-01, -3.76671582e-01,  6.18517697e-02,\n",
       "         -2.74833411e-01, -3.92653614e-01, -7.66408145e-02,\n",
       "          1.75409332e-01,  5.64987026e-03,  1.22065477e-01,\n",
       "          1.06465518e-01,  4.64581996e-02, -9.66835991e-02,\n",
       "          1.19479358e-01,  2.77958542e-01, -3.27194333e-01,\n",
       "         -8.12570751e-02, -4.36380366e-03],\n",
       "        [-4.23274487e-01,  3.34854096e-01, -1.51443794e-01,\n",
       "         -2.12288961e-01,  1.90088093e-01,  3.13372426e-02,\n",
       "         -4.60065067e-01,  7.01170489e-02, -4.69130546e-01,\n",
       "         -7.13685900e-02,  1.62651703e-01, -1.13034986e-01,\n",
       "         -2.94327736e-01, -2.41295691e-03,  1.44040622e-02,\n",
       "          2.67078757e-01,  2.09789854e-02,  1.24401778e-01,\n",
       "          2.30498388e-01,  1.88573942e-01],\n",
       "        [-4.62124534e-02,  6.50997981e-02,  1.78328887e-01,\n",
       "          4.91204828e-01, -3.17882717e-01,  4.37086940e-01,\n",
       "          2.74932444e-01,  2.08560318e-01, -2.51891892e-02,\n",
       "         -1.19307354e-01, -2.91085869e-01, -3.66291165e-01,\n",
       "         -2.00023472e-01, -1.58861816e-01,  1.76564101e-02,\n",
       "         -2.70787664e-02,  2.21220292e-02,  3.84220332e-01,\n",
       "          3.32995862e-01,  3.87204856e-01],\n",
       "        [-4.22428280e-01,  7.77456611e-02, -2.48735934e-01,\n",
       "          6.48518503e-02,  1.29164442e-01, -1.08281210e-01,\n",
       "         -1.58385739e-01, -1.35851741e-01, -1.50341354e-02,\n",
       "          1.48870692e-01,  3.28828722e-01,  1.70669094e-01,\n",
       "         -2.90140174e-02, -1.18238561e-01,  6.30835891e-02,\n",
       "          8.50695651e-03,  5.07044941e-02,  4.70533445e-02,\n",
       "         -1.15768760e-01, -3.04502249e-01],\n",
       "        [-1.26281947e-01, -3.57319593e-01,  3.99587929e-01,\n",
       "          3.21240515e-01, -2.32160673e-01,  3.17092389e-01,\n",
       "          1.64929554e-01, -1.68221354e-01, -1.29195139e-01,\n",
       "          4.08921055e-02, -1.02015920e-01,  6.65706694e-02,\n",
       "         -1.45824449e-02,  4.92834091e-01, -8.89570042e-02,\n",
       "         -2.48078108e-01,  2.98042059e-01,  1.06556058e-01,\n",
       "          4.46292102e-01,  6.21193573e-02],\n",
       "        [ 3.23827684e-01, -2.51074910e-01,  3.21160346e-01,\n",
       "         -1.25917301e-01, -1.72094882e-01, -1.34836659e-01,\n",
       "         -9.23023745e-03,  2.66747177e-01,  1.43714786e-01,\n",
       "          1.61287021e-02, -3.66878770e-02,  2.21647248e-01,\n",
       "          1.12739526e-01, -3.12222838e-01,  4.65259671e-01,\n",
       "          3.65342110e-01,  8.79125744e-02,  2.34022960e-01,\n",
       "          1.59147382e-02,  8.87308717e-02],\n",
       "        [ 3.10066760e-01,  1.25016585e-01,  2.43060187e-01,\n",
       "         -1.06794141e-01,  1.11823864e-01,  4.19204295e-01,\n",
       "         -3.95935029e-02,  1.74473196e-01, -1.37178645e-01,\n",
       "         -9.45263579e-02,  3.04615289e-01, -9.39097777e-02,\n",
       "          4.30877507e-02,  2.84977168e-01, -4.90389317e-01,\n",
       "          1.78002879e-01, -2.60390401e-01, -4.36757207e-01,\n",
       "          3.10625851e-01,  3.50128114e-03],\n",
       "        [-2.24359930e-02,  1.97580159e-01, -4.01191145e-01,\n",
       "         -1.60192415e-01, -3.39163363e-01,  5.21971360e-02,\n",
       "         -4.28944200e-01, -4.94456701e-02,  7.81828165e-02,\n",
       "         -7.92436302e-02,  1.52372733e-01, -3.75381321e-01,\n",
       "          4.24793325e-02,  4.05663788e-01, -2.17345104e-01,\n",
       "         -1.64412156e-01,  1.78612843e-01,  2.21970960e-01,\n",
       "          5.77402487e-02,  4.89510037e-02],\n",
       "        [ 8.36248770e-02,  3.12338173e-01,  7.18631595e-02,\n",
       "         -4.62243915e-01, -2.29932904e-01,  1.28200531e-01,\n",
       "         -6.61311448e-02, -2.00959429e-01,  3.77116054e-01,\n",
       "         -2.66955376e-01, -4.90259677e-01,  1.17273875e-01,\n",
       "          1.14477262e-01,  1.26999661e-01, -3.23949844e-01,\n",
       "         -2.26480231e-01, -3.58969420e-01,  1.29982218e-01,\n",
       "          2.38661408e-01,  1.36646762e-01],\n",
       "        [ 2.93212384e-01, -1.81641251e-01, -4.02715832e-01,\n",
       "          3.39606702e-01, -3.31700593e-02, -6.24993667e-02,\n",
       "         -2.77108878e-01,  7.62630533e-03,  1.17902957e-01,\n",
       "          4.93169576e-01, -3.67985547e-01, -2.38725245e-01,\n",
       "          2.68760234e-01, -1.92781344e-01,  8.88125878e-03,\n",
       "          2.40026802e-01,  2.75674164e-01, -7.12501183e-02,\n",
       "          3.18734616e-01,  4.27052081e-01],\n",
       "        [ 1.83172241e-01,  1.79302588e-01, -1.41301066e-01,\n",
       "          1.98317185e-01, -2.70613372e-01, -1.82698503e-01,\n",
       "          3.24099511e-01,  8.61837938e-02,  5.39500453e-03,\n",
       "          3.67110163e-01,  1.38997704e-01, -4.60291088e-01,\n",
       "         -4.63579595e-03,  2.12024242e-01, -2.57564157e-01,\n",
       "          1.03451009e-03,  1.14634059e-01, -1.46756366e-01,\n",
       "          2.10598081e-01, -2.12853588e-03],\n",
       "        [ 2.81699687e-01,  4.44486290e-02,  5.38320243e-01,\n",
       "          8.70354325e-02,  1.61969274e-01,  2.38970667e-01,\n",
       "         -8.01527053e-02,  1.63299501e-01, -2.78860837e-01,\n",
       "          1.24063306e-01,  3.05478007e-01, -1.12916537e-01,\n",
       "         -1.41824126e-01, -2.00520039e-01, -1.82932708e-04,\n",
       "         -2.20972791e-01, -2.47263640e-01, -1.63838327e-01,\n",
       "         -1.18211873e-01, -1.28540605e-01],\n",
       "        [ 1.47211641e-01, -2.96687037e-01,  8.34182650e-02,\n",
       "          3.98750193e-02,  1.60176709e-01, -1.66421175e-01,\n",
       "          1.65672526e-01, -2.36915290e-01, -7.81371370e-02,\n",
       "         -4.31378074e-02,  2.44673520e-01, -3.89729500e-01,\n",
       "          3.65015745e-01, -2.21627980e-01, -3.04115172e-02,\n",
       "         -4.53926474e-02,  1.85000122e-01,  8.84144660e-03,\n",
       "         -1.23869099e-01,  2.94539961e-03],\n",
       "        [-1.68392196e-01,  9.21700597e-02, -1.69607639e-01,\n",
       "          3.28257263e-01, -6.13275319e-02,  2.51490176e-01,\n",
       "          3.49042505e-01,  5.84801193e-03,  1.31148696e-01,\n",
       "          9.43008065e-02,  2.11534873e-01, -1.18140668e-01,\n",
       "         -2.21414223e-01, -3.67708355e-01, -1.90030560e-01,\n",
       "          3.26367654e-03,  2.06575245e-02,  1.57077566e-01,\n",
       "         -7.29260445e-02, -3.35043631e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_92_1/bias:0' shape=(20,) dtype=float32, numpy=\n",
       " array([ 0.04163145,  0.0424313 ,  0.03932239, -0.04048116,  0.04493926,\n",
       "         0.04437481, -0.04125374, -0.03716297, -0.04571662,  0.03248229,\n",
       "         0.04089603,  0.04193347, -0.04243973,  0.04086624, -0.01354346,\n",
       "        -0.04182826, -0.03560619, -0.03794827,  0.02598363, -0.04027464],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_93_1/kernel:0' shape=(20, 1) dtype=float32, numpy=\n",
       " array([[ 0.06549514],\n",
       "        [ 0.06548209],\n",
       "        [ 0.19249259],\n",
       "        [-0.13684149],\n",
       "        [ 0.02536809],\n",
       "        [ 0.02907612],\n",
       "        [-0.09040824],\n",
       "        [-0.02064584],\n",
       "        [-0.03878889],\n",
       "        [-0.00501134],\n",
       "        [ 0.07914264],\n",
       "        [ 0.03651865],\n",
       "        [-0.05365163],\n",
       "        [ 0.08613516],\n",
       "        [-0.01720366],\n",
       "        [-0.0727512 ],\n",
       "        [-0.01283225],\n",
       "        [-0.01932631],\n",
       "        [-0.0084159 ],\n",
       "        [-0.13415384]], dtype=float32)>,\n",
       " <tf.Variable 'dense_93_1/bias:0' shape=(1,) dtype=float32, numpy=array([0.03977264], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_246_1/moving_mean:0' shape=(10,) dtype=float32, numpy=\n",
       " array([-1.9394011e-03,  6.5676626e-03, -3.0744933e-03,  1.6120675e-03,\n",
       "         2.7616338e-03, -4.5280424e-03, -7.2699571e-03,  7.1180140e-05,\n",
       "         2.9944615e-03,  4.5653118e-04], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_246_1/moving_variance:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.66981816, 0.66968334, 0.66985476, 0.66994005, 0.6692672 ,\n",
       "        0.6695408 , 0.6694257 , 0.67015505, 0.66956013, 0.67049336],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_247_1/moving_mean:0' shape=(20,) dtype=float32, numpy=\n",
       " array([ 0.02320888,  0.00119234,  0.01103519, -0.02204275,  0.00114479,\n",
       "         0.01997797, -0.03331695,  0.00912547, -0.01028076,  0.00296711,\n",
       "         0.04372228,  0.04560302, -0.01411749,  0.02751859,  0.00152295,\n",
       "         0.0056313 ,  0.00965947, -0.00943227,  0.04061076,  0.03658664],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_247_1/moving_variance:0' shape=(20,) dtype=float32, numpy=\n",
       " array([0.7941357 , 0.80539536, 0.8162422 , 1.0574975 , 0.7305754 ,\n",
       "        0.8919972 , 0.89699066, 0.8758905 , 0.7930839 , 0.8168984 ,\n",
       "        0.8905547 , 0.92217135, 0.83876693, 0.75957054, 0.7470627 ,\n",
       "        0.81294066, 0.80272686, 0.915586  , 0.8367836 , 0.76386935],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_248_1/moving_mean:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.04688541, -0.00420344,  0.08072429,  0.05427508,  0.07498758,\n",
       "        -0.00758899, -0.0193714 , -0.00884765,  0.03826338,  0.01565486],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_248_1/moving_variance:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.98662394, 1.0902193 , 1.036755  , 0.96188647, 1.075315  ,\n",
       "        1.5192846 , 1.324617  , 0.9831705 , 0.86818933, 1.1354446 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_249_1/moving_mean:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.04117984,  0.06483054,  0.01762968,  0.01609576, -0.00474573,\n",
       "         0.04773308,  0.04909327,  0.04584774,  0.03018713,  0.02709959],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_249_1/moving_variance:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.8711536 , 0.8559602 , 0.8900384 , 2.071681  , 1.5578189 ,\n",
       "        0.8050348 , 0.85339046, 0.8622375 , 0.8862746 , 1.4472008 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_250_1/moving_mean:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.0657252 , 0.04822057, 0.04766611, 0.06729601, 0.04711656,\n",
       "        0.10427711, 0.03294663, 0.05745428, 0.04116364, 0.04767036],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_250_1/moving_variance:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.85310245, 0.7784063 , 0.753104  , 0.84719384, 0.9923937 ,\n",
       "        1.1230441 , 1.2785518 , 0.84159225, 0.89087677, 0.8092762 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_251_1/moving_mean:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.10666236, 0.10472652, 0.12745905, 0.15674022, 0.12762395,\n",
       "        0.11009295, 0.1082961 , 0.1370659 , 0.10480997, 0.10489315],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_251_1/moving_variance:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.8387572 , 0.8790204 , 0.935405  , 1.6025075 , 0.8837194 ,\n",
       "        1.0779358 , 0.9261465 , 1.3497232 , 0.96305126, 0.9070433 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_252_1/moving_mean:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.19127442, 0.2076104 , 0.20707585, 0.18812068, 0.32215562,\n",
       "        0.24842939, 0.18262662, 0.2079789 , 0.2627139 , 0.24776393],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_252_1/moving_variance:0' shape=(10,) dtype=float32, numpy=\n",
       " array([0.8686013 , 1.0528005 , 0.90167344, 0.8127699 , 1.1835014 ,\n",
       "        1.1651387 , 0.8897972 , 0.9255455 , 1.2347124 , 1.5186111 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_253_1/moving_mean:0' shape=(20,) dtype=float32, numpy=\n",
       " array([ 0.03885742, -0.05981798, -0.02331911, -0.04693062,  0.00581599,\n",
       "         0.02036424, -0.00773874,  0.05292863, -0.01915769, -0.017059  ,\n",
       "         0.03897826, -0.02728937, -0.03147633,  0.00087034,  0.00684528,\n",
       "        -0.00420183,  0.05794048,  0.01339531,  0.05333511,  0.03484641],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_253_1/moving_variance:0' shape=(20,) dtype=float32, numpy=\n",
       " array([1.1118042 , 1.0466352 , 1.066351  , 1.082121  , 1.0597026 ,\n",
       "        1.1042202 , 1.0175657 , 1.1365969 , 0.96844643, 1.0403498 ,\n",
       "        1.1054975 , 1.1156838 , 1.0050486 , 1.131593  , 1.0983351 ,\n",
       "        1.1673137 , 1.132628  , 1.041215  , 1.0566562 , 1.1330907 ],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnns[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45693 [00:00<?, ?it/s]\n",
      "  0%|          | 0/43033 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev:  0 , now:  2000 , size 2000\n",
      "[383, 383, 383, 383, 383, 85]\n",
      "Lambda: 0\n",
      "0 383\n",
      "0 0\n",
      "383 766\n",
      "0 0\n",
      "766 1149\n",
      "0 0\n",
      "1149 1532\n",
      "0 0\n",
      "1532 1915\n",
      "0 0\n",
      "1915 2000\n",
      "0 85\n",
      "validating\n",
      "2000 2660\n",
      "Lambda: 0.001\n",
      "0 383\n",
      "0 0\n",
      "383 766\n",
      "0 0\n",
      "766 1149\n",
      "0 0\n",
      "1149 1532\n",
      "0 0\n",
      "1532 1915\n",
      "0 0\n",
      "1915 2000\n",
      "0 85\n",
      "validating\n",
      "2000 2660\n",
      "Test\n",
      "2660 48353\n",
      "prev:  2000 , now:  4000 , size 2000\n",
      "[383, 383, 383, 383, 383, 85]\n",
      "Lambda: 0\n",
      "2000 2383\n",
      "0 0\n",
      "2383 2766\n",
      "0 0\n",
      "2766 3149\n",
      "0 0\n",
      "3149 3532\n",
      "0 0\n",
      "3532 3915\n",
      "0 0\n",
      "3915 4000\n",
      "0 85\n",
      "validating\n",
      "4000 5320\n",
      "Lambda: 0.001\n",
      "2000 2383\n",
      "0 0\n",
      "2383 2766\n",
      "0 0\n",
      "2766 3149\n",
      "0 0\n",
      "3149 3532\n",
      "0 0\n",
      "3532 3915\n",
      "0 0\n",
      "3915 4000\n",
      "0 85\n",
      "validating\n",
      "4000 5320\n",
      "Test\n",
      "5320 48353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CNN: support batching\n",
    "prev_sample = 0\n",
    "# number_samples = [120, 200, 700]\n",
    "lambda_vec = [0, 0.001]  #0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "for cnn in cnns:\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "for number_sample in number_samples:\n",
    "    current_sample = number_sample - prev_sample\n",
    "    print(\"prev: \", prev_sample, \", now: \", number_sample, \", size\", current_sample) \n",
    "    train_samples = [batch_size] * (current_sample//batch_size) + ([current_sample%batch_size] if \n",
    "                                                                    current_sample%batch_size else [])\n",
    "    print(train_samples)\n",
    "    \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb_idx, lamb in enumerate(lambda_vec):\n",
    "        print(\"Lambda:\", lamb)\n",
    "#         cnn = cnn_model(10, lamb, 0)\n",
    "#         cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "        # training on all batches\n",
    "                                    \n",
    "        for i, train_sample in enumerate(train_samples):\n",
    "            for image_num in range(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample):\n",
    "                print(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample)\n",
    "                print((prev_sample + i * batch_size - prev_sample) % batch_size, \n",
    "                      (prev_sample + i * batch_size + train_sample - prev_sample)% batch_size)\n",
    "                break\n",
    "\n",
    "        \n",
    "        # validating\n",
    "        print(\"validating\")\n",
    "        val_size = math.ceil(number_sample * validation_size)\n",
    "        for image_num in range(val_size):\n",
    "            print(number_sample, val_size + number_sample)\n",
    "            break\n",
    "     \n",
    "    print(\"Test\") \n",
    "    \n",
    "    # evaluating test images\n",
    "\n",
    "    \n",
    "    for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "        print(number_sample + val_size, data_reg.shape[0])\n",
    "        break\n",
    "    prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + 'best_cnn_4000samples' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                 dtime + \".dat\", \"wb\") # file for saving results\n",
    "pickle.dump(best_model, file=var_f)\n",
    "var_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:57, 57.66s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [02:23, 143.92s/it]\u001b[A\n",
      "2it [04:46, 143.57s/it]\u001b[A\n",
      "3it [07:09, 143.27s/it]\u001b[A\n",
      "4it [09:32, 143.17s/it]\u001b[A\n",
      "5it [10:23, 124.68s/it]\u001b[A\n",
      " 17%|█▋        | 1/6 [11:23<56:58, 683.79s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.211368327594533\n",
      "Lambda: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:56, 56.09s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [02:19, 139.20s/it]\u001b[A\n",
      "2it [04:38, 139.22s/it]\u001b[A\n",
      "3it [06:57, 139.21s/it]\u001b[A\n",
      "4it [09:18, 139.72s/it]\u001b[A\n",
      "5it [10:08, 121.72s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [22:31<45:15, 678.85s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.379879925942782\n",
      "Lambda: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:58, 58.13s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [02:24, 144.03s/it]\u001b[A\n",
      "2it [04:48, 144.30s/it]\u001b[A\n",
      "3it [07:14, 144.74s/it]\u001b[A\n",
      "4it [09:39, 144.71s/it]\u001b[A\n",
      "5it [10:31, 126.24s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [34:03<34:08, 682.78s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.986079897483191\n",
      "Lambda: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:56, 56.09s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [02:18, 138.72s/it]\u001b[A\n",
      "2it [04:37, 138.66s/it]\u001b[A\n",
      "3it [06:56, 138.75s/it]\u001b[A\n",
      "4it [09:14, 138.70s/it]\u001b[A\n",
      "5it [10:04, 120.90s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [45:06<22:33, 676.92s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.314812567979636\n",
      "Lambda: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:55, 55.93s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [02:18, 138.30s/it]\u001b[A\n",
      "2it [04:36, 138.31s/it]\u001b[A\n",
      "3it [06:54, 138.26s/it]\u001b[A\n",
      "4it [09:12, 138.16s/it]\u001b[A\n",
      "5it [10:02, 120.43s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [56:06<11:12, 672.05s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.257873288155691\n",
      "Lambda: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:56, 56.58s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [02:20, 140.02s/it]\u001b[A\n",
      "2it [04:40, 140.21s/it]\u001b[A\n",
      "3it [07:00, 140.04s/it]\u001b[A\n",
      "4it [09:20, 139.96s/it]\u001b[A\n",
      "5it [10:10, 122.09s/it]\u001b[A\n",
      "100%|██████████| 6/6 [1:07:16<00:00, 672.77s/it]\n",
      "  0%|          | 27/41779 [00:00<02:35, 269.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.043452635827206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41779/41779 [02:38<00:00, 263.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_samples:  2000 , average_error:  6.545  fp_average_error:  3.067\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## use self-training\n",
    "unlabeled_train_samples = [batch_size] * (len(y_test_p)//batch_size) + ([len(y_test_p)%batch_size] if len(y_test_p)%batch_size else [])\n",
    "labeled_train_samples = [batch_size] * (number_sample//batch_size) + ([number_sample%batch_size] if number_sample%batch_size else [])   \n",
    "min_min_error = float('inf')\n",
    "best_best_model, best_best_lam = None, None\n",
    "for lamb in tqdm.tqdm(lambda_vec):\n",
    "    print(\"Lambda:\", lamb)\n",
    "    cnn = cnn_model(10, lamb, 0)\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#     cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "    # training on all batches\n",
    "    # training on all batches\n",
    "    for i, train_sample in tqdm.tqdm(enumerate(labeled_train_samples)):\n",
    "        x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "        y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "        for image_num in range(i * batch_size, i * batch_size + train_sample):\n",
    "            x_train[image_num % batch_size] = read_image(image_num)\n",
    "            y_train[image_num % batch_size] = np.asarray(data_reg[image_num][-1], dtype=float_memory_used)\n",
    "        cnn.fit(x_train, y_train, epochs=6, verbose=0, batch_size=1, validation_split=0.0)\n",
    "        del x_train, y_train\n",
    "            \n",
    "    for i, train_sample in tqdm.tqdm(enumerate(unlabeled_train_samples)):\n",
    "        x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "        y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "        for image_num in range(i * batch_size + number_sample + val_size, i * batch_size + number_sample + val_size + train_sample):\n",
    "            x_train[(image_num-number_sample - val_size) % batch_size] = read_image(image_num)\n",
    "            y_train[(image_num-number_sample - val_size) % batch_size] = np.asarray(y_test_p[image_num-(number_sample + val_size)], dtype=float_memory_used)\n",
    "        cnn.fit(x_train, y_train, epochs=3, verbose=0, batch_size=1, validation_split=0.0)\n",
    "        del x_train, y_train\n",
    "        \n",
    "    # validating\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "    val_mae, val_fp_mae = 0.0, 0.0\n",
    "    for image_num in range(val_size):\n",
    "        val_y = data_reg[image_num + number_sample][-1]\n",
    "        image = read_image(image_num + number_sample)\n",
    "        val_yp = cnn.predict(image)[0][0]\n",
    "        val_mae += abs(val_y - val_yp)\n",
    "        if val_yp > val_y:\n",
    "            val_fp_mae += abs(val_yp - val_y)\n",
    "    val_mae /= val_size\n",
    "    val_fp_mae /= val_size\n",
    "    print(val_mae)\n",
    "    if val_mae < min_min_error:\n",
    "        min_min_error = val_mae\n",
    "        best_best_model = cnn\n",
    "        best_best_lam = lamb\n",
    "    sum_mae, sum_fp_mae = 0, 0\n",
    "    test_size = 0\n",
    "    \n",
    "for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "    test_size += 1\n",
    "    test_image = read_image(test_num)\n",
    "    test_y = data_reg[test_num][-1]\n",
    "    test_yp = best_best_model.predict(test_image)[0][0]\n",
    "#     y_test_p[test_num - (number_sample + val_size)] = test_yp\n",
    "    sum_mae += abs(test_yp - test_y)\n",
    "    if test_yp > test_y:\n",
    "        sum_fp_mae += abs(test_yp - test_y)\n",
    "fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "print('number_samples: ', number_sample, ', average_error: ', average_diff_power[-1], ' fp_average_error: ', \n",
    "      fp_mean_power[-1])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6.285, 6.366, 6.45, 6.454, 6.382, 6.26, 6.49, 6.224, 6.052, 5.87, 4.915, 4.836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "prev_sample = 0\n",
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1]\n",
    "max_train_samples = math.ceil(number_samples[-1] * (1 + validation_size))\n",
    "x_train = np.empty((max_train_samples, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "# x_train1 = np.empty((max_train_samples, 1, max_x, max_y), dtype=float_memory_used)\n",
    "# x_train2 = np.empty((max_train_samples, 1, max_x, max_y), dtype=float_memory_used)\n",
    "y_train = np.empty((max_train_samples), dtype=float_memory_used)\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "for number_sample in number_samples:\n",
    "    sample = math.ceil(number_sample * (1 + validation_size))\n",
    "    for image_num in range(prev_sample, sample):\n",
    "        prev_sample = sample\n",
    "        if style == \"image_intensity\":\n",
    "            image = plt.imread(image_dir + '/image' + str(image_num)+'.png')\n",
    "            image = np.swapaxes(image, 0, 2)\n",
    "            x_train[image_num] = np.array(image[:number_image_channels], dtype=float_memory_used).reshape(1, number_image_channels, max_x, max_y)\n",
    "            del image\n",
    "        elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "            x_train[image_num] = np.load(image_dir + '/image' + str(image_num)+'.npy')\n",
    "#             image = np.load(image_dir + '/image' + str(image_num)+'.npy')\n",
    "#             x_train1[image_num][0] = image[0][0]\n",
    "#             x_train2[image_num][0] = image[0][1]\n",
    "        y_train[image_num] = np.asarray(data_reg[image_num][-1], dtype=float_memory_used)\n",
    "        if image_num + 1 % 100 == 0:\n",
    "            print(image_num)\n",
    "#     cnn = cnn_model(7, 0, 0)\n",
    "#     cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#     cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "#             (validation_size + 1))\n",
    "    \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb in lambda_vec:\n",
    "        print(\"Lambda:\", lamb)\n",
    "        cnn = cnn_model(10, lamb, 0)\n",
    "        cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#         cnn.fit([x_train1[:sample], x_train2[:sample]], y_train[:sample], epochs=6, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "#                 (validation_size + 1))\n",
    "        cnn.fit(x_train[:sample], y_train[:sample], epochs=6, verbose=0, batch_size=1, validation_split=validation_size/\n",
    "                (validation_size + 1))\n",
    "        if cnn.history.history['val_mean_absolute_error'][-1] < min_error:\n",
    "            min_error = cnn.history.history['val_mean_absolute_error'][-1]\n",
    "            best_model = cnn\n",
    "            best_lam = lamb\n",
    "    print(\"best_lambda, \", best_lam, \"min_error\", min_error)    \n",
    "    # evaluating test images\n",
    "    sum_mae, sum_fp_mae = 0, 0\n",
    "    test_size = 0\n",
    "#     for test_num in range(max_train_samples, data_reg.shape[0]):\n",
    "    for test_num in range(sample, data_reg.shape[0]):\n",
    "        test_size += 1\n",
    "        if style == \"image_intensity\":\n",
    "            test_image = plt.imread(image_dir + '/image' + str(test_num) + '.png')\n",
    "            test_image = np.swapaxes(test_image, 0, 2)\n",
    "            test_image = np.array(test_image[:number_image_channels]).reshape(1, number_image_channels, max_x, max_y)\n",
    "        elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "            test_image = np.load(image_dir + '/image' + str(test_num)+'.npy')\n",
    "        test_y = data_reg[test_num][-1]\n",
    "        test_yp = best_model.predict(test_image)[0][0]\n",
    "        sum_mae += abs(test_yp - test_y)\n",
    "        if test_yp > test_y:\n",
    "            sum_fp_mae += abs(test_yp - test_y)\n",
    "        if test_num % 500 == 0:\n",
    "            print('test: ', test_num)\n",
    "    fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "    average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "    print('number_samples: ', number_sample, ', average_error: ', average_diff_power[-1], ' fp_average_error: ', fp_mean_power[-1])\n",
    "    print(\"\\n\")\n",
    "    var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + dtime + \".dat\", \"wb\") # file for saving results\n",
    "    pickle.dump([average_diff_power, fp_mean_power, number_samples], file=var_f)\n",
    "    var_f.close()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power[8], average_diff_power[9] = average_diff_power[9], average_diff_power[8]\n",
    "# fp_mean_power = fp_mean_power[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapee = Input(shape=(number_image_channels, max_x, max_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapee[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(1, 0)\n",
    "cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnn.history.history['val_mean_absolute_error'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(10, 0, 0)\n",
    "cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "            (validation_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3]\n",
    "min_error = float('inf')\n",
    "best_model, best_lam = None, None\n",
    "for lamb in lambda_vec:\n",
    "    print(\"Lambda:\", lamb)\n",
    "    cnn = cnn_model(15, lamb, 0)\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "    cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "            (validation_size + 1))\n",
    "    if cnn.history.history['val_mean_absolute_error'][-1] < min_error:\n",
    "        min_error = cnn.history.history['val_mean_absolute_error'][-1]\n",
    "        best_model = cnn\n",
    "        best_lam = lamb\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_lam)\n",
    "print(best_model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just run to dispaly the image. First change return line from create_image\n",
    "aa = np.swapaxes(np.append(np.array(x_train[50]), np.zeros((2,max_x, max_y), dtype=float_memory_used), axis=0), 0, 2)\n",
    "plt.imshow(aa)\n",
    "# plt.imsave('image.png', aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to read saved variables\n",
    "var_ff = open('ML/data/pictures_1000_1000/log_201912_0705_37.txt', 'rb')\n",
    "[average_diff_power_1, fp_mean_power_1, number_samples_1] = pickle.load(var_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_mean_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power[-1]*(data_reg.shape[0] - max_train_samples)/(300-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_fp_mae/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_mean_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pydotplus\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "keras.utils.vis_utils.pydot = pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARALLEL CNN\n",
    "def cnn_model(num_filters, kernel_lam, bias_lam):\n",
    "#     num_filters, lam = 5, 5\n",
    "    data_format = 'channels_first'\n",
    "    convolution_filter, dense_filter = 'selu', 'linear' #softsign, sigmoid; relu, linear\n",
    "    filter_shape, pool_size = (3, 3), (2,2)\n",
    "    # CNN for PU image\n",
    "    input1  = layers.Input(shape=(number_image_channels - 1, max_x, max_y), name='pus_input')\n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(input1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    \n",
    "    # CNN for SU\n",
    "    input2  = layers.Input(shape=(1, max_x, max_y), name='su_input')\n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(input2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    \n",
    "    # concatanate two CNN outputs\n",
    "    x = layers.concatenate([x1, x2])\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    x = layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    out = layers.Dense(1, activation=dense_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    \n",
    "    model = models.Model(inputs=[input1, input2], outputs=out)\n",
    "#     plot_model(model, to_file='model.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'square'\n",
    "# style = \"image_intensity\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# average_diff_power = [9.110476626067186, 21.070721128267266, 9.389938883165568, 10.886098907990405,\n",
    "#                                        7.697396928362106, 7.522477509027216, 9.493729427772132, 8.198866980620753,\n",
    "#                                        7.781910785203122, 9.41743984825801, 8.499455442627129, 9.86776958065812,\n",
    "#                                        9.033719411254367, 8.150143941293027, 8.963829050517273, 8.708150642874065,\n",
    "#                                        7.468060397898071, 8.233182799553932,8.206, 7.768]\n",
    "# fp_mean_power =  [8.174990557021465, 0.18043087058937837, 1.5141939559853392, 10.273307557711494,\n",
    "#                                    3.2306742061521443, 4.423113329284006, 8.674172526579392, 2.38235061342411,\n",
    "#                                    5.014172646429496, 6.884079514994618, 3.4544130456368367, 7.81721202679044,\n",
    "#                                    6.438635364829745, 4.069245107144559, 5.202978504937615, 3.405858414831347,\n",
    "#                                    4.117573271657338, 2.8100743146184377, 3.951, 3.502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAX_POWER ANAlysis\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# pu_shape, su_shape = 'circle', 'circle'\n",
    "# style = \"image_intensity\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# test_size = 3670\n",
    "# average_diff_power = [7.811849328268183, 9.178415418536536, 8.11891504382307, 7.881934146750136, 7.918868224324312,\n",
    "#                       7.709452054502398, 7.471729821563216, 8.63783455122861, 7.7635068514166345, 8.557134470036884,\n",
    "#                       8.103793715416188, 9.189284948409279, 11.977416480154307, 8.291134394492891, 8.960065032512803,\n",
    "#                       9.992745143323642, 8.475335283779392, 8.051642160173987, 7.322538645284376, 7.768582958795206]\n",
    "# fp_mean_power = [6.1844398077234635, 1.6157812496465958, 6.5620574110067595, 2.898169187355567, 6.262096880097353,\n",
    "#                  2.5478307871639267, 3.5784209073932067, 7.416731632966506, 5.5822838290638135, 5.800529848947965,\n",
    "#                  4.6984887763519785, 2.337296353076653, 9.85739104089764, 3.710259461284922, 5.323224159423669, \n",
    "#                  6.198328912769283, 2.302462751745074, 4.023802978234984, 3.781413967880959, 3.2793608103510508]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle'\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# num_pus = 15\n",
    "average_diff_power = [9.711, 7.867, 8.958, 7.571, 7.509, 7.891, 8.272, 7.118, 7.696, 7.689, 8.026, 9.674, 7.51, 7.771, 8.17,\n",
    "                      7.938, 7.869, 7.833, 9.434, 8.501]\n",
    "fp_mean_power = [9.229, 5.101, 8.037, 3.993, 5.095, 2.491, 2.298, 4.654, 3.787, 2.685, 5.676, 8.033, 3.911, 4.235, 3.278,\n",
    "                 5.809, 3.586, 4.257, 4.377, 5.015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "\n",
    "# number_samples = [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 8001, 1000))\n",
    "\n",
    "\n",
    "# cnn_type = \"classification\"  # {\"classification\", \"regression\"}\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 200, 200, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# else:\n",
    "#     su_param = None\n",
    "# sensors = False\n",
    "# if sensors:\n",
    "#     sensors_num = 50\n",
    "#     sensors_file_path = \"rsc/\" + str(sensors_num) + \"/sensors\"\n",
    "    \n",
    "average_diff_power = [6.779, 5.645, 5.473, 4.982, 4.481, 4.071, 4.05, 3.639, 2.813, 2.343, 2.21, 2.372, 2.005, 1.997,\n",
    "                      1.937, 1.901]\n",
    "\n",
    "fp_mean_power = [4.073, 2.409, 3.424, 3.163, 2.833, 2.663, 2.857, 2.744, 1.744, 1.33, 1.184, 1.55, 0.579, 1.216, 1.492, 1.266]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "\n",
    "number_samples = [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 6001, 1000)) + [8000]\n",
    "# dataframe = pd.read_csv('ML/data/dynamic_pus_using_pus50000_15PUs_201912_3000_40_200.txt', delimiter=',', header=None)\n",
    "# dataframe_max = pd.read_csv('ML/data/dynamic_pus_max_power50000_15PUs_201912_3000_40_200.txt', delimiter=',', header=None)\n",
    "\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 200, 200, 4, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 5\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# else:\n",
    "#     su_param = None\n",
    "# sensors = False\n",
    "    \n",
    "average_diff_power = [12.742, 12.906, 12.731, 12.595, 12.859, 13.272, 12.632, 12.647, 11.309, 7.455, 7.131, 5.677,\n",
    "                      5.645, 5.292, 4.445]\n",
    "\n",
    "fp_mean_power = [5.963, 5.861, 8.957, 8.821, 8.215, 9.518, 8.633, 6.644, 6.605, 3.919, 2.539, 3.866, 1.96, 2.717, 1.671]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_diff_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_width = 5\n",
    "marker_size = 12\n",
    "reg_style = 'solid'\n",
    "class_reg = 'dashed'\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, average_diff_power, color='r', linewidth=line_width, markersize=marker_size, linestyle=class_reg)\n",
    "plt.plot(number_samples, fp_mean_power, color='midnightblue', linewidth=line_width, markersize=marker_size, linestyle=class_reg)\n",
    "plt.xlabel('# of Training Samples', fontsize=47)\n",
    "plt.ylabel('Avg. Diff. wrt Opt. (dB)', fontsize=45)\n",
    "plt.title('Dynamic PUs(200m*200m)')\n",
    "plt.grid(True)\n",
    "\n",
    "ax.set_yticks(np.arange(0,14, 2))\n",
    "# ax.set_xticks(np.arange(100,7000, 1500))\n",
    "plt.rcParams.update({'font.size': 42})\n",
    "ax.tick_params(axis='x', labelsize=46)\n",
    "ax.tick_params(axis='y', labelsize=45)\n",
    "\n",
    "# matplotlib.rcParams.update({'font.size': 22})\n",
    "\n",
    "ax.set_ylim([0, 14])\n",
    "ax.set_xlim([0, 8000])\n",
    "plt.legend(['Total', 'False-Positive'], ncol=2, loc='best', handletextpad=0.1,borderpad=0, columnspacing=0.2, borderaxespad=0.2)\n",
    "# plt.legend(handletextpad=0.1)\n",
    "plt.savefig('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + dtime + \".png\", \n",
    "            bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(image_dir + '/image10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/'.join(image_dir.split('/')[:-1]) + '/log_5__202001_1519_01.dat', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/home/shahrokh/projects/research/MLSpectrumAllocation/ML/data/pictures_1000_1000/log/noisy_std_1/' +\n",
    "            'pu_circle_su_circle_30/raw_power_min_max_norm/color/log_3/900sensors/log_3__202003_2919_03.dat', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "[average1,fp1, samples1] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2048, 4096]\n",
      "[6.988, 6.984]\n",
      "[4.007, 4.434]\n"
     ]
    }
   ],
   "source": [
    "print(samples1)\n",
    "print(average1)\n",
    "print(fp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fp1, fp2, fp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples1, samples2, samples3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
