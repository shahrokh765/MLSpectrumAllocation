{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "Point = namedtuple('Point', ('x', 'y'))\n",
    "Circle = namedtuple('Circle', ('r'))\n",
    "Square = namedtuple('Square', ('side'))\n",
    "Rectangle = namedtuple('Rectangle', ('length', 'width'))\n",
    "PointWithDistance = namedtuple('PointWithDistance', ('p', 'dist'))\n",
    "float_memory_used = 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "dataframe = pd.read_csv('ML/data/dynamic_pus_using_pus50000_15PUs_201912_0623_57.txt', delimiter=',', header=None)\n",
    "dataframe_max = pd.read_csv('ML/data/dynamic_pus_max_power50000_15PUs_201912_0623_57.txt', delimiter=',', header=None)\n",
    "\n",
    "dataframe.reset_index(drop=True, inplace=True)\n",
    "dataframe_max.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dataframe_tot = pd.concat([dataframe, dataframe_max.iloc[:, dataframe_max.columns.values[-1]]], axis=1,\n",
    "                        ignore_index=True)\n",
    "idx = dataframe_tot[dataframe_tot[dataframe_tot.columns[-1]] == -float('inf')].index\n",
    "dataframe_tot.drop(idx, inplace=True)\n",
    "\n",
    "data_reg = np.concatenate((dataframe_tot.values[:, 0:dataframe_tot.shape[1]-3], \n",
    "                           dataframe_tot.values[:, dataframe_tot.shape[1]-1:dataframe_tot.shape[1]]), axis=1)\n",
    "data_class = dataframe_tot.values[:, 0:dataframe_tot.shape[1]-1]\n",
    "y_class_power = dataframe_tot.values[:, -1]\n",
    "del dataframe, dataframe_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "number_samples = [150]\n",
    "\n",
    "validation_size, noise_floor = 0.33, -90.0\n",
    "su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "max_x, max_y, number_image_channels, su_szie = 1000, 1000, 1, 10\n",
    "pu_shape, su_shape = 'circle', 'square'\n",
    "pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "if su_shape == 'circle':\n",
    "    su_param = Circle(su_szie)\n",
    "elif su_shape == 'square':\n",
    "    su_param = Square(su_szie)\n",
    "num_pus = (data_reg.shape[1] - 3)//3\n",
    "dtime = datetime.datetime.now().strftime('_%Y%m_%d%H_%M')\n",
    "color = \"color\" if number_image_channels > 1 else \"grey\"\n",
    "image_dir = 'ML/data/pictures_' + str(max_x) + '_' + str(max_y) + '/pu_' + pu_shape + '_su_' + su_shape + '_' + str(\n",
    "    su_szie) + \"/\" + color +'/' + intensity_degradation + '_' + str(slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(p1: Point, p2: Point):\n",
    "    return ((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2) ** 0.5\n",
    "\n",
    "def calculate_mu_sigma(data, num_pus):\n",
    "    sum_non_noise = 0\n",
    "    for pu_n in range(num_pus): # calculate mu\n",
    "        sum_non_noise += data[pu_n*3+2]\n",
    "    mu = ((max_x * max_y - num_pus) * noise_floor + sum_non_noise)/(max_x * max_y)\n",
    "    sum_square = 0\n",
    "    for pu_n in range(num_pus): # calculate sigma\n",
    "        sum_square += (data[pu_n*3+2]-mu)**2\n",
    "    sum_square += (max_x * max_y - num_pus) * (noise_floor - mu)**2\n",
    "    sigma = math.sqrt(sum_square/(max_x * max_y))\n",
    "    return mu, sigma\n",
    "\n",
    "def create_image(data, pus_num, slope, style=\"raw_power_z_score\", noise_floor=-90, pu_shape= 'circle', pu_param=None, \n",
    "                 su_shape='circle', su_param=None, intensity_degradation=\"log\"):  \n",
    "    # style = {\"raw_power_z_score\", \"image_intensity\"}\n",
    "    # intensity_degradation= {\"log\", \"linear\"}\n",
    "    # if param is None, it's automatically calculated. Highest brightness(or power value) (255 or 1.) would\n",
    "    # assigned to the center(PU location) and radius(side) would be calculated based on its power, slope, and noise floor.\n",
    "    # If it is given, intensity(power) of pixel beside center would be calculated in the same fashin with an exception that \n",
    "    # intensity below zero(noise_floor) would be replaced by zero(noise_floor)\n",
    "    if style == \"raw_power_z_score\":\n",
    "        pass\n",
    "        # In this way, PUs' location are replaced with their power(dBm) and the power would fade with \n",
    "        # slope till gets noise_floor(in circle shape)\n",
    "#         pu_image = [[(noise_floor - mu)/sigma] * max_y for _ in range(max_x)]\n",
    "    elif style == \"image_intensity\":\n",
    "        # creating PU image\n",
    "        image = np.zeros((1,number_image_channels,max_x, max_y), dtype=float_memory_used)\n",
    "        for pu_i in range(pus_num):\n",
    "            pu_x, pu_y, pu_p = max(0, min(max_x-1, int(data[pu_i*3]))), max(0, min(max_x-1, int(data[pu_i*3+1]))), data[pu_i*3+2]\n",
    "            if pu_param is None:\n",
    "                if pu_shape == 'circle':\n",
    "                    if intensity_degradation == \"linear\":\n",
    "                        pu_param = Circle(math.ceil((pu_p - noise_floor) / slope)) # linear\n",
    "                    elif intensity_degradation == \"log\":\n",
    "                        pu_param = Circle(math.ceil(10 ** ((pu_p - noise_floor) / (10 *slope)))) # log_based\n",
    "                elif pu_shape == 'square':\n",
    "                    if intensity_degradation == \"linear\":\n",
    "                        pu_param = Square(math.ceil(2 ** 0.5 * (pu_p - noise_floor) / slope)) # linear\n",
    "                    elif intensity_degradation == \"log\":\n",
    "                        pu_param = Square(math.ceil(2 ** 0.5 * 10 ** ((pu_p - noise_floor) / (10 *slope)))) # log_based\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported PU shape(create_image)! \", pu_shape)\n",
    "            points = points_inside_shape(center=Point(pu_x, pu_y), shape=pu_shape, param=pu_param)\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if intensity_degradation == \"linear\":\n",
    "                        image[0][0][point.p.x][point.p.y] += max((pu_p - slope * point.dist + abs(noise_floor))\n",
    "                                                              /(pu_p + abs(noise_floor)), 0)\n",
    "                    elif intensity_degradation == \"log\":\n",
    "                        if point.dist < 1:\n",
    "                            image[0][0][point.p.x][point.p.y] = 1\n",
    "                        else:\n",
    "                            image[0][0][point.p.x][point.p.y] += max((pu_p - slope * 10*math.log10(point.dist) + abs(noise_floor))\n",
    "                                                                 /(pu_p + abs(noise_floor)), 0)\n",
    "                    image[0][0][point.p.x][point.p.y] = min(image[0][0][point.p.x][point.p.y], 1.0)\n",
    "                        \n",
    "        # creating SU image\n",
    "        su_num = (len(data) - pus_num * 3) // 2\n",
    "        if not (len(data) - pus_num * 3) % 2:\n",
    "            raise ValueError(\"Data provided is not correct; can't get SUs' information(create_image)\")\n",
    "#         su_image = np.zeros((max_x, max_y), dtype=float_memory_used)\n",
    "        if su_param is None:\n",
    "            # if su_param is unavailable, a circle(square) with radius(side) 1 is created\n",
    "            if su_shape == 'circle':\n",
    "                su_param = Circle(1)\n",
    "            elif su_shape == 'square':\n",
    "                su_param = Square(1)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported SU shape(create_image)! \", su_shape)\n",
    "        su_intensity = 1.\n",
    "        for su_i in range(su_num):\n",
    "            su_x, su_y, su_p = max(0, min(max_x-1, int(data[pus_num*3+su_i*2]))\n",
    "                                  ), max(0, min(max_x-1, int(data[pus_num*3+su_i*2+1]))), su_intensity\n",
    "            points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if number_image_channels > 1:\n",
    "                        image[0][1][point.p.x][point.p.y] = su_intensity\n",
    "                    elif number_image_channels == 1:\n",
    "                        image[0][0][point.p.x][point.p.y] = su_intensity\n",
    "#         return np.array([pu_image, su_image, [[0.] * max_y for _ in range(max_x)]], dtype='float32') # return like this to be able to display as an RGB image with pyplot.imshow(imsave)\n",
    "#         return np.append(pu_image, su_image, axis=0)\n",
    "        return image\n",
    "        \n",
    "            \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported style(create_image)! \", style)\n",
    "        \n",
    "def points_inside_shape(center: Point, shape: str, param)-> list:\n",
    "    # This function returns points+distance around center with defined shape\n",
    "    if shape == 'circle':\n",
    "        # First creates points inside a square(around orgigin) with 2*r side and then remove those with distance > r.\n",
    "        # Shift all remaining around center. O(4r^2)\n",
    "        r, origin = param.r, Point(0, 0)\n",
    "        square_points = set([Point(x, y) for x in range(-r, r+1) for y in range(-r, r+1)])\n",
    "        points = []\n",
    "        while square_points:\n",
    "            p = square_points.pop()\n",
    "            dist = euclidian_distance(p, origin)\n",
    "            if dist <= r:\n",
    "                points.append(PointWithDistance(Point(p.x + center.x, p.y + center.y), dist))\n",
    "                if p.x != 0:\n",
    "                    points.append(PointWithDistance(Point(-p.x + center.x, p.y + center.y), dist))\n",
    "                    square_points.remove(Point(-p.x, p.y))\n",
    "                if p.y != 0:\n",
    "                    points.append(PointWithDistance(Point(p.x + center.x, -p.y + center.y), dist))\n",
    "                    square_points.remove(Point(p.x, -p.y))\n",
    "                if p.x != 0 and p.y != 0:\n",
    "                    points.append(PointWithDistance(Point(-p.x + center.x, -p.y + center.y), dist))\n",
    "                    square_points.remove(Point(-p.x, -p.y))\n",
    "        return points\n",
    "    elif shape == 'square':\n",
    "        half_side = param.side // 2\n",
    "        return [PointWithDistance(Point(x, y), euclidian_distance(Point(x, y), center)) for x in range(-half_side + center.x,\n",
    "                                                                                               half_side + center.x+1) \n",
    "                         for y in range(-half_side + center.y, half_side + center.y + 1)]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported shape(points_inside_shape)! \", shape)\n",
    "    \n",
    "# TODO: Consider using min_max normalization becasue difference between values using\n",
    "# z-score is huge since most of the pixels have the same value, noise floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving images once to save time\n",
    "# run this cell just for creating images\n",
    "if not os.path.exists(image_dir):\n",
    "    os.makedirs(image_dir)\n",
    "# for image_num in range(115, data_reg.shape[0]):\n",
    "for image_num in range(0, 500):\n",
    "    image = create_image(data=data_reg[image_num], slope=slope, style=\"image_intensity\", noise_floor=noise_floor,\n",
    "                         pu_shape=pu_shape, su_shape=su_shape, su_param=su_param, pus_num=pus_num, \n",
    "                         intensity_degradation=intensity_degradation)\n",
    "    if number_image_channels != 3:\n",
    "        image = np.append(np.array(image[0]), np.zeros((3-number_image_channels,max_x, max_y), \n",
    "                                                       dtype=float_memory_used), axis=0)\n",
    "    image_save = np.swapaxes(image, 0, 2)\n",
    "    plt.imsave(image_dir + '/image' + str(image_num)+'.png', image_save)\n",
    "    if image_num + 1 % 100 == 0:\n",
    "        print(image_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO, CNN Model here\n",
    "def cnn_model(num_filters, lam):\n",
    "#     num_filters, lam = 5, 5\n",
    "    data_format = 'channels_first'\n",
    "    convolution_filter, dense_filter = 'relu', 'linear' #softsign, sigmoid; relu, linear\n",
    "    filter_shape, pool_size = (10, 10), (3,3)\n",
    "    cnn = models.Sequential()\n",
    "    cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels, max_x, max_y), data_format=data_format, \n",
    "                          kernel_regularizer=regularizers.l2(lam), bias_regularizer=regularizers.l2(lam)))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size=pool_size, data_format=data_format))\n",
    "    cnn.add(layers.Conv2D(num_filters, filter_shape,padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(lam), bias_regularizer=regularizers.l2(lam)))\n",
    "    cnn.add(layers.MaxPool2D(pool_size=pool_size, data_format=data_format))\n",
    "#     cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "#                          kernel_regularizer=regularizers.l2(lam), bias_regularizer=regularizers.l2(lam)))\n",
    "#     cnn.add(layers.MaxPool2D(pool_size, data_format=data_format))\n",
    "#     cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "#                          kernel_regularizer=regularizers.l2(lam), bias_regularizer=regularizers.l2(lam)))\n",
    "#     cnn.add(layers.MaxPool2D(pool_size, data_format=data_format))\n",
    "#     cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format))\n",
    "#     cnn.add(layers.MaxPool2D(pool_size, data_format=data_format))\n",
    "    cnn.add(layers.Flatten())\n",
    "    # cnn.add(layers.Dense(5, activation=dense_filter))\n",
    "    cnn.add(layers.Dense(1, activation=dense_filter, kernel_regularizer=regularizers.l2(lam),\n",
    "                         bias_regularizer=regularizers.l2(lam)))\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_111 (Conv2D)          (None, 5, 1000, 1000)     505       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_111 (MaxPoolin (None, 5, 333, 333)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 5, 333, 333)       2505      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_112 (MaxPoolin (None, 5, 111, 111)       0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 61605)             0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 61606     \n",
      "=================================================================\n",
      "Total params: 64,616\n",
      "Trainable params: 64,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 134 samples, validate on 66 samples\n",
      "Epoch 1/5\n",
      "134/134 [==============================] - 74s 554ms/step - loss: 266.4205 - mean_squared_error: 256.5165 - mean_absolute_error: 12.9741 - val_loss: 96.6204 - val_mean_squared_error: 85.7242 - val_mean_absolute_error: 7.4998\n",
      "Epoch 2/5\n",
      "134/134 [==============================] - 72s 540ms/step - loss: 117.6809 - mean_squared_error: 106.7643 - mean_absolute_error: 7.8762 - val_loss: 92.1600 - val_mean_squared_error: 81.6229 - val_mean_absolute_error: 7.0769\n",
      "Epoch 3/5\n",
      "134/134 [==============================] - 71s 527ms/step - loss: 93.0819 - mean_squared_error: 82.5056 - mean_absolute_error: 7.0081 - val_loss: 127.2116 - val_mean_squared_error: 116.3379 - val_mean_absolute_error: 8.6044\n",
      "Epoch 4/5\n",
      "134/134 [==============================] - 71s 527ms/step - loss: 73.5808 - mean_squared_error: 61.8423 - mean_absolute_error: 6.1326 - val_loss: 141.0335 - val_mean_squared_error: 129.0991 - val_mean_absolute_error: 8.9377\n",
      "Epoch 5/5\n",
      " 16/134 [==>...........................] - ETA: 1:00 - loss: 45.5688 - mean_squared_error: 33.3611 - mean_absolute_error: 5.0398"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-823882101514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# evaluating test images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "# prev_sample = 0\n",
    "# max_train_samples = math.ceil(number_samples[-1] * (1 + validation_size))\n",
    "# x_train = np.empty((max_train_samples, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "# y_train = np.empty((max_train_samples), dtype=float_memory_used)\n",
    "# average_diff_power, fp_mean_power = [], []\n",
    "for number_sample in number_samples:\n",
    "    sample = math.ceil(number_sample * (1 + validation_size))\n",
    "    for image_num in range(prev_sample, sample):\n",
    "        prev_sample = sample\n",
    "        image = plt.imread(image_dir + '/image' + str(image_num)+'.png')\n",
    "        image = np.swapaxes(image, 0, 2)\n",
    "        x_train[image_num] = np.array(image[:number_image_channels], dtype=float_memory_used).reshape(1, number_image_channels, max_x, max_y)\n",
    "        y_train[image_num] = np.asarray(data_reg[image_num][-1], dtype=float_memory_used)\n",
    "        del image\n",
    "        if image_num + 1 % 100 == 0:\n",
    "            print(image_num)\n",
    "    cnn = cnn_model(5, 1)\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "    cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size)\n",
    "    \n",
    "    # evaluating test images\n",
    "    sum_mae, sum_fp_mae = 0, 0\n",
    "    test_size = 0\n",
    "#     for test_num in range(max_train_samples, data_reg.shape[0]):\n",
    "    for test_num in range(sample, 500):\n",
    "        test_size += 1\n",
    "        test_image = plt.imread(image_dir + '/image' + str(test_num) + '.png')\n",
    "        test_image = np.swapaxes(test_image, 0, 2)\n",
    "        test_image = np.array(test_image[:number_image_channels]).reshape(1, number_image_channels, max_x, max_y)\n",
    "        test_y = data_reg[test_num][-1]\n",
    "        test_yp = cnn.predict(test_image)[0][0]\n",
    "        sum_mae += abs(test_yp - test_y)\n",
    "        if test_yp > test_y:\n",
    "            sum_fp_mae += abs(test_yp - test_y)\n",
    "        if test_num % 500 == 0:\n",
    "            print('test: ', test_num)\n",
    "    fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "    average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "    print('number_samples: ', number_sample, ', average_error: ', average_diff_power[-1], ' fp_average_error: ', fp_mean_power[-1])\n",
    "    \n",
    "#     var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + dtime + \".dat\", \"wb\") # file for saving results\n",
    "#     pickle.dump([average_diff_power, fp_mean_power, number_samples], file=var_f)\n",
    "#     var_f.close()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f787e3de400>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just run to dispaly the image. First change return line from create_image\n",
    "aa = np.swapaxes(np.append(np.array(x_train[50]), np.zeros((2,max_x, max_y), dtype=float_memory_used), axis=0), 0, 2)\n",
    "plt.imshow(aa)\n",
    "# plt.imsave('image.png', aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to read saved variables\n",
    "var_ff = open('ML/data/pictures_1000_1000/log_201912_0705_37.txt', 'rb')\n",
    "[average_diff_power_1, fp_mean_power_1, number_samples_1] = pickle.load(var_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_mean_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power[-1]*(data_reg.shape[0] - max_train_samples)/(300-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_fp_mae/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_mean_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'square'\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# average_diff_power = [9.110476626067186, 21.070721128267266, 9.389938883165568, 10.886098907990405,\n",
    "#                                        7.697396928362106, 7.522477509027216, 9.493729427772132, 8.198866980620753,\n",
    "#                                        7.781910785203122, 9.41743984825801, 8.499455442627129, 9.86776958065812,\n",
    "#                                        9.033719411254367, 8.150143941293027, 8.963829050517273, 8.708150642874065,\n",
    "#                                        7.468060397898071, 8.233182799553932,8.206, 7.768]\n",
    "# fp_mean_power =  [8.174990557021465, 0.18043087058937837, 1.5141939559853392, 10.273307557711494,\n",
    "#                                    3.2306742061521443, 4.423113329284006, 8.674172526579392, 2.38235061342411,\n",
    "#                                    5.014172646429496, 6.884079514994618, 3.4544130456368367, 7.81721202679044,\n",
    "#                                    6.438635364829745, 4.069245107144559, 5.202978504937615, 3.405858414831347,\n",
    "#                                    4.117573271657338, 2.8100743146184377, 3.951, 3.502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAX_POWER ANAlysis\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# pu_shape, su_shape = 'circle', 'circle'\n",
    "# test_size = 3670\n",
    "# average_diff_power = [7.811849328268183, 9.178415418536536, 8.11891504382307, 7.881934146750136, 7.918868224324312,\n",
    "#                       7.709452054502398, 7.471729821563216, 8.63783455122861, 7.7635068514166345, 8.557134470036884,\n",
    "#                       8.103793715416188, 9.189284948409279, 11.977416480154307, 8.291134394492891, 8.960065032512803,\n",
    "#                       9.992745143323642, 8.475335283779392, 8.051642160173987, 7.322538645284376, 7.768582958795206]\n",
    "# fp_mean_power = [6.1844398077234635, 1.6157812496465958, 6.5620574110067595, 2.898169187355567, 6.262096880097353,\n",
    "#                  2.5478307871639267, 3.5784209073932067, 7.416731632966506, 5.5822838290638135, 5.800529848947965,\n",
    "#                  4.6984887763519785, 2.337296353076653, 9.85739104089764, 3.710259461284922, 5.323224159423669, \n",
    "#                  6.198328912769283, 2.302462751745074, 4.023802978234984, 3.781413967880959, 3.2793608103510508]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_width = 5\n",
    "marker_size = 12\n",
    "reg_style = 'solid'\n",
    "class_reg = 'dashed'\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, average_diff_power, color='r', linewidth=line_width, markersize=marker_size, linestyle=class_reg)\n",
    "plt.plot(number_samples, fp_mean_power, color='midnightblue', linewidth=line_width, markersize=marker_size, linestyle=class_reg)\n",
    "plt.xlabel('# of Training Samples', fontsize=47)\n",
    "plt.ylabel('Avg. Diff. wrt Opt. (dB)', fontsize=45)\n",
    "# plt.title('Mean Power Error(Static PUs)')\n",
    "plt.grid(True)\n",
    "\n",
    "ax.set_yticks(np.arange(0,20, 2))\n",
    "plt.rcParams.update({'font.size': 42})\n",
    "ax.tick_params(axis='x', labelsize=46)\n",
    "ax.tick_params(axis='y', labelsize=45)\n",
    "\n",
    "# matplotlib.rcParams.update({'font.size': 22})\n",
    "\n",
    "ax.set_ylim([1, 20])\n",
    "ax.set_xlim([0, 1000])\n",
    "plt.legend(['Total', 'False-Positive'], ncol=2, loc='best', handletextpad=0.1,borderpad=0, columnspacing=0.2, borderaxespad=0.2)\n",
    "# plt.legend(handletextpad=0.1)\n",
    "plt.savefig('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + dtime + \".png\", \n",
    "            bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
